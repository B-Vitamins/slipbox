:PROPERTIES:
:ID:       c5c49d66-52e9-4586-a0c6-d4bd9aa2e460
:END:
#+TITLE: Solutions to Principles of Quantum Mechanics by Ramamurthy Shankar
#+FILETAGS: :pqm:problems:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org
#+BEGIN: clocktable :maxlevel 2 :scope nil :emphasize nil
#+CAPTION: Clock summary at [2024-11-02 Sat 23:07]
| Headline                                    |     Time |       |
|---------------------------------------------+----------+-------|
| *Total time*                                | *213:23* |       |
|---------------------------------------------+----------+-------|
| Mathematical Introduction                   |     6:54 |       |
| Simple Problems in One Dimension            |     2:42 |       |
| Systems with N Degrees of Freedom           |    19:00 |       |
| \_  Notes                                   |          |  6:44 |
| \_  Problem 10.1.1                          |          |  0:50 |
| \_  Problem 10.1.2                          |          |  0:19 |
| \_  Problem 10.1.3                          |          |  1:34 |
| \_  Problem 10.2.1                          |          |  0:09 |
| \_  Problem 10.2.2                          |          |  0:51 |
| \_  Problem 10.2.3                          |          |  0:52 |
| \_  Problem 10.3.1                          |          |  0:33 |
| \_  Problem 10.3.2                          |          |  0:08 |
| \_  Problem 10.3.3                          |          |  0:16 |
| \_  Problem 10.3.4                          |          |  0:14 |
| \_  Problem 10.3.5                          |          |  1:47 |
| \_  Problem 10.3.6                          |          |  0:44 |
| Symmetries and Their Consequences           |     6:02 |       |
| \_  Notes                                   |          |  2:35 |
| \_  Problem 11.2.1                          |          |  0:38 |
| \_  Problem 11.2.2                          |          |  0:04 |
| \_  Problem 11.2.3                          |          |  0:41 |
| \_  Problem 11.4.1                          |          |  0:20 |
| \_  Problem 11.4.2                          |          |  0:23 |
| \_  Problem 11.4.3                          |          |  0:22 |
| \_  Problem 11.4.4                          |          |  0:27 |
| Rotational Invariance and Angular...        |    88:10 |       |
| \_  Notes                                   |          |  9:39 |
| \_  Problem 12.1.1                          |          |  0:11 |
| \_  Problem 12.2.1                          |          |  0:18 |
| \_  Problem 12.2.2                          |          |  4:19 |
| \_  Problem 12.2.3                          |          |  1:13 |
| \_  Problem 12.2.4                          |          |  3:28 |
| \_  Problem 12.3.2                          |          |  1:02 |
| \_  Problem 12.3.3                          |          |  2:26 |
| \_  Problem 12.3.4                          |          |  0:18 |
| \_  Problem 12.3.5                          |          |  0:35 |
| \_  Problem 12.3.6                          |          |  0:31 |
| \_  Problem 12.3.7                          |          |  6:58 |
| \_  Problem 12.3.8                          |          |  9:56 |
| \_  Problem 12.4.1                          |          |  0:53 |
| \_  Problem 12.4.2                          |          |  1:41 |
| \_  Problem 12.4.3                          |          |  0:52 |
| \_  Problem 12.4.4                          |          |  0:41 |
| \_  Problem 12.5.1                          |          |  1:21 |
| \_  Problem 12.5.2                          |          |  2:17 |
| \_  Problem 12.5.3                          |          |  1:47 |
| \_  Problem 12.5.4                          |          |  1:42 |
| \_  Problem 12.5.5                          |          |  4:41 |
| \_  Problem 12.5.6                          |          |  2:32 |
| \_  Problem 12.5.7 Euler Angles             |          |  3:09 |
| \_  Problem 12.5.8                          |          |  2:10 |
| \_  Problem 12.5.9                          |          |  3:48 |
| \_  Problem 12.5.10                         |          |  1:23 |
| \_  Problem 12.5.11                         |          |  1:31 |
| \_  Problem 12.5.12                         |          |  1:55 |
| \_  Problem 12.5.13                         |          |  0:08 |
| \_  Problem 12.5.14                         |          |  1:14 |
| \_  Problem 12.6.1                          |          |  1:29 |
| \_  Problem 12.6.2                          |          |  4:50 |
| \_  Problem 12.6.3                          |          |  2:03 |
| \_  Problem 12.6.4                          |          |  0:59 |
| \_  Problem 12.6.5                          |          |  1:08 |
| \_  Problem 12.6.6                          |          |  0:25 |
| \_  Problem 12.6.7                          |          |  0:18 |
| \_  Problem 12.6.8                          |          |  0:29 |
| \_  Problem 12.6.9                          |          |  1:18 |
| \_  Problem 12.6.10                         |          |  0:11 |
| The Hydrogen Atom                           |    15:38 |       |
| \_  Notes                                   |          |  3:05 |
| \_  Problem 13.1.1                          |          |  0:42 |
| \_  Problem 13.1.3                          |          |  1:33 |
| \_  Problem 13.1.4                          |          |  0:23 |
| \_  Problem 13.1.5 Virial Theorem           |          |  4:02 |
| \_  Problem 13.2.1                          |          |  2:17 |
| \_  Problem 13.3.1                          |          |  0:36 |
| \_  Problem 13.3.2                          |          |  0:15 |
| \_  Problem 13.3.3                          |          |  0:44 |
| \_  Problem 13.4.1                          |          |  0:21 |
| \_  Problem 13.4.2                          |          |  1:06 |
| \_  Problem 13.4.3                          |          |  0:10 |
| Spin                                        |    38:51 |       |
| \_  Notes                                   |          |  4:28 |
| \_  Problem 14.3.1                          |          |  0:40 |
| \_  Problem 14.3.2                          |          |  1:44 |
| \_  Problem 14.3.3                          |          |  0:12 |
| \_  Problem 14.3.4                          |          |  4:44 |
| \_  Problem 14.3.5                          |          |  0:15 |
| \_  Problem 14.3.6                          |          |  0:47 |
| \_  Problem 14.3.7                          |          |  1:41 |
| \_  Problem 14.3.8                          |          |  2:08 |
| \_  Problem 14.4.1                          |          |  1:29 |
| \_  Problem 14.4.2                          |          |  0:53 |
| \_  Problem 14.4.3                          |          |  7:53 |
| \_  Problem 14.4.4                          |          |  0:38 |
| \_  Problem 14.4.5                          |          |  2:33 |
| \_  Problem 14.4.6 A Density Matrix Problem |          |  1:42 |
| \_  Problem 14.5.1                          |          |  0:17 |
| \_  Problem 14.5.2                          |          |  1:30 |
| \_  Problem 14.5.3                          |          |  2:19 |
| \_  Problem 14.5.4                          |          |  2:34 |
| Addition of Angular Momenta                 |    19:31 |       |
| \_  Notes                                   |          | 17:41 |
| \_  Problem 15.1.1                          |          |  1:44 |
| Time-Independent Perturbation Theory        |    16:35 |       |
| \_  Notes                                   |          |  1:58 |
| \_  Problem 17.2.1                          |          |  1:03 |
| \_  Problem 17.2.2                          |          |  1:04 |
| \_  Problem 17.2.3                          |          |  3:29 |
| \_  Problem 17.2.4                          |          |  1:28 |
| \_  Problem 17.2.5                          |          |  1:13 |
| \_  Problem 17.3.1                          |          |  0:44 |
| \_  Problem 17.3.2                          |          |  0:59 |
#+END:
* Mathematical Introduction
CLOSED: [2022-11-13 Sun 20:05]
:LOGBOOK:
CLOCK: [2022-11-16 Wed 20:55]--[2022-11-16 Wed 23:32] =>  2:37
CLOCK: [2022-11-16 Wed 14:28]--[2022-11-16 Wed 18:04] =>  3:36
CLOCK: [2022-11-16 Wed 18:05]--[2022-11-16 Wed 18:46]  =>  0:41
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-16 Wed 19:42]--[2022-11-16 Wed 19:42] =>  0:00
:END:
#+NAME: Vector Space

#+ATTR_LATEX: :environment definition
#+BEGIN_definition
Let \(\mathbb{V} = \left \lbrace \vert 1 \rangle , \thinspace \vert 2 \rangle , \thinspace \dotso, \thinspace \vert V \rangle, \thinspace \vert W \rangle, \dotso \right \rbrace\) be a set of elements. Let \(\mathbb{F}\) be a /field/ over scalars, \(B_{1}\) and \(B_{2}\) be two binary operations defined on the elements of \(\mathbb{V}\) such that:

\[B_{1}: \mathbb{V} \times \mathbb{V} \to \mathbb{V}\]
\[B_{2}: \mathbb{F} \times \mathbb{V} \to \mathbb{V}\]

\(\mathbb{V}\) called a /vector space/, and the elements called /vectors/ if: 

+ \(B_{2}\) is /associative/, /distributive in scalars/, /distributive in vectors/,
+ \(B_{1}\) is /associative/ and /commutative/
+ There is a /null vector/ \(\vert 0 \rangle\) in \(\mathbb{V}\) that satisfies

  \[ \vert V \rangle + \vert 0 \rangle = \vert V \rangle,\]
+ For every vector \(\vert V \rangle\), there exists an /inverse under addition/ \(\vert - V \rangle\) such that

  \[\vert V \rangle + \vert - V \rangle = \vert 0 \rangle\].
#+END_definition

#+NAME: Field
#+ATTR_LATEX: :environment definition
#+begin_definition latex
The numbers \(a\), \(b\), \(\dotso\), are called the /field/ over which the vector space is defined.
#+end_definition

#+NAME: Linear Independence
#+ATTR_LATEX: :environment definition
#+begin_definition latex
A set of vectors is called linearly independent /iff/:
\begin{align*}
\sum_{i=1}^{n} a_{i} \vert i \rangle = 0 \Longrightarrow a_{i} = 0 \quad \text{for all} \quad i.
\end{align*}
#+end_definition

#+NAME: Dimensionality
#+ATTR_LATEX: :environment definition
#+begin_definition latex
A vector space has dimensions \(n\) if it can accomodale a maximum of \(n\) linearly independent vectors. When such a vector space is defined over the field of real numbers it is denoted by \(\mathbb{V}^n(R)\). When it is defined over the field of complex numbers it is denoted by \(\mathbb{V}^{n}(C)\).
#+end_definition

#+NAME: Span
#+ATTR_LATEX: :environment definition
#+begin_theorem latex
Any \(|v\rangle \in V^n\) may be written as a linear combination of \(n\) linearly independent vectors \(\{11\rangle, \ldots,|n\rangle\}\).
#+end_theorem

#+NAME: Basis
#+ATTR_LATEX: :environment definition
#+begin_definition latex
A set of \(n\) linearly independent vectors in an n-dimensional vector space is called a /basis/.

\(|v\rangle=\sum_{i=1}^n v_i|i\rangle\)

where \(\left \lbrace \vert 1 \rangle, \vert 2 \rangle, \dotso, \vert n \rangle  \right \rbrace\) form a /basis/.
#+end_definition

#+NAME: Components of a Vector
#+ATTR_LATEX: :environment definition
#+begin_definition latex
The coefficients of expansion \(v_i\) of a vector in terms of a linearly independent basis \(\{|i\rangle\}\) are called the components of the vector in that basis.
#+end_definition

#+NAME: Uniqueness of Vector Expansion
#+ATTR_LATEX: :environment definition
#+begin_theorem latex
The expansion of a vector \(|v\rangle\), in a given basis \(\{ \vert i\rangle\}\), with the coefficients \(\left\{v_i\right\}\) is unique.
#+end_theorem

\begin{align*}
&|V\rangle=\sum v_i|i\rangle, \quad
|W\rangle=\sum \omega_i|i\rangle, \quad |V\rangle+|W\rangle=\sum\left(v_i+w_i\right)|i\rangle
\end{align*}

\begin{align*}
|V\rangle=\sum v_i|i\rangle, \quad a|V\rangle=\sum a v_i|i\rangle.
\end{align*}

#+NAME: Inner Product
#+ATTR_LATEX: :environment definition
#+begin_definition latex
The inner-product between two vectors \(|V\rangle\) and \(|W\rangle\), denoted is \(\langle V \mid W\rangle\) is a number complex in general) that has the properties:
(a) \(\langle V \mid W\rangle=\langle W \mid V\rangle^*\) (Skew-symmetry)
(b) \(\langle V \mid V\rangle \geqslant 0,\langle V \mid V\rangle= 0 \Longleftrightarrow \vert V\rangle= \vert 0\rangle\) (Positive semi-definiteness)
(c) \(\langle V|(a|W\rangle+b|Z\rangle) \equiv\langle V \mid a W+b Z\rangle=a\langle V \mid W\rangle+b\langle V \mid Z\rangle\) (Linearity in ket)
#+end_definition

Skew-symmetry implies /anti-linearity of the inner product in bras/.

\(\langle a W+b Z \mid V\rangle=a^*\langle W \mid V\rangle+b^*\langle Z \mid V\rangle\)

#+NAME: Orthogonality
#+ATTR_LATEX: :environment definition
#+begin_definition
\(|V\rangle\) and \(|W\rangle\) are called orthogonal (to each other) iff \(\langle V \mid W\rangle=0\).
#+end_definition

#+NAME: Norm
#+begin_definition latex
Given vector \(|V\rangle, \sqrt{\langle V \mid V\rangle} \equiv|V|\) is called its norm. A normalized vector has unit norm.
#+end_definition

#+NAME: Orthonormal Basis
#+begin_definition latex
A set of normalized basis vectors, that are pair-wise orthogonal are said to form an orthonormal basis.
#+end_definition

Given two vectors \(|V\rangle\) and \(|W\rangle\) expanded in two different basis \(\{|i\rangle\}\) and \(\{\vert j\rangle\}\), their inner product is given as \(\langle V \mid W \rangle=\sum_i \sum_j v_i^* w_j\langle i \mid j\rangle\).

For every ket \(|V\rangle\), there exists a bra, denoted by \(\langle V|\). The bra is the Ket's /adjoint/ (transpose-conjugate). /Bras and Kets reside in distinct vector spaces/. Formally, the inner product is a /bilinear map/ - a machine that tokes vectors from two distinct vector spaces - the space of the kets and a /dual space/ of bras - and spits out a number.

\begin{equation*}
|V\rangle \leftrightarrow\left[\begin{array}{c}
v_1 \\
\vdots \\
v_n
\end{array}\right] \leftrightarrow\left[v_1^*, \ldots, v_n^*\right] \leftrightarrow\langle V|
\end{equation*}

Expanding two vectors in a common orthonormal basis simplifies the inner product:

\begin{align*}
\langle V \mid W \rangle=\sum_i \sum_j v_i^* w_j \underbrace{ \langle i \vert j \rangle}_{\equiv\delta_{ij}} &=\sum_i v_i^* w_i\langle i \mid i\rangle =\sum_i v_i^* w_i.
\end{align*}

Expanding a vector in an orthonormal basis simplifies finding the coefficients:

\begin{align*}
| V \rangle =\sum_i v_i | i\rangle, \quad \langle j \mid V \rangle=\sum_i v_i \underbrace{\langle j \mid i\rangle}_{\equiv \delta_{j i}}=v_j \Longrightarrow \vert V\rangle =\sum_i | i\rangle \langle i \mid V \rangle.
\end{align*}

#+NAME: Gram-Schmidt
#+begin_theorem latex
Any basis \(\{\vert i\rangle\}\) can be converted into an orthonormal basis. An orthonormal basis has the property:

\begin{align*}
\langle i \mid j\rangle= \delta_{ij} \equiv \begin{cases}1, & i=j \\ 0, & i \neq j\end{cases}.
\end{align*}

Here \(\delta_{ij}\) is the /Kronecker delta/.

Let \(|I\rangle\), \(\vert II \rangle\), \(\dotso\) be a /linearly independent basis/. The orthonormal basis \(|1\rangle,|2\rangle, \ldots\) is:

\(|1\rangle=|I\rangle /|I|\)

\(\vert 2 \rangle = \vert 2^{\prime} \rangle / \lvert 2^{\prime} \rvert, \quad \vert 2^{\prime} \rangle = \vert II \rangle - \vert 1 \rangle \langle 1 \mid II \rangle\)

\(\vert 3 \rangle= \vert 3^{\prime}\rangle / \lvert 3^{\prime} \rvert, \quad  \vert 3^{\prime} \rangle= \vert III \rangle - \vert 2 \rangle \langle 2 \mid III \rangle - |1 \rangle \langle 1 \mid III \rangle\)

Linear independence of \(\{ \vert I \rangle, \vert II \rangle, \dotso \}\) guarantees /completion of the orthogonalization/.
#+end_theorem

#+NAME: Dimensionality
#+begin_theorem latex
The dimensionality of a space equals \(n_{\perp}\), the maximum number of mutually or thogonds vectors in it.
#+end_theorem

#+NAME: Schwarz Inequality
#+begin_theorem latex
\begin{align*}
|\langle V \mid W\rangle| \leqslant|V||W|.
\end{align*}
#+end_theorem

#+NAME: Triangle Inequality
#+begin_theorem latex
\begin{align*}
\vert V+W \vert \leq |V|+|W|.
\end{align*}
#+end_theorem

#+NAME: Subspace
#+begin_definition latex
Given a vector space \(\mathbb{V}\), a subset of its elements that form a vector space among themselves is called a /subspace/. The \(i^{\text {th }}\) subspace with dimensionality \(n_i\) is denoted as \(\mathbb{V}_i^{n_{i}}\).
#+end_definition

#+NAME: Sum of Vector (sub) Spaces
#+begin_definition latex
Given two subspaces \(\mathbb{V}_i^{n_i}, \mathbb{V}_j^{m_j}\), the sum, denoted as

\(\mathbb{V}_{i}^{n_i} \oplus \mathbb{V}_{j}^{m_j} \equiv \mathbb{V}_{k}^{o_{k}}\)

is the set containing:

(1) all elements of \(\mathbb{V}_i^{n_i}\)

(2) all elements of \(\mathbb{V}_j^{m_j}\)

(3) all possible linear combinations of the above.
#+end_definition

#+NAME: Linear Operator
#+begin_definition latex
An linear operator is a function from one vector space to another; a mapping between vectors.

\(\Omega: \mathbb{V} \rightarrow \mathbb{W}, \quad \Omega | V \rangle = | W \rangle\).
#+end_definition

A linear operafor satisfying closure has the following properties:

\(\Omega: \mathbb{V} \rightarrow \mathbb{V}, \quad \Omega| V \rangle=\left|V^{\prime}\right\rangle\)

+ \(\Omega \alpha\left|V_i\right\rangle=\alpha \Omega\left|V_i\right\rangle\)
  
+ \(\Omega\left(\alpha\left|V_i\right\rangle+\beta\left|V_j\right\rangle\right)=\alpha \Omega\left|V_i\right\rangle+\beta \Omega\left|V_j\right\rangle\)
  
+ \(\left\langle V_i\right| \alpha \Omega=\left\langle V_i\right| \Omega \alpha\)
  
+ \(\left(\left\langle V_i\right| \alpha+\left\langle V_j\right| \beta\right) \Omega=\alpha\left\langle V_i\right| \Omega+\beta\left\langle V_j\right| \Omega\)
  
+ \(\Omega|V\rangle=\Omega\left(\sum_i v_i|i\rangle\right)=\sum_i v_i \Omega|i\rangle=\sum_i v_i\left|i^{\prime}\right\rangle\)

#+NAME: Commutator
#+begin_definition latex
\([\Omega, \Lambda] \equiv \Omega \Lambda-\Lambda \Omega\) is called the commutator of \(\Omega\) and \(\Lambda\).
#+end_definition

The commutator satisfies the identities:

\begin{align*}
&{[\Omega, \Lambda \theta]=\Lambda[\Omega, \theta]+[\Omega, \Lambda] \theta} \\
\end{align*}

\begin{align*}
&{[\Lambda \Omega, \theta]=\Lambda[\Omega, \theta]+[\Lambda, \theta] \Omega}
\end{align*}

#+NAME: Identity Operator
#+begin_definition latex
\(I\) is the identity operator, a machine that returns the same vector it took.
#+end_definition

#+NAME: Inverse of an Operator
#+begin_definition latex
The inverse of a operator \(\Omega\), denoted by \(\Omega^{-1}\), by definition, satisfies:

\begin{align*}
\Omega \Omega^{-1}=\Omega^{-1} \Omega=I.
\end{align*}

#+end_definition

In general, the existence of the inverse is not guaranteed.

The inverse of a product of operators is given as:

\begin{align*}
(\Omega \Lambda)^{-1}=\Lambda^{-1} \Omega^{-1}.
\end{align*}

#+NAME: Matrix Elements of an Operator
#+begin_definition latex
In a given basis \(\{|i\rangle\}\) for \(\mathbb{V}^n\), an operator is represented as a matrix. The \(i j^{\text{th}}\) element of this matrix is

\begin{align*}
\Omega_{i j}=\langle i|\Omega| j\rangle.
\end{align*}

The \(n^2\) numbers, \(\Omega_{i j}\), are the /matrix elements/ of \(\Omega\) in this basis.
#+end_definition

\begin{align*}
|V\rangle=\sum_i v_i|i\rangle, \quad \Omega|V\rangle=\left|V^{\prime}\right\rangle, \quad
\left|V^{\prime}\right\rangle=\sum_i v_i^{\prime}|i\rangle, \quad v_i^{\prime}=\sum_j \Omega_{i j} v_j
\end{align*}

#+NAME: Projection Operator
#+begin_definition latex
The projection operator for ket \(\vert i \rangle\) is defined as:

\begin{align*}
\mathbb{P}_i=|i\rangle\langle i|, \quad\left(\mathbb{P}_i\right)_{k l}=\langle k \mid i\rangle\langle i \mid \ell\rangle=\delta_{k i} \delta_{i l}.
\end{align*}
#+end_definition

#+NAME: Completeness Relation
#+begin_definition latex
The identity operator may be expressed as a sum over projection operators. It is called the completeness relation.
\begin{align*}
I=\sum_{i=1}^n|i\rangle\langle i|=\sum_{i=1}^n \mathbb{P}_i.
\end{align*}
#+end_definition

The action of projection operator on bras and kets is:

\begin{align*}
\mathbb{P}_i|v\rangle=|i\rangle\left\langle i\left|\sum_{j=1}^n v_j\right| j\right\rangle=\sum_{j=1}^n v_j|i\rangle\langle i \mid j\rangle=\sum_{j=1}^n v_j|i\rangle \delta_{i j}=v_i|i\rangle,
\end{align*}

\begin{align*}
\left\langle v\left|\mathbb{P}_i=\sum_{j=1}^n v_j^*\right| j\right\rangle^*|i\rangle\langle i|=\sum_{j=1}^n v_j^*\langle i|\langle j \mid i\rangle=\sum_{j=1}^n v_j^*\langle i| \delta_{j i}=v_i^*\langle i|.
\end{align*}

Projection operators have the property:

\begin{align*}
\mathbb{P}_i \mathbb{P}_j=|i\rangle\langle i \mid j\rangle\langle j|=\delta_{i j} \mathbb{P}_j.
\end{align*}

#+NAME: Outer Product
#+begin_definition latex
The object \(|V\rangle\left\langle V^{\prime}\right|\) is called the outer product of \(|V\rangle\) and \(\langle V^{\prime} \vert\). It is a linear operator. If \(| V \rangle \in \mathbb{V}^{n}\), then the matrix representation of \(|V\rangle\langle V^{\prime}|\) has \(n^2\) elements.
#+end_definition

#+NAME: Adjoint of an Operator
#+begin_definition latex
An operator acting on a ket has a corresponding operator that acts on the bras, called its adjoint

\begin{align*}
\Omega|V\rangle=|\Omega V\rangle=\left|V^{\prime}\right\rangle, \quad\left\langle V^{\prime}\right|=\langle\Omega V|=\langle V| \Omega^{\dagger}
\end{align*}

\begin{align*}
\left(\Omega^{\dagger}\right)_{i j}=\left\langle i\left|\Omega^{\dagger}\right| j\right\rangle=\langle\Omega i \mid j\rangle=\langle j \mid \Omega i\rangle^*=\langle j|\Omega | i\rangle^{\ast} =\left(\Omega_{j i}^{\ast}\right).
\end{align*}
#+end_definition

The adjoint of a product is the product of the adjoint in reverse:

\begin{align*}
(\Omega \Lambda)^{\dagger} = \Lambda^{\dagger} \Omega^{\dagger}.
\end{align*}

*To take the adjoint of an equation consisting of kets, scalars, and operators, reverse the order of all factors and make the substitutions*

\begin{align*}
\left.\Omega \leftrightarrow \Omega^{\dagger}, \quad | \rangle \leftrightarrow \langle |, \quad \alpha \leftrightarrow \alpha^{\ast}.
\end{align*}

Example: The adjoint of

\begin{align*}
&\alpha_1\left|V_1\right\rangle=\alpha_2\left|V_2\right\rangle+\alpha_3\left|V_3\right\rangle\left\langle V_4 | V_5\right\rangle+\alpha_4 \Omega \Lambda \left| V_6 \right\rangle \\
\end{align*}

is

\begin{align*}
\left\langle V_1\right| \alpha_1^{*} = \left\langle V_{2} \right| \alpha_2^{*} + \left\langle V_{5} | V_4\right\rangle\left\langle V_3\right| \alpha_3^*+\left\langle V_6\right| \Lambda^{\dagger} \Omega^{\dagger} \alpha_4^*.
\end{align*}

#+NAME: Hermitian Operator
#+begin_definition latex
An operator \(\Omega\) is Hermitian if \(\Omega^{\dagger}=\Omega\).
#+end_definition

#+NAME: Anti-Hermitian
#+begin_definition latex
An operator \(\Omega\) is anti-Hermitian if \(\Omega^{\dagger} = -\Omega\).
#+end_definition

#+NAME: Hermitian Decomposition
#+begin_theorem latex
An arbitrary operator \(\Omega\) can be expressed as a sum of a Hermitian and anti-Hermitian operator:

\begin{align*}
\Omega=\frac{\Omega+\Omega^{\dagger}}{2}+\frac{\Omega-\Omega^{\dagger}}{2}.
\end{align*}

#+end_theorem

#+NAME: Unitary Operator
#+begin_definition latex
An operator \(U\) is unitary if

\begin{align*}
U U^{\dagger}=I=U^{\dagger} U, \quad U^{-1}=U^{\dagger}, \quad \left[U, U^{\dagger}\right]=0.
\end{align*}

#+end_definition

#+NAME: Unitary Operators preserve the Norm
#+begin_theorem latex
Unitary operators preserve the inner product between the vectors they act on, i.e.,

if

\begin{align*}
U\left|V_1\right\rangle=\left|V_1^{\prime}\right\rangle \quad \text{and} \quad U\left|V_2\right\rangle=\left|V_2^{\prime}\right\rangle
\end{align*}

then

\begin{align*}
\left\langle V_2^{\prime} | V_1^{\prime} \rangle = \left\langle V_2 | V_{1} \rangle.
\end{align*}

#+end_theorem

#+NAME: Columns (or rows) of a Unitary Matrix are pairwise orthonormal
#+begin_theorem latex
The \((n)\) columns and \((n)\) rows of an \(n \times n\) unitary matrix, when treated as vectors in \(\mathbb{V}^n\), are orthonormal.
#+end_theorem

Hermitian, anti-Hermitian, and Unitary operators are analogous to pure real, pure imaginary, complex numbers of unit modulus respectively.

Unitary operators are generalizations of rotation operators from \(\mathbb{V}^{3}(R)\) to \(\mathbb{V}^{n}(C)\) - preserving the inner-product, and thus the length of vectors.

#+NAME: Active Transformation
#+begin_definition latex
\begin{align*}
|V\rangle \rightarrow U|V\rangle, \quad \Omega \rightarrow \Omega, \quad \left\langle V^{\prime}|\Omega| V\right\rangle \rightarrow\left\langle V^{\prime}\left|U^{\dagger} \Omega U\right| V\right\rangle
\end{align*}
#+end_definition

#+NAME: Passive Transformation
#+begin_definition latex
\begin{align*}
|V\rangle \rightarrow|V\rangle, \quad \Omega \rightarrow U^{\dagger} \Omega U, \quad \left\langle V^{\prime}|\Omega| V\right\rangle \rightarrow\left\langle V^{\prime}\left|U^{\dagger} \Omega U\right| V\right\rangle
\end{align*}
#+end_definition

A ``passive transformation" is really an ``active transformation" done backstage. Choosing between the two views is choosing between being on audience or a member of the crew. I'm active, unless it's =Birdman=. Then I'm PASSIVE.

#+NAME: Eigenvalue Equation
#+begin_definition latex
\begin{align*}
\Omega \vert V \rangle = \omega \vert V \rangle.
\end{align*}
#+end_definition

#+NAME: Characteristic Polynomial
#+begin_definition latex
\begin{align*}
P^{n}(\omega) = \sum_{m=0} c_{m} \omega^{m}.
\end{align*}
#+end_definition

#+NAME: Characteristic Equation
#+begin_definition latex
\begin{align*}
P^{n}(\omega) = \sum_{m=0} c_{m} \omega^{m} = 0.
\end{align*}
#+end_definition

+ A sequence of steps to go from the eigenvalue equation to the characteristic equation:
  + \(\Omega \vert V \rangle = \omega \vert V \rangle\),
  + \(\left( \Omega - \omega I \right) \vert V \rangle = \vert 0 \rangle\),
  + \(\det \left( \Omega - \omega I \right) = 0\) if non-trivial eigenkets are to exist.
  + \(\det \left( \Omega - \omega I \right)\) is obtained as a product of the projection of \(\left( \Omega - \omega I \right) \vert V \rangle = \vert 0 \rangle\) onto the entire set of basis bras \(\{ \langle i \vert \}\) and has the general form: \(\sum_{m}^{n} c_{m} \omega^{m} = 0\) which is the characteristic equation.

Finding eigenvalues of \(\Omega\) has been /reduced to root-finding/.

Finding eigenvectors has been reduced to /solving a system of linear equation./

Each distinct (or not) eigenvalue ( \(n\) for the \(n\) roots of the characteristic polynomial for \(\Omega\) acting on vectors in \(\mathbb{V}^n\) ) may /not/ pair with a unique eigenket (upto a scaling factor). Some eigenvalues may not have a corresponding eigenket at all.

+ A polynomial \(P^n(x)=\sum_{i=0}^n a_i x^i\) is guaranteed to have \(n\) -roots, not necessarily distinct or real.
+ Roots of \(P^n(x)\) are value of \(x\), say \(x^*\), such that \(P^n\left(x^*\right)=0\).
+ Real roots are points on real axis that satisfy \(P^n(x)=0\).
+ Complex roots are points in the complex plane that satisfy \(P^n(x)=0\).
  
+ A root of the characteristic polynomial of a non-degenerate operator \(\Omega: \mathbb{V}^{n} \to \mathbb{V}^{n}\), upon substitution in the eigenvalue equation yields a system of \(n\) linear equation. There are \(n\) such systems. The freedom to scale eigenkets can be used to eliminate 1 equation from every system. The solution to each system is the eigenket for the eigenvalue that generated it. A solution, in general, is not guaranteed.
  
+ For a degenerate operator \(\Lambda\) that has for \(m\) roots out of \(n\), the \(i^{\text {th }}\) one repeating \(k_i\) times, \((n-m)\) systems with \(n-1\) equations each are obtained, the solutions of which (if exists) yields \(n-m\) eigenkets, corresponding to the \(n-m\) distinct eigenvalues. Another \(m\) systems are obtained for the \(m\) degenerate roots all the same, but only \(m - \sum_{i} k_{i}\) of them are /unique/. Each degenerate eigenvalue adds a degree of freedom to its eigenket: the eigenket of the \(i^{\text{th}}\) root (it it exists at all) lives in an eigenspace of dimensionality \(k_i\).

#+NAME: Eigenvalues of a Hermitian Operator
#+begin_theorem latex
The eigenvalues of a Hermitian operator are real.
#+end_theorem

#+NAME: Eigenvalues of a Unitary Operator
#+begin_theorem latex
The eigenvalues of a unitary operator are complex numbers of unit modulus.
#+end_theorem

#+NAME: Eigenvectors of a Non-Degenerate Unitary Operator
#+begin_theorem latex
The eigenvectors of a non-degenerate unitary operator are mutually orthogonal.
#+end_theorem

#+NAME: Diagonalization of Hermitian Operator
#+begin_theorem latex
To every Hermitian operator \(\Omega\), there exists (at least) a basis consisting of its orthonormal eigenvectors. It is diagonal in this eigenbasis and has its eigenvalues as its diagonal entries.
#+end_theorem

#+NAME: Similarity Transformation
#+begin_theorem latex
If \(\Omega\) is Hermitian, there exists a unitary matrix \(U\) ( its columns being the eigenvectors of \(\Omega\) ) such that \(\mathrm{U}^{+} \Omega \mathrm{U}^*\) is diagonal.
#+end_theorem  
  
Finding a basis that diagonalizes \(\Omega\) is /reduced to solving its eigenvalue problem./

#+NAME: Simultaneous Diagonalization
#+begin_theorem latex
If \(\Omega\) and \(\Lambda\) are two commuting Hermitian matrices/operators, there exists (at least) a basis of common eigenkets that diagonalizes them both.
#+end_theorem

Consider

\begin{align*}
f(x)=\sum_{n=0}^{\infty} a_n x^n.
\end{align*}

In this equation \(x\) is a /``c-number"/.

Consider

\begin{align*}
f(\Omega)=\sum_{n=0}^{\infty} a_n \Omega^n
\end{align*}

In this equation \(\Omega\) is a /``q-number"/.

#+NAME: Derivative of a Operator
#+begin_definition latex
The derivative of an operator w.r.t a parameter is defined as

\begin{align*}
\frac{d \theta(\lambda)}{d \lambda}=\lim _{\Delta \lambda \rightarrow 0}\left[\frac{\theta(\lambda+\Delta \lambda)-\theta(\lambda)}{\Delta \lambda}\right]
\end{align*}
#+end_definition

Example: Suppose \(\theta(\lambda)=\exp [\lambda \Omega], \quad \Omega=\Omega^{\dagger}\).

Since \(\Omega\) is Hermitian, \(\exp [\Omega]=\sum_{n=1}^{\infty} \Omega^n / n !\) is well-defined (it should be obvious why). We then have:

\begin{align*}
\frac{d \theta}{d \lambda}=\Omega \exp [\lambda \Omega]=\exp [\lambda \Omega] \Omega=\theta(\lambda) \Omega.
\end{align*}

If only one \(q\) -number appears in an equation (or its powers), everything commutes and they may thus be treated just like \(c\) -numbers. If more than one \(q\) number is involved, the order of factors is all important. For example:

\begin{align*}
\exp (\alpha \Omega) \exp (\beta \Omega)=\exp ((\alpha+\beta) \Omega),
\end{align*}

but

\begin{align*}
\exp (\alpha \Omega) \exp (\beta \theta) \neq \exp (\alpha \Omega+\beta \theta)
\end{align*}

unless \([\Omega, \theta]=0\).

Similarly

\begin{align*}
\exp (\alpha \Omega) \exp (\beta \theta) \exp (-\alpha \Omega) \neq \exp (\beta \theta),
\end{align*}

and

\begin{align*}
\Omega \exp (\lambda \Omega) \exp (\beta \theta)=\exp (\lambda \Omega) \Omega \exp (\beta \theta)$ \neq \exp (\lambda \Omega ) \exp (\beta \theta) \Omega
\end{align*}

unless \([\Omega, \theta]=0\).

The chain rule for differentiating a product of functions of operators

\begin{align*}
\frac{d}{d \lambda} f(\Omega) g(\theta)=\frac{d}{d \lambda} f(\Omega) \cdot g(\theta)+f(\Omega) \frac{d}{d \lambda} g(\theta)
\end{align*}

As an example:

\begin{align*}
\frac{d}{d \lambda} \exp (\lambda \Omega) \exp (\beta \theta)=\Omega \exp (\lambda \Omega) \exp (\beta \theta)+\exp (\lambda \Omega) \exp (\beta \theta).
\end{align*}

Functions can be elements of vector spaces. Each function is represented by a ket \(|f\rangle\) belonging to an infinite-dimensional vector space. Vector addition and scalar multiplication is analogous to the finite-dimensional case. The space must satisfy all the axioms satisfied by a vector space. The space of square integrable functions is an example of a Hilbert space.

The inner product is redefined as:

\begin{align*}
\langle f \vert g\rangle=\int f^{\ast}(x) g(x) d x
\end{align*}

+ \(\langle f \vert g\rangle=0 \Rightarrow|f\rangle\) and \(|g\rangle\) are orthogonal.
+ \(\langle f \vert f\rangle=0+1=1 \Rightarrow|f\rangle\) is normalized.

The completeness relation is redefined as:

\begin{align*}
\int\left|x^{\prime}\right\rangle\left\langle x^{\prime}\right| d x^{\prime}=I.
\end{align*}

The orthogonality condition is redefined as:

\begin{align*}
\left \langle x \vert x^{\prime} \right \rangle = \delta \left( x - x^{\prime} \right).
\end{align*}

This is /not/ the Kronecker della, it is the /Dirac delta function/.

#+NAME: Dirac delta function
#+begin_definition latex
A heuristic characterization of the Dirac delta function is:

\begin{align*}
\delta \left( x \right) \simeq
\begin{cases}
+ \infty, \quad &x = 0 \\
0, \quad &x \neq 0
\end{cases}
\end{align*}

and

\begin{align*}
\int_{-\infty}^{\infty} \delta \left( x \right) dx = 1.
\end{align*}
#+end_definition

The Dirac della function is defined only in the context of an integration:

\begin{align*}
\int \delta\left(x-x^{\prime}\right) f\left(x^{\prime}\right) d x^{\prime}=f(x).
\end{align*}

+ The Dirac delta function is even, real.
+ The Dirac delta function may be defined as a Gaussian distribution in the limit of zero variance:

\begin{align*}
g_{\Delta} = \dfrac{1}{\left( \pi \Delta \right)^{1/2}} \exp \left \lbrace - \dfrac{\left( x - x^{\prime} \right)^{2}}{\Delta^{2}}  \right \rbrace,
\end{align*}

so that

\begin{align*}
\lim_{\Delta \to 0} g_{\Delta} \left( x - x^{\prime} \right) = \delta \left( x - x^{\prime} \right).
\end{align*}

+ The Dirac delta function may be defined as a fourier integral:

\begin{align*}
\delta \left( x^{\prime} - x \right) \equiv \dfrac{1}{2 \pi} \int_{-\infty}^{\infty} dk \exp \left \lbrace i k \left[ x^{\prime} - x \right]  \right \rbrace.
\end{align*}

The derivative of Dirac delta function is
  
\begin{align*}
\delta^{\prime}\left(x-x^{\prime}\right)=\frac{d}{d x} \delta\left(x-x^{\prime}\right) \\
\Longrightarrow \int \delta^{\prime}\left(x-x^{\prime}\right) f\left(x^{\prime}\right) d x^{\prime} &= \int \frac{d}{d x} \delta\left(x-x^{\prime}\right) f(x^{\prime}) d x^{\prime} \\
&= \dfrac{d}{dx} \int \delta \left( x - x^{\prime} \right) f \left( x^{\prime} \right) d x^{\prime} \\
&= \dfrac{d}{dx} f(x).
\end{align*}

Now

\begin{align*}
\delta^{\prime}\left(x-x^{\prime}\right)=\frac{d}{d x} \delta\left(x-x^{\prime}\right) = - \dfrac{d}{d x^{\prime}} \delta \left( x - x^{\prime} \right),
\end{align*}

so that

\begin{align*}
\int-\frac{d}{d x^{\prime}} \delta\left(x-x^{\prime}\right) f(x) d x &=
\int\frac{d}{d x^{\prime}} \delta\left(x^{\prime}-x\right) f(x) d x \\
&= \dfrac{d}{d x^{\prime}} \int \delta \left( x^{\prime} - x \right) f \left( x \right) d x \\
&= \dfrac{d}{d x^{\prime}} f \left( x^{\prime} \right).
\end{align*}

+ \(\delta^{\prime} \left( x - x^{\prime} \right)\) is an odd function.
+ The action of higher derivatives may similarly be represented as:

\begin{align*}
\frac{d^n \delta\left(x-x^{\prime}\right)}{d x^n}=\delta\left(x-x^{\prime}\right) \frac{d^n}{d x^{\prime n}}
\end{align*}


Linear operators may be defined on function spaces. They change one function to another.

\begin{align*}
\Omega|f\rangle=|\tilde{f}\rangle
\end{align*}

#+NAME: Differential Operator
#+begin_definition latex
The /differential operator/ \(D\) has the action:

\begin{align*}
D \vert f \rangle = \vert df/dx \rangle.
\end{align*}

#+end_definition

\begin{align*}
&\dfrac{d f(x)}{dx} = \int \delta^{\prime} \left( x - x^{\prime} \right) f \left( x^{\prime} \right) d x^{\prime} = \int \left \langle x \left \lvert D  \right \rvert x^{\prime} \right \rangle \left \langle x^{\prime} \vert f \right \rangle d x^{\prime} \\
&\Longrightarrow \left \langle x \left \lvert D  \right \rvert x^{\prime} \right \rangle = \delta^{\prime} \left( x - x^{\prime} \right) = \delta \left( x - x^{\prime} \right) \dfrac{d}{d x^{\prime}}.
\end{align*}

+ \(D\) is /not/ Hermitian:

\begin{align*}
&\left \langle x \left \lvert D  \right \rvert x^{\prime} \right \rangle = \delta^{\prime} \left( x - x^{\prime} \right) \neq - \delta^{\prime} \left( x - x^{\prime} \right) = \left \langle x^{\prime} \left \lvert D  \right \rvert x \right \rangle^{\ast}
\Longrightarrow D \neq D^{\dagger}.
\end{align*}

- \(K \equiv-i D\) is Hermitian /given that it is defined on a function space in which the *surface term* vanishes/:

\begin{align*}
&K \stackrel{?}{=} K^{\dagger} \\
\text{or} & \left \langle g \left \lvert K  \right \rvert f \right \rangle \stackrel{?}{=} \left \langle f \left \lvert K  \right \rvert g \right \rangle^{\ast} \\
\text{or} & \int_{a}^{b} \int_{a}^{b} \left \langle g \vert x \right \rangle \left \langle x \left \lvert K  \right \rvert x^{\prime} \right \rangle \left \langle x^{\prime} \vert f \right \rangle dx dx^{\prime} \stackrel{?}{=} \left( \int_{a}^{b} \int_{a}^{b} \left \langle f \vert x \right \rangle \left \langle x \left \lvert K  \right \rvert x^{\prime} \right \rangle \left \langle x^{\prime} \vert g \right \rangle dx dx^{\prime} \right)^{\ast} \\
\text{or} &\int_{a}^{b} g^{\ast} \left( x \right) \left[ - i \dfrac{d f(x)}{dx} \right] dx \stackrel{?}{=} \left( \int_{a}^{b} f^{\ast} (x) \left[ - i \dfrac{d g (x)}{dx} \right] dx \right)^{\ast} \\
\text{or} &- i g^{\ast} (x) f (x) \Big \vert_{a}^{b} + i \int_{a}^{b} \dfrac{dg^{\ast}(x)}{dx} f(x) dx \stackrel{?}{=} i \int_{a}^{b} \dfrac{d g^{\ast} (x)}{dx} f(x) dx \\
\text{or} &- i g^{\ast} (x) f (x) \Big \vert_{a}^{b} \stackrel{?}{=} 0.
\end{align*}

Examples of function spaces in which \(K\) is Hermitian:

1) \(f(x)\) defined on \(0 \leqslant x \leqslant L\), and \(f(0)=f(L)=0\).
2) Periodic functions.
3) \(f(x)\) defined on \(-\infty \leqslant x \leqslant \infty\), and \(|x| \rightarrow \infty \Rightarrow f(x) \rightarrow 0\).
4) \(f(x) = \exp \left \lbrace i k x  \right \rbrace\), and:

\begin{align*}
\exp \left \lbrace i k x  \right \rbrace \exp \left \lbrace - i k^{\prime} x \right \rbrace \Big \vert_{-\infty}^{\infty} &=
\lim_{x \to \infty} \exp \left \lbrace i k x  \right \rbrace \exp \left \lbrace - i k^{\prime} x  \right \rbrace \\
&= \lim_{\Delta \to \infty, L \to \infty} \dfrac{1}{\Delta} \int_{L}^{\lambda - \Delta} \exp \left \lbrace i \left[ k - k^{\prime} \right] x  \right \rbrace dx \\
&= 0 \quad \text{if} \quad k \neq k^{\prime}.
\end{align*}

\begin{align*}
K \vert k \rangle = k \vert k \rangle &\Longrightarrow \left \langle x \left \lvert K  \right \rvert k \right \rangle = k \left \langle x \vert k \right \rangle \xrightarrow[]{\left( \psi_k(x) \equiv\langle x \vert k \rangle \right)} \\
&\text{or} \int\left\langle x|K| x^{\prime}\right\rangle\langle x^{\prime} \vert k\rangle d x^{\prime}=k \psi_k(x) \\
&\text{or} - i \dfrac{d}{dx} \psi_{k} \left( x \right) = k \psi_{k} \left( x \right).
\end{align*}

The solution for this differential equation is:

\begin{align*}
\psi_k(x)=A \exp \left \lbrace i k x  \right \rbrace.
\end{align*}

Any real number \(k\) is an eigenvalue, and the corresponding eigenfunction is given by \(A \exp \left \lbrace i k x  \right \rbrace\). Normalizing \(\vert k \rangle\)

\begin{align*}
\vert k \rangle \longleftrightarrow \dfrac{1}{(2 \pi)^{1/2}} \exp \left \lbrace i k x  \right \rbrace.
\end{align*}

The orthogonality condition is:

\begin{align*}
\left \langle k \vert k^{\prime} \right \rangle = \int_{-\infty}^{\infty} \left \langle k \vert x \right \rangle \left \langle x \vert k^{\prime} \right \rangle dx = \dfrac{1}{2 \pi} \int_{-\infty}^{\infty} \exp \left \lbrace - i \left( k - k^{\prime} \right) x \right \rbrace dx = \delta \left( k - k^{\prime} \right),
\end{align*}

as it should be. Therefore:

\begin{align*}
\left \langle k \left \lvert K  \right \rvert k^{\prime} \right \rangle = k^{\prime} \left \langle k \vert k \right \rangle = k^{\prime} \delta \left( k - k^{\prime} \right).
\end{align*}

We shall only be concerned with the *physical Hilbert space* - the space of functions that can either be /normalized to unity/ or to the /Dirac delta function/.

Because \(K\) is Hermitian, there exists a basis (orthonormal) in which \(K\) is diagonal. The ket \(\vert f \rangle\) may thus be expanded in the ``\(K\) basis":

\begin{align*}
f \left( k \right) = \left \langle k \vert f \right \rangle = \int_{-\infty}^{\infty} \left \langle k \vert x \right \rangle \left \langle x \vert f \right \rangle dx = \dfrac{1}{\left( 2 \pi \right)^{1/2}} \int_{-\infty}^{\infty} \exp \left \lbrace - i k x  \right \rbrace f \left( x \right) dx.
\end{align*}

\begin{align*}
f \left( x \right) = \left \langle x \vert f \right \rangle = \int_{-\infty}^{\infty} \left \langle x \vert k \right \rangle \left \langle k \vert f \right \rangle dk = \dfrac{1}{\left( 2 \pi \right)^{1/2}} \int_{-\infty}^{\infty} \exp \left \lbrace i k x  \right \rbrace f \left( k \right) dk.
\end{align*}

Suppose that \(X\), a Hermitian operator, brings into focus an (orthonormal) basis in which it is diagonal, and that this basis is made of \(\{|x\rangle\}\). The eigenvalue equation of \(X\) is

\begin{align*}
X \vert x \rangle = x \vert x \rangle,
\end{align*}

and the matrix elements of \(X\) are:

\begin{align*}
\left \langle x^{\prime} \left \lvert X  \right \rvert x \right \rangle = x \left \langle x^{\prime} \vert x \right \rangle = x \delta \left( x^{\prime} - x \right).
\end{align*}

The action of \(X\) on functions is

\begin{align*}
X \vert f \rangle = \vert \tilde{f} \rangle.
\end{align*}

But

\begin{align*}
\left \langle x \left \lvert X  \right \rvert f \right \rangle &= \int \left \langle x \left \lvert X  \right \rvert x^{\prime} \right \rangle \left \langle x^{\prime} \vert f \right \rangle dx^{\prime} = x f \left( x \right) = \left \langle x \vert \tilde{f} \right \rangle = \tilde{f} (x),
\end{align*}

so

\begin{align*}
X \vert f \rangle = x f \left( x \right) = \tilde{f} \left( x \right) = \vert x f (x) \rangle.
\end{align*}

Now

\begin{align*}
\left \langle k \left \lvert X  \right \rvert k^{\prime} \right \rangle &=
\dfrac{1}{2 \pi} \int_{-\infty}^{\infty} \exp \left \lbrace - i k x  \right \rbrace x \exp \left \lbrace i k^{\prime} x \right \rbrace dx \\
&= i \dfrac{d}{dk} \left( \dfrac{1}{2 \pi} \int_{-\infty}^{\infty} \exp \left \lbrace i \left( k^{\prime} - k \right) x \right \rbrace dx \right) \\
&= i \delta^{\prime} \left( k - k^{\prime} \right).
\end{align*}

It follows that:

\begin{align*}
X \vert g \left( k \right) \rangle = \Big \vert i \dfrac{d g (k)}{dk} \Big \rangle.
\end{align*}

In the \(x\) basis, \(x\) acts as \(x\) and \(K\) as \(-i d / d x\) (on functions \(f(x)\)), while in the \(K\) basis, \(K\) acts like \(k\) and \(x\) acts like \(i d / d k\) (on functions \(f(k)\)). Operators with this inter-relationship are called *conjugate* to each other.

\begin{align*}
[X, K]|f\rangle &\rightarrow(X K-K X) \vert f \rangle \rightarrow X K \vert f \rangle - K X \vert f \rangle \\
&\rightarrow - i x \frac{d f(x)}{d x}-\left(-i \frac{d}{d x} [x f(x)]\right) \\
&\rightarrow i I \vert f \rangle.
\end{align*}

Thus, \([X, K]=i I\), i.e \(X\) and \(K\) don't commute.
** SOLVED Problem 1.1.1
CLOSED: [2022-11-16 Wed 03:20]

- \(|0\rangle=|0\rangle+\left|0^{\prime}\right\rangle=\left|0^{\prime}\right\rangle\)
  
- \(0|v\rangle=(0+0)|v\rangle=0|v\rangle+0|v\rangle=|0\rangle\)
  
- \(|-v\rangle=|-v\rangle+|0\rangle=|-v\rangle+ 0| v\rangle=|-v\rangle+(1-1)|v\rangle=|-v\rangle+|v\rangle-|v\rangle=|0\rangle-|v\rangle=-|v\rangle\)
  
- \(|-v\rangle=|-v\rangle+|0\rangle=|-v\rangle+|v\rangle+\left|-v^{\prime}\right\rangle=|0\rangle+\left|-v^{\prime}\right\rangle=\left|-v^{\prime}\right\rangle\)
  
** SOLVED Problem 1.1.2
CLOSED: [2022-11-16 Wed 03:21]
- Null vector of \((a, b, c)\) is \((0,0,0)\)
- Inverse of \((a, b, c)\) is \((-a,-b,-c)\)
- Vectors of the form \((a, b, 1)\) do not form a vector space because they violate closure under the operations defined on the vector space.
** SOLVED Problem 1.1.3
CLOSED: [2022-11-16 Wed 03:21]
- Functions that vanish af endpoints \(x=0\) and \(x=L\) form a vector space.
- Functions that are periodic, \(f(0)=f(L)\), do not form a vector space. They violate closure under addition and scalar multiplication.
** SOLVED Problem 1.1.4
CLOSED: [2022-11-16 Wed 03:22]
No they are not. Consider \(2|2 \rangle-|1\rangle+|3\rangle\), Clearly \(2|2 \rangle-|1\rangle+|3\rangle = \vert 0 \rangle\), with non-zero coefficients.
** SOLVED Problem 1.1.5
CLOSED: [2022-11-16 Wed 03:23]
- \(2(1,1,0)+(1,0,1)-(3,2,1)=(0,0,0)\)
- They lie on the \(x y, x z, y z\) plane respectively. Only linear combination of them that vanishes is the trivial one.
** TOSOLVE Problem 1.3.1                                          
*Form an orthogonal basis in two dimensions starting with* \(\vec{A} = 3 \vec{i} + 4 \vec{j}\) *and* \(\vec{B} = 2 \vec{i} - 6 \vec{j}\). *Can you generate another orthonormal basis starting with these two vectors? If so, produce another.*
** SOLVED Problem 1.3.2
CLOSED: [2022-11-16 Wed 03:27]

\begin{align*}
\vert 1 \rangle &= \dfrac{1}{\sqrt{\left \langle I \vert I \right \rangle}} \cdot \vert I \rangle \\
\vert 2 \rangle &= \dfrac{1}{\sqrt{\left \langle II \vert II \right \rangle}} \\
\vert 3 \rangle &= \dfrac{1}{\sqrt{\left \langle III^{\prime} \vert III^{\prime} \right \rangle}} \cdot \vert III^{\prime} \rangle, \quad \vert III^{\prime} \rangle = - 12 \vert II \rangle + 5 \vert III \rangle.
\end{align*}

** SOLVED Problem 1.3.3
CLOSED: [2022-11-16 Wed 03:29]
- The Schwarz inequality is

\(|\langle V \mid W \rangle| \leqslant|V \| W|\).

- Equality implies \(\langle W \mid V\rangle\langle V \mid W\rangle=\langle V \mid V\rangle\langle W \mid W\rangle\) or \(|V\rangle=|W\rangle\)
- Yes, it does.
** SOLVED Problem 1.3.4
CLOSED: [2022-11-16 Wed 03:40]

\begin{align*}
\vert V + W \vert ^2 &=\langle V+W \vert V+W\rangle^*\langle V+W \vert V+W\rangle \\
&=\langle V+W \vert V\rangle^*\langle V+W \vert V\rangle+\langle V+W \vert W\rangle^*\langle V+W \vert W\rangle \\
&+\langle V+W \vert V\rangle^*\langle V+W \vert W\rangle+\langle V+W \vert W\rangle^*\langle V+W \vert V\rangle \\
&=\langle V \vert V+W\rangle\langle V+W \vert V\rangle+\langle W \vert V+W\rangle\langle V+W \vert W\rangle \\
&+\langle V \vert V+W\rangle\langle V+W \vert W\rangle+\langle W \vert V+W\rangle\langle V+W \vert V\rangle \\
&=\langle V \vert V\rangle+\langle W \vert W\rangle+2 \Re\langle V \vert W\rangle \\
&=\vertV\vert^2+\vertW\vert^2+2 \Re\langle V \vert W\rangle \\
&\leq \vert V \vert^2+\vert W \vert^2+2 \Re\langle V \vert W \rangle \\
&\leq \vert V \vert^2+\vert W \vert^2+2\vert\langle V \vert W \rangle\vert \\
&\leq \vert V \vert^2+\vert W \vert^2+2\vert\langle V \vert W \rangle\vert \\
&\leq  \vert V \vert^2+\vert W \vert^2+2\vert V \vert\vert W \vert \\
&\leq (\vert V \vert+\vert W \vert)^2 \\
\end{align*}

i.e.,

\begin{align*}
\left \lvert V + W  \right \rvert \leq \left \lvert V  \right \rvert + \left \lvert W  \right \rvert.
\end{align*}

Equality demands \(\left \lvert V + W  \right \rvert = \left \lvert V  \right \rvert + \left \lvert W  \right \rvert\), i.e., sum of norms be equal to the norm of sums, i.e.,

\begin{align*}
\vert V \rangle = a \vert W \rangle, \quad \text{\(a\) is a real positive scalar.} \quad 
\end{align*}

** SOLVED Problem 1.4.1
CLOSED: [2022-11-16 Wed 03:44]
- Among the vectors \(\left\{\left|v_{\perp}^1\right\rangle,\left|v_{\perp}^2\right\rangle, \ldots\right\}\) is af least a set of \(n-1\) vectors which along with \(|v\rangle \neq 0\) form a basis for \(\mathbb{N}^n\). These basis vectors are pairwise orthogonal. The \(n-1\) vectors from the set therefore also form a basis and span \(\mathbb{V}^{n-1}\).
** SOLVED Problem 1.4.2
CLOSED: [2022-11-16 Wed 03:47]
Choose \(n_1\) vectors from \(\mathbb{V}_1^{n_1}\) that form a basis for it. Similarly choose \(n_2\) vectors from \(\mathbb{V}_2^{n_2}\) that form a basis for it.
- The \(n_1\) vectors are orthogonal to each other, as the \(n_2\) vectors from \(\mathbb{V}_2^{n_{2}}\) in a pairwise manner. Further, any element of \(\mathbb{V}_1\) is orthogonal to any element of \(\mathbb{V}_2\) by assumption.
- The \(n_1+n_2\) vectors together form in orthogonal basis. Therefore, the vector space they span, namely \(\mathbb{V}_{1} \oplus \mathbb{V}_2\) has dimensions \(n_1+n_2\).
** SOLVED Problem 1.6.1
CLOSED: [2022-11-16 Wed 13:38]

*An operator* \(\Omega\) *is given by the matrix*

\begin{align*}
\left[\begin{array}{lll}0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0\end{array}\right].
\end{align*}

*What is it's action?*

Say \(\quad \left \lbrace \vert 1 \rangle, \vert 2 \rangle, \vert 3 \rangle \right \rbrace \text{ is a basis for } \mathbb{V}^{3}\) on which \(\Omega\) is defined.

\begin{align*}
\Omega(a|1\rangle+b|2\rangle+c|3\rangle) &=a \Omega|1\rangle+b \Omega|2\rangle+c \Omega|3\rangle \\
&=a|2\rangle+b|3\rangle+c|1\rangle \\
\end{align*}

\begin{align*}
\Omega(a|1\rangle+b|2\rangle+c|3\rangle) &=c|1\rangle+a|2\rangle+b|3\rangle \Longrightarrow \Omega = R \left( \dfrac{\pi}{2} \vec{j} \right) R \left( \dfrac{\pi}{2} \vec{k} \right).
\end{align*}
** SOLVED Problem 1.6.2
CLOSED: [2022-11-16 Wed 04:42]

\begin{align*}
\Omega \Lambda =
\begin{cases}
\Omega^{\dagger} \Lambda^{\dagger} = \left( \Lambda \Omega \right)^{\dagger} \quad \text{iff} \quad \left[ \Omega, \Lambda \right] = 0 \\
- \left[ \Lambda, \Omega \right] + \Lambda \Omega \qquad \(otherwise\)
\end{cases}.
\end{align*}

/``Product of Hermitian matrices is Hermitian iff their commutator vanishes."/

\begin{align*}
\Omega \Lambda + \Lambda \Omega &
\stackrel{?}{=}
\left[ (\Omega \Lambda + \lambda \Omega)^{\dagger} \right]^{\dagger} \\
& \stackrel{?}{=} \left[ \Lambda^{\dagger} \Omega^{\dagger} + \Lambda^{\dagger} \Omega^{\dagger} \right]^{\dagger} \\
& \stackrel{?}{=} \left[ \Lambda \Omega + \lambda^{\dagger} \Omega \right]^{\dagger} = \Omega^{\dagger} \Lambda^{\dagger} + \Lambda \Omega^{\dagger} \\
& \stackrel{?}{=} \Omega \Lambda + \Lambda \Omega.
\end{align*}

/``The commutator of Hermitian matrices varnishes iff the adjoint of the product is a product of the adjoint"./

Cleary.

\begin{align*}
i[\Omega, \Lambda] &= i\Omega \Lambda-i \Lambda \Omega \\
&= - i \left[ \Lambda, \Omega \right] = - i \left[ \Omega, \Lambda \right]^{\dagger}.
\end{align*}

/``The commutator of Hermitian matrices is Hermitian."/

** SOLVED Problem 1.6.3
CLOSED: [2022-11-16 Wed 13:45]

Let \(U\) and \(V\) be unitany operators

\begin{align*}
(U V)(U V)^{\dagger}=(U V)\left(V^{\dagger} U^{\dagger}\right)=U\left(V V^{\dagger}\right) U^{\dagger}=U I U^{\dagger} =U U^{\dagger}=I.
\end{align*}

/``Product of unitary matrices is unitary."/
** SOLVED Problem 1.6.4
CLOSED: [2022-11-16 Wed 13:51]

Suppose \(U\) is unitary

\begin{align*}
|U|=1 /\left|U^{\dagger}\right| \Longrightarrow |U|^2 = \left(1 /\left|U^{\dagger}\right|\right)\left(1 /\left|U^{\dagger}\right|^{\ast}\right)
\end{align*}

Therefore:

\begin{align*}
|U|^2=\frac{1}{\left|U^{\dagger}\right|} \cdot \frac{1}{\left|U^{T}\right|}=\frac{1}{\left|U^{\dagger}\right|} \cdot \frac{1}{|U|}=\frac{1}{\left|U U^{\dagger}\right|}=\frac{1}{|I|}=1.
\end{align*}

*``The determinant of a unitary matrix is a complex number with unit modulus".*
- Columns (or roues) of unitary matrices form an orthonormal basis.
** SOLVED Problem 1.6.5
CLOSED: [2022-11-16 Wed 13:51]

\begin{align*}
R \left( \dfrac{1}{2} \pi \vec{i} \right) \leftrightarrow
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & -1 \\
0 & 1 & 0
\end{pmatrix},
\qquad
R \left( \dfrac{1}{2} \pi \vec{i} \right) R \left( \dfrac{1}{2} \pi \vec{i} \right)^{\dagger} = I.
\end{align*}

*Columns (or rows) of unitary matrices form an orthonormal basis.*
** SOLVED Problem 1.6.6
CLOSED: [2022-11-16 Wed 13:58]

+ \(\left(\dfrac{1}{2^{1 / 2}}\right)^2\left[\begin{array}{ll}1 & i \\ i & 1\end{array}\right]\left[\begin{array}{cc}1 & -i \\ -i & 1\end{array}\right]=\dfrac{1}{2}\left[\begin{array}{ll}2 & 0 \\ 0 & 2\end{array}\right]=I\).

+ \(\left(\dfrac{1}{2}\right)^2\left[\begin{array}{cc}1+i & 1-i \\ 1-i & 1+i\end{array}\right]\left[\begin{array}{ll}1+i & 1-i \\ 1-i & 1+i\end{array}\right]=\dfrac{1}{4}\left[\begin{array}{ll}4 & 0 \\ 0 & 4\end{array}\right]=I\).

+ \(\operatorname{det}\left(\dfrac{1}{2^{1 / 2}}\left[\begin{array}{ll}1 & i \\ i & 1\end{array}\right]\right)=\left(\dfrac{1}{2^{1 / 2}}\right)^2\left[1 \times 1-i^2\right]=\dfrac{1}{2} \times 2=1\).

+ \(\left|\dfrac{1}{2^{1 / 2}}\left[\begin{array}{ll}1 & i \\ i & 1\end{array}\right]\right|^2=|\exp (i \theta)|^2\) with \(\theta=0 \Longrightarrow \dfrac{1}{2^{1 / 2}}\left[\begin{array}{ll}1 & i \\ i & 1\end{array}\right]=\exp (i \theta), \thinspace \theta=0\).
  
+ \(\operatorname{det}\left(\dfrac{1}{2}\left[\begin{array}{ccc}1+i & 1-i \\ 1-i & 1+i\end{array}\right]\right)=\left(\dfrac{1}{2}\right)^2\left[(1+i)^2-(1-i)^2\right]=i\).
  
+ \(\left|\dfrac{1}{2}\left[\begin{array}{lll}1+i & 1 -i \\ 1-i & 1+i\end{array}\right]\right|^2=1=|\exp (i \theta)|^2, \thinspace \theta=\pi / 2 \Rightarrow \dfrac{1}{2^{1 / 2}}\left[\begin{array}{ll}1 & i \\ i & 1\end{array}\right]=\exp (i \theta), \thinspace \theta=\pi / 2\).
  
No, none of the above matrices are Hermitian.
** SOLVED Problem 1.7.1
CLOSED: [2022-11-16 Wed 14:05]
*(1)* \(\operatorname{tr}\{\Omega \Lambda\}=\operatorname{tr}\{\Lambda \Omega\} \quad\)

\begin{align*}
\operatorname{tr}\{\Omega \Lambda\} \equiv \sum_i(\Omega \Lambda)_{i i}=\sum_i \sum_j \Omega_{i j} \Lambda_{j i} =\sum_j \sum_i \Lambda_{j i} \Omega_{i j}=\sum_j(\Lambda \Omega)_{j j}=\operatorname{tr}\left\{\Lambda \Omega \right\}.
\end{align*}

*(2)* \(\operatorname{tr}\{\Omega \Lambda \theta\}=\operatorname{tr}\{\Omega(\Lambda \theta)\}=\operatorname{tr}\{(\Lambda \theta) \Omega\}=\operatorname{tr}\{\Lambda \theta \Omega\} =\operatorname{tr}\{\Lambda(\theta \Omega)\}=\operatorname{tr}\{(\theta \Omega) \Lambda\}=\operatorname{tr}\{\theta \Omega \Lambda\}\)

*(3)* \(\operatorname{tr}\{\Omega\}=\operatorname{tr}\left\{U^{\dagger} \Omega U\right\}\) wher \(U\) is unitary.

\begin{align*}
\operatorname{tr}\left\{U^{\dagger} \Omega U\right\}=\operatorname{tr}\left\{\Omega U U^{\dagger}\right\}=\operatorname{tr}\{\Omega I\}=\operatorname{tr}\{\Omega\}.
\end{align*}

Being nested inside a trace is like having the house to yourself. Nothing's off the menu.
** SOLVED Problem 1.7.2
CLOSED: [2022-11-16 Wed 14:10]

\begin{align*}
\operatorname{det}\left(U^{\dagger} \Omega U\right)=\operatorname{det}(\Omega)
\end{align*}

\begin{align*}
\operatorname{det}\left(U^{\dagger} \Omega U\right) &= \operatorname{det}\left(U^{\dagger}\right) \operatorname{det}(\Omega U) \\
&= \operatorname{det}\left(U^{\dagger}\right) \operatorname{det}(\Omega) \operatorname{det}(U) \\
&= \operatorname{det}\left(U^{T}\right)^{\ast} \operatorname{det}(\Omega) \operatorname{det}(U) \\
&=\operatorname{det}(U)^* \operatorname{det}(U) \operatorname{det}(\Omega) \\
&= |\operatorname{det}(U)|^2 \operatorname{det}(\Omega)=\operatorname{det} \Omega.
\end{align*}

In the pen-ultimate step we have used the fact that determinant of a unitary matrix is a complex number of unit moduli.

/*A unitary change of basis preserves the trace and the determinant.*/
** SOLVED Problem 1.8.1
CLOSED: [2022-11-16 Wed 14:44]

*(1)* We have

\begin{align*}
\Omega \equiv\left[\begin{array}{lll}1 & 3 & 1 \\ 0 & 2 & 0 \\ 0 & 1 & 4\end{array}\right] \quad &\operatorname{det}(\Omega-\omega I)=0 \\
&\Longrightarrow  \operatorname{det}\left(\left[\begin{array}{ccc}1-\omega & 3 & 1 \\ 0 & 2-\omega & 0 \\ 0 & 1 & 4-\omega\end{array}\right]\right)=0, \\
&\Longrightarrow (1-\omega)[(2-\omega)(4-\omega)]-3 \times 0+1 \times 0=0, \\
&\Longrightarrow (1-w)(2-w)(4-w)=0, \\
&\Longrightarrow \omega_{1} = 1, \thinspace \omega_{2} = 2, \thinspace \omega_{3} = 4.
\end{align*}

\begin{align*}
\Omega \vert \omega_{i} \rangle = \omega_{i} \vert \omega_{i} \rangle \Longrightarrow
\begin{pmatrix}
1 & 3 & 1 \\
0 & 2 & 0 \\
0 & 1 & 4
\end{pmatrix}
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix}
=
\omega_{i}
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix}.
\end{align*}

\begin{align*}
\omega_{1} = 1: &\\
&x_{1} + 3 x_{2} + x_{3} = x_{1}, \\
&2 x_{2} = x_{2} \Longrightarrow x_{2} = 0, \\
&x_{2} + 4 x_{3} = x_{3} \Longrightarrow x_{3} = 0.
\end{align*}

\begin{align*}
\omega_{2} = 2: &\\
& x_{1} + 3 x_{2} + x_{3} = 2 x_{1} \Longrightarrow x_{1} = - x_{3} + 2 x_{2}, \\
& 2 x_{2} = 2 x_{2}, \\
& x_{2} + 4 x_{3} = x_{3} \Longrightarrow x_{3} = - x_{2}/3.
\end{align*}

\begin{align*}
\omega_{3} = 3: & \\
&x_{1} + 3 x_{2} + x_{3} = 4 x_{1} \Longrightarrow x_{1} =  x_{3}/3, \\
&2 x_{2} = 4 x_{2} \Longrightarrow x_{2} = 0, \\
&x_{2} + 4 x_{3} = 4 x_{3}.
\end{align*}

\begin{align*}
\vert \omega_{1} \rangle =
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}, \qquad
\vert \omega_{2} \rangle = \dfrac{1}{\sqrt{59}}
\begin{bmatrix}
7 \\
3 \\
-1
\end{bmatrix}, \qquad
\vert \omega_{3} \rangle = \dfrac{1}{\sqrt{10}}
\begin{bmatrix}
1 \\
0 \\
3
\end{bmatrix}.
\end{align*}

*(2)*

No, the matrix is not Hermitian, \(\Omega^{T} \neq \Omega\). No, the eigenvectors are not orthogonal: you don't need an inner product to be able to say that.

** SOLVED Problem 1.8.2
CLOSED: [2022-11-16 Wed 15:03]

\begin{align*}
\Omega \equiv\left[\begin{array}{lll}0 & 0 & 1 \\ 0 & 0 & 0 \\ 1 & 0 & 0\end{array}\right]
\end{align*}

(1) Yes, it is Hermitian.
(2) \(P(\omega)=(-\omega)\left(\omega^2\right)+\omega=0\).

\begin{align*}
\omega\left(1-\omega^2\right)=0 \Longrightarrow \omega_1=0, \thinspace \omega_2=1, \thinspace \omega_3=-1.
\end{align*}

\begin{align*}
\left|\omega_1\right\rangle=\left[\begin{array}{l}0 \\ 1 \\ 0\end{array}\right], \quad
\left|\omega_2\right\rangle=\dfrac{1}{\sqrt{2}}\left[\begin{array}{l}1 \\ 0 \\ 1\end{array}\right], \quad
\left|\omega_3\right\rangle=\dfrac{1}{\sqrt{2}}\left[\begin{array}{c}1 \\ 0 \\ -1\end{array}\right].
\end{align*}

\begin{align*}
U=\left[\begin{array}{ccc}0 & 1 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & -1\end{array}\right], \quad U^{\dagger}=\left[\begin{array}{ccc}0 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 0 & -1\end{array}\right].
\end{align*}

\begin{align*}
U^{\dagger} \Omega U &=
\left[\begin{array}{ccc}0 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 0 & -1\end{array}\right]\left[\begin{array}{lll}0 & 0 & 1 \\ 0 & 0 & 0 \\ 1 & 0 & 0\end{array}\right]\left[\begin{array}{lll}0 & 1 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & -1\end{array}\right] \\
&=\left[\begin{array}{ccc}0 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 0 & -1\end{array}\right]\left[\begin{array}{ccc}0 & 1 & -1 \\ 0 & 0 & 0 \\ 0 & 1 & 1\end{array}\right] \\
&=2\left[\begin{array}{ccc}
0 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & -1
\end{array}\right].
\end{align*}

Indeed, \(U^{-1} \Omega U\) is diagonal, \(U\) being the matrix of eigenvectors of \(\Omega\).
** SOLVED Problem 1.8.3
CLOSED: [2022-11-16 Wed 15:16]

\begin{align*}
\Omega = \dfrac{1}{2}
\begin{pmatrix}
2 & 0 & 0 \\
0 & 3 & -1 \\
0 & -1 & 3
\end{pmatrix}.
\end{align*}

*(1)* The secular equation and its solutions are:

\begin{align*}
P \left( \omega \right) = \left( 1 - \omega \right) \left[ \left( \dfrac{3}{2} - \omega \right)^{2} - \dfrac{1}{4} \right] = 0 \Longrightarrow \omega_{1} = 1, \thinspace \omega_{2} = 1, \thinspace \omega_{3} = 2.
\end{align*}

*(2)*

\begin{align*}
\Omega\left|\omega_3\right\rangle &= \frac{1}{2}\left[\begin{array}{ccc}2 & 0 & 0 \\ 0 & 3 & -1 \\ 0 & -1 & 3\end{array}\right]\left[\begin{array}{l}x_1 \\ x_2 \\ x_3\end{array}\right]=2\left|\omega_3\right\rangle \\
&\Longrightarrow x_1=2 x_1 \Longrightarrow x_1=0, \\
&\Longrightarrow \left(3 x_2-x_3\right) / 2=2 x_2 \Longrightarrow x_{2} = -x_{3}, \\
&\Longrightarrow \left( 3 x_3 - x_2 \right) / 2 = 2 x_3 \Longrightarrow x_{3} = - x_{2}.
\end{align*}

\begin{align*}
\vert \omega_{3} \rangle = \dfrac{1}{\left( 2 a^{2} \right)^{1/2}}
\begin{bmatrix}
0 \\
a \\
-a
\end{bmatrix}.
\end{align*}

*(3)*

\begin{align*}
\Omega \vert \omega_{1} \rangle = 1 \vert \omega_{1} \rangle &= 1
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix} \\
&\Longrightarrow x_1 = x_1, \\
&\Longrightarrow \left( 3 x_2 - x_3 \right)/2 = x_{2} \Longrightarrow x_{2} = x_{3}, \\
&\Longrightarrow \left( 3 x_{3} - x_{2} \right)/2 = x_{3} \Longrightarrow x_{3} = x_{2}.
\end{align*}

\begin{align*}
\left|\omega_1\right\rangle=\dfrac{1}{\left(b^2+2 c^2\right)^{1 / 2}}\left[\begin{array}{l}b \\ c \\ c\end{array}\right]
\end{align*}

More simply, you could look af \(\left|\omega_3\right\rangle\) while remembering that \(\Omega\) is Hermitian, and the form of \(\left|\omega_1\right\rangle\) would become immediately obvious.
** SOLVED Problem 1.8.4
CLOSED: [2022-11-16 Wed 15:23]

\begin{align*}
\Omega =\left[\begin{array}{cc}4 & 1 \\ -1 & 2\end{array}\right], \quad P(\omega)=(4-\omega)(2-\omega)+1=0 \Longrightarrow \omega_1=3, \thinspace \omega_2=3.
\end{align*}

\begin{align*}
\Omega\left|\omega_2\right\rangle &= \left[\begin{array}{ll}4 & 1 \\ -1 & 2\end{array}\right]\left[\begin{array}{l}x_1 \\ x_2\end{array}\right]=3\left|\omega_3\right\rangle = 3
\begin{bmatrix}
x_{1} \\
x_{2} 
\end{bmatrix} \\
&\Longrightarrow 4 x_1 + x_2 = 3 x_1, \\
&\Longrightarrow 2 x_2 - x_1 = 3 x_2, \\
&\Longrightarrow x_2 = - x_1, \thinspace x_1 = - x_2.
\end{align*}

\begin{align*}
\left|w_2\right\rangle=\left|\omega_1\right\rangle=\dfrac{1}{\left(2 a^2\right)^{1/2}}\left[\begin{array}{l}+a \\ -a\end{array}\right].
\end{align*}

** SOLVED Problem 1.8.5
CLOSED: [2022-11-16 Wed 15:36]

\(\Omega=\left[\begin{array}{cc}\cos \theta & \sin \theta \\ -\sin \theta & \cos \theta\end{array}\right]\),

*(1)*

\begin{align*}
\Omega \Omega^{\dagger}=\left[\begin{array}{cc}\sin ^2 \theta+\cos ^2 \theta & 0 \\ 0 & \sin ^2 \theta+\cos ^2 \theta\end{array}\right] =\left[\begin{array}{ll}1 & 0 \\ 0 & 1\end{array}\right]=I.
\end{align*}

*(2)*

\begin{align*}
&P(\omega)=(\cos \theta-\omega)^2+\sin ^2 \theta=0 \Rightarrow \cos \theta-\omega=\pm i \sin \theta \\
&\Rightarrow \omega=\cos \mp i \sin \theta \Longrightarrow \omega_1=\exp (i \theta), \quad \omega_2=\exp (-i \theta).
\end{align*}

*(3)*

\begin{align*}
\Omega\left|\omega_1\right\rangle &= \omega_1\left|\omega_1\right\rangle, \\
&\Longrightarrow x_1 \cos \theta+x_2 \sin \theta=x_1 \cos \theta- i x_1 \sin \theta. \\
&\text{and } x_2 \cos \theta-x_1 \sin \theta=x_2 \cos \theta- i x_2 \sin \theta. \\
&\Longrightarrow x_1=+i x_2, \thinspace x_2=-i x_1, \thinspace x_1=a, \thinspace x_2=-i a.
\end{align*}

\begin{align*}
\left|\omega_1\right\rangle=\left[\begin{array}{c}a \\ i a\end{array}\right], \thinspace \left|\omega_2\right\rangle=\left[\begin{array}{c}a \\ -i a\end{array}\right], \thinspace \left\langle\omega_1 \mid \omega_2\right\rangle=a^2+(i a)^2=0.
\end{align*}
*(4)*

\begin{align*}
U^{\dagger}\Omega U &= a^2\left[\begin{array}{rr}1 & -i \\ 1 & i\end{array}\right]\left[\begin{array}{cc}\cos \theta & \sin \theta \\ -\sin \theta & \cos \theta\end{array}\right]\left[\begin{array}{cc}1 & 1 \\ i & -i\end{array}\right] \\
&= a^2\left[\begin{array}{cc}
2(\cos \theta+i \sin \theta) & 0 \\
0 & 2(\cos \theta-i \sin \theta)
\end{array}\right] \\
&=2 a^2\left[\begin{array}{cc}\exp (i \theta) & 0 \\ 0 & \exp (-i \theta)\end{array}\right].
\end{align*}

Its diagonal alright.

** SOLVED Problem 1.8.6
CLOSED: [2022-11-16 Wed 15:42]
*(1)* Consider \(\operatorname{det} \Omega\) and \(U\) (a unitary matrix made of the eigenvectors of \(\Omega\) ). \(U^{\dagger} \Omega U\) is a diagonal matrix, with the eigenvalues of \(\Omega\) as its entries.

\begin{align*}
\operatorname{det} \Omega=\operatorname{det}\left(U^{\dagger} \Omega U\right) = \prod_{i=1}^n \omega_i
\end{align*}

*(2)*

\begin{align*}
\operatorname{tr}\{\Omega\}=\sum_{i=1}^n \omega_i \text { because } \operatorname{tr}\left\{U^{\dagger} \Omega U\right\} =\operatorname{tr}\left\{\Omega U U^{\dagger}\right\} =\operatorname{tr}\{\Omega I\} =\operatorname{tr}\{\Omega\}.
\end{align*}

** SOLVED Problem 1.8.7
CLOSED: [2022-11-16 Wed 15:45]
Suppose that \(w_1\) and \(w_2\) are the eigenvalues of a Hermitian matrix \(\Omega\).

\begin{align*}
w_1 w_2=-3 \quad \text{and} \quad w_1+w_2=2 \Longrightarrow \omega_1=3 \quad \text{and} \quad \omega_2=-1.
\end{align*}

By explicit computation, \((1-\omega)^2-4=0\),  \(\omega=-1\) or \(\omega=3\).

In general, you cant ron this procedure if your matrix is not Hermitian.

For \(2 \times 2\) Hermitian matrices, the result from the previous question allows computation of the eigenvalues without solving the characteristic equation.

** SOLVED Problem 1.8.8
CLOSED: [2022-11-16 Wed 15:54]

*(1)*

\(M^{1}\), \(M^2\), \(M^3\), \(M^4\) are Hermitian matrices that obey

\begin{align*}
M^i M^j+M^j M^i=2 \delta^{i j} I, \quad i, j = 1, \thinspace 2, \thinspace 3, \thinspace 4.
\end{align*}

In other words,

\begin{align*}
&M^i M^j=I \text { if } i=j, \\
&M^i M^j=-M^j M^i \quad \text { if } i \neq j.
\end{align*}

+ In still other words, all matrices pair-wise anti-commute and commute with themselves. Further \(M^1=\left(M^1\right)^{-1}\) if \(i \neq j\).
+ \(M^{1}\), \(M^2\), \(M^3\), \(M^4\) are /involutory matrices/.
+ \(M^{1}\), \(M^2\), \(M^3\), \(M^4\) are Hermitian involufory matrices. \(M^{1}\) is diagonal in its eigenbasis and \(M^{1} M^{1}=I \Longrightarrow w_i^2=1 \quad \forall \thinspace i\). Thus all eigenvalues are \(\pm 1\).
+ A Hermitian involutory matrix is a /signature matrix/ in its eigenbasis.
  
*(2)*

\begin{align*}
\operatorname{tr}\left\{M^i M^j\right\}=\operatorname{tr}\left\{M^j M^i\right\}=\operatorname{tr}\left\{-M^j M^i\right\}\( for \)i \neq j.
\end{align*}

Therefore, the traces of \(M^i\) and \(M^j\) most vanish, because the trace of \(M^i M^j\) vanishes, and

\begin{align*}
\tr \left \lbrace M^{i} \right \rbrace = \tr \left\{-M^i M^j M^i\right\}= \tr \left\{-M^j\right\}.
\end{align*}

*(3)*

In its eigenbasis, \(M^1\) is a signature matrix. The trace of a signature matrix can only vanish when it is even-dimensional. Thus \(M^1, M^2, M^3, M^4\) are *NOT* odd-dimensional.

** SOLVED Problem 1.8.9
CLOSED: [2022-11-16 Wed 16:07]

\begin{align*}
\vec{L} &= \sum_\alpha m_\alpha\left(\vec{r_\alpha} \times \vec{v_\alpha}\right)=\sum_\alpha m_\alpha\left(\vec{r_\alpha} \times \vec{\omega} \times \vec{r_\alpha}\right) \\
&= \sum_\alpha m_\alpha\left[\vec{\omega}\left(\vec{r_\alpha} \cdot \vec{r_\alpha}\right)-\vec{r_\alpha}\left(\vec{r_\alpha} \cdot \vec{\omega}\right)\right].
\end{align*}

We have used the identity \(A \times \left( B \times C \right) = B \left( A \cdot C \right) - C \left( A \cdot B \right)\). Now,

\begin{align*}
L_i=\vec{i} \cdot \vec{L}
&=\sum_\alpha m_\alpha\left[r_\alpha^2 \vec{\imath} \cdot \vec{\omega}-\left(\vec{i} \cdot \vec{r_\alpha}\right)\left(\vec{r_\alpha} \cdot \vec{\omega}\right)\right] \\
&=\sum_\alpha m_\alpha\left[r_\alpha^2 \vec{\omega}_i-\vec{r_{\alpha, i}}\left(\sum_j \vec{r}_{\alpha, j} \vec{\omega}_j\right)\right] \\
&=\sum_j\left(\sum_\alpha m_\alpha\left[r_\alpha^2 \delta_{i j}-\vec{r}_{\alpha, i} \vec{r}_{\alpha, j}\right]\right) \vec{\omega}_j \\
&=\sum_j M_{i j} \omega_j \\
&\Longrightarrow |L\rangle=M|\omega\rangle.
\end{align*}

*(1)* No. Angular momentum \(\vert L \rangle\) and angular velocity \(\vert \omega \rangle\) will *not* be parallel to each other, say when the angular velocity \(\vert \omega \rangle\) is *not* an eigenvector of \(M\).

*(2)*

\begin{align*}
\left(M_{i j}\right)^{T} &= \left(M_{j i}\right) \\
&=\left(\sum_\alpha m_\alpha\left[r_\alpha^2 \delta_{j i}-\vec{r_{\alpha, j}} \vec{r_{\alpha, i}}\right]\right) \\ &=\left(\sum_\alpha m_\alpha\left[r_\alpha^2 \delta_{i j}-\vec{r_{\alpha, i}} \vec{r_{\alpha, j}}\right]\right) \\
&=\left(M_{i j}\right)
\end{align*}

Thus, the moment of inertia tensor is Hermitian.

*(3)*

Because \(M\) is Hermitian, it can be diagonalized. It has three eigenkets. If \(|\omega\rangle\) is along any of these eigenkets, then \(|L\rangle\) and \(|\omega\rangle\) shall be parallel.

*(4)*

The three eigenvalues must be the same, because the eigenspace is the vector space itself, i.e., \(M\) is /completely degenerate/ just like me.

** SOLVED Problem 1.8.10
CLOSED: [2022-11-16 Wed 16:17]

\begin{align*}
\Omega=\left[\begin{array}{lll}
1 & 0 & 1 \\
0 & 0 & 0 \\
1 & 0 & 1
\end{array}\right], \thinspace
\Lambda=\left[\begin{array}{ccc}
2 & 1 & 1 \\
1 & 0 & -1 \\
1 & -1 & 2
\end{array}\right], \quad
\Omega^{\dagger}=\Omega, \quad \Lambda^{\dagger}=\Lambda.
\end{align*}

\begin{align*}
[\Omega, \Lambda]=\Omega \Lambda-\Lambda \Omega=\left[\begin{array}{lll}3 & 0 & 3 \\ 0 & 0 & 0 \\ 3 & 0 & 3\end{array}\right]-\left[\begin{array}{lll}3 & 0 & 3 \\ 0 & 0 & 0 \\ 3 & 0 & 3\end{array}\right]=\left[\begin{array}{lll}0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0\end{array}\right].
\end{align*}

Eigenvalues of \(\Omega\),  \(\omega_1=2\), \(\omega_2=0\), and \(\omega_3=0\).

\begin{align*}
\left|\omega_1\right\rangle=\left[\begin{array}{l}
1 \\
0 \\
1
\end{array}\right], \quad
\left|\omega_2\right\rangle=\left[\begin{array}{c}
-1 \\
0 \\
1
\end{array}\right], \quad
\left|\omega_3\right\rangle=\left[\begin{array}{l}
0 \\
1 \\
0
\end{array}\right].
\end{align*}

Eigenvalues of \(\Lambda\), \(\lambda_1=3\), \(\lambda_2=2\), \(\lambda_3=-1\).

\begin{align*}
\left|\lambda_1\right\rangle=\left[\begin{array}{l}
1 \\
0 \\
1
\end{array}\right], \quad
\left|\lambda_2\right\rangle=\left[\begin{array}{c}
-1 \\
-1 \\
1
\end{array}\right], \quad
\left|\lambda_3\right\rangle=\left[\begin{array}{c}
-1 \\
2 \\
1
\end{array}\right].
\end{align*}

+ \(\left|\omega_1\right\rangle=\left|\lambda_1\right\rangle\).
  
+ Since \(\Omega\) is degenerate and \(\Lambda\) is not, the change of basis matrix that simultaneously diagonalizes \(\Omega\) and \(\Lambda\) is made up of the eigenvectors of \(\Lambda\).
  
+ The matrix that simultaneously diagonalizes \(\Omega\) and \(\Lambda\) is:

\begin{align*}
U=\left[\begin{array}{ccc}-1 & -1 & 1 \\ 2 & -1 & 0 \\ 1 & 1 & 1\end{array}\right].
\end{align*}

+ We have
\begin{align*}
U^{-1} \Omega U=\left[\begin{array}{lll}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 2
\end{array}\right], \quad
U^{-1} \Lambda U=\left[\begin{array}{ccc}
-1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 3
\end{array}\right].
\end{align*}

** SOLVED Problem 1.8.11
CLOSED: [2022-11-16 Wed 17:04]

\begin{align*}
\Omega=\left[\begin{array}{c}\Omega_{11} \thinspace \Omega_{12} \\ \Omega_{21} \thinspace \Omega_{22}\end{array}\right], \quad \Omega_{11}, \thinspace \Omega_{22}=\frac{-2 k}{m}, \quad \Omega_{12}, \thinspace \Omega_{21} = \dfrac{k}{m}.
\end{align*}

*Step 1*

Let \(\omega_I, \omega_{II}\) be the eigenvalues of \(\Omega\) and \(\vert I \rangle\) and \(\vert II \rangle\) be the eigenvectors.

\begin{align*}
\omega_{I}=\left(\frac{k}{m}\right)^{1 / 2}, \quad |I\rangle \leftrightarrow \frac{1}{2^{1 / 2}}\left[\begin{array}{l}
1 \\
1
\end{array}\right]; \quad
\omega_{II}=\left(\frac{3 k}{m}\right)^{1 / 2}, \quad |II\rangle \leftrightarrow \frac{1}{2^{1 / 2}}\left[\begin{array}{r}
1 \\
-1
\end{array}\right].
\end{align*}

*Step 2*

\begin{align*}
\vert x \left( 0 \right) \rangle =|1\rangle, \quad x_I(0)=\langle I \mid 1\rangle= \dfrac{1}{2^{1/2}}, \quad x_{II}(0)=\langle II \mid 1\rangle= \dfrac{1}{2^{1/2}}.
\end{align*}

*Step 3*

\begin{align*}
|x(t)\rangle=|I\rangle\left(\frac{1}{2^{1 / 2}} \cos \left(\left(\frac{k}{m}\right)^{1 / 2} t\right)\right)+|II \rangle \left(\frac{1}{2^{1 / 2}} \cos \left(\left(\frac{3 k}{m}\right)^{1 / 2} t\right)\right)
\end{align*}

Use the /completeness relation/ in the \(\left \lbrace \vert 1 \rangle, \thinspace \vert 2 \rangle  \right \rbrace\) basis to obtain:

\begin{align*}
\left( \vert 1 \rangle \langle 1 \vert + \vert 2 \rangle \langle 2 \vert \right) \vert x \left( t \right) \rangle
&= \vert 1 \rangle \left[ \left \langle 1 \vert I \right \rangle \left[ \dfrac{1}{2^{1/2}} \cos \left( \left[\frac{k}{m}\right]^{1 / 2} t\right) \right]
+ \left \langle 1 \vert II \right \rangle \left[ \dfrac{1}{2^{1/2}} \cos \left(\left[\frac{3 k}{m}\right]^{1 / 2} t \right) \right] \right] + \\
&+ \vert 2 \rangle \left[ \left \langle 2 \vert I \right \rangle \left[ \dfrac{1}{2^{1/2}} \cos \left( \left[ \dfrac{k}{m} \right]^{1/2} t \right) \right] + \left \langle 2 \vert II \right \rangle \left[ \dfrac{1}{2^{1/2}} \cos \left( \left[ \dfrac{3k}{m} \right]^{1/2} t \right) \right] \right].
\end{align*}

Thus

\begin{align*}
\vert 1 \left( t \right) \rangle = \dfrac{\vert 1 \rangle}{2} \left[ \cos \left( \left[ \dfrac{k}{m} \right]^{1/2} t \right) + \cos \left( \left[ \dfrac{3k}{m} \right]^{1/2} t \right) \right] + \dfrac{\vert 2 \rangle}{2} \left[ \cos \left( \left[ \dfrac{k}{m} \right]^{1/2} t \right) - \cos \left( \left[ \dfrac{3k}{m} \right]^{1/2} t \right) \right].
\end{align*}

Given

\begin{align*}
\vert 1(0) \rangle = \dfrac{1}{2} \left( \dfrac{1}{2^{1/2}} \vert I \rangle + \dfrac{1}{2^{1/2}} \vert II \rangle \right),
\end{align*}

\begin{align*}
|1(t)\rangle=\left[\frac{1}{2^{1 / 2}} \cos \left(\left[\frac{k}{m}\right]^{1 / 2} t\right)\right] | I \rangle / 2^{1 / 2} + \left[\frac{1}{2^{1 / 2}} \cos \left(\left[\frac{3 k}{m}\right]^{1 / 2} t\right)\right] |II\rangle / 2^{1 / 2}.
\end{align*}

+ Think of \(|1(0)\rangle\) as first displacing both masses by the same amount and then displacing them in the opposite direction by the same amount is before.
+ The evolution of the system is as if the governing only care about two kinds of displacements and give a prescription for the evolution of scalar multiples of these two kinds of displacement. Isn't it strange?
+ No it's not. All myriad initial conditions and the associated restoring forces are really just different amounts of two fundamental restoring forces in the system - equivalent to two springs, one with a force constant \(k\) and another with force constant \(3k\). It only /feels/ strange because of your hyperfidelity to the \(|1\rangle, |2\rangle\) basis and your unwillingness to accomodate a shift in perspective.
+ In fact, here's another shift in perspective. You may view the system as /two different masses/ attached to a wall, the first with a single spring with constant \(k\) and the second with /three/ springs - each of constant \(k\). Starting from /any/ initial condition with \(\dot{x}_1(0)=0\) \(\dot{x}_2(0)=0\), it is possible to obtain \(x_1(t)\) and \(x_2(t)\) via linear combinations of the displacements of these two masses.
- This is the /physical analogue of diagonalization/. The decoupling of the differential equations is analogous to decoupling of the masses. By the way \(\Omega\) is called the /stiffness matrix/.
** SOLVED Problem 1.8.12
CLOSED: [2022-11-16 Wed 17:10]

*(1)*

\begin{align*}
&|x(t)\rangle=U(t)|x(0)\rangle, \quad |\ddot{x}(t)\rangle=\Omega|x(t)\rangle.
\end{align*}

Thus

\begin{align*}
&\left\left(D_{t}^{2}-\Omega\right)|x(t)\rangle=\left(D_{t}^{2}-\Omega\right) U(t)|x(0)\rangle= \vert 0\right\rangle \Longrightarrow D_{t}^{2} U(t)=\Omega U(t).
\end{align*}

*(2)*

\(S=\frac{1}{2}\left[\begin{array}{cc}1 & 1 \\ 1 & -1\end{array}\right]\) diagonalizes \(U(t)\).

\begin{align*}
S^{\dagger} U S =\left[\begin{array}{cc}
\cos \left((k / m)^{1 / 2} t\right) & 0 \\
0 & \cos \left((3 k / m)^{1 / 2} t\right)
\end{array}\right].
\end{align*}

In the co-eigenbasis of the /propagator/ \(|U(t)\rangle\) and the /stiffness matrix/ \(\vert \Omega \rangle\), the diagonal entries of \(|U(t)\rangle\) give the /normal modes/.
** SOLVED Problem 1.9.1
CLOSED: [2022-11-16 Wed 17:12]
+ \(f(\Omega)=\sum_{n=0}^{\infty} \Omega^n, \Omega^t=\Omega\).
+ In the eigenbasis of \(\Omega\), the diagonal of \(\Omega\) have its eigenvalues as entries.
+ In this basis, \(f(\Omega)\) is a diagonal matrix, with each element on the diagonal being a geometric series with a common ratio equal to the eigenvalue of \(\Omega\) at that corresponding location.
+ Thus, to identity \(f(\Omega)\) as \((1-\Omega)^{-1}\), we must have \(\left|w_i\right|<1\), where \(w_i\) is the \(i^{\text {th }}\) eigenvalue of \(\Omega\).
** SOLVED Problem 1.9.2
CLOSED: [2022-11-16 Wed 17:18]

We have

\begin{align*}
U=\exp (i H), H^{+}=H, U=\left[\begin{array}{ccc}\exp \left(i \omega_1\right) & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \exp \left(i \omega_n\right)\end{array}\right].
\end{align*}

Now

\begin{align*}
U^{\dagger} &= \left(\exp (i H) \right)^{\dagger} =\left(\sum_{n=0}^{\infty} \frac{(i H)^n}{n !}\right)^{\dagger} =\sum_{n=0}^{\infty} \frac{(-i H)^n}{n !} =\sum_{n=0}^{\infty} \frac{(-i H)^n}{n !}\right =\exp (-i H) \\
&=\left[\begin{array}{cccc}\exp \left(-i \omega_1\right) & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \exp \left(-i \omega_n\right)\end{array}\right].
\end{align*}

Therefore

\begin{align*}
U U^{\dagger}&=\left[\begin{array}{cccc}\exp \left(i \omega_1\right) \exp \left(-i \omega_1\right) & \cdots & \cdots \\ \vdots & \ddots & 0 \\ 0 & \cdots & \exp \left(i \omega_n\right) & \exp \left(-i \omega_n\right)\end{array}\right] \\
&=\left[\begin{array}{ccc}
1 & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & 1
\end{array}\right]=I.
\end{align*}
** SOLVED Problem 1.9.3
CLOSED: [2022-11-16 Wed 17:20]

In the eigenbasis of \(H\),

\begin{align*}
\operatorname{det} U=\prod_{n=1}^m \exp \left(i \omega_n\right)=\exp \left(i \sum_{n=1}^m \omega_n\right)=\exp (i \operatorname{tr}\{H\})
\end{align*}

** SOLVED Problem 1.10.1
CLOSED: [2022-11-16 Wed 17:22]

\begin{align*}
\int \delta(a x) d(a x)=\int \delta(a x)|a| d x=|a| \int \delta(a x) d x=1  \quad \Longrightarrow \delta(a x)=\delta(x) /|a|
\end{align*}

We have used \(\delta(x)=\delta(-x)\). Let's do it in another way

\begin{align*}
\delta(a x)=\lim _{\Delta \rightarrow 0} g_{\Delta}(a x)=\frac{1}{\sqrt{\pi \Delta^2}} \exp \left(-\frac{(a x)^2}{\Delta^2}\right)
\end{align*}

Choose \(\Delta=\beta a\)
\begin{aligned}
\delta(a x) &=\lim _{\beta \rightarrow 0} g_{\beta a}(a x)=\left.\frac{1}{\sqrt{\pi \beta^2 a^2}} \exp \left(-\left(\frac{a x}{\beta a}\right)^2\right)\right|_{\beta \rightarrow 0} \\
&=\frac{1}{|a|} \lim _{\beta \rightarrow 0} \frac{1}{\sqrt{\pi \beta^2}} \exp \left(-\frac{x^2}{\beta^2}\right)=\frac{1}{|a|} \delta(x).
\end{aligned}

** SOLVED Problem 1.10.2
CLOSED: [2022-11-16 Wed 17:26]

Near the \(i^{\text {th }}\) root, \(f(x)\) may be expanded as:

\begin{align*}
f(x) &=\left.\sum_i \frac{d f}{d x} \Bigg \vert_{x_i} \left(x-x_i\right).
\end{align*}

Thus
\begin{align*}
\delta(f(x)) &=\sum_i \delta\left(\frac { d f } { d x } \Bigg \vert_{x_{ i }} \left(x-x_i\right)\right)\\
&=\sum_i\left|\frac{d f}{d x}\right|_{x_i}^{-1} \delta\left(x_i - x \right)\\
&=\sum_i \frac{\delta\left(x_i-x\right)}{\left|d f / d x_i\right|}.
\end{align*}

We have used \(\delta \left( a x \right) = \left( 1/ \left \lvert a  \right \rvert \right) \delta \left( x \right)\) and \(\delta \left( x \right) = \delta \left( -x \right)\).

** SOLVED Problem 1.10.3
CLOSED: [2022-11-16 Wed 17:40]

\begin{align*}
\theta\left(x-x^{\prime}\right) \equiv\left\{\begin{array}{lll}1 & \text { if } & x>x^{\prime} \\ 0 & \text { if } & x<x^{\prime}\end{array}\right
\end{align*}

Now

\begin{align*}
\int_{-\infty}^{\infty} \delta\left(x-x^{\prime}\right) d x^{\prime} = 1 \Longrightarrow \int_{-\infty}^x \delta\left(x-x^{\prime}\right) d x^{\prime}=\left\{\begin{array}{lll}1 & \text { if } x>x^{\prime} \\ 0 & \text { if } x<x^{\prime}\end{array}\right
\end{align*}

Therefore

\begin{align*}
\theta\left(x-x^{\prime}\right)=\int_{-\infty}^x \delta\left(x-x^{\prime}\right) d x^{\prime} \Longrightarrow \delta\left(x-x^{\prime}\right)=\frac{d}{d x} \theta\left(x-x^{\prime}\right).
\end{align*}

Let's do it another way.

\begin{align*}
\theta\left(x-x^{\prime}\right) &=\lim _{k \rightarrow \infty}\left(1 /\left(1+\exp \left(-2 k\left(x-x^{\prime}\right)\right)\right)\right.\\
& \equiv \lim _{k \rightarrow \infty} H_k\left(x-x^{\prime}\right).
\end{align*}

Now

\begin{align*}
D_{x} \theta\left(x-x^{\prime}\right) &=\lim _{k \rightarrow \infty}\left(\frac{2 k\left(x-x^{\prime}\right) \exp \left(-2 k\left(x-x^{\prime}\right)\right)}{\left(1+\exp \left(-2 k\left(x-x^{\prime}\right)\right)\right)^2}\right) \xrightarrow[]{\kappa = 1/ 2\beta^{2}} \\
&=\lim_{\beta \rightarrow 0}\left(\frac{\left(x-x^{\prime}\right) \exp \left(-\left(x-x^{\prime}\right) / \beta^2\right)}{\beta^2\left(1+\exp \left(-\left(x-x^{\prime}\right) / \beta^2\right)\right.}\right) \xrightarrow[]{y^{2} = \left( x - x^{\prime} \right)} \\
&=\lim_{\beta \to 0} \left(\frac{y^2 \exp \left(-y^2 / \beta^2\right)}{\beta^2\left(1+\exp \left(-y^2 / \beta^2\right)\right.}\right) \\
&=\delta\left(y^2\right)=\delta\left(x-x^{\prime}\right).
\end{align*}

Nothing special about Gaussian. I can progressively make a Gamma distribution slender and towering to obtain the Dirac delta just fine. These results must be committed to memory:

\begin{align*}
\delta(a x)=\frac{\delta(x)}{|a|}, \quad \delta(f(x))=\sum_i \frac{\delta\left(x_i-x\right)}{\left|d f / d x_i\right|}, \quad \frac{d}{d x} \theta\left(x-x^{\prime}\right)=\delta(x-x^{\prime}).
\end{align*}

** SOLVED Problem 1.10.4
CLOSED: [2022-11-16 Wed 18:04]

Here's the initial condition:

\begin{align*}
\psi(x, 0) =
\begin{cases}
2 x h / L \quad &\text{if} \quad 0 \leqslant x \leqslant L / 2 \\
(2 h / L)(L-x) \quad &\text{if} \quad \frac{L}{2} \leqslant x \leqslant L
\end{cases}.
\end{align*}

\begin{align*}
\psi \left( x, t \right) &= \sum_m\left(\frac{2}{L}\right) \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t \\
&\times \left[ 2 \int_0^{L/2} \sin \left(\frac{m \pi x^{\prime}}{L}\right) \frac{x^{\prime} h}{L} d x^{\prime} + 2 \int_{L/2}^{L} \sin \left(\frac{m \pi x^{\prime}}{L}\right) \frac{h}{L} \left(L-x^{\prime}\right) d x^{\prime} \right] \xrightarrow[]{y = \frac{m \pi x^{\prime}}{L}} \\
&=\sum_{m=1}^{\infty} \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t \\
&\times 4\left[\int_0^{x^{\prime}=L / 2} \frac{h}{\pi^2 m^2} y \sin y d y+\int_{x^{\prime}=L / 2}^{x^{\prime}=L} \frac{h}{\pi^2 m^2} \frac{(\pi m L-y L)}{L} \sin y d y\right]\\
&=\sum_{m=1}^{\infty} \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t \\
&\times 4\left[\frac { h } { \pi ^ { 2 } m ^ { 2 } } \left(\int_0^{\frac{m \pi}{2}} y \sin y d y+\int_{m \pi / 2}^{m \pi}(\pi m-y) \sin y dy \right) \right]\\
&=\sum_{m=1}^{\infty} \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t \times \left(\frac{8 h}{\pi^2 m^2}\right) \\
&\times \frac{1}{2}\Bigg [ \left(\sin (m \pi / 2)-\frac{m \pi}{2} \cos (m \pi / 2)\right)+\left(\cos \left(\frac{m \pi}{2}\right) \frac{\pi m}{2} - \pi m \cos (m \pi) \right) \\
&- \left(\sin (m \pi) - m \pi \cos (m \pi)- \sin\left(\frac{m \pi}{2}\right)
+\frac{m \pi}{2} \cos \left(\frac{m \pi}{2}\right) \right) \Bigg ] \xrightarrow[]{\sin \left( m \pi \right) = 0} \\
&=\sum_{m=1}^{\infty} \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t\left(\frac{8 h}{\pi^2 m^2}\right)\left[\frac{1}{2}\left(2 \sin \left(\frac{m \pi}{2}\right)\right)\right]\\
&= \left(\frac{8 h}{\pi^2 m^2}\right) \sum_{m=1}^{\infty} \sin \left(\frac{m \pi x}{L}\right) \cos \omega_m t \sin \left(\frac{\pi m}{2}\right).
\end{align*}
* All Is Not Well with Classical Mechanics            
CLOSED: [2022-11-11 Fri 17:04]
* The Postulates a General Discussion                 
CLOSED: [2022-11-13 Sun 20:06]
*** SOLVED Problem 4.2.1
CLOSED: [2022-11-19 Sat 13:58]
\[
L_x=\frac{1}{2^{1 / 2}}\left[\begin{array}{lll}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{array}\right], L_y=\frac{1}{2^{1 / 2}}\left[\begin{array}{ccc}
0 & -i & 0 \\
i & 0 & -i \\
0 & i & 0
\end{array}\right], L_z=\left[\begin{array}{ccc}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & -1
\end{array}\right]
\]
(1) The eigenvalues of \(L_z\) are 1,0 , and \(-1\).
(2) \(\left\langle L_x\right\rangle=\left\langle L_z=+1\left|L_x\right| L_z=+1\right\rangle=0\)
\[
\begin{aligned}
\left\langle L_x^2\right\rangle &=1 / 2 \\
\Delta L_x &=\sqrt{\left\langle L_x^2\right\rangle_c}=\sqrt{\left\langle L_x^2\right\rangle-\left\langle L_x\right\rangle^2}=1 / \sqrt{2}
\end{aligned}
\]
(3) In the \(L_x\) basis,
- \(\left|L_x=1\right\rangle=\left[\begin{array}{c}1 \\ \sqrt{2} \\ 1\end{array}\right],\left|L_x=-1\right\rangle=\left[\begin{array}{c}1 \\ -\sqrt{2} \\ 1\end{array}\right],\left|L_x=0\right\rangle=\left[\begin{array}{c}-1 \\ 0 \\ 1\end{array}\right]\)
- If you want them normalized
\[
\left|L_x=1\right\rangle \rightarrow\left[\begin{array}{c}
1 / 2 \\
1 / 2^{1 / 2} \\
1 / 2
\end{array}\right],\left|L_x=-1\right\rangle=\left[\begin{array}{c}
1 / 2 \\
-1 / 2^{1 / 2} \\
1 / 2
\end{array}\right],\left|L_x=0\right\rangle \rightarrow\left[\begin{array}{c}
-1 / 2^{\prime} \\
1 / 2^{1 / 2}
\end{array}\right.
\]
(4)) \(\left|L_z=-1\right\rangle\) may be expanded in the eigenbasis of
\(L_x\) as follows
\[
\begin{aligned}
\left|L_z=-1\right\rangle=&\left|L_x=1\right\rangle\left\langle L_x=1 \mid L_z=-1\right\rangle+\\
&\left|L_x=-1\right\rangle\left\langle L_x=-1 \mid L_z=-1\right\rangle+\\
&\left|L_x=0\right\rangle\left\langle L_x=0 \mid L_z=-1\right\rangle \\
\left|L_z=-1\right\rangle=\frac{1}{4}\left|L_x=1\right\rangle+\frac{1}{4}\left|L_x=-1\right\rangle+\frac{1}{2}\left|L_x=0\right\rangle
\end{aligned}
\]


- Thus, \(P\left(L_x=1\right)=P\left(L_x=-1\right)=1 / 4\) and \(P\left(L_x=0\right)=1 / 2\)
(5) \(|\psi\rangle=\left[\begin{array}{l}1 / 2 \\ 1 / 2 \\ 1 / 2^{1 / 2}\end{array}\right] \quad L_z^2=\left[\begin{array}{lll}1 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1\end{array}\right]\)
- |य> in the \(L x^2\) basis
\[
\begin{aligned}
|\psi\rangle=&\left|L_z^2=1\right\rangle_\alpha\left\langle L_z^2=1 \mid \psi\right\rangle+\\
&\left|L_z^2=1\right\rangle_\beta\left\langle L_z^2=1 \mid \psi\right\rangle+\\
&\left|L_z^2=0\right\rangle\left\langle L_z^2=0 \mid \psi\right\rangle \\
=& \frac{1}{2^{1 / 2}}\left|L_z^2=1, \alpha\right\rangle+\frac{1}{2}\left|L_z^2=1, \beta\right\rangle+\frac{1}{2} \mid L_z^2=y \\
\stackrel{\langle\psi|\langle\rangle=1}{\longrightarrow} \sqrt{\frac{1}{2}}\left|L_z^2=1, \alpha\right\rangle+\sqrt{\frac{1}{4}}\left|L_z^2=1, \beta\right\rangle+\sqrt{\frac{1}{4}}\left|L_z^2=0\right\rangle
\end{aligned}
\]
- A measurement of \(L_2^2\) yielding \(+1\) means \(|\psi\rangle\)
\[
\text { - } P\left(L_z^2=1\right)=\left.\sum_{\alpha, \beta}\left|\left\langle L_z^2=1 \mid \psi\right\rangle\right\rangle\right|^ 2=3 / 4
\]
- \(|\psi\rangle=\left|L_2=1\right\rangle\left\langle L_2=1 \mid \psi\right\rangle+\)
\[
\begin{aligned}
&\left|L_z=0\right\rangle\left\langle L_z=0 \mid \psi\right\rangle+\\
&\left|L_z=-1\right\rangle\left\langle L_z=-1 \mid \psi\right\rangle \\
=\frac{1}{2}\left|L_z=1\right\rangle+\frac{1}{2}\left|L_z=0\right\rangle+\frac{1}{2^{1 / 2}}\left|L_z=-1\right\rangle
\end{aligned}
\]


\(\stackrel{\langle\psi \mid \psi\rangle=1}{\longrightarrow} \frac{1}{4}\left|L_z=1\right\rangle+\frac{1}{4}\left|L_z=0\right\rangle+\frac{1}{2}\left|L_z=-1\right\rangle\)
- \(|\psi\rangle \underset{L_z^2=1}{\longrightarrow} \frac{1}{(1 / 4+1 / 2)^{1 / 2}}\left[\begin{array}{c}1 / 2 \\ 0 \\ 1 / 2^{1 / 2}\end{array}\right]\)
\(\underbrace{1}\left|L_z=1\right\rangle+\frac{2^{1 / 2}}{3^{1 / 2}} \mid L_z=-\)
(6) Yes, I'm convinced.
- \(P\left(L_x=0\right)=\left|\left\langle L_x=0 \mid \psi\right\rangle\right|^2\)
\(\begin{aligned}=\mid \frac{1}{2^{1 / 2}}[10-1]\left(\frac{\exp \left(i \delta_1\right)}{2}\left|b_z=1\right\rangle\right.\\ &+\frac{\exp \left(i \delta_2\right)}{2^{1 / 2}}\left|L_2=0\right\rangle \\ &\left.+\frac{\exp \left(i \delta_3\right)}{2}\left|L_2=-1\right\rangle\right)\left.\right|^2 \end{aligned}\)
\(=\frac{1}{8}\left|\exp \left(i \delta_{21}\right)-\exp \left(i \delta_3\right)\right|^2\)
\(=\frac{1}{8}\left|1-\exp \left(i\left[\delta_3-\delta_1\right]\right)\right|^2\)
- Clearly the phase factors are not irrelevant since \(P\left(L_x=0\right)\) depends on them.
*** TOSOLVE Problem 4.2.2
*** TOSOLVE Problem 4.2.3
* Simple Problems in One Dimension                        
:LOGBOOK:
CLOCK: [2022-09-21 Wed 15:00]--[2022-09-21 Wed 15:25] =>  0:25
CLOCK: [2022-09-21 Wed 02:54]--[2022-09-21 Wed 05:11] =>  2:17
:END:
*** TOSOLVE Problem 5.1.1.
*** TOSOLVE Problem 5.1.2.
*** TOSOLVE Problem 5.1.3.
*** TOSOLVE Problem 5.1.4.
*** TOSOLVE Problem 5.2.1.
*** TOSOLVE Problem 5.2.2.
*** TOSOLVE Problem 5.2.3.
*** TOSOLVE Problem 5.2.4.
*** TOSOLVE Problem 5.2.5.
*** TOSOLVE Problem 5.2.6.
*** TOSOLVE Problem 5.3.1.
*** TOSOLVE Problem 5.3.2.
*** TOSOLVE Problem 5.3.3.
*** TOSOLVE Problem 5.3.4.
*** TOSOLVE Problem 5.3.5.
*** TOSOLVE Problem 5.3.6.
*** TOSOLVE Problem 5.4.1
*** TOSOLVE Problem 5.4.2
*** TOSOLVE Problem 5.4.3
* The Classical Limit                                 
* The Harmonic Oscillator                                 
*** TOSOLVE Problem 7.3.1
*** TOSOLVE Problem 7.3.2
*** TOSOLVE Problem 7.3.3
*** TOSOLVE Problem 7.3.4
*** TOSOLVE Problem 7.3.5
*** TOSOLVE Problem 7.3.6
*** TOSOLVE Problem 7.3.7
*** TOSOLVE Problem 7.4.1
*** TOSOLVE Problem 7.4.2
*** TOSOLVE Problem 7.4.3
*** TOSOLVE Problem 7.4.4
*** TOSOLVE Problem 7.4.5
*** TOSOLVE Problem 7.4.6
*** TOSOLVE Problem 7.4.7
*** TOSOLVE Problem 7.4.8
*** TOSOLVE Problem 7.4.9
*** TOSOLVE Problem 7.4.10
*** TOSOLVE Problem 7.5.1
*** TOSOLVE Problem 7.5.2
*** TOSOLVE Problem 7.5.3
*** TOSOLVE Problem 7.5.4
* The Path Integral Formulation of Quantum Theory          
* The Heisenberg Uncertainty Relations                    
*** TOSOLVE Problem 9.4.1
*** TOSOLVE Problem 9.4.2
*** TOSOLVE Problem 9.4.3
*** TOSOLVE Problem 9.4.4
*** TOSOLVE Problem 9.4.5
*** TOSOLVE Problem 9.4.6
* Systems with N Degrees of Freedom
CLOSED: [2022-11-19 Sat 09:28]
:LOGBOOK:
CLOCK: [2022-11-17 Thu 01:22]--[2022-11-17 Thu 03:51] =>  2:29
CLOCK: [2022-11-14 Mon 15:47]--[2022-11-14 Mon 17:17] =>  1:30
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-18 Fri 21:40]--[2022-11-19 Sat 04:24] =>  6:44
:END:
Consider two particles described classically by coordinates \((x_{1}, p_{1})\) and \((x_{2},p_{2})\). The Hilbert space for this system may be characterized in two ways:
1) the /simultaneous eigenkets/ \(\vert \omega_{1} \omega_{2} \rangle\) of two commuting operators \(\Omega_{1} \left( X_{1}, P_{1} \right)\) and \(\Omega_{2} \left( X_{2}, P_{2} \right)\) defines a basis \(\Omega\) that spans the /two-particle Hilbert space/ \(\mathbb{V}_{1 \otimes 2}\). The commuting operators \(\Omega_{1} \left( X_{1}, P_{1} \right)\) and \(\Omega_{2} \left( X_{2}, P_{2} \right)\) defined on the /two-particle Hilbert space/ \(\mathbb{V}_{1 \otimes 2}\) acts on its eigenket \(\ket{\omega_{1} \omega_{2}}\) as:

\begin{align*}
\Omega_{1} \vert \omega_{1} \omega_{2} \rangle = \omega_{1} \vert \omega_{1} \omega_{2} \rangle,
\end{align*}

\begin{align*}
\Omega_{2} \vert \omega_{1} \omega_{2} \rangle = \omega_{2} \vert \omega_{1} \omega_{2} \rangle.
\end{align*}
   
2) the /direct product/ \(\vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle\) of the eigenkets of operator \(\Omega_{1}^{(1)} \otimes \Omega_{2}^{(2)}\) span the /direct product space/ \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\) of \(\mathbb{V}_{1}\) and \(\mathbb{V}_{2}\). The operator \(\Omega_{1}^{(1)} \otimes \Omega_{2}^{(2)}\), a /direct product of operators/ \(\Omega_{1}^{(1)}\) and  \(\Omega_{2}^{(2)}\), defined on the direct product space \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\) acts on its eigenket \(\ket{\omega_{1}} \otimes \ket{\omega_{2}}\) as:

\begin{align*}
\left( \Omega_{1}^{(1)} \otimes \Omega_{2}^{(2)} \right) \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle = \vert \Omega_{1}^{(1)} \omega_{1} \rangle \otimes \vert \Omega_{2}^{(2)} \otimes \omega_{2} \rangle.
\end{align*}

We have the equivalences:

\begin{align*}
\mathbb{V}_{1 \otimes 2} \equiv \mathbb{V}_{1} \otimes \mathbb{V}_{2}, \qquad \vert \omega_{1} \omega_{2} \rangle \equiv \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle, \qquad \Omega_{1} \equiv \Omega_{1}^{(1)} \otimes I^{(2)}, \qquad \Omega_{2} \equiv I^{(1)} \otimes \Omega_{2}^{(2)}.
\end{align*}

Remarks:
1) The direct product is a product of /vectors from two different spaces/.
2) The direct product is a linear operation:
   
\begin{align*}
\left( \alpha \vert x_{1} \rangle + \alpha^{\prime} \vert x_{1}^{\prime} \rangle \right) \otimes \left( \beta \vert x_{2} \rangle \right) = \alpha \beta \vert x_{1} \rangle \otimes \vert x_{2} \rangle + \alpha^{\prime} \beta \vert x_{1}^{\prime} \rangle \otimes \vert x_{2} \rangle.
\end{align*}
   
3) The dimensionality of \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\) is the product of the dimensionality of \(\mathbb{V}_{1}\) and the dimensionality of \(\mathbb{V}_{2}\): to each basis vector \(\ket{\omega_{1}}\) of \(\mathbb{V}_{1}\) and \(\ket{\omega_{2}}\) of \(\mathbb{V}_{2}\), there is one and only one basis vector \(\ket{\omega_{1}} \otimes \ket{\omega_{2}}\) of \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\).
4) Not every element of a direct product space \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\) is a direct product; for example: \(\ket{\psi} = \vert \omega_{1}^{\prime} \rangle \otimes \vert \omega_{2}^{\prime} \rangle + \vert \omega_{1}^{\prime \prime} \rangle \otimes \vert x_{2}^{\prime \prime} \rangle\).

The inner product of \(\vert \omega_1 \rangle \otimes \vert \omega_{2} \rangle\) and \(\vert \omega_{1}^{\prime} \rangle \otimes \vert \omega_{2}^{\prime} \rangle\) is

\begin{align*}
\left( \langle \omega_{1}^{\prime} \vert \otimes \langle \omega_{2}^{\prime} \vert \right) \left( \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle \right) = \left \langle \omega_{1}^{\prime} \vert \omega_{1} \right \rangle \left \langle \omega_{2}^{\prime} \vert \omega_{2} \right \rangle = \delta \left( \omega_{1}^{\prime} - \omega_{1} \right) \delta \left( \omega_{2}^{\prime} - \omega_{2} \right).
\end{align*}

Because the basis \(\vert \omega_1 \rangle \otimes \vert \omega_{2} \rangle\) spans \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\), the equation above defines the inner product between any two vectors. A ket \(\vert \psi \rangle\) may be expanded as:

\begin{align*}
\vert \psi \rangle = \sum_{\omega_{1}} \sum_{\omega_{2}} \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle \left(\langle \omega_{1} \vert \otimes \langle \omega_{2} \vert \right) \vert \psi \rangle \equiv \sum_{\omega_{1}} \sum_{\omega_{2}} C_{\omega_{1}, \omega_{2}} \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle.
\end{align*}

in practice, one usually works in a basis, usually the coordinate basis comprised of the simultaneous eigenkets \(\vert x_1 x_2 \rangle\) of \(X_{1}\) and \(X_{2}\):

\begin{align*}
X_{1} \vert x_{1} x_{2} \rangle = x_{1} \vert x_{1} x_{2} \rangle,
\end{align*}

\begin{align*}
X_{2} \vert x_{1} x_{2} \rangle = x_{2} \vert x_{1} x_{2} \rangle.
\end{align*}

The normalization is:

\begin{align*}
\left \langle x_{1}^{\prime} x_{2}^{\prime} \vert x_{1} x_{2} \right \rangle = \delta \left( x^{\prime}_{1} - x_{1} \right) \delta \left( x_{2}^{\prime} - x_{2} \right).
\end{align*}

In this basis:

\begin{align*}
\vert \psi \rangle \longrightarrow \left \langle x_{1} x_{2} \vert \psi \right \rangle = \psi \left( x_{1}, x_{2} \right),
\end{align*}

\begin{align*}
X_{i} \longrightarrow x_{i},
\end{align*}

\begin{align*}
P_{i} \longrightarrow - i \hbar \partial_{x_{i}},
\end{align*}

and we may interpret

\begin{align*}
P \left( x_{1}, x_{2} \right) = \left \lvert \left \langle x_{1} x_{2} \vert \psi \right \rangle  \right \rvert^{2}.
\end{align*}

Descending to coordinate basis:

\begin{align*}
\vert \psi \rangle &= \sum_{\omega_{1}} \sum_{\omega_{2}} C_{\omega_{1}, \omega_{2}} \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle \xrightarrow[]{\text{coordinate basis}} \\
&\psi \left( x_{1}, x_{2} \right) = \sum_{\omega_{1}} \sum_{\omega_{2}} C_{\omega_{1}, \omega_{2}} \omega_{1} \left( x_{1} \right) \omega_{2} \left( x_{2} \right).
\end{align*}

The Schrodinger equation for a two particle ket \(\vert \psi \rangle\) living in \(\mathbb{V}_{1 \otimes 2}\) is:

\begin{align*}
i \hbar \vert \dot{\psi} \rangle = \left[ \dfrac{P_{1}^{2}}{2m_{1}} + \dfrac{P_{2}^{2}}{2m_{2}} + V \left( X_{1}, X_{2} \right) \right] \vert \psi \rangle = H \vert \psi \rangle.
\end{align*}

1) If \(H\) is *separable*, the time-independent Schrodinger equation, for a stationary state \(\vert \psi \left( t \right) \rangle = \vert E \rangle \exp \left \lbrace - i E t / \hbar \right \rbrace\) is

\begin{align*}
\left[ H_{1} \left( X_{1}, P_{1} \right) + H_{2} \left( X_{2}, P_{2} \right) \right] \vert E \rangle = E \vert E \rangle.
\end{align*}

Operators of particle 1 commute with those of particle 2. Thus we have \(\left[ H_1, H_2 \right] = 0\): \(H_{1}\) and \(H_{2}\) share an eigenbasis. Their simultaneous eigenkets are \(\vert E \rangle = \vert E_1 \rangle \otimes \vert E_2 \rangle = \vert E_{1} E_{2} \rangle\), where \(\vert E_1 \rangle\) and \(\vert E_2 \rangle\) are solutions to

\begin{align*}
H_{1}^{(1)} \vert E_{1} \rangle = E_{1} \vert E_{1} \rangle
\end{align*}

and

\begin{align*}
H_{2}^{(1)} \vert E_{2} \rangle = E_{2} \vert E_{2} \rangle.
\end{align*}

The state \(\vert E_1 \rangle \otimes \vert E_2 \rangle\) corresponds to particle \(1\) being in the energy eigenstate \(\vert E_1 \rangle\) and particle \(2\) being in the energy eigenstate \(\vert E_{2} \rangle\). Clearly then,

\begin{align*}
H \vert E \rangle = \left( H_{1} + H_{2} \right) \vert E_{1} \rangle \otimes \vert E_{2} \rangle = \left( E_{1} + E_{2} \right) \vert E_{1} \rangle \otimes \vert E_{2} \rangle = \left( E_{1} + E_{2} \right) \vert E \rangle,
\end{align*}

so that

\begin{align*}
E = E_{1} + E_{2}.
\end{align*}

Feeding

\begin{align*}
\vert E \rangle = \vert E_1 \rangle \otimes \vert E_2 \rangle = \vert E_{1} E_{2} \rangle
\end{align*}

in

\begin{align*}
\left[ H_{1} \left( X_{1}, P_{1} \right) + H_{2} \left( X_{2}, P_{2} \right) \right] \vert E \rangle = E \vert E \rangle,
\end{align*}

we get

\begin{align*}
\vert \psi \left( t \right) \rangle = \vert E_{1} \rangle \exp \left \lbrace - i E_{1} t/ \hbar  \right \rbrace \otimes \vert E_{2} \rangle \exp \left \lbrace - i E_{2} t/ \hbar \right \rbrace.
\end{align*}

Descending to coodinate basis:

\begin{align*}
&\vert \psi \left( t \right) \rangle = \vert E_{1} \rangle \exp \left \lbrace - i E_{1} t/ \hbar  \right \rbrace \otimes \vert E_{2} \rangle \exp \left \lbrace - i E_{2} t/ \hbar \right \rbrace \xrightarrow[]{\text{coordinate basis}} \\
& \psi_{E} \left( x_{1}, x_{2}, t \right) = \psi_{E} \left( x_{1}, x_{2} \right) \exp \left \lbrace - i E t / \hbar  \right \rbrace = \psi_{E_{1}} \left( x_{1} \right) \exp \left \lbrace - i E_{1} t/ \hbar \right \rbrace \psi_{E_{2}} \left( x_{2} \right) \exp \left \lbrace - i E_{2} t/ \hbar  \right \rbrace,
\end{align*}

where \(\psi_{E_{1}}\) and \(\psi_{E_{2}}\) are eigenfunctions of the one-particle Schrodinger equation with eigenvalues \(E_{1}\) and \(E_{2}\) respectively.

2) If \(H\) is *not separable*, i.e.,

\begin{align*}
V \left( X_{1}, X_{2} \right) \neq V \left( X_{1} \right) + V \left( X_{2} \right),
\end{align*}

the solution is irreducible to a direct product of the solutions of two single-particle problems, and must be treated case-by-case, apart from a special case when:

\begin{align*}
V \left( X_{1}, X_{2} \right) = V \left( X_{1} - X_{2} \right).
\end{align*}

In this case, a /similarity transform/ to /Jacobi coordinates/:

\begin{align*}
X_{\text{CM}} = \dfrac{m_{1} X_{1} + m_{2} X_{2}}{m_{1} + m_{2}}, \quad \text{and} \quad X_{\text{rel}} = X_{1} - X_{2},
\end{align*}

reduces the problem to that of two independent fictitious particles: one, the \(\text{CM}\) which is free, has mass \(M = m_{1} + m_{2}\) and momentum \(P_{\text{CM}} = M \dot{X}_{\text{CM}} = m_{1} \dot{X}_{1} + m_{2} \dot{X_{2}}\), and another, with the /reduced mass/ \(\mu = m_{1} m_{2}/ \left( m_{1} + m_{2} \right)\), momentum \(P = \mu \dot{X}_{\text{rel}}\), moving under the influence of \(V(x)\):

\begin{align*}
H \left( X_{1}, P_{1} ; P_{2}, P_{2} \right) &\xrightarrow[]{\text{Jacobi coordinates}} H \left( X_{\text{CM}}, P_{\text{CM}}; X_{\text{rel}}, P_{\text{rel}} \right) \\
&= H_{\text{CM}} + H_{\text{rel}} = \dfrac{P_{\text{CM}}^{2}}{2M} + \dfrac{P_{\text{rel}}^{2}}{2 \mu} + V \left( X \right).
\end{align*}

See =Exercise 2.5.4= and =Exercise 2.7.6=. We have the commutation relations

\begin{align*}
\left[ X_{\text{CM}}, P_{\text{CM}} \right] = i \hbar
\end{align*}

\begin{align*}
\left[ X_{\text{rel}}, P_{\text{rel}} \right] = i \hbar,
\end{align*}

and all other commutators zero. The eigenkets of \(H\) now factorize as:

\begin{align*}
\vert \psi_{E} \left( t \right) \rangle = \exp \left \lbrace - i E t / \hbar  \right \rbrace \vert \psi_{\text{CM}} \rangle \otimes \vert \psi_{\text{rel}} \rangle, \quad \text{and} \quad E = \dfrac{P_{\text{CM}}^{2}}{2M} + E_{\text{rel}}.
\end{align*}

Descending to coordinate basis:

\begin{align*}
&\vert \psi_{E} \left( t \right) \rangle = \exp \left \lbrace - i E t / \hbar  \right \rbrace \vert \psi_{\text{CM}} \rangle \otimes \vert \psi_{\text{rel}} \rangle \xrightarrow[]{\text{coordinate basis}} \\
&\psi_{E} \left( x_{\text{CM}}, x_{\text{rel}} \right) = \dfrac{1}{\left( 2 \pi \hbar \right)^{1/2}} \exp \left \lbrace i p_{\text{CM}} \cdot x_{\text{CM}} / \hbar \right \rbrace \cdot \psi_{E_{\text{rel}}} \left( x \right),
\end{align*}
and

\begin{align*}
E = \dfrac{p_{\text{CM}}^{2}}{2M} + E_{\text{rel}}.
\end{align*}

Since the \(\text{CM}\) drifts along as a free particle, one usually chooses to study the problem in the \(\text{CM}\) frame. In this case \(E_{\text{CM}} = P_{\text{CM}}^{2}/2M\) drops out of the energy, and the plane wave factor in \(\psi\) representing \(\text{CM}\) motion becomes a constant.

The entirety of what has been mentioned till now generalizes in a straightforward manner to arbitrary number of particles except for a non-separable \(H\) but a \(V\) as a functions of difference of coordinates: a transform to Jacobi coordinates does not yield a separable equation expect for when \(V\) is (or can be recast as) quadratic in in coordinates. In such cases, the oscillators become independent and their energies add both in the classical and quantum cases.

Generalization from one-dimension (which is what we have been considering so far) to more than one dimension is mathematically equivalent to an increasing in the number of particles equal to the increase in the number of dimensions.

A special case of many particle systems is the family of systems comprised of /identical particles/. Two particles are identical when no conceivable experiment can distinguish between their intrinsic properties. Within the ambits of classical mechanics, there is no such thing as /indistinguishability/ - /intrinsic/ to each particle is its /unique trajectory/ in configuration space. In contrast, /non-locality/ and /superposition/ in /quantum mechanics/ allows for the notion of /indistinguishability/.

If a measurement of \(\Omega\) of two /identical/ particles yields \(\omega_1\) and \(\omega_2\), the state vectors /before/ and /after/ measurement satisfy the constraint

\begin{align*}
\vert \psi \left( \omega_{1}, \omega_{2} \right) \rangle = \alpha \vert \psi \left( \omega_{2}, \omega_{1} \right) \rangle
\end{align*}

where \(\alpha\) is any complex number. In the \(\vert \omega_{1} \omega_{2} \rangle\) basis we may /not/ have:

\begin{align*}
\vert \psi \left( \omega_{1}, \omega_{2} \right) \rangle \longleftrightarrow \vert \omega_{1} \omega_{2} \rangle \quad \text{and} \quad \vert \psi \left( \omega_{2}, \omega_{1} \right) \rangle \longleftrightarrow \vert \omega_{2} \omega_{1} \rangle
\end{align*}

since \(\vert \omega_{1} \omega_{2} \rangle\) and \(\vert \omega_{2} \omega_{1} \rangle\) are not multiples of each other. The superpositions

\begin{align*}
\vert \psi \left( \omega_{1}, \omega_{2} \right) \rangle &\longleftrightarrow \beta \vert \omega_{1} \omega_{2} \rangle + \gamma \vert \omega_{2} \omega_{1} \rangle \quad \\
&\text{and} \quad \vert \psi \left( \omega_{2}, \omega_{1} \right) \rangle \longleftrightarrow \beta \vert \omega_{2} \omega_{1} \rangle + \gamma \vert \omega_{1} \omega_{2} \rangle
\end{align*}

,however, work just fine for:

\begin{align*}
\beta = \alpha \gamma \quad \text{and} \quad \gamma = \alpha \beta
\end{align*}

is solved by \(\beta = \pm \gamma\) and \(\alpha = \pm 1\). The allowed (un-normalized) /state vector/ in the \(\vert \omega_{1} \omega_{2} \rangle\) basis therefore are:

\begin{align*}
\vert \omega_{1} \omega_{2}, S \rangle = \vert \omega_{1} \omega_{2} \rangle + \vert \omega_{2} \omega_{1} \rangle \quad \text{and} \quad \vert \omega_{1} \omega_{2}, A \rangle = \vert \omega_{1} \omega_{2} \rangle - \vert \omega_{2} \omega_{1} \rangle,
\end{align*}

called respectively the /symmetric/ and /anti-symmetric/ state vectors. Symmetric states are called /bosons/ and anti-symmetric states are called /fermions/ - the Hilbert space of two identical particles may /not/ accomodate /both/ bosons and fermions for

\begin{align*}
\beta \vert \omega_{1} \omega_{2} , S \rangle + \gamma \vert \omega_{1} \omega_{2}, A \rangle = \alpha \left( \beta \vert \omega_{2} \omega_{1}, S \rangle + \gamma \vert \omega_{2} \omega_{1}, A \rangle \right)
\end{align*}

and thus

\begin{align*}
\beta + \gamma = \alpha \left( \beta - \gamma \right) \quad \text{and} \quad \beta - \gamma = \alpha \left( \beta + \gamma \right)
\end{align*}

only has solutions \(\alpha = + 1\) and \(\vert \omega_1 \omega_2, A \rangle = \vert 0 \rangle\) or \(\alpha = - 1\) and \(\vert \omega_1 \omega_2, S \rangle = \vert 0 \rangle\). Observations confirm this expectation - once a boson, /always/ a boson, such as pions, photons, and gravitons, and once a fermion, /always/ a fermion such as electrons, protons, and neutrons.

/Two identical fermions cannot be in the same quantum state/ for to say so is to say that a measurement of \(\Omega\) yields say \(\omega\) for /both/ of them which is equivalent to saying that non-existent states have measureable properties:

\begin{align*}
\Omega \vert \omega \omega, A \rangle = \Omega \left( \vert \omega \omega \rangle - \vert \omega \omega \rangle \right)  =  \Omega \vert 0 \rangle = \omega \vert 0 \rangle,
\end{align*}

which is bogus. This is called the /Pauli exclusion principle/.

*Once a boson, always a boson? Says /who/?*

Pair of eigenkets \(\vert \omega_1 \omega_2 \rangle\) and \(\vert \omega_2 \omega_1 \rangle\) of the direct product Hilbert space \(\mathbb{V}_{1 \otimes 2}\) combine to to form either a boson or a fermion but /nothing else/:

\begin{align*}
\mathbb{V}_{1 \otimes 2} = \mathbb{V}_{S} \oplus \mathbb{V}_{A},
\end{align*}

where \(\mathbb{V}_{S}\) is the /bosonic Hilbert space/ and \(\mathbb{V}_{A}\) is the /fermionic Hilbert space/. This is true for two identical particles. For three or more identical particles \(\dim \mathbb{V}_{1 \otimes 2} > \dim \mathbb{V}_{S} \oplus \dim \mathbb{V}_{A}\). Note that \(\dim \mathbb{V}_{S} > \dim \mathbb{V}_{A}\) because of Pauli's exclusion principle.

*How do I know whether I'm in Bosonia or Fermionia?*

For a two-particle bosonic Hilbert spaces, the normalization for the eigenkets is:

\begin{align*}
\vert \omega_{1} \omega_{2}, S \rangle =
\begin{cases}
2^{-1/2} \left[ \vert \omega_{1} \omega_{2} \rangle + \vert \omega_{2} \omega_{1} \rangle \right] \quad &\text{if} \quad \omega_{1} \neq \omega_{2} \\
\vert \omega \omega \rangle \quad &\text{if} \quad \omega_{1} = \omega_{2} = \omega \\
\end{cases}.
\end{align*}

\begin{align*}
\vert \omega_{1} \omega_{2}, A \rangle =
2^{-1/2} \left[ \vert \omega_{1} \omega_{2} \rangle - \vert \omega_{2} \omega_{1} \rangle \right].
\end{align*}

An arbitrary two-particle bosonic state vector \(\vert \psi_S \rangle\) expanded in the in terms of the eigenkets of operator \(\Omega\) with a /discrete spectrum/:

\begin{align*}
\vert \psi_{S} \rangle \xrightarrow[]{\text{\(\Omega\) basis}}
\begin{cases}
\sum_{\omega_{1}, \omega_{2}}^{\prime} 2^{-1/2} \vert \omega_{1} \omega_{2} \rangle \langle \omega_{1} \omega_{2} \vert \left[ \vert \omega_{1} \omega_{2} \rangle + \vert \omega_{2} \omega_{1} \rangle \right] \quad &\text{if} \quad \omega_{1} \neq \omega_{2} \\
\sum_{\omega_{1}, \omega_{2}}^{\prime} \vert \omega_{1} \omega_{2} \rangle \langle \omega_{1} \omega_{2} \vert \omega \omega \rangle
\end{cases}.
\end{align*}

The sum is restricted to prevent double-counting of indistinguishable states \(\vert \omega_1 \omega_2, S \rangle\) and \(\vert \omega_2 \omega_1, S \rangle\). The probability of obtaining \(\omega_1\) and \(\omega_{2}\) on a measurement of \(\Omega\) is

\begin{align*}
P_{S} \left( \omega_{1}, \omega_{2} \right) = \left \lvert \left \langle \omega_{1} \omega_{2}, S \vert \psi_{S} \right \rangle  \right \rvert^{2},
\end{align*}

and thus

\begin{align*}
\sum_{\omega_{1}, \omega_{2}}^{\prime} P_{S} \left( \omega_{1}, \omega_{2} \right) = \sum_{\omega_{1}, \omega_{2}}^{\prime} \left \lvert \left \langle \omega_{1} \omega_{2}, S \vert \psi_{S} \right \rangle  \right \rvert^{2} = 1.
\end{align*}

In terms of the eigenkets of an operator \(\Lambda\) with a /continous spectrum/, the normalization condition is:

\begin{align*}
\iint P_{S} \left( \lambda_{1}, \lambda_{2} \right) \dfrac{d \lambda_{1} d \lambda_{2}}{2} = \iint \left \lvert \left \langle \lambda_{1} \lambda_{2}, S \vert \psi_{S} \right \rangle  \right \rvert^{2} \dfrac{d \lambda_{1} d \lambda_{2}}{2} = 1,
\end{align*}

where the measure has been modified to account for the double-counting. With

\begin{align*}
\vert \psi \left( \lambda_{1}, \lambda_{2} \right) \rangle \equiv 2^{-1/2} \left \langle \lambda_{1} \lambda_{2}, S \vert \psi_{S} \right \rangle
\end{align*}

an equivalent normalization condition is

\begin{align*}
\iint \left \lvert \psi_{S} \left( \lambda_{1}, \lambda_{2} \right)  \right \rvert^{2} d \lambda_{1} d \lambda_{2} = \iint \left \langle \psi_{S} \vert \lambda_{1} \lambda_{2} \right \rangle \left \langle \lambda_{1} \lambda_{2} \vert \psi_{S} \right \rangle d \lambda_{1} d \lambda_{2} = 1,
\end{align*}

for

\begin{align*}
&\vert \psi \left( \lambda_{1}, \lambda_{2} \right) \rangle \equiv 2^{-1/2} \left \langle \lambda_{1} \lambda_{2}, S \vert \psi_{S} \right \rangle \\
&\Longrightarrow P_{S} \left( \lambda_{1} , \lambda_{2} \right) = 2 \left \lvert \psi_{S} \left( \lambda_{1}, \lambda_{2} \right)  \right \rvert^{2}
\quad \text{and} \quad \psi_{S} \left( \lambda_{1}, \lambda_{2} \right) = \left \langle \lambda_{1} \lambda_{2} \vert \psi_{S} \right \rangle.
\end{align*}

For a two-particle fermionic Hilbert spaces, the normalization for the eigenkets is:

\begin{align*}
\vert \omega_{1} \omega_{2}, A \rangle =
2^{-1/2} \left[ \vert \omega_{1} \omega_{2} \rangle - \vert \omega_{2} \omega_{1} \rangle \right].
\end{align*}

An arbitrary two-particle fermionic state vector \(\vert \psi_S \rangle\) expanded in the in terms of the eigenkets of operator \(\Omega\) with a /discrete spectrum/:

\begin{align*}
\vert \psi_{A} \rangle \xrightarrow[]{\text{\(\Omega\) basis}}
\sum_{\omega_{1}, \omega_{2}}^{\prime} 2^{-1/2} \vert \omega_{1} \omega_{2} \rangle \langle \omega_{1} \omega_{2} \vert \left[ \vert \omega_{1} \omega_{2} \rangle - \vert \omega_{2} \omega_{1} \rangle \right]
\end{align*}

The sum is restricted to prevent double-counting of indistinguishable states \(\vert \omega_1 \omega_2, A \rangle\) and \(\vert \omega_2 \omega_1, A \rangle\). The probability of obtaining \(\omega_1\) and \(\omega_{2}\) on a measurement of \(\Omega\) is

\begin{align*}
P_{A} \left( \omega_{1}, \omega_{2} \right) = \left \lvert \left \langle \omega_{1} \omega_{2}, A \vert \psi_{A} \right \rangle  \right \rvert^{2},
\end{align*}

and thus

\begin{align*}
\sum_{\omega_{1}, \omega_{2}}^{\prime} P_{A} \left( \omega_{1}, \omega_{2} \right) = \sum_{\omega_{1}, \omega_{2}}^{\prime} \left \lvert \left \langle \omega_{1} \omega_{2}, A \vert \psi_{A} \right \rangle  \right \rvert^{2} = 1.
\end{align*}

In terms of the eigenkets of an operator \(\Lambda\) with a /continous spectrum/, the normalization condition is:

\begin{align*}
\iint P_{A} \left( \lambda_{1}, \lambda_{2} \right) \dfrac{d \lambda_{1} d \lambda_{2}}{2} = \iint \left \lvert \left \langle \lambda_{1} \lambda_{2}, A \vert \psi_{A} \right \rangle  \right \rvert^{2} \dfrac{d \lambda_{1} d \lambda_{2}}{2} = 1,
\end{align*}

where the measure has been modified to account for the double-counting. With

\begin{align*}
\vert \psi \left( \lambda_{1}, \lambda_{2} \right) \rangle \equiv 2^{-1/2} \left \langle \lambda_{1} \lambda_{2}, A \vert \psi_{A} \right \rangle
\end{align*}

an equivalent normalization condition is

\begin{align*}
\iint \left \lvert \psi_{A} \left( \lambda_{1}, \lambda_{2} \right)  \right \rvert^{2} d \lambda_{1} d \lambda_{2} = \iint \left \langle \psi_{A} \vert \lambda_{1} \lambda_{2} \right \rangle \left \langle \lambda_{1} \lambda_{2} \vert \psi_{A} \right \rangle d \lambda_{1} d \lambda_{2} = 1,
\end{align*}

for

\begin{align*}
&\vert \psi \left( \lambda_{1}, \lambda_{2} \right) \rangle \equiv 2^{-1/2} \left \langle \lambda_{1} \lambda_{2}, A \vert \psi_{A} \right \rangle \\
&\Longrightarrow P_{A} \left( \lambda_{1} , \lambda_{2} \right) = 2 \left \lvert \psi_{A} \left( \lambda_{1}, \lambda_{2} \right)  \right \rvert^{2}
\quad \text{and} \quad \psi_{A} \left( \lambda_{1}, \lambda_{2} \right) = \left \langle \lambda_{1} \lambda_{2} \vert \psi_{A} \right \rangle.
\end{align*}

A measurement of \(\Lambda\) for a two-particle (of identical particles) state whose fermionic/bosonic nature is as of yet unbeknown will yield:

\begin{align*}
P_{S/A} \left( \lambda_{1}, \lambda_{2} \right) &= 2 \left \lvert \psi_{S/A} \left( \lambda_{1}, \lambda_{2} \right)  \right \rvert^{2} \\
&= 2 \left \lvert 2^{-1/2} \left[ \vert \lambda_{1} \rangle \vert \lambda_{2} \rangle \pm \vert \lambda_{2} \rangle \vert \lambda_{1} \rangle \right]  \right \rvert^{2} \\
&= \left \lvert \lambda_{1}  \right \rvert^{2} \left \lvert \lambda_{2} \right \rvert^{2} + \left \lvert \lambda_{2}  \right \rvert^{2} \left \lvert \lambda_{1}  \right \rvert^{2} \pm \left[ \left \langle \lambda_{1} \vert \lambda_{1} \right \rangle \left \langle \lambda_{2} \vert \lambda_{2} \right \rangle + \left \langle \lambda_{2} \vert \lambda_{2} \right \rangle \left \langle \lambda_{1} \vert \lambda_{1} \right \rangle \right].
\end{align*}

\(\left[ \left \langle \lambda_{1} \vert \lambda_1 \right \rangle \left \langle \lambda_{2} \vert \lambda_2 \right \rangle + \left \langle \lambda_{2} \vert \lambda_{2} \right \rangle \left \langle \lambda_{1} \vert \lambda_{1} \right \rangle \right]\) is called the /interference term/. Now notice that

\begin{align*}
P_{S} \left( \lambda_{1} \to \lambda, \lambda_{2} \to \lambda \right) = 4 \left \lvert \lambda  \right \rvert^{4} \quad \text{and} \quad P_{A} \left( \lambda_{1} \to \lambda, \lambda_{2} \to \lambda \right) = 0.
\end{align*}

\(P_{S}\) is called a /Bose-Einstein particle statistics/ and \(P_{A}\) is called a /Fermi-Dirac particle statistics/. The joint probability density function over \(\lambda_1\) and \(\lambda_{2}\) will /vanish/ along the \(\lambda_1 = \lambda_2\) line for fermions; for bosons it will have /mode/ there. This striking difference immediately lends way for distinguishing the fermionic/bosonic nature of the as of yet unknown two-particle state function - via an empirical reconstruction of the the probability distribution over the spectrum of some arbitrary operator (usually position) from their ensemble averages of its eigenvalue measurements.

A measurement of \(\Lambda\) /also/ betrays the /indistinguishability/ of particles: to say that two particles are /not/ indistinguishable is to say that they have /labels/, be they as they may unbeknown to us. Labels are instantiations of a certain property say \(P\). Say two possible labels for the property \(P\) of a state are \(A\) and \(B\). We will then have:

\begin{align*}
P_{S/A} \left( \lambda_{1}, \lambda_{2} \right) &= \left \lvert \lambda_{1}  \right \rvert_{A}^{2} \left \lvert \lambda_{2} \right \rvert_{B}^{2} + \left \lvert \lambda_{2}  \right \rvert_{B}^{2} \left \lvert \lambda_{1}  \right \rvert_{A}^{2} \\
&\pm \left[ {}_{A}\left \langle \lambda_{1} \vert \lambda_{1} \right \rangle_{B} {}_{B} \left \langle \lambda_{2} \vert \lambda_{2} \right \rangle_{A} + {}_{B} \left \langle \lambda_{2} \vert \lambda_{2} \right \rangle_{A} {}_{A}\left \langle \lambda_{1} \vert \lambda_{1} \right \rangle_{B} \right].
\end{align*}

so that

\begin{align*}
P_{S/A} \left( \lambda_{1} \to \lambda, \lambda_{2} \to \lambda \right) = 2 \left \lvert \lambda  \right \rvert_{A}^{2} \left \lvert \lambda  \right \rvert_{B}^{2} \pm 2 \left \lvert {}_{A}\left \langle \lambda \vert \lambda \right \rangle_{B} \right \rvert^{2}
\end{align*}

We have the ratio

\begin{align*}
\dfrac{\left \lvert {}_{A}\left \langle \lambda \vert \lambda \right \rangle_{B} \right \rvert^{2}}{\left \lvert \lambda  \right \rvert_{A}^{2} \left \lvert \lambda  \right \rvert_{B}^{2}} \xrightarrow[A = B]{\text{identical bosons}} 1 \quad \text{and} \quad \dfrac{\left \lvert {}_{A}\left \langle \lambda \vert \lambda \right \rangle_{B} \right \rvert^{2}}{\left \lvert \lambda  \right \rvert_{A}^{2} \left \lvert \lambda  \right \rvert_{B}^{2}} \xrightarrow[A = B]{\text{identical fermions}} 1.
\end{align*}

whose computation betrays indistinguishablity: any deviation from \(1\) reflects our ignorance of /some/ label that distinguishes these particles based on property \(P\).

That's how you determine whether you're in Bosonia or Fermionia. Are you so much better off now?

*Is it possible that some of these identical particles manifest a bosonic nature while the other a fermionic nature?*

To say that they do so is to say that spanning the state vector of these identical particles requires kets from /both/ bosonic and fermionic Hilbert spaces. Wait a second, what happened to once a boson/fermion always a boson/fermion? Indeed. If the evolution of the state vector of a bunch of identical particles is restricted to a fermionic/bosonic subspace, how could it possibly have picked those non-vanishing coefficients for the kets of the bosonic/fermionic subspace? Did it sneak a dip? There you have your answer.

** SOLVED Problem 10.1.1
CLOSED: [2022-11-14 Mon 18:07]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 17:17]--[2022-11-14 Mon 18:07] =>  0:50
:END:
*Show the following:*
*(1)* \(\left[ \Omega_{1}^{(1)} \otimes I^{(2)}, I^{(1)} \otimes \Lambda_{2}^{(2)} \right] = 0\) *for any* \(\Omega_{1}^{(1)}\) *and* \(\Lambda_{2}^{(2)}\) *(operators of particle 1 commute with those of particle 2).*

Because \(\Omega_{1}^{(1)} \otimes I^{(2)} \equiv \Omega_{1}\) and \(I^{(1)} \otimes \Lambda_{2}^{(2)} \equiv \Lambda_{2}\), we have

\begin{align*}
\left[ \Omega_{1}^{(1)} \otimes I^{(2)}, I^{(1)} \otimes \Lambda_{2}^{(2)} \right] = \left[ \Omega_{1}, \Lambda_{2} \right] = 0,
\end{align*}

where in the final step we have used the fact that operators of particle 1 commute with those of particle 2.

*(2)* \(\left( \Omega_{1}^{(1)} \otimes \Gamma_{2}^{(2)} \right) \left( \theta_{1}^{(1)} \otimes \Lambda_{2}^{(2)} \right) = \left( \Omega \theta \right)_{1}^{(1)} \otimes \left( \Gamma \Lambda \right)_{2}^{(2)}\).

Consider:

\begin{align*}
\left( \Omega_{1}^{(1)} \otimes \Gamma_{2}^{(2)} \right) \left( \theta_{1}^{(1)} \otimes \Lambda_{2}^{(2)} \right) \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle &\equiv \left( \Omega_{1}^{(1)} \otimes \Gamma_{2}^{(2)} \right) \vert \theta_{1}^{(1)} \omega_{1} \rangle \otimes \vert \Lambda_{2}^{(2)} \omega_{2} \rangle \\
&\equiv \vert \Omega_{1}^{(1)} \theta_{1}^{(1)} \omega_{1} \rangle \otimes \vert \Gamma_{2}^{(2)} \Lambda_{2}^{(2)} \omega_{2} \rangle \\
&\equiv \left( \left(\Omega \theta\right)_{1}^{(1)} \otimes \left( \Gamma \Lambda \right)_{2}^{(2)} \right) \vert \omega_{1} \rangle \otimes \vert \omega_{2} \rangle.
\end{align*}

Clearly \(\left( \Omega_{1}^{(1)} \otimes \Gamma_{2}^{(2)} \right) \left( \theta_{1}^{(1)} \otimes \Lambda_{2}^{(2)} \right) = \left( \Omega \theta \right)_{1}^{(1)} \otimes \left( \Gamma \Lambda \right)_{2}^{(2)}\).

*(3)* *If*

\begin{align*}
\left[ \Omega_{1}^{(1)}, \Lambda_{1}^{(1)} \right] = \Gamma_{1}^{(1)}
\end{align*}

*then*

\begin{align*}
\left[ \Omega_{1}^{(1) \otimes (2)}, \Lambda_{1}^{(1) \otimes (2)}  \right] = \Gamma_{1}^{(1)} \otimes I^{(2)}
\end{align*}

*and similarly with* \(1 \to 2\).

Use the result from part (2):

\begin{align*}
\left[ \Omega_{1}^{(1) \otimes (2)}, \Lambda_{1}^{(1) \otimes (2)}  \right] &= \left[ \Omega_{1}^{(1)} \otimes I_{2}^{(2)} , \Lambda_{1}^{(1)} \otimes I_{2}^{(2)}  \right] \\
&= \left(\Omega_{1}^{(1)} \otimes I_{2}^{(2)}\right) \left(\Lambda_{1}^{(1)} \otimes I_{2}^{(2)} \right) - \left(\Lambda_{1}^{(1)} \otimes I_{2}^{(2)} \right) \left(\Omega_{1}^{(1)} \otimes I_{2}^{(2)}\right) \\
&= \left( \left(\Omega \Lambda \right)_{1}^{(1)} \right) \otimes \left( \left( I I \right)_{2}^{(2)} \right) -
\left( \left(\Lambda \Omega  \right)_{1}^{(1)} \right) \otimes \left( \left( I I \right)_{2}^{(2)} \right) \\
&= \left[ \Omega_{1}^{(1)}, \Lambda_{1}^{(1)} \right] \otimes I_{2}^{(2)} = \Gamma_{1}^{(1)} \otimes I_{2}^{(2)}.
\end{align*}

The \(1 \to 2\) case is a straightforward extension.

*(4)* \(\left( \Omega_{1}^{(1) \otimes (2)} + \Omega_{2}^{(1) \otimes (2)} \right)^{2} = \left( \Omega_{1}^{2} \right)^{(1)} \otimes I^{(2)} + I^{(1)} \otimes \left( \Omega_{2}^{2} \right)^{(2)} + 2 \Omega_{1}^{(1)} \otimes \Omega_{2}^{(2)}\).

Use \(\Omega_{1}^{(1) \otimes (2)} = \Omega_{1}^{(1)} \otimes I_{2}^{(2)}\) and \(\Omega_{2}^{(1) \otimes (2)} = I_{1}^{(1)} \otimes \Omega_{1}^{(1)}\), expand, then apply the result of part (2).

\begin{align*}
\left( \Omega_{1}^{(1) \otimes (2)} + \Omega_{2}^{(1) \otimes (2)} \right)^{2} &=
\left( \Omega_{1}^{(1)} \otimes I_{2}^{(2)} + I_{1}^{(1)} \otimes \Omega_{1}^{(1)} \right)^{2} \\
&= \left(\Omega_{1}^{(1)} \otimes I_{2}^{(2)}\right) \left(\Omega_{1}^{(1)} \otimes I_{2}^{(2)}\right) + \left(  \Omega_{1}^{(1)} \otimes I_{2}^{(2)} \right) \left( I_{1}^{(1)} \otimes \Omega_{2}^{(2)} \right) \\
&+ \left(I_{1}^{(1)} \otimes \Omega_{2}^{(2)} \right) \left( \Omega_{1}^{(1)} \otimes I_{2}^{(2)} \right) + \left( I_{1}^{(1)} \otimes \Omega_{2}^{(2)} \right) \left( I_{1}^{(1)} \otimes \Omega_{2}^{(2)} \right)   \\
&= \left( \left( \Omega \Omega \right)_{1}^{(1)} \right) \otimes \left( \left( II \right)_{2}^{(2)} \right) + \left( \left( II \right)_{1}^{(1)} \right) \otimes \left( \left( \Omega \Omega \right)_{2}^{(2)} \right) \\
&+ \left( \left( \Omega I \right)_{1}^{(1)} \right) \otimes \left( \left( I \Omega \right)_{2}^{(2)}  \right)
+ \left( \left( I \Omega \right)_{1}^{(1)} \right) \otimes \left( \left( \Omega I \right)_{2}^{(2)}  \right) \\
&= \left( \Omega_{1}^{2} \right)^{(1)} \otimes I^{(2)} + I^{(1)} \otimes \left( \Omega_{2}^{2} \right)^{(2)} + 2 \Omega_{1}^{(1)} \otimes \Omega_{2}^{(2)}.
\end{align*}
** SOLVED Problem 10.1.2
CLOSED: [2022-11-14 Mon 18:58]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 18:39]--[2022-11-14 Mon 18:58] =>  0:19
:END:
*Imagine a fictitious world in which the single-particle Hilbert space is two-dimensional. Let us denote the basis vectors by* \(\ket{+}\) and \(\ket{-}\). *Let*

\begin{align*}
\sigma_{1}^{(1)} =
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\quad \text{and} \quad
\sigma_{2}^{(2)} =
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix}
\end{align*}

be operators in \(\mathbb{V}_{1}\) and \(\mathbb{V}_{2}\), respectively. The space \(\mathbb{V}_{1} \otimes \mathbb{V}_{2}\) is spanned by four vectors \(\vert + \rangle \otimes \vert + \rangle\), \(\vert + \rangle \otimes \vert - \rangle\), \(\vert - \rangle \otimes \vert + \rangle\), and \(\vert - \rangle \otimes \vert - \rangle\). *Show (using the method of images or otherwise) that*

*(1)*

\begin{align*}
\sigma_{1}^{(1) \otimes (2)} = \sigma_{1}^{(1)} \otimes I^{(2)} =
\begin{pmatrix}
a & 0 & b & 0 \\
0 & a & 0 & b \\
c & 0 & d & 0 \\
0 & c & 0 & d
\end{pmatrix}.
\end{align*}

\begin{align*}
\sigma_{1}^{(1)} \otimes I^{(2)} =
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\otimes
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
=
\begin{pmatrix}
a
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix} &
b
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix} \\
c
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix} &
d
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\end{pmatrix}
=
\begin{pmatrix}
a & 0 & b & 0 \\
0 & a & 0 & b \\
c & 0 & d & 0 \\
0 & c & 0 & d
\end{pmatrix}.
\end{align*}

*Recall that* \(\langle \alpha \vert \otimes \langle \beta \vert\) *is the bra corresponding to* \(\vert \alpha \rangle \otimes \vert \beta \rangle\) *).*

*(2)*

\begin{align*}
\sigma_{2}^{(1) \otimes (2)} =
\begin{pmatrix}
e & f & 0 & 0 \\
g & h & 0 & 0 \\
0 & 0 & e & f \\
0 & 0 & g & h
\end{pmatrix}.
\end{align*}

\begin{align*}
\sigma_{2}^{(1) \otimes (2)} = I^{(1)} \otimes \sigma_{2}^{(2)} =
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\otimes
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix}
=
\begin{pmatrix}
1
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} &
0
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} \\
0
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} &
1
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix}
\end{pmatrix}
=
\begin{pmatrix}
e & f & 0 & 0 \\
g & h & 0 & 0 \\
0 & 0 & e & f \\
0 & 0 & g & h
\end{pmatrix}.
\end{align*}

*(3)*

\begin{align*}
\left( \sigma_{1} \sigma_{2} \right)^{(1) \otimes (2)} = \sigma_{1}^{(1)} \otimes \sigma_{2}^{(2)} =
\begin{pmatrix}
ae & af & be & bf \\
ag & ah & bg & bh \\
ce & cf & de & df \\
cg & ch & dg & dh
\end{pmatrix}.
\end{align*}

*Do part (3) in two ways, by taking the matrix product of* \(\sigma_{1}^{(1) \otimes \left( 2 \right)}\) *and* \(\sigma_{2}^{(1) \otimes (2)}\) *and by directly computing the matrix elements of* \(\sigma_{1}^{(1)} \otimes \sigma_{2}^{(2)}\).

\begin{align*}
\left( \sigma_{1} \sigma_{2} \right)^{(1) \otimes (2)} = \sigma_{1}^{(1)} \otimes \sigma_{2}^{(2)} &=
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix} \otimes
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} \\
&=
\begin{pmatrix}
a
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} &
b
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} \\
c
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix} &
d
\begin{pmatrix}
e & f \\
g & h
\end{pmatrix}
\end{pmatrix} \\
&=
\begin{pmatrix}
ae & af & be & bf \\
ag & ah & bg & bh \\
ce & cf & de & df \\
cg & ch & dg & dh
\end{pmatrix}.
\end{align*}

\begin{align*}
\left( \sigma_{1} \sigma_{2} \right)^{(1) \otimes (2)} = \sigma_{1}^{(1) \otimes (2)} \sigma_{2}^{(1) \otimes (2)} &=
\begin{pmatrix}
a & 0 & b & 0 \\
0 & a & 0 & b \\
c & 0 & d & 0 \\
0 & c & 0 & d
\end{pmatrix}
\begin{pmatrix}
e & f & 0 & 0 \\
g & h & 0 & 0 \\
0 & 0 & e & f \\
0 & 0 & g & h
\end{pmatrix} \\
&=
\begin{pmatrix}
ae & af & be & bf \\
ag & ah & bg & bh \\
ce & cf & de & df \\
cg & ch & dg & dh
\end{pmatrix}.
\end{align*}

** SOLVED Problem 10.1.3
CLOSED: [2022-11-18 Fri 16:40]
:LOGBOOK:
CLOCK: [2022-11-18 Fri 15:46]--[2022-11-18 Fri 16:40] =>  0:54
CLOCK: [2022-11-18 Fri 01:50]--[2022-11-18 Fri 02:30] =>  0:40
:END:
*Consider the Hamiltonian of the coupled mass system:*

\begin{align*}
H = \dfrac{p_{1}^{2}}{2m} + \dfrac{p_{2}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} \left[ x_{1}^{2} + x_{2}^{2} + \left( x_{1} - x_{2} \right)^{2} \right].
\end{align*}

*We know from* =Example 1.8.6= *that* \(H\) *can be decoupled if we use normal coordinates*

\begin{align*}
x_{\text{I,II}} = \dfrac{x_{1} \pm x_{2}}{2^{1/2}}
\end{align*}

*and the corresponding momenta*

\begin{align*}
p_{\text{I,II}} = \dfrac{p_{1} \pm p_{2}}{2^{1/2}}.
\end{align*}

*(1)* *Rewrite* \(H\) *in terms of normal coordinates. Verify that the normal coordinates are also canonical, i.e., that*

\begin{align*}
\left \lbrace x_{i}, p_{j}  \right \rbrace = \delta_{ij} \quad \text{etc.;} \quad i,j = \text{I, II}.
\end{align*}

Solving for \(p_1\), \(p_2\), \(x_1\) and \(x_2\), in terms of the normal coordinates we get:

\begin{align*}
p_{1} = \dfrac{p_{\text{I}} + p_{\text{II}}}{2^{1/2}} \quad \text{and} \quad p_{2} = \dfrac{p_{\text{I}} - p_{\text{II}}}{2^{1/2}},
\end{align*}

\begin{align*}
x_{1} = \dfrac{x_{\text{I}} + x_{\text{II}}}{2^{1/2}} \quad \text{and} \quad x_{2} = \dfrac{x_{\text{I}} - x_{\text{II}}}{2^{1/2}}.
\end{align*}

Substituting in the Hamiltonian:

\begin{align*}
H = \dfrac{p_{\text{I}}^{2}}{2m} + \dfrac{p_{\text{II}}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} \left[ x_{\text{I}}^{2} + 3 x_{\text{II}}^{2} \right].
\end{align*}

\begin{align*}
\delta_{II} &\stackrel{?}{=} \left \lbrace x_I, p_I  \right \rbrace \\
&= \left \lbrace \dfrac{x_1 + x_{2}}{2^{1/2}}, \dfrac{p_1 + p_2}{2^{1/2}}  \right \rbrace \\
&= \dfrac{1}{2} \left[ \left \lbrace x_{1}, p_{1}  \right \rbrace + \left \lbrace x_{2} , p_{2} \right \rbrace + \left \lbrace x_{1}, p_{2}  \right \rbrace + \left \lbrace x_{2}, p_{1}  \right \rbrace \right] \\
&= \dfrac{1}{2} \left[ 1 + 1 \right] \\
&= 1.
\end{align*}

Simiarly, \(\left \lbrace x_{II}, p_{II}  \right \rbrace = 1\).

*Now quantize the system, promoting these variables to operators obeying*

\begin{align*}
\left[ X_{i}, P_{j} \right] = i \hbar \delta_{ij} \quad \text{etc.;} \quad i,j = \text{I, II}.
\end{align*}

*Write the eigenvalue equation for* \(H\) *in the simultaneous eigenbasis of* \(X_{1}\) and \(X_{\text{II}}\).

The quantum Hamiltonian is

\begin{align*}
H = \dfrac{P_{\text{I}}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} X_{\text{I}}^{2} + \dfrac{P_{\text{II}}^{2}}{2m} + \dfrac{3}{2} m \omega^{2} X_{\text{II}}^{2} \equiv H_{1} + H_{2},
\end{align*}

where

\begin{align*}
H_{\text{I}} = \dfrac{P_{\text{I}}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} X_{\text{I}}^{2},
\end{align*}

and

\begin{align*}
H_{\text{II}} = \dfrac{P_{\text{II}}^{2}}{2m} + \dfrac{3}{2} m \omega^{2} X_{\text{II}}^{2}.
\end{align*}

In the simultaneous eigenbasis of \(X_{\text{I}}\) and \(X_{\text{II}}\):

\begin{align*}
\vert \psi \rangle \xrightarrow[]{} \left \langle x_{\text{I}} x_{\text{II}} \vert \psi  \right \rangle = \psi \left( x_{\text{I}}, x_{\text{II}} \right),
\end{align*}

\begin{align*}
X_{i} \xrightarrow[]{} x_{i},
\end{align*}

and

\begin{align*}
P_{i} \xrightarrow[]{} - i \hbar \partial_{x_{i}},
\end{align*}

so that the eigenvalue equation

\begin{align*}
H \vert \psi \rangle = \left( H_{\text{I}} + H_{\text{II}} \right) \vert \psi \rangle = E \vert \psi \rangle
\end{align*}

is:

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{x_{\text{I}}}^{2} + \dfrac{1}{2} m \omega^{2} x_{\text{I}}^{2} \right] \psi \left( x_{\text{I}}, x_{\text{II}} \right)
&+ \left[ - \dfrac{i \hbar}{2m} \partial_{x_{\text{II}}}^{2} + \dfrac{3}{2} m \omega^{2} x_{\text{II}}^{2} \right] \psi \left( x_{\text{I}}, x_{\text{II}} \right) \\
&= E \psi \left( x_{\text{I}}, x_{\text{II}} \right).
\end{align*}

*(2)* *Quantize the system directly, by promoting* \(x_{1}\), \(x_{2}\), \(p_{1}\), \(p_{2}\) *to quantum operators. Write the eigenvalue equation for* \(H\) *in the simultaneous eigenbasis of* \(X_{1}\) *and* \(X_{2}\). *Now change from* \(x_{1}\), \(x_{2}\) *(and of course* \(\partial_{x_1}\), \(\partial_{x_{2}}\) *) to* \(x_{\text{I}}\), \(x_{\text{II}}\) *(and* \(\partial_{x_\text{I}}, \partial_{x_{\text{II}}}\) *) in the differential equation. You should end up with the result from part (1).*

\begin{align*}
H = \dfrac{P_{1}^{2}}{2m} + \dfrac{P_{2}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} \left[ X_{1}^{2} + X_{2}^{2} + \left( X_{1} - X_{2} \right)^{2} \right].
\end{align*}

In the simultaneous eigenbasis of \(X_{1}\) and \(X_{2}\):

\begin{align*}
\Big [ - \dfrac{i \hbar}{2m} \partial_{x_{\text{1}}}^{2} &+ \dfrac{1}{2} m \omega^{2} x_{\text{1}}^{2} \Big ] \psi \left( x_{\text{1}}, x_{\text{2}} \right) \\
&+ \left[ - \dfrac{i \hbar}{2m} \partial_{x_{\text{2}}}^{2} + \dfrac{1}{2} m \omega^{2} x_{\text{2}}^{2} \right] \psi \left( x_{\text{1}}, x_{\text{2}} \right) \\
&+ \left( x_{1} - x_{2} \right)^{2} \psi \left( x_{\text{1}}, x_{\text{2}} \right) = E \psi \left( x_{\text{1}}, x_{\text{2}} \right).
\end{align*}

Substituting

\begin{align*}
-i \hbar \partial_{x_{1}} = \dfrac{- i \hbar \partial_{x_{\text{I}}} - i \hbar \partial_{x_{\text{II}}}}{2^{1/2}} \quad \text{and} \quad -i \hbar \partial_{x_{2}} = \dfrac{- i \hbar \partial_{x_{\text{I}}} + i \hbar \partial_{x_{\text{II}}}}{2^{1/2}},
\end{align*}

\begin{align*}
x_{1} = \dfrac{x_{\text{I}} + x_{\text{II}}}{2^{1/2}} \quad \text{and} \quad x_{2} = \dfrac{x_{\text{I}} - x_{\text{II}}}{2^{1/2}},
\end{align*}

and simplifying (mentally), we recover:

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{x_{\text{I}}}^{2} + \dfrac{1}{2} m \omega^{2} x_{\text{I}}^{2} \right] \psi \left( x_{\text{I}}, x_{\text{II}} \right)
&+ \left[ - \dfrac{i \hbar}{2m} \partial_{x_{\text{II}}}^{2} + \dfrac{3}{2} m \omega^{2} x_{\text{II}}^{2} \right] \psi \left( x_{\text{I}}, x_{\text{II}} \right) \\
&= E \psi \left( x_{\text{I}}, x_{\text{II}} \right).
\end{align*}

** SOLVED Problem 10.2.1
CLOSED: [2022-11-18 Fri 17:00]
:LOGBOOK:
CLOCK: [2022-11-18 Fri 16:51]--[2022-11-18 Fri 17:00] =>  0:09
:END:
*Recall that a particle in a one-dimensional box extending from* \(x=0\) *to* \(x=L\) *is confined to the region* \(0 \leq x \leq L\); *its wave function vanishes at the edges* \(x = 0\) *and* \(L\) *and beyond* (=Exercise 5.2.5=). *Consider now a particle confined in a three-dimensional cubic box of volume* \(L^{3}\). *Choosing as the origin one of its corners, and the* \(x, y, z\) *axes along the three edges meeting there, show that the normalized energy eigenfunctions are*

\begin{align*}
\psi_{E} \left( x, y, z \right) = \left( \dfrac{2}{L} \right)^{1/2} \sin \left( \dfrac{n_{x} \pi x}{L} \right) \left( \dfrac{2}{L} \right)^{1/2} \sin \left( \dfrac{n_{y} \pi y}{L} \right) \left( \dfrac{2}{L} \right)^{1/2} \sin \left( \dfrac{n_{z} \pi z}{L} \right)
\end{align*}

*where*

\begin{align*}
E = \dfrac{\hbar^{2} \pi^{2}}{2 M L^{2}} \left( n_{x}^{2} + n_{y}^{2} + n_{z}^{2} \right)
\end{align*}

*and* \(n_{i}\) *are positive integers.*

Assume that one corner of the box is pinned to the origin and edges all of length \(L\) lay along the \(x\), \(y\), and \(z\) direction respectively of a rectangular coordinate system. Start with the rewrite

\begin{equation*}
 \left[ \partial^{2}_{x} + \partial^{2}_{y} + \partial^{2}_{z} \right] \psi(x,y,z) = - \left(\dfrac{2mE}{\hbar^{2}}\right) \psi(x,y,z).
\end{equation*}

/Assuming/ an ansatz of the form \(\psi(x,y,z) = \Psi_{x}(x)\Psi_{y}(y)\Psi_{z}(z)\) separate variables as

\begin{equation*}
D_{x}^{2} \Psi_{x} \equiv - k_{x}^{2} \Psi_{x} \quad \text{where} \quad k_{x} > 0,
\end{equation*}

\begin{equation*}
D_{y}^{2} \Psi_{y} \equiv - k_{y}^{2} \Psi_{y} \quad \text{where} \quad k_{y} > 0,
\end{equation*}

\begin{equation*}
D_{z}^{2} \Psi_{z} \equiv - k_{z}^{2} \Psi_{z} \quad \text{where} \quad k_{z} > 0,
\end{equation*}

such that

\begin{equation*}
k_{x}^{2} + k_{y}^{2} + k_{z}^{2} \equiv k^{2} = \dfrac{2mE}{\hbar^{2}}.
\end{equation*}

The pure solutions

\begin{equation*}
\Psi_{x} (x) = \exp \left \lbrace \pm i \thinspace k_{x} x  \right \rbrace, \quad \Psi_{y} (y) = \exp \left \lbrace \pm i \thinspace k_{y} y \right \rbrace, \quad \Psi_{z} (z) = \exp \left \lbrace \pm i \thinspace k_{z} z \right \rbrace,
\end{equation*}

furnish as superpositions the general solutions

\begin{equation*}
\Psi_{x} (x) = A_{k_{x}} \exp \left \lbrace i k_{x} x  \right \rbrace + B_{k_{x}} \exp \left \lbrace - i k_{x} x  \right \rbrace,
\end{equation*}

\begin{equation*}
\Psi_{y} (y) = A_{k_{y}} \exp \left \lbrace i k_{y} y  \right \rbrace + B_{k_{y}} \exp \left \lbrace - i k_{y} y \right \rbrace,
\end{equation*}

\begin{equation*}
\Psi_{z} (z) = A_{k_{z}} \exp \left \lbrace i k_{z} z  \right \rbrace + B_{k_{z}} \exp \left \lbrace - i k_{z} z \right \rbrace.
\end{equation*}

The boundary conditions and their respective implications are

\begin{equation*}
\Psi_{x} (a) = 0 \Longrightarrow A_{k_{x}} = - B_{k_{x}} \quad \text{and} \quad k_{x} L = n_{x} \pi, \quad \text{where} \quad n_{x} = 1, \thinspace 2, \dotso
\end{equation*}

\begin{equation*}
\Psi_{y} (b) = 0 \Longrightarrow A_{k_{y}} = - B_{k_{y}} \quad \text{and} \quad k_{y} L = n_{y} \pi, \quad \text{where} \quad n_{y} = 1, \thinspace 2, \dotso
\end{equation*}

\begin{equation*}
\Psi_{z} (c) = 0 \Longrightarrow A_{k_{z}} = - B_{k_{z}} \quad \text{and} \quad k_{z} L = n_{z} \pi, \quad \text{where} \quad n_{z} = 1, \thinspace 2, \dotso
\end{equation*}

so that the /full/ general solution consistent with the boundary conditions is

\begin{equation*}
\psi (x, y, z) = \sum_{n_{x}, n_{y}, n_{z}}^{\prime} A_{n_{x} n_{y} n_{z}} \sin \left( n_{x} \pi \left[ x/L \right] \right) \thinspace
\sin \left( n_{y} \pi \left[ y/L \right] \right) \thinspace
\sin \left( n_{z} \pi \left[ z/L \right] \right) \thinspace.
\end{equation*}

The sum is restricted so that

\begin{equation*}
E = \dfrac{\pi^{2} \hbar^{2}}{2m L^{2}} \left( n_{x}^{2} + n_{y}^{2} + n_{z}^{2} \right).
\end{equation*}


\(n_{x}\), \(n_{y}\), \(n_{z}\) are /strictly positive/ because thats the only possibility consistent with \(k_{x}\), \(k_{y}\), and \(k_{z}\) being strictly positive and \(a, b, c \geq 0\).

\(A_{n_{x} n_{y} n_{z}}\) is determined by imposing \(\int \int \int \left \lvert \psi  \right \rvert^{2} = 1\) and evaluates to:

\begin{align*}
A_{n_{x} n_{y} n_{z}} = \left( \dfrac{2}{L} \right)^{3/2}.
\end{align*}

The /full/ general solution reduces to:

\begin{equation*}
\psi (x, y, z) = \sum_{n_{x}, n_{y}, n_{z}}^{\prime} \left( \dfrac{2}{L} \right)^{3/2} \sin \left( n_{x} \pi \left[ x/L \right] \right) \thinspace
\sin \left( n_{y} \pi \left[ y/L \right] \right) \thinspace
\sin \left( n_{z} \pi \left[ z/L \right] \right) \thinspace.
\end{equation*}

Clearly then the energy eigenfunctions are:

\begin{align*}
\psi_{E} (x, y, z) = \left( \dfrac{2}{L} \right)^{3/2} \sin \left( n_{x} \pi \left[ x/L \right] \right) \thinspace
\sin \left( n_{y} \pi \left[ y/L \right] \right) \thinspace
\sin \left( n_{z} \pi \left[ z/L \right] \right) \thinspace.
\end{align*}

** SOLVED Problem 10.2.2
CLOSED: [2022-11-18 Fri 17:58]
:LOGBOOK:
CLOCK: [2022-11-18 Fri 17:07]--[2022-11-18 Fri 17:58] =>  0:51
:END:
*Quantize the two-dimensional oscillator for which*

\begin{align*}
H = \dfrac{p_{x}^{2} + p_{y}^{2}}{2m} + \dfrac{1}{2} m \omega_{x}^{2} x^{2} + \dfrac{1}{2} m \omega_{y}^{2} y^{2}.
\end{align*}

*(1)* *Show that the allowed energies are*

\begin{align*}
E = \left( n_{x} + 1/2 \right) \hbar \omega_{x} + \left( n_{y} + 1/2 \right) \hbar \omega_{y}, \qquad n_{x}, n_{y} = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

Quantize the system first:

\begin{align*}
H = \dfrac{P_{X}^{2} + P_{Y}^{2}}{2m} + \dfrac{1}{2} m \omega_{X}^{2} X^{2} + \dfrac{1}{2} m \omega_{Y}^{2} Y^{2}.
\end{align*}

Descend to the coordinate basis spanned by the simultaneous eigenkets \(\vert xy \rangle\) of \(X\) and \(Y\) and write the eigenvalue equation for \(H\):

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{x}^{2} + \dfrac{1}{2} m \omega_{x}^{2} x^{2} \right] \psi \left( x, y\right)
&+ \left[ - \dfrac{i \hbar}{2m} \partial_{y}^{2} + \dfrac{1}{2} m \omega_{y}^{2} y^{2} \right] \psi \left( x, y \right) \\
&= E \psi \left( x, y \right).
\end{align*}

Feed ansatz \(\psi \left( x, y \right) = \Psi_{x} \left( x \right) \Psi_{y} \left( y \right)\) into the eigenvalue equation and separate variables to obtain:

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{x}^{2} + \dfrac{1}{2} m \omega_{x}^{2} x^{2} \right] \Psi_{x} \left( x\right) = E_{x} \Psi_{x} \left( x \right),
\end{align*}

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{y}^{2} + \dfrac{1}{2} m \omega_{y}^{2} y^{2} \right] \Psi_{y} \left( y \right) = E_{y} \Psi_{y} \left( y \right),
\end{align*}

so that

\begin{align*}
E = E_{x} + E_{y}.
\end{align*}

Separation of variables in the coordinate basis has decoupled the state vector into two /independent/ harmonic oscillator wave functions along the \(x\) and \(y\) direction. It immediately follows

\begin{align*}
E_{x} = \hbar \omega_{x} \left( n_{x} + 1/2 \right), \qquad n_{x} = 0, \thinspace 1, \thinspace 2, \thinspace \dotso.
\end{align*}

\begin{align*}
E_{y} = \hbar \omega_{y} \left( n_{y} + 1/2 \right), \qquad n_{y} = 0, \thinspace 1, \thinspace 2, \thinspace \dotso.
\end{align*}

so that

\begin{align*}
E = E_{x} + E_{y} = \hbar \omega_{x} \left( n_{x} + 1/2 \right) + \hbar \omega_{y} \left( n_{y} + 1/2 \right), \qquad n_{x}, n_{y} = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

*(2)* *Write down the corresponding wave functions in terms of single oscillator wave functions. Verify that they have definite parity (even/odd) number* \(x \to -x\), \(y \to -y\) *and that the parity depends only on* \(n = n_{x} + n_{y}\).

The single oscillator wavefunctions have parity:

\begin{align*}
\Psi_{x} \left( -x \right) = \left( -1 \right)^{n_{x}} \Psi_{x} \left( x \right),
\end{align*}

\begin{align*}
\Psi_{y} \left( -y \right) = \left( -1 \right)^{n_{y}} \Psi_{y} \left( y \right).
\end{align*}

so that

\begin{align*}
\psi \left( -x, -y \right) &= \Psi_{x} \left( -x \right) \Psi_{y} \left( -y \right) \\
&= \left( -1 \right)^{n_{x} + n_{y}} \Psi_{x} \left( x \right) \Psi_{y} \left( y \right) = \left( -1 \right)^{n} \psi \left( x, y \right),
\end{align*}

where \(n = n_{x} + n_{y}\).

*(3)* *Consider next the /isotropic oscillator/* \(\left( \omega_{x} = \omega_{y} \right)\). *Write /explicitly/, normalized eigenfunctions of the first three states (that is, for the cases* \(n=0\) *and* \(1\) *).* *Reexpress your results in terms of polar coordinates* \(\rho\) *and* \(\phi\) *(for later use)*. *Show that the degeneracy of a level with* \(E = \left( n + 1 \right) \hbar \omega\) *is* \((n + 1)\).

For \(n =0\) we must have \(n_{x} = n_{y} = 0\) so that the eigenfunction is

\begin{align*}
\psi_{00} \left( x, y \right) &=  \Psi_{x,0} \left( x \right) \Psi_{y,0} \left( y \right) \\
&= \left(\left( \dfrac{m \omega_{x}}{\pi \hbar} \right)^{1/4} \exp \left \lbrace - \left( \dfrac{m \omega_{x}}{2 \hbar} \right) x^{2}  \right \rbrace\right) \times \\
& \left(\left( \dfrac{m \omega_{y}}{\pi \hbar} \right)^{1/4} \exp \left \lbrace - \left(\dfrac{m \omega_{y}}{2 \hbar}\right) x^{2}  \right \rbrace\right) \\
&= \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \left( x^{2} + y^{2} \right)  \right \rbrace.
\end{align*}

For \(n=1\) we have the possibilities \(n_{x} = 0, \thinspace n_{y} = 1\) or \(n_{x} = 1, n_{y} = 0\) so that the degenerate eigenfunctions are:

\begin{align*}
\psi_{01} \left( x, y \right) &= \Psi_{x,0} \left( x \right) \Psi_{y,1} \left( y \right) \\
&= \left(\left( \dfrac{m \omega_{x}}{\pi \hbar} \right)^{1/4} \exp \left \lbrace - \left( \dfrac{m \omega_{x}}{2 \hbar} \right)  x^{2}  \right \rbrace\right) \times \\
& \left( \left( \dfrac{m \omega_{y}}{\pi \hbar} \right)^{1/4} \left( 2^{1/2} y \right) \exp \left \lbrace - \left( \dfrac{m \omega_{y}}{2 \hbar} \right) y^{2}  \right \rbrace \right) \\
&= 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} y \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \left( x^{2} + y^{2} \right)  \right \rbrace,
\end{align*}

and

\begin{align*}
\psi_{10} \left( x, y \right) &= \Psi_{x,1} \left( x \right) \Psi_{y,0} \left( y \right) \\
&= \left( \left( \dfrac{m \omega_{x}}{\pi \hbar} \right)^{1/4} \left( 2^{1/2} x \right) \exp \left \lbrace - \left( \dfrac{m \omega_{x}}{2 \hbar} \right) x^{2}  \right \rbrace \right) \times \\
& \left(\left( \dfrac{m \omega_{y}}{\pi \hbar} \right)^{1/4} \exp \left \lbrace - \left( \dfrac{m \omega_{y}}{2 \hbar} \right)  y^{2}  \right \rbrace\right) \\
&= 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} x \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \left( x^{2} + y^{2} \right)  \right \rbrace.
\end{align*}

The change to polar coordinates is trivial:

\begin{align*}
\psi_{00} \left( \rho \right) = \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2}  \right \rbrace,
\end{align*}

\begin{align*}
\psi_{01} \left( \rho, \theta \right) = 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \rho \sin \theta \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2} \right \rbrace,
\end{align*}

\begin{align*}
\psi_{10} \left( \rho, \theta \right) = 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \rho \cos \theta \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2} \right \rbrace.
\end{align*}

Now to show the result on degeneracy, note that we simply need the number of ways of partitioning \(n\) quanta into \(2\) separate non-negative aggregates of quanta (it's the /stars and bars/ problem of counting - /For any pair of positive integers/ \(n\) /and/ \(k\), /the number of/ \(k\) -/tuples of *non-negative* integers whose sum is/ \(n\) /is equal to the number of multisets of cardinality/ \(n\) /taken from a set of size/ \(k\), /or equivalently, the number of multisets of cardinality/ \(k - 1\) /taken from a set of size/ \(n + 1\): \(\binom{n+k-1}{k-1}\)):

\begin{align*}
\text{Degeneracy} = \binom{n+2-1}{2-1} = \dfrac{\left( n+1 \right)!}{1! \thinspace n!} = n + 1.
\end{align*}

** SOLVED Problem 10.2.3
CLOSED: [2022-11-18 Fri 18:50]
:LOGBOOK:
CLOCK: [2022-11-18 Fri 17:58]--[2022-11-18 Fri 18:50] =>  0:52
:END:
*Quantize the three-dimensional /isotropic oscillator/ for which*

\begin{align*}
H = \dfrac{p_{x}^{2} + p_{y}^{2} + p_{z}^{2}}{2m} + \dfrac{1}{2} m \omega^{2} \left( x^{2} + y^{2} + z^{2} \right).
\end{align*}

*(1)* *Show that* \(E = \left( n + 3/2 \right) \hbar \omega\); \(n = n_{x} + n_{y} + n_{z}\); \(n_{x}, \thinspace n_{y}, \thinspace n_{z} = 0, \thinspace 1, \thinspace 2, \dotso\)

Quantize the system first:

\begin{align*}
H = \dfrac{P_{X}^{2} + P_{Y}^{2} + P_{Z}^{2}}{2m} + \dfrac{1}{2} m \omega_{X}^{2} X^{2} + \dfrac{1}{2} m \omega_{Y}^{2} Y^{2} + \dfrac{1}{2} m \omega_{Z}^{2} Z^{2}.
\end{align*}

Descend to the coordinate basis spanned by the simultaneous eigenkets \(\vert xyz \rangle\) of \(X\) and \(Y\) and \(Z\) to write the eigenvalue equation for \(H\):

\begin{align*}
&\left[ - \dfrac{i \hbar}{2m} \partial_{x}^{2} + \dfrac{1}{2} m \omega_{x}^{2} x^{2} \right] \psi \left( x, y, z \right)
+ \left[ - \dfrac{i \hbar}{2m} \partial_{y}^{2} + \dfrac{1}{2} m \omega_{y}^{2} y^{2} \right] \psi \left( x, y, z \right) \\
&+ \left[ - \dfrac{i \hbar}{2m} \partial_{z}^{2} + \dfrac{1}{2} m \omega_{z}^{2} z^{2} \right] \psi \left( x, y, z\right) = E \psi \left( x, y,z \right).
\end{align*}

Feed ansatz \(\psi \left( x, y, z \right) = \Psi_{x} \left( x \right) \Psi_{y} \left( y \right) \Psi_{z} \left( z \right)\) into the eigenvalue equation and separate variables to obtain:

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{x}^{2} + \dfrac{1}{2} m \omega_{x}^{2} x^{2} \right] \Psi_{x} \left( x\right) = E_{x} \Psi_{x} \left( x \right),
\end{align*}

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{y}^{2} + \dfrac{1}{2} m \omega_{y}^{2} y^{2} \right] \Psi_{y} \left( y \right) = E_{y} \Psi_{y} \left( y \right),
\end{align*}

\begin{align*}
\left[ - \dfrac{i \hbar}{2m} \partial_{z}^{2} + \dfrac{1}{2} m \omega_{z}^{2} z^{2} \right] \Psi_{z} \left( z \right) = E_{z} \Psi_{z} \left( z \right),
\end{align*}

so that

\begin{align*}
E = E_{x} + E_{y} + E_{z}.
\end{align*}

Separation of variables in the coordinate basis has decoupled the state vector into three /independent/ harmonic oscillator wave functions along the \(x\) , \(y\), and \(z\) direction. It immediately follows

\begin{align*}
E_{x} = \hbar \omega_{x} \left( n_{x} + 1/2 \right), \qquad n_{x} = 0, \thinspace 1, \thinspace 2, \thinspace \dotso.
\end{align*}

\begin{align*}
E_{y} = \hbar \omega_{y} \left( n_{y} + 1/2 \right), \qquad n_{y} = 0, \thinspace 1, \thinspace 2, \thinspace \dotso.
\end{align*}

\begin{align*}
E_{z} = \hbar \omega_{z} \left( n_{z} + 1/2 \right), \qquad n_{z} = 0, \thinspace 1, \thinspace 2, \thinspace \dotso.
\end{align*}

so that

\begin{align*}
E &= E_{x} + E_{y} + E_{z} \\
&= \hbar \omega_{x} \left( n_{x} + 1/2 \right) + \hbar \omega_{y} \left( n_{y} + 1/2 \right) + \hbar \omega_{z} \left( n_{z} + 1/2 \right), \\
&\qquad \qquad \qquad n_{x}, n_{y}, n_{z} = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

For the isotropic oscillator \(\omega_x = \omega_y = \omega_z \equiv \omega\) so that with \(n \equiv n_{x} + n_{y} + n_{z}\) we have:

\begin{align*}
E = \hbar \omega \left( n_{x} + n_{y} + n_{z} + \dfrac{3}{2} \right) = \hbar \omega \left( n + \dfrac{3}{2} \right), \qquad n_{x}, n_{y}, n_{z} = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

*(2)* *Write the corresponding eigenfunctions in terms of single-oscillator wave functions and verify that the parity of the level with a given* \(n\) *is* \((-1)^{n}\). *Reexpress the first four states in terms of spherical coordinates. Show that the degeneracy of a level with energy* \(E = \left( n + 3/2 \right) \hbar \omega\) *is* \(\left( n + 1 \right) \left( n + 2 \right)/2\).

The single oscillator wavefunctions have parity:

\begin{align*}
\Psi_{x} \left( -x \right) = \left( -1 \right)^{n_{x}} \Psi_{x} \left( x \right),
\end{align*}

\begin{align*}
\Psi_{y} \left( -y \right) = \left( -1 \right)^{n_{y}} \Psi_{y} \left( y \right),
\end{align*}

\begin{align*}
\Psi_{z} \left( -z \right) = \left( -1 \right)^{n_{z}} \Psi_{z} \left( z \right),
\end{align*}

so that

\begin{align*}
\psi \left( -x, -y, -z \right) &= \Psi_{x} \left( -x \right) \Psi_{y} \left( -y \right) \Psi_{z} \left( -z \right) \\
&= \left( -1 \right)^{n_{x} + n_{y} + n_{z}} \Psi_{x} \left( x \right) \Psi_{y} \left( y \right) \Psi_{z} \left( z \right) = \left( -1 \right)^{n} \psi \left( x, y, z \right).
\end{align*}

where \(n = n_{x} + n_{y} + n_{z}\).

I'm gonna skip the grind. What I'm about to write should be obvious from the answer to =Exercise 10.2.2=. In spherical coordinates:

\begin{align*}
\psi_{000} \left( \rho \right) = \left( \dfrac{m \omega}{\pi \hbar} \right)^{3/4} \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2}  \right \rbrace,
\end{align*}

\begin{align*}
\psi_{001} \left( \rho, \theta \right) = 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \rho \cos \theta \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2} \right \rbrace,
\end{align*}

\begin{align*}
\psi_{010} \left( \rho, \theta, \phi \right) = 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \rho \sin \theta \sin \phi \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2} \right \rbrace.
\end{align*}

\begin{align*}
\psi_{100} \left( \rho, \theta, \phi \right) = 2^{1/2} \left( \dfrac{m \omega}{\pi \hbar} \right)^{1/2} \rho \sin \theta \cos \phi \thinspace \exp \left \lbrace - \left( \dfrac{m \omega}{2 \hbar} \right) \rho^{2} \right \rbrace.
\end{align*}

Now to show the result on degeneracy, note that we simply need the number of ways of partitioning \(n\) quanta into \(3\) separate /non-negative/ aggregates of quanta (it's the /stars and bars/ problem of counting - /For any pair of positive integers/ \(n\) /and/ \(k\), /the number of/ \(k\) -/tuples of *non-negative* integers whose sum is/ \(n\) /is equal to the number of multisets of cardinality/ \(n\) /taken from a set of size/ \(k\), /or equivalently, the number of multisets of cardinality/ \(k - 1\) /taken from a set of size/ \(n + 1\): \(\binom{n+k-1}{k-1}\)):

\begin{align*}
\text{Degeneracy} = \binom{n+3-1}{3-1} = \dfrac{\left( n+2 \right)!}{2! \thinspace n!} = \dfrac{\left( n + 2 \right) \left( n + 1 \right)}{2}.
\end{align*}

** SOLVED Problem 10.3.1
CLOSED: [2022-11-19 Sat 04:58]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 04:24]--[2022-11-19 Sat 04:57] =>  0:33
CLOCK: [2022-11-19 Sat 04:24]--[2022-11-19 Sat 04:24] =>  0:00
:END:
*Two identical bosons are found to be in states* \(\vert \phi \rangle\) *and* \(\vert \psi \rangle\). *Write down the normalized state vector describing the system when* \(\left \langle \phi \vert \psi \right \rangle \neq 0\).

Suppose that the normalized wavefunction for the system \(\vert \varphi \rangle\) is:

\begin{align*}
\vert \varphi \rangle = \alpha \left( \vert \phi \psi \rangle + \vert \psi \phi \rangle \right) 
\end{align*}

for complex \(\alpha\). The normalization is

\begin{align*}
1 = \left \langle \varphi \vert \varphi \right \rangle &= \left \lvert \alpha  \right \rvert^{2} \left[ \left \langle \phi \psi \vert \phi \psi \right \rangle + \left \langle \phi \psi \vert \psi \phi \right \rangle + \left \langle \psi \phi \vert \phi \psi \right \rangle + \left \langle \psi \phi \vert \psi \phi \right \rangle \right] \\
&= \left \lvert \alpha  \right \rvert^{2} \left[ \left \langle \phi \psi \vert \phi \psi \right \rangle + \left \langle \phi \psi \vert \psi \phi \right \rangle + \left \langle \psi \phi \vert \phi \psi \right \rangle + \left \langle \psi \phi \vert \psi \phi \right \rangle \right] \\
&= \left \lvert \alpha  \right \rvert^{2} \left[ \left \langle \phi \vert \phi \right \rangle \left \langle \psi \vert \psi \right \rangle  + 2 \left \langle \psi \vert \phi \right \rangle \left \langle \phi \vert \psi \right \rangle + \left \langle \psi \vert \psi \right \rangle \left \langle \phi \vert \phi \right \rangle \right] \\
&= \left \lvert \alpha  \right \rvert^{2} \left[ 1 + 2 \left \lvert \left \langle \psi \vert \phi \right \rangle  \right \rvert^{2} + 1 \right] \\
&\Longrightarrow \alpha = \dfrac{1}{2^{1/2}\left( 1 + \left \lvert \left \langle \phi \vert \psi \right \rangle  \right \rvert^{2} \right)^{1/2}}.
\end{align*}

In the second step we have a manipulation \(\left \langle \phi \psi \vert \phi \psi \right \rangle = \sum_{\vert \psi \phi \rangle} \langle \phi \psi \vert \psi \phi \rangle \langle \psi \phi \vert \phi \psi \rangle = \left \langle \phi \vert \phi \right \rangle \left \langle \psi \vert \psi \right \rangle\) by noting that \(\vert \phi \psi \rangle\) and \(\langle \phi \psi \vert\) is just notation for \(\vert \phi^{(1)} \rangle \otimes \vert \psi^{(2)} \rangle\) and \(\langle \phi^{(1)} \vert \otimes \langle \psi^{(2)} \vert\) respectively and used the results from =Exercise 10.1.1= for all of the four inner products between direct product states. Thus

\begin{align*}
\vert \varphi \rangle = \dfrac{\vert \phi \psi \rangle + \vert \psi \phi \rangle}{2^{1/2}\left( 1 + \left \lvert \left \langle \phi \vert \psi \right \rangle  \right \rvert^{2} \right)^{1/2}}.
\end{align*}

** SOLVED Problem 10.3.2
CLOSED: [2022-11-19 Sat 05:11]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 05:03]--[2022-11-19 Sat 05:11] =>  0:08
:END:
*When an energy measurement is made on a system of three bosons in a box, the* \(n\) *values obtained were* \(3\), \(3\), *and* \(4\). *Write down a symmetrized, normalized state vector.*

The un-normalized symmetrized state vector is

\begin{align*}
\vert 3 3 4 \rangle &= \dfrac{1}{\left( 3! \right)^{1/2}} \left[ \vert 334 \rangle + \vert 343 \rangle + \vert 3 4 3 \rangle + \vert 334 \rangle + \vert 4 3 3 \rangle + \vert 4 3 3 \rangle \right] \\
&= \dfrac{2}{\left( 3! \right)^{1/2}} \left[ \vert 334 \rangle + \vert 343 \rangle + \vert 4 3 3 \rangle \right].
\end{align*}

The normalization is straightforward and may be done mentally: The symmetrized, normalizeed state vector is:

\begin{align*}
\vert 3 3 4  \rangle = \dfrac{1}{3^{1/2}} \left[ \vert 334 \rangle + \vert 343 \rangle + \vert 433 \rangle \right].
\end{align*}

** SOLVED Problem 10.3.3
CLOSED: [2022-11-19 Sat 05:31]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 05:15]--[2022-11-19 Sat 05:31] =>  0:16
:END:
*Imagine a situation in which there are three identical particles and only three states* \(a\), \(b\), *and* \(c\) *available to them. Show that the total number of allowed, distinct configurations for this system is*
*(1)* \(27\) *if they are labeled*

Straightforward. All of the direct product states \(\vert n_1 \rangle \otimes \vert n_2 \rangle \otimes \vert n_3 \rangle\) for \(n_{1}, n_{2}, n_{3} = a, b, c\) are distinct configurations for this system and there are \(27\) such direct product states.

*(2)* \(10\) *if they are bosons*

\(3\) distinct states for when all of the particles are in the same state, \(6\) distinct state, \(2\) each for when two of the particles are in the same state, \(1\) distinct state for when all of the particles occupy different states for a total of \(10\) distinct configurations.

*(3)* \(1\) *if they are fermions.*

\(1\) distinct configuration cause Pauli.

** SOLVED Problem 10.3.4
CLOSED: [2022-11-19 Sat 05:48]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 05:34]--[2022-11-19 Sat 05:48] =>  0:14
:END:
*Two identical particles of mass* \(m\) *are in a one-dimensional box of length* \(L\). *Energy measurement of the system yields the value* \(E_{\text{sys}}= \hbar^{2} \pi^{2} / m L^{2}\). *Write down the state vector of the system. Repeat for* \(E_{\text{sys}} = 5 \hbar^{2} \pi^{2}/ 2 m L^{2}\). *(There are two possible vectors in this case.) You are not told if they are bosons or fermions. You may assume that the only degrees of freedom are orbital.*

The expression for energy in terms of the quantum numbers \(n_{1}\) and \(n_{2}\) of particle \(1\) and \(2\) respectively are:

\begin{align*}
E = \dfrac{\hbar^{2} \pi^{2}}{2 m L^{2}} \left( n_{1}^{2} + n_{2}^{2} \right).
\end{align*}

For \(E_{\text{sys}} = \hbar^{2} \pi^{2} / m L^{2}\), the only possibility is \(n_{1} = 1\) and \(n_{2} = 1\). They can't be femions cause Pauli. The bosonic state vector then is

\begin{align*}
\psi_{S} = \vert 1 1 \rangle.
\end{align*}

For \(E_{\text{sys}} = 5 \hbar^{2} \pi^{2} / 2 m L^{2}\), the possibilities are \(n_{1} = 1\), \(n_{2} = 2\) or \(n_{1} = 2\), \(n_{2} = 1\). If the ask refers to the same system, they /can't/ be fermions, not cause Pauli, but cause once a boson, always a boson. So the state vector is

\begin{align*}
\psi_{S} = 2^{1/2} \left( \vert 12 \rangle + \vert 21 \rangle \right).
\end{align*}

For a different system, nothing prevents them being fermions so that

\begin{align*}
\psi_{A} = 2^{1/2} \left( \vert 12 \rangle - \vert 21 \rangle \right).
\end{align*}

** SOLVED Problem 10.3.5
CLOSED: [2022-11-19 Sat 07:36]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 05:49]--[2022-11-19 Sat 07:36] =>  1:47
:END:
*Consider the /exchange operator/* \(P_{12}\) *whose action on the* \(X\) *basis is* \(P_{12} \vert x_{1}, x_{2} \rangle = \vert x_{2}, x_{1} \rangle\).

*(1)* *Show that* \(P_{12}\) *has eigenvalues* \(\pm 1\). *(It is Hermitian and unitary.)*

The action of \(P_{12}\) on its eigenkets \(\vert p \rangle\) by definition are:

\begin{align*}
P_{12} \vert p \rangle = p \vert p \rangle \Longrightarrow P_{12}^{2} \vert p \rangle = p^{2} \vert p \rangle.
\end{align*}

Descending to \(X\) basis to project along \(\vert x_{1}, x_{2} \rangle\)

\begin{align*}
\left \langle x_{1}, x_{2} \left \lvert P_{12}^{2}  \right \rvert p \right \rangle = \left \langle x_{2}, x_{1} \left \lvert P_{12}  \right \rvert p \right \rangle = \left \langle x_{1}, x_{2} \vert p \right \rangle = p^{2} \left \langle x_{1}, x_{2} \vert p \right \rangle \Longrightarrow p^{2} = 1 \Longrightarrow p = \pm 1.
\end{align*}

*(2)* *Show that its action on the basis ket* \(\vert \omega_1, \omega_2 \rangle\) *is also to exchange the labels* \(1\) *and* \(2\), *and hence that* \(\mathbb{V}_{S/A}\) *are its eigenspaces with eigenvalues* \(\pm 1\).

Using the completeness of \(X\) basis:

\begin{align*}
\vert \omega_{1}, \omega_{2} \rangle &= \sum_{x_{1}, x_{2}} \vert x_{1}, x_{2} \rangle \langle x_{1}, x_{2} \vert \omega_{1}, \omega_{2} \rangle \\ \Longrightarrow P_{12} \vert \omega_{1}, \omega_{2} \rangle &= \sum_{x_{1}, x_{2}} \vert x_{2}, x_{1} \rangle \langle x_{1}, x_{2} \vert \omega_{1}, \omega_{2} \rangle \\
&= \sum_{x_{1}, x_{2}} \vert x_{2}, x_{1} \rangle \left \langle x_1 \vert \omega_{1} \right \rangle \left \langle x_{2} \vert \omega_{2} \right \rangle \\
&= \sum_{x_{1}, x_{2}} \vert x_{2}, x_{1} \rangle \left \langle x_{2} \vert \omega_{2} \right \rangle \left \langle x_1 \vert \omega_{1} \right \rangle \\
&= \sum_{x_{1}, x_{2}} \vert x_{2}, x_{1} \rangle \left \langle x_{2} \vert \omega_{2} \right \rangle \left \langle x_1 \vert \omega_{1} \right \rangle \\
&= \sum_{x_{1}, x_{2}} \vert x_{2}, x_{1} \rangle \langle x_{2}, x_{1} \vert \omega_{2}, \omega_{1} \rangle \\
&= \vert \omega_{2}, \omega_{1} \rangle.
\end{align*}

That \(\mathbb{V}_{S/A}\) are its eigenspaces with eigenvalues \(\pm 1\) follows trivially.

*(3)* *Show that* \(P_{12} X_{1} P_{12} = X_{2}, \thinspace P_{12} X_{2} P_{12} = X_{1}\), *and similarly for* \(P_{1}\) *and* \(P_{2}\). *Then show that* \(P_{12} \Omega \left( X_{1}, P_{1} ; X_{2}, P_{2} \right) P_{12} = \Omega \left( X_{2}, P_{2} ; X_{1}, P_{1} \right)\). *[Consider the action on* \(\vert x_1, x_2 \rangle\) *or* \(\vert p_1, p_2 \rangle\). *As for the functions of* \(X\) *and* \(P\), *assume they are given by power series and consider any term in the series. If you need help, peek into the discussion leading to* \(\text{Eq.} (11.2.22)\).

Following the hint:

\begin{align*}
P_{12} X_{1} P_{12} \vert x_{1}, x_{2} \rangle = P_{12} X_{1} \vert x_{2}, x_{1} \rangle = x_{2} P_{12} \vert x_{2}, x_{1} \rangle = x_{2} \vert x_{1}, x_{2} \rangle = X_{2} \vert x_{1}, x_{2} \rangle.
\end{align*}

\begin{align*}
P_{12} X_{2} P_{12} \vert x_{1}, x_{2} \rangle = P_{12} X_{2} \vert x_{2}, x_{1} \rangle = x_{1} P_{12} \vert x_{2}, x_{1} \rangle = x_{1} \vert x_{1}, x_{2} \rangle = X_{1} \vert x_{1}, x_{2} \rangle.
\end{align*}

\begin{align*}
P_{12} P_{1} P_{12} \vert p_{1}, p_{2} \rangle = P_{12} P_{1} \vert p_{2}, p_{1} \rangle = p_{2} P_{12} \vert p_{2}, p_{1} \rangle = p_{2} \vert p_{1}, p_{2} \rangle = P_{2} \vert p_{1}, p_{2} \rangle.
\end{align*}

\begin{align*}
P_{12} P_{2} P_{12} \vert p_{1}, p_{2} \rangle = P_{12} P_{2} \vert p_{2}, p_{1} \rangle = p_{1} P_{12} \vert p_{2}, p_{1} \rangle = p_{1} \vert p_{1}, p_{2} \rangle = P_{1} \vert p_{1}, p_{2} \rangle.
\end{align*}


Consider the term \(P_{12} X_{1}^{a} P_{1}^{b} X_{2}^{c} P_{2}^{d} P_{12}\) in the power series expansion of \(P_{12} \Omega \left( X_{1}, P_{1} ; X_{2}, P_{2} \right) P_{12}\). Since \(P_{12} P_{12} = I\) we may write

\begin{align*}
P_{12} X_{1}^{a} P_{1}^{b} X_{2}^{c} P_{2}^{d} P_{12} &= \prod_{a} P_{12} X_{1} P_{12} \prod_{b} P_{12} P_{1} P_{12} \prod_{c} X_{12} X_{2} P_{12} \prod_{d} P_{12} P_{2} P_{12} \\
&= X_{1}^{a} P_{1}^{b} X_{2}^{c} P_{2}^{d}.
\end{align*}

It follows that

\begin{align*}
P_{12} \Omega \left( X_{1}, P_{1} ; X_{2}, P_{2} \right) P_{12} = \Omega \left( X_{2}, P_{2} ; X_{1}, P_{1} \right).
\end{align*}

*(4)* *Show that the Hamiltonian and propagator for two /identical/ particles are left unaffected under* \(H \to P_{12} H P_{12}\) *and* \(U \to P_{12} U P_{12}\). *Given this, show that any eigenstate of* \(P_{12}\) *continues to remain an eigenstate with the same eigenvalue as time passes, i.e., elements of* \(\mathbb{V}_{S/A}\)  *never leave the symmetric or antisymmetric subspaces they start in.*

Using the result from (3) we have

\begin{align*}
P_{12} H \left( X_{1}, P_{1}; X_{2}, P_{2} \right) P_{12} = H \left( X_{1}, P_{1}; X_{2}, P_{2} \right),
\end{align*}

and

\begin{align*}
P_{12} U \left( X_{1}, P_{1}; X_{2}, P_{2} \right) P_{12} = U \left( X_{1}, P_{1}; X_{2}, P_{2} \right).
\end{align*}

The identical particles are thus left unaffected under \(H \to P_{12} H P_{12}\) and \(U \to P_{12} U P_{12}\).

The eigenket \(\vert p \rangle\) of \(P_{12}\) satisfies:

\begin{align*}
P_{12} \vert + \rangle = + \vert + \rangle \quad \text{and} \quad P_{12} \vert - \rangle = - \vert - \rangle
\end{align*}

when they are from the bosonic and fermionic subspaces respectively.

Now \(\vert \pm (t) \rangle = U (t) \vert \pm (0) \rangle\) so we have:

\begin{align*}
P_{12} \vert \pm \left( t \right) \rangle &= P_{12} U (t)\vert \pm \left( 0 \right) \rangle \\
&= U \left( t \right) P_{12} \vert \pm \left( 0 \right) \rangle \\
&= \pm U \left( t \right) \vert p \left( 0 \right) \rangle \\
&= \pm \vert \pm \left( t \right) \rangle.
\end{align*}

Therefore any eigenstate of \(P_{12}\) continues to remain an eigenstate with the same eigenvalue as time passes, i.e., elements of \(\mathbb{V}_{S/A}\)  never leave the symmetric or antisymmetric subspaces they start in. Once a boson, always a boson. Once a fermion, always a fermion. Sorry, it's stuck in my head.
** SOLVED Problem 10.3.6
CLOSED: [2022-11-19 Sat 09:28]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 08:44]--[2022-11-19 Sat 09:28] =>  0:44
:END:
*Consider a composite object such as the hydrogen atom. Will it behave as a boson or fermion? Argue in general that objects containing an even/odd number of fermions will behave as bosons/fermions.*

The state vector \(\vert \omega_{1} \omega_{2} \dotso \omega_{2n}, ? \rangle\) of an object containing an even number of fermions in the \(\vert \omega_1 \omega_2 \dotso \omega_{2n} \rangle\) basis is

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n}, ? \rangle &= \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n} \rangle, \\
&\qquad k_{i} = 1, \thinspace 2, \dotso 2n, \quad \text{and} \quad k_{i} = k_{j} \Longrightarrow i = j.
\end{align*}

Achieving \(\vert \omega_{2n} \omega_{2n-1} \dotso \omega_{j} \dotso \omega_{i} \dotso \omega_{2} \omega_{1}  \rangle\) requires and /even/ number of pairwise flips, thus:

\begin{align*}
\sgn \left( \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} \right) = \sgn \left( \epsilon_{k_{2n} \thinspace k_{2n-1}, \thinspace \dotso k_{j}, \dotso, k_{i}, \dotso k_{1}}  \right).
\end{align*}

But then:

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n}, ? \rangle = \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} &\Big ( \vert \omega_{2n} \omega_{2n-1} \dotso \omega_{j} \dotso \omega_{i} \dotso \omega_{2} \omega_{1} \rangle \\
&+  \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n} \rangle \Big ),
\end{align*}

meaning the state vector of the composite object is spanned by /symmetric ket/ - it behaves like a boson:

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n}, S \rangle &= \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n} \rangle, \\
&\qquad k_{i} = 1, \thinspace 2, \dotso 2n, \quad \text{and} \quad k_{i} = k_{j} \Longrightarrow i = j.
\end{align*}

The state vector \(\vert \omega_{1} \omega_{2} \dotso \omega_{2n+1}, ? \rangle\) of an object containing an odd number of fermions in the \(\vert \omega_1 \omega_2 \dotso \omega_{2n+1} \rangle\) basis is

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n+1}, ? \rangle &= \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n+1}} \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n+1} \rangle, \\
&\qquad k_{i} = 1, \thinspace 2, \dotso 2n + 1, \quad \text{and} \quad k_{i} = k_{j} \Longrightarrow i = j.
\end{align*}

Achieving \(\vert \omega_{2n+1} \omega_{2n} \dotso \omega_{j} \dotso \omega_{i} \dotso \omega_{2} \omega_{1}  \rangle\) requires and /odd/ number of pairwise flips, thus:

\begin{align*}
\sgn \left( \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} \right) = -\sgn \left( \epsilon_{k_{2n} \thinspace k_{2n-1}, \thinspace \dotso k_{j}, \dotso, k_{i}, \dotso k_{1}}  \right).
\end{align*}

But then:

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n+1}, ? \rangle = \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n+1}} &\Big ( \vert \omega_{2n+1} \omega_{2n} \dotso \omega_{j} \dotso \omega_{i} \dotso \omega_{2} \omega_{1} \rangle \\
&-  \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n+1} \rangle \Big ),
\end{align*}

meaning the state vector of the composite object is spanned by /anti-symmetric kets/ - it behaves like a fermion:

\begin{align*}
\vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n}, A \rangle &= \epsilon_{k_{1} \thinspace k_{2}, \thinspace \dotso k_{i}, \dotso, k_{j}, \dotso k_{2n}} \vert \omega_{1} \omega_{2} \dotso \omega_{i} \dotso \omega_{j} \dotso \omega_{2n} \rangle, \\
&\qquad k_{i} = 1, \thinspace 2, \dotso 2n, \quad \text{and} \quad k_{i} = k_{j} \Longrightarrow i = j.
\end{align*}
* Symmetries and Their Consequences
CLOSED: [2022-11-22 Tue 05:52]
:LOGBOOK:
CLOCK: [2022-11-21 Mon 15:45]--[2022-11-21 Mon 16:17] =>  0:32
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-19 Sat 18:46]--[2022-11-19 Sat 19:32] =>  0:46
CLOCK: [2022-11-19 Sat 16:36]--[2022-11-19 Sat 16:55] =>  0:19
CLOCK: [2022-11-19 Sat 16:08]--[2022-11-19 Sat 16:22] =>  0:14
CLOCK: [2022-11-19 Sat 14:02]--[2022-11-19 Sat 15:18] =>  1:16
:END:
In the /active transformation picture/ (in which the particle is physically displaced to the /right/ by \(\epsilon\)), the quantum correspondence for classical /translations/ is

\begin{align*}
\left \langle X  \right \rangle \to \left \langle X  \right \rangle + \epsilon \quad \text{or} \quad \left \langle \psi_{\epsilon} \left \lvert X  \right \rvert \psi_{\epsilon} \right \rangle = \left \langle \psi \left \lvert X  \right \rvert \psi \right \rangle + \epsilon,
\end{align*}

\begin{align*}
\left \langle P  \right \rangle \to \left \langle P  \right \rangle \quad \text{or} \quad \left \langle \psi_{\epsilon} \left \lvert P  \right \rvert \psi_{\epsilon} \right \rangle = \left \langle \psi \left \lvert P  \right \rvert \psi \right \rangle.
\end{align*}

In terms of a /translation operator/ \(T \left( \epsilon \right)\),

\begin{align*}
T \left( \epsilon \right) \vert \psi \rangle = \vert \psi_{\epsilon} \rangle,
\end{align*}

\begin{align*}
\left \langle \psi \left \lvert T \left( \epsilon \right)^{\dagger} X T \left( \epsilon \right)  \right \rvert \psi \right \rangle = \left \langle \psi \left \lvert X  \right \rvert \psi \right \rangle + \epsilon,
\end{align*}

\begin{align*}
\left \langle \psi \left \lvert T \left( \epsilon \right)^{\dagger} P T \left( \epsilon \right)  \right\rvert \psi \right \rangle = \left \langle \psi \left \lvert P  \right \rvert \psi \right \rangle.
\end{align*}

In /coordinate basis/:

\begin{align*}
T \left( \epsilon \right) \vert x \rangle &= \vert x + \epsilon \rangle
\end{align*}

\begin{align*}
\vert \psi_{\epsilon} \rangle = T \left( \epsilon \right) \vert \psi \rangle &= T \left( \epsilon \right) \int_{-\infty}^{\infty} \vert x \rangle \left \langle x \vert \psi \right \rangle dx \\
&= \int_{-\infty}^{\infty} \vert x + \epsilon \rangle \left \langle x \vert \psi \right \rangle dx \xrightarrow[]{x^{\prime} = x + \epsilon} \\
&= \int_{-\infty}^{\infty} \vert x^{\prime} \rangle \left \langle x^{\prime} - \epsilon \vert \psi \right \rangle d x^{\prime}.
\end{align*}

Thus if \(\left \langle x \vert \psi \right \rangle = \psi \left( x \right)\) then

\begin{align*}
\left \langle x \left \lvert T \left( \epsilon \right)  \right \rvert \psi \right \rangle = \psi \left( x - \epsilon \right).
\end{align*}

Further

\begin{align*}
\left \langle \psi_{\epsilon} \left \lvert P  \right \rvert \psi_{\epsilon} \right \rangle &=
\int_{-\infty}^{\infty} \psi_{\epsilon}^{\ast} \left( x \right) \left( - i \hbar D_{x} \right) \psi_{\epsilon} \left( x \right) dx \\
&= \int_{-\infty}^{\infty} \psi^{\ast} \left( x - \epsilon \right) \left( - i \hbar D_{x} \right) \psi \left( x - \epsilon \right) dx \xrightarrow[]{x^{\prime} = x - \epsilon} \\
&= \int_{-\infty}^{\infty} \psi^{\ast} \left( x^{\prime} \right) \left( - i \hbar D_{x^{\prime}} \right) \psi \left( x^{\prime} \right) d x^{\prime} \\
&= \left \langle \psi \left \lvert P  \right \rvert \psi \right \rangle.
\end{align*}

While \(x \to x + \epsilon\) and \(p \to p\) are two /independent relations/ in classical mechanics/, in the quantum case we have: \(\left \langle x \left \lvert T \left( \epsilon \right)  \right \rvert \psi \right \rangle = \psi \left( x - \epsilon \right) \Longrightarrow \left \langle \psi_{\epsilon} \left \lvert P  \right \rvert \psi_{\epsilon} \right \rangle \left \langle \psi \left \lvert P  \right \rvert \psi \right \rangle\). The reason for this is that we should /actually/ demand the correspondence:

\begin{align*}
T \left( \epsilon \right) \vert x \rangle = \exp \left \lbrace i \epsilon g \left( x \right)/ \hbar \right \rbrace \vert x + \epsilon \rangle
\end{align*}

so that

\begin{align*}
\left \langle X  \right \rangle \xrightarrow[]{T \left( \epsilon \right)} \left \langle X  \right \rangle + \epsilon
\end{align*}

and

\begin{align*}
\left \langle P  \right \rangle \to \left \langle P  \right \rangle + \epsilon \left \langle f \left( X \right)  \right \rangle
\end{align*}

where \(f = g^{\prime}\).

\(T \left( \epsilon \right) = \exp \left \lbrace i \epsilon g \left( x \right)/ \hbar \right \rbrace \vert x + \epsilon \rangle\) only reduces to \(T \left( \epsilon \right) \vert x \rangle = \vert x + \epsilon \rangle\) on demanding \(\left \langle P  \right \rangle \to \left \langle P  \right \rangle\). (See =Exercise 11.2.1=).

The quantum correspondence for /translational invariance/ is defined by

\begin{align*}
\left \langle \psi \left \lvert H  \right \rvert \psi \right \rangle = \left \langle \psi_{\epsilon} \left \lvert H  \right \rvert \psi_{\epsilon} \right \rangle
\end{align*}

To derive the associated /conservation law/ we need the matrix elements of \(T \left( \epsilon \right)\). To order \(\epsilon\)

\begin{align*}
T \left( \epsilon \right) = I - \dfrac{i \epsilon}{\hbar} G,
\end{align*}

where the operator \(G\), called the /generator of translations/, is Hermitian.

\begin{align*}
\left \langle x \left \lvert T \left( \epsilon \right)  \right \rvert \psi \right \rangle = \psi \left( x - \epsilon \right) \Longrightarrow \psi \left( x \right) - \dfrac{i \epsilon}{\hbar} \left \langle x \left \lvert G  \right \rvert \psi \right \rangle = \psi \left( x \right) - \epsilon D_{x} \psi \Longrightarrow G = P,
\end{align*}

so

\begin{align*}
T \left( \epsilon \right) = I - \dfrac{i \epsilon}{\hbar} P.
\end{align*}

The /momentum operator/ is the generator of infinitesimal translations. The associated /conservation law/ is the /conservation of momentum/:

\begin{align*}
\left \langle \psi \left \lvert H  \right \rvert \psi \right \rangle &= \left \langle \psi_{\epsilon} \left \lvert H  \right \rvert \psi_{\epsilon} \right \rangle \\
&= \left \langle T \left( \epsilon \right) \psi \left \lvert H  \right \rvert T \left( \epsilon \right) \psi \right \rangle = \left \langle \psi \left \lvert T^{\dagger} \left( \epsilon \right) H T \left( \epsilon \right) \right \rvert \psi \right \rangle \\
&= \left \langle \psi \left \lvert \left( I + \dfrac{i \epsilon}{\hbar} P \right) H \left( I - \dfrac{i \epsilon}{\hbar} P \right)  \right \rvert \psi \right \rangle \\
&= \left \langle \psi \left \lvert H  \right \rvert \psi \right \rangle + \dfrac{i \epsilon}{\hbar} \left \langle \psi \left \lvert \left[ P, H \right]  \right \rvert \psi \right \rangle + \mathcal{O} \left( \epsilon^{2} \right).
\end{align*}

We must have:

\begin{align*}
\left \langle \psi \left \lvert \left[ P, H \right]  \right \rvert \psi \right \rangle = \left \langle \left[ P, H \right]  \right \rangle = 0 \Longrightarrow \left \langle D_{t} P  \right \rangle = 0.
\end{align*}

In the /passive transformation picture/ (in which the state vector in unaltered, but \(X\) and \(P\) are modified by \(T \left( \epsilon \right)\) - physically, the coordinate system, sources of external field if any, etc. moves to the /left/ by \(\epsilon\)), the quantum correspondence for classical translational invariance is

\begin{align*}
X \to T^{\dagger} \left( \epsilon \right) X T \left( \epsilon \right)
\end{align*}

\begin{align*}
P \to T^{\dagger} \left( \epsilon \right) P T \left( \epsilon \right)
\end{align*}

such that

\begin{align*}
T^{\dagger} \left( \epsilon \right) X T \left( \epsilon \right) = X + \epsilon I
\end{align*}

\begin{align*}
T^{\dagger} \left( \epsilon \right) P T \left( \epsilon \right) = P.
\end{align*}

The quantum correspondence for /translational invariance/ is defined by:

\begin{align*}
T^{\dagger} \left( \epsilon \right) H T \left( \epsilon \right) = H
\end{align*}

The explicit form for \(T \left( \epsilon \right)\) is same as in the active picture:

\begin{align*}
T \left( \epsilon \right) = I - \dfrac{i \epsilon}{\hbar} P,
\end{align*}

The /conservation of momentum/ follows from the requirement of translational invariance:

\begin{align*}
0 &= T^{\dagger} \left( \epsilon \right) H T \left( \epsilon \right) - H = \left( I + i \epsilon P/ \hbar \right) H \left( I - i \epsilon P / \hbar \right) - H \\
&= \dfrac{- i \epsilon}{\hbar} \left[ H, P \right] \Longrightarrow \left \langle D_{t} P  \right \rangle = 0.
\end{align*}

In the final step we have invoked Ehrenfest's theorem.

The operator \(T \left( a \right)\) corresponding to /finite translations/ \(a\) is found by dividing the interval \(a\) into \(N\) parts of size \(a/N\). As \(N \to \infty\), \(a/N\) becomes infinitesimal so that:

\begin{align*}
T \left( a/ N \right) = I - \dfrac{i a}{\hbar N} P,
\end{align*}

and a translation by \(a\) is equal to \(N\) translations by \(a/N\),

\begin{align*}
T \left( a \right) = \lim_{N \to \infty} \left( T \left( a/ N \right) \right)^{N} = \exp \left \lbrace - i a P / \hbar \right \rbrace,
\end{align*}

where we have used:

\begin{align*}
\exp \left \lbrace - a x  \right \rbrace = \lim_{N \to \infty} \left( 1 - \dfrac{a x}{N} \right)^{N}.
\end{align*}

It's a law bound move, \(P\) is the only operator so it acts like a c-number. In the \(X\) basis

\begin{align*}
T \left( a \right) \xrightarrow[]{X \text{ basis}} \exp \left \lbrace - a D_{x} \right \rbrace
\end{align*}

so that

\begin{align*}
\left \langle x \left \lvert T \left( a \right)  \right \rvert \psi \right \rangle = \psi \left( x \right) - D_{x} \psi a + D_{x}^{2} \psi \dfrac{\alpha^{2}}{2!} + \dotso.
\end{align*}

which is the full Taylor series for \(\psi \left( x - a \right)\) about the point \(x\). \(\exp \left \lbrace - i a P / \hbar \right \rbrace\) satisfies the /consistency condition/:

\begin{align*}
T \left( a \right) T \left( b \right) = \exp \left \lbrace - i a P/ \hbar  \right \rbrace \exp \left \lbrace - i b P / \hbar  \right \rbrace = \exp \left \lbrace - i \left( a + b \right) P / \hbar \right \rbrace = T \left( a + b \right),
\end{align*}

so that

\begin{align*}
T \left( a \right) T \left( b \right) \stackrel{?}{=} T \left( a + b \right),
\end{align*}

evaluates as affirmative.

For a system of \(N\) particles,

\begin{align*}
T \left( \epsilon \right) = I - \dfrac{i \epsilon}{\hbar} \sum_{i=1}^{N} P_{i} = I - \dfrac{i \epsilon}{\hbar} P,
\end{align*}

where \(P\) is the /total momentum operator/. The associated conservation law is the /conservation of total momentum/ a consequence of /translational invariance:

\begin{align*}
H \left( X, P \right) = T^{\dagger} \left( \epsilon \right) H \left( X, P \right) T \left( \epsilon \right) = H \left( X + \epsilon I, P \right)
\end{align*}

where the indices have been suppressed. For a single-particle the implication was that the particle was /free/, for a \(N\) particle system, the condition is merely that \(V\) be a function of the coordinate /differences/. *Any system whose parts interact with each other, but nothing external, will have this property.*

Translational invariance of \(H\) implies homogeneity of space: the same experiment repeated at two different places will give the same result (as seen by the local observers). Observations indicate that every known interaction - gravitational, weak, electromagnetic, and strong - is translationally invariant, in that every experiment, if repeated at a new site, will give the same result.

Time translational invariance of \(H\) implies homogeneity in time: the same experiment repeated at two different times gives the same result. Time translation invariance requires:

\begin{align*}
\left \langle D_t H  \right \rangle = 0.
\end{align*}

The associated conservation law is the /conservation of energy./ Observations indicate that every known interaction - gravitational, weak, electromagnetic, and strong - is time-translationally invariant, in that every experiment, if repeated at a different time, will give the same result.

An example of a discrete transformation is the /parity operation/. In the /active transformation picture/, classically, the parity operation corresponds to reflecting the state of the particle through the origin

\begin{align*}
x \xrightarrow[]{\text{parity}} - x,
\end{align*}

\begin{align*}
p \xrightarrow[]{\text{parity}} - p.
\end{align*}

In quantum theory, we define the action of the parity operator on the \(X\) basis as:

\begin{align*}
\Pi \vert x \rangle = \vert -x \rangle.
\end{align*}

We have:

\begin{align*}
\Pi \vert x \rangle = \vert -x \rangle \Longrightarrow \Pi \vert p \rangle = \vert -p \rangle.
\end{align*}

The action of the parity operator on an arbitrary ket is:

\begin{align*}
\Pi \vert \psi \rangle &= \Pi \int_{-\infty}^{\infty} \vert x \rangle \left \langle x \vert \psi \right \rangle dx \\
&= \int_{-\infty}^{\infty} \vert -x \rangle \left \langle x \vert \psi \right \rangle dx \\
&= \int_{-\infty}^{\infty} \vert x^{\prime} \rangle \left \langle - x^{\prime} \vert \psi \right \rangle d x^{\prime}.
\end{align*}

Therefore:

\begin{align*}
\left \langle x \vert \psi \right \rangle = \psi \left( x \right) = \psi \left( x \right) \Longrightarrow \left \langle x \left \lvert \Pi  \right \rvert \psi \right \rangle = \psi \left( -x \right).
\end{align*}

Applying the above to a momentum eigenket will furnish \(\Pi \vert p \rangle = \vert -p \rangle\). The eigenvalues of \(\Pi\) are \(\pm 1\), same as the exchange operator. Some of the properties of \(\Pi\) are:

\begin{align*}
\Pi^{2} = I,
\end{align*}

\begin{align*}
\Pi = \Pi^{-1},
\end{align*}

\begin{align*}
\text{The eigenvalues of } \Pi \text{ are} \pm 1,
\end{align*}

\begin{align*}
\Pi^{\dagger} = \Pi \quad \text{and} \quad \Pi^{\dagger} \Pi = I.
\end{align*}

\begin{align*}
\Pi^{-1} = \Pi^{\dagger} = \Pi.
\end{align*}

The eigenvectors with eigenvalue \(\pm 1\) are said to have even/odd parity. In the \(X\) basis, where

\begin{align*}
\psi \left( x \right) \xrightarrow[]{\Pi} \psi \left( -x \right),
\end{align*}

even-parity vectors have even wave functions and odd-parity vectors have odd wave functions. The same goes for the \(P\) basis since

\begin{align*}
\psi \left( p \right) \xrightarrow[]{\Pi} \psi \left( - p \right).
\end{align*}

In an arbitrary \(\Omega\) basis, \(\psi \left( \omega \right)\) need not be even or odd even if \(\vert \psi \rangle\) is a parity eigenstate (check this).

In the /passive transformation picture/, \(\Pi\) in terms of its action on the operators:

\begin{align*}
\Pi^{\dagger} X \Pi = - X,
\end{align*}

\begin{align*}
\Pi^{\dagger} P \Pi = - P.
\end{align*}

We say \(H \left( X, P \right)\) is parity invariant if

\begin{align*}
\Pi^{\dagger} H \left( X, P \right) \Pi = H \left( -X, -P \right) = H \left( X, P \right).
\end{align*}

In this case:

\begin{align*}
\left[ \Pi, H \right] = 0,
\end{align*}

and a common eigenbasis of \(\Pi\) and \(H\) can be found.
** SOLVED Problem 11.2.1
CLOSED: [2022-11-19 Sat 15:56]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 15:18]--[2022-11-19 Sat 15:56] =>  0:38
:END:
If we demand

\begin{align*}
\vert \psi_{\epsilon} \rangle = T \left( \epsilon \right) \vert \psi \rangle &= \exp \left \lbrace i \epsilon g \left( x \right)/ \hbar \right \rbrace \vert x + \epsilon \rangle \\
\end{align*}

then we must have

\begin{align*}
\left \langle X  \right \rangle \xrightarrow[]{T \left( \epsilon \right)} \left \langle X  \right \rangle + \epsilon,
\end{align*}

same as before but

\begin{align*}
\left \langle \psi_{\epsilon} \left \lvert P  \right \rvert \psi_{\epsilon} \right \rangle &=
\left \langle x + \epsilon \left \lvert \exp \left \lbrace - i \epsilon g \left( x \right) / \hbar \right \rbrace \left( - i \hbar D_{x} \right) \exp \left \lbrace i \epsilon g \left( x \right) / \hbar \right \rbrace  \right \rvert x + \epsilon \right \rangle \\
&= \left \langle x + \epsilon \left \lvert \epsilon \left( D_{x} g \right) \right \rvert x + \epsilon \right \rangle + \left \langle x + \epsilon \left \lvert \left( - i \hbar D_{x} \right)  \right \rvert x + \epsilon \right \rangle \xrightarrow[]{x^{\prime} = x - \epsilon} \\
&= \epsilon \left \langle x^{\prime} \left \lvert \left( D_{x^{\prime}} g \left( x^{\prime} \right) \right)  \right \rvert x^{\prime} \right \rangle + \left \langle x^{\prime} \left \lvert P  \right \rvert x^{\prime} \right \rangle \\
&= \left \langle P  \right \rangle + \epsilon \left \langle D_{x} g \left( x \right)  \right \rangle \\
&= \left \langle P  \right \rangle + \epsilon \left \langle f \left( X \right)  \right \rangle, \qquad f \left( X \right) = D_{X} g \left( X \right).
\end{align*}


which should satisfy the ask. We must now independently demand (as in the classical case) that \(\left \langle P  \right \rangle \to \left \langle P  \right \rangle\) so that

\begin{align*}
\left \langle f \left( X \right)  \right \rangle = 0 \Longrightarrow g \left( X \right) = \text{constant}.
\end{align*}

We /choose/ \(g \left( X \right) = 0\) so that

\begin{align*}
\vert \psi_{\epsilon} \rangle = T \left( \epsilon \right) \vert \psi \rangle &= \exp \left \lbrace i \epsilon g \left( x \right)/ \hbar \right \rbrace \vert x + \epsilon \rangle \\
&\longrightarrow \vert \psi_{\epsilon} \rangle = T \left( \epsilon \right) \vert \psi \rangle = \vert x + \epsilon \rangle.
\end{align*}

** SOLVED Problem 11.2.2
CLOSED: [2022-11-19 Sat 16:08]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 16:04]--[2022-11-19 Sat 16:08] =>  0:04
:END:

\begin{align*}
I = T^{\dagger} \left( \epsilon \right) T \left( \epsilon \right) &=
\left( I + \dfrac{i \epsilon}{\hbar} G^{\dagger} \right) \left( I - \dfrac{i \epsilon}{\hbar} G \right) \\
&= I - \dfrac{i \epsilon}{\hbar} G + \dfrac{i \epsilon}{\hbar} G^{\dagger} \Longrightarrow G^{\dagger} = G.
\end{align*}

** SOLVED Problem 11.2.3
CLOSED: [2022-11-19 Sat 18:19]
:LOGBOOK:
CLOCK: [2022-11-19 Sat 17:38]--[2022-11-19 Sat 18:19] =>  0:41
:END:
\begin{align*}
x \to x + \theta \left \lbrace x, l_{z}  \right \rbrace + \dfrac{\theta^{2}}{2!} \left \lbrace \left \lbrace x, l_z  \right \rbrace l_{z} \right \rbrace + \dotso
\end{align*}

We have

\begin{align*}
\left \lbrace x, l_{z} \right \rbrace &= - y,
\end{align*}

\begin{align*}
\left \lbrace \left \lbrace x, l_{z}  \right \rbrace, l_{z} \right \rbrace = - \left \lbrace y , l_{z} \right \rbrace = - x,
\end{align*}

\begin{align*}
\left \lbrace \left \lbrace \left \lbrace x, l_{z} \right \rbrace l_{z} \right \rbrace l_{z} \right \rbrace = \left \lbrace \left \lbrace -y, l_{z} \right \rbrace l_{z} \right \rbrace = \left \lbrace -x ,l_{z} \right \rbrace = y.
\end{align*}

and so on. Therefore,

\begin{align*}
x \to \bar{x} &= x \left[ 1 - \dfrac{\theta^{2}}{2!} + \dfrac{\theta^{4}}{4!} - \dotso \right] + y \left[ \theta - \dfrac{\theta^3}{3!} + \dotso \right] \\
&= x \cos \theta - y \sin \theta.
\end{align*}

** SOLVED Problem 11.4.1
CLOSED: [2022-11-22 Tue 04:40]
:LOGBOOK:
CLOCK: [2022-11-22 Tue 04:20]--[2022-11-22 Tue 04:40] =>  0:20
:END:
*Prove that if* \(\left[ \Pi, H \right] = 0\), *a system that starts out in a state of even/odd parity maintains its parity. (Note that since parity is a discrete operation, it has no associated conservation law in classical mechanics.)*

\begin{align*}
\left[ \Pi, H \right] = 0 \Longrightarrow \left[ U, H \right] = 0,
\end{align*}

since \(U\) is simply made up of powers of \(H\). To show that a system that starts out in a state of even/odd parity maintains its parity, we need to show that given \(\Pi \vert \psi \left( 0 \right) \rangle = p \vert \psi \left( 0 \right) \rangle \Longrightarrow \Pi \vert \psi \left( t \right) \rangle = p \vert \psi \left( t \right) \rangle\). We have:

\begin{align*}
\Pi \vert \psi \left( t \right) \rangle &= \Pi U (t) \vert \psi \left( 0 \right) \rangle \\
&= U (t) \Pi \vert \left( 0 \right) \rangle \\
&= p U (t) \vert \psi \left( 0 \right) \rangle \\
&= p \vert \psi \left( t \right) \rangle.
\end{align*}

** SOLVED Problem 11.4.2
CLOSED: [2022-11-22 Tue 05:05]
:LOGBOOK:
CLOCK: [2022-11-22 Tue 04:42]--[2022-11-22 Tue 05:05] =>  0:23
:END:
*A particle is in a potential*

\begin{align*}
V \left( x \right) = V_{0} \sin \left( 2 \pi x /a \right)
\end{align*}

*which is invariant under the translations* \(x \to x + ma\), *where* \(m\) *is an integer. Is momentum conserved? Why not?*

We want to know:

\begin{align*}
D_{t} \left \langle P  \right \rangle \stackrel{?}{=} 0.
\end{align*}

Using Ehrenfest's Theorem

Because \(\left \langle \left[ P, H \right]  \right \rangle \neq 0\).

\begin{align*}
i \hbar D_{t} \left \langle P  \right \rangle &= \left \langle \left[ P, H \right]  \right \rangle \\
&= \left \langle \left[ P, P^{2}/2m + V \right]  \right \rangle \\
&= \left \langle \left[ P, P^{2}/2m \right] + \left[ P, V \right]  \right \rangle \\
&= \left \langle \left[ P, V \right]  \right \rangle \\
\end{align*}

With ket

\begin{align*}
i \hbar D_{t} \left \langle P \vert \psi \rangle \right \rangle &= \left \langle \left[ P, V \right] \vert \psi \rangle  \right \rangle \\
&= \left \langle P V \vert \psi \rangle - V P \vert \psi \rangle  \right \rangle.
\end{align*}

Descend to coordinate basis:

\begin{align*}
i \hbar D_{t} \left \Big \langle P \vert \psi \rangle  \right \rangle &= \left \langle V_{0} \dfrac{2 \pi}{a} \cos \left( 2 \pi x / a \right) \vert \psi \rangle \\
&+ V_{0} \dfrac{2 \pi}{a} \sin \left( 2 \pi x / a \right) D_{x} \vert \psi \rangle - V_{0} \sin \left( 2 \pi x/ a \right) D_{x} \vert \psi \rangle  \right \Big \rangle \\
&= \left \langle V_{0} \dfrac{2 \pi}{a} \cos \left( 2 \pi x / a \right) \vert \psi \rangle \right \rangle \neq 0.
\end{align*}

Thus the momentum is not conserved. The potential being translationally invariant under a /specific transformation/ namely \(x \to x + ma\) does not imply that the generator of translations \(P\) commutes with the Hamiltonian.
** SOLVED Problem 11.4.3
CLOSED: [2022-11-22 Tue 05:27]
:LOGBOOK:
CLOCK: [2022-11-22 Tue 05:05]--[2022-11-22 Tue 05:27] =>  0:22
:END:
*You are told that in a certain reaction, the electron comes out with its spin always parallel to its momentum. Argue that parity is violated.*
Parity is violated because an eigenket of the spin operator is an eigenket of the parity operator with eigenvalue \(1\) while an eigenket of the momentum operator is an eigenket of the parity operator with eigenvalue \(-1\). For momentum vectors uniformly distributed in space, the action of parity is transform them to their mirror reflection, but leave the spin angular momentum vectors invariant. Thus, conservation of parity is incompatible with the momentum vectors always landing up parallel to the momentum.
** SOLVED Problem 11.4.4
CLOSED: [2022-11-22 Tue 05:54]
:LOGBOOK:
CLOCK: [2022-11-22 Tue 05:27]--[2022-11-22 Tue 05:54] =>  0:27
:END:
*We have treated parity as a mirror reflection. This is certainly true in one dimension, where* \(x \to - x\) *may be viewed as the effect of reflecting through a (point) mirror at the origin. In higher dimensions when we use a plane mirror (say lying on the* \(x-y\) *plane), one one* \((z)\) *coordinate gets reversed, whereas the parity transformation reverses all three coordinates.*
*Verify that reflection on a mirror in the* \(x-y\) *plane is the same as parity followed by* \(180^{\circ}\) *rotation about the* \(x\) *axis. Since rotational invariance holds for weak interactions, non-invariance under mirror reflection implies noninvariance under parity.*

Under reflection on a mirror in the \(x-y\) plane:

\begin{align*}
x \to x \qquad y \to y \qquad z \to -z.
\end{align*}

Under parity:

\begin{align*}
x \to -x \qquad y \to - y \qquad z \to -z.
\end{align*}

Now for a rotation about \(x\), the rotation matrix is:

\begin{align*}
R \left( \theta \vec{i} \right) =
\begin{pmatrix}
\cos \theta & \sin \theta & 0 \\
- \sin \theta & \cos \theta & 0 \\
0 & 0 & 1
\end{pmatrix}.
\end{align*}

Thus

\begin{align*}
-x \to -x \cos \theta + -y \sin \theta,
\end{align*}

\begin{align*}
-y \to  x \sin \theta - y \cos \theta,
\end{align*}

\begin{align*}
-z \to -z.
\end{align*}

For \(\theta = \pi\)

\begin{align*}
-x \to x, \qquad -y \to y, \qquad -z \to -z,
\end{align*}

so that the net transformation is

\begin{align*}
x \to x, \qquad y \to y, \qquad z \to -z,
\end{align*}

same as a reflection on a mirror in the \(x-y\) plane.
* Rotational Invariance and Angular Momentum
CLOSED: [2022-11-12 Sat 23:14]
:LOGBOOK:
CLOCK: [2022-10-26 Wed 12:42]--[2022-10-26 Wed 13:03] =>  0:21
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-26 Sat 10:39]--[2022-11-26 Sat 15:17] =>  4:38
CLOCK: [2022-11-26 Sat 04:22]--[2022-11-26 Sat 08:18] =>  3:56
CLOCK: [2022-11-22 Tue 08:19]--[2022-11-22 Tue 09:24] =>  1:05
:END:
*** Infinitesimal translations in Hilbert space
The translation operator in Hilbert space along the direction \(\hat{e}\) is \(U \left[ T \left( \epsilon \hat{e} \right) \right] = I - \dfrac{i \epsilon}{\hbar} \hat{e} \cdot G\), where \(G\) is the generator of infinitesimal translations along \(\hat{e}\). The generators of infinitesimal translations along the \(x\) and \(y\) directions are, respectively,

\begin{align*}
P_{x} \xrightarrow[]{\text{coordinate basis}} - i \hbar \partial_{x},
\end{align*}

\begin{align*}
P_{y} \xrightarrow[]{\text{coordinate basis}} - i \hbar \partial_{y},
\end{align*}

\begin{align*}
P_{z} \xrightarrow[]{\text{coordinate basis}} - i \hbar \partial_{z},
\end{align*}

or

\begin{align*}
\vec{P} = P_{x} \vec{i} + P_{y} \vec{j} + P_{z} \vec{k}.
\end{align*}

\(\hat{n} \cdot \vec{P} \equiv P_{\hat{n}}\) is the generator of translations in the direction of the unit vector \(\hat{n}\).
*** Finite translations in Hilbert space
Finite translation operators are found by exponentiation. Thus \(T \left( \vec{a} \right)\) which translates by \(\vec{a}\), is given by

\begin{align*}
U \left[T \left( \vec{a} \right) \right] = \exp \left \lbrace - i a P_{\hat{a}} / \hbar  \right \rbrace = \exp \left \lbrace -i a \hat{a} \cdot \vec{P}/ \hbar  \right \rbrace = \exp \left \lbrace - i \vec{a} \cdot \vec{P}/ \hbar  \right \rbrace
\end{align*}

where \(\hat{a} = \vec{a}/a\).

The law of combination for translation operators is

\begin{align*}
U \left[ T \left( \vec{b} \right) \right] U \left[ T \left( \vec{a} \right) \right] &= \exp \left \lbrace - i \vec{b} \cdot \vec{P}/ \hbar  \right \rbrace \exp \left \lbrace - i \vec{a} \cdot \vec{P}/ \hbar  \right \rbrace \\
&= \exp \left \lbrace - i \left( \vec{a} + \vec{b} \right) \cdot \vec{P}/ \hbar \right \rbrace \\
&= U \left[ T \left( \vec{a} + \vec{b} \right) \right].
\end{align*}

This is true because \(\left[ P_i, P_j \right] = 0\) and they behave just like \(c\) numbers.
*** Translational invariance
A Hamiltonian with translational invariance satisfies along \(\hat{n}\) satisfies:

\begin{align*}
U^{\dagger} \left[ T_{\hat{n}} \right] H \left( X, P_{x}; Y, P_{y} \right) U \left[ T_{\hat{n}} \right] = H \left( X, P_{x}; Y, P_{y} \right) \Longrightarrow \left[ P_{\hat{n}}, H \right] = 0.
\end{align*}

i.e., there exists a common basis for \(P_{\hat{\theta}}\) and \(H\) or \(P_{\hat{\theta}}\) and \(H\) are simultaneously diagonalizable.
*** Infinitesimal rotations in Hilbert space
The rotation operator in Hilbert space about the direction \(\hat{e}\) \(U \left[ R \left( \epsilon_{z} \hat{e} \right) \right] = I - \dfrac{i \epsilon}{\hbar} \hat{e} \cdot J\), where \(J\) is the generator of infinitestimal rotations about \(\hat{e}\).

\(U \left[ R \left( \epsilon\hat{e} \right) \right] = I - \dfrac{i \epsilon}{\hbar} \hat{e} \cdot J\) can be fed into the /passive transformation/ equations for an infinitesimal rotation:

\begin{align*}
U^{\dagger} \left[ R \right] X U \left[ R \right] = X - Y \epsilon_{z},
\end{align*}

\begin{align*}
U^{\dagger} \left[ R \right] Y U \left[ R \right] = X \epsilon_{z} + Y,
\end{align*}

\begin{align*}
U^{\dagger} \left[ R \right] P_{x} U \left[ R \right] = P_{x} - P_{y} \epsilon_{z},
\end{align*}

\begin{align*}
U^{\dagger} \left[ R \right] P_{y} U \left[ R \right] = P_{x} \epsilon_{z} + P_{y},
\end{align*}

to obtain

\begin{align*}
\left[ X, J_{z} \right] = - i \hbar Y,
\end{align*}

\begin{align*}
\left[ Y, J_{z} \right] = i \hbar X,
\end{align*}

\begin{align*}
\left[ P_{x}, J_{z} \right] = - i \hbar P_{y},
\end{align*}

\begin{align*}
\left[ P_{y}, J_{z} \right] = i \hbar P_{x}.
\end{align*}

\(J_{i}\) is called the /total angular momentum/. It decompses into a sum of the /orbital angular momentum/ \(L_{i}\) and the /spin angular momentum/ \(S_{i}\):

\begin{align*}
J_{i} = L_{i} + S_{i}.
\end{align*}

For the moment assume \(S_{i} = 0\) because we will descend to various coordinate bases. We will learn to do that for \(S_{i}\) later. \(S_{i} \neq 0\) and \(S_{i} = 0\) means we have ourselves a /vector wavefunction/ and a /scalar wavefunction/ respectively. The commutation relations above uniquely fix the generators of infinitesimal rotations about the \(x\), \(y\), and \(z\) directions.(=Exercise 12.2.2=) They are:

\begin{align*}
L_{x} &= Y P_{z} - Z P_{y}\\
&\xrightarrow[]{\text{rectangular coordinate basis}} - i \hbar \thinspace y \thinspace \partial_{z} + i \hbar \thinspace z \thinspace \partial_{y} \\
&\xrightarrow[]{\text{spherical coordinate basis}} i \hbar \thinspace \left( \sin \phi \thinspace \partial_{\theta} + \cos \phi \thinspace \cot \theta \thinspace \partial_{\phi} \right),
\end{align*}

\begin{align*}
L_{y} &= Z P_{x} - X P_{z} \\
& \xrightarrow[]{\text{rectangular coordinate basis}} - i \hbar \thinspace z \thinspace \partial_{x} + i \hbar \thinspace x \thinspace \partial_{z} \\
& \xrightarrow[]{\text{spherical coordinate basis}} i \hbar \left( - \cos \phi \thinspace \partial_{\theta} + \sin \phi \thinspace \cot \theta \thinspace \partial_{\phi} \right),
\end{align*}

\begin{align*}
L_{z} &= X P_{y} - Y P_{x} \\
& \xrightarrow[]{\text{rectangular coordinate basis}} - i \hbar \thinspace x \thinspace \partial_{y} + i \hbar \thinspace y \thinspace \partial_{x} \\
& \xrightarrow[]{\text{spherical coordinate basis}} - i \hbar \thinspace \partial_{\phi}.
\end{align*}

or

\begin{align*}
\vec{L} = L_{x} \vec{i} + L_{y} \vec{j} + L_{z} \vec{k}.
\end{align*}
*** Commutator relations of the total angular momentum
The components of \(\vec{J}\) components satisfy the commutator relations:

\begin{align*}
\left[ J_{x}, J_{y} \right] = i \hbar J_{z}, \quad \left[ J_{y}, J_{z} \right] = i \hbar J_{x}, \quad \left[ J_{z}, J_{x} \right] = i \hbar J_{y}.
\end{align*}

Equivalently:

\begin{align*}
\left[ J_{i}, J_{j} \right] = i \hbar \sum_{k=1}^{3} \epsilon_{ijk} J_{k}.
\end{align*}

Equivalently still:

\begin{align*}
\vec{J} \times \vec{J} = i \hbar \vec{J}.
\end{align*}

\(J^{2}\) is called the /total angular momentum operator squared/:

\begin{align*}
J^{2} \equiv \vec{J} \cdot \vec{J} = J_{x}^{2} + J_{y}^{2} + J_{z}^{2}.
\end{align*}

It satisfies the commutator relations:

\begin{align*}
\left[ J^{2}, J_{x} \right] = 0, \quad \left[ J^{2}, J_{y} \right] = 0, \quad \left[ J^{2}, J_{z} \right] = 0.
\end{align*}
*** Raising and lowering operators \(J_{\pm}\)
\(J_{\pm}\), called the /raising and lowering operators/ are defined as:

\begin{align*}
J_{\pm} = J_{x} \pm i J_{y}.
\end{align*}

They satisfy the commutator relations:

\begin{align*}
\left[ J_{z}, J_{\pm} \right] = \pm \hbar J_{\pm} \quad \text{and} \quad \left[ J^{2}, J_{\pm} \right] = 0.
\end{align*}

\(J_{\pm}\) raise/lower the eigenvalue of \(J_{z}\) by \(\hbar\) while leaving the eigenvalue of \(J^{2}\) alone.

*** Eigenvalue problem of \(J_{z}\) and \(J^{2}\)
The solution to the eigenvalue problem of \(J_{z}\) and \(J^{2}\) is

\begin{align*}
J^{2} \vert jm \rangle = j \left( j + 1 \right) \hbar^{2} \vert jm \rangle, \quad j = 0, \thinspace 1/2, \thinspace 1, \thinspace 3/2, \thinspace \dotso
\end{align*}

\begin{align*}
J_{z} \vert jm \rangle = m \hbar \vert jm \rangle \quad m = j, \thinspace j-1, \thinspace j-2, \dotso, -j.
\end{align*}

The eigenvalue of \(J_{z}\) and \(J^{2}\) associated with its eigenket \(\vert jm \rangle\) is \(m \hbar\) and \(j \left( j + 1 \right) \hbar^{2}\) respectively. For /scalar wavefunctions/ \(\vec{J} \to \vec{L}\), half-integral values of \(j\) are discarded:

\begin{align*}
L^{2} \vert lm \rangle = l \left( l + 1 \right) \hbar^{2} \vert lm \rangle, \quad l = 0, \thinspace 1, \thinspace 2, \dotso
\end{align*}

\begin{align*}
L_{z} \vert lm \rangle = m \hbar \vert lm \rangle \quad m = l, \thinspace l-1, \thinspace l-2, \dotso, -l.
\end{align*}

\(m\) is called the /magnetic quantum number/. \(l\) is called the /azimuthal quantum number/.

Finding the eigenkets \(\vert jm \rangle\) corresponds to finding the matrix elements \(\left \langle j^{\prime} m^{\prime} \left \lvert J_{x} \right \rvert jm \right \rangle\), \(\left \langle j^{\prime} m^{\prime} \left \lvert J_{y} \right \rvert jm \right \rangle\), \(\left \langle j^{\prime} m^{\prime} \left \lvert J_{z} \right \rvert jm \right \rangle\) and \(\left \langle j^{\prime} m^{\prime} \left \lvert J^{2} \right \rvert jm \right \rangle\). The eigenket \(\vert jm \rangle\) satisfy the identity:

\begin{align*}
J_{\pm} \vert jm \rangle = \hbar \sqrt{j \left( j + 1 \right) - m \left( m \pm 1 \right)} \thinspace \vert j, m \pm 1 \rangle.
\end{align*}

Therefore:

\begin{align*}
\left \langle j^{\prime} m^{\prime} \left \lvert J_{x} \right \rvert jm \right \rangle &= \left \langle j^{\prime} m^{\prime} \left \lvert \dfrac{J_{+} + J_{-}}{2}  \right \rvert jm \right \rangle \\
&= \dfrac{\hbar}{2} \Big \lbrace \delta_{jj^{\prime}} \delta_{m^{\prime}, m+1} \sqrt{j \left( j+1 \right) - m \left( m + 1 \right)} \\
&+ \delta_{jj^{\prime}} \delta_{m^{\prime}, m-1} \sqrt{j \left( j+1 \right) - m \left( m - 1 \right)} \Big \rbrace,
\end{align*}

\begin{align*}
\left \langle j^{\prime} m^{\prime} \left \lvert J_{y} \right \rvert jm \right \rangle &= \left \langle j^{\prime} m^{\prime} \left \lvert \dfrac{J_{+} - J_{-}}{2i}  \right \rvert jm \right \rangle \\
&= \dfrac{\hbar}{2i} \Big \lbrace \delta_{jj^{\prime}} \delta_{m^{\prime}, m+1} \sqrt{j \left( j+1 \right) - m \left( m + 1 \right)} \\
&- \delta_{jj^{\prime}} \delta_{m^{\prime}, m-1} \sqrt{j \left( j+1 \right) - m \left( m - 1 \right)} \Big \rbrace,
\end{align*}

\begin{align*}
\left \langle j^{\prime} m^{\prime} \left \lvert J_{z} \right \rvert jm \right \rangle &= m \hbar \delta_{m, m^{\prime}},
\end{align*}

\begin{align*}
\left \langle j^{\prime} m^{\prime} \left \lvert J^{2}  \right \rvert jm \right \rangle &= j \left( j + 1 \right) \hbar^{2} \delta_{j, j^{\prime}}.
\end{align*}

\(J^{2}\) and \(J_{z}\) are diagonal in the \(\vert jm \rangle\) basis. \(J_{x}\) and \(J_{y}\) are /block diagonal/ in the \(\vert jm \rangle\) basis. This is because \(J_{\pm}\) do not change \(j\) when they act on \(\vert jm \rangle\). Since the \(J\)'s are all block diagonal, the blocks do not mix when we multiply them. /In particular when we consider a commutation relation such as/ \(\left[ J_x, J_y \right] = i \hbar J_{z}\), /it will be satisfied within each block./ If we denote the \((2j + 1) \times \left( 2j + 1 \right)\) block in \(J_{i}\), corresponding to a certain \(j\), by \(J_{i}^{(j)}\), then we have:

\begin{align*}
\left[ J_{x}^{(j)}, J_{y}^{(j)} \right] = i \hbar J_{z}^{(j)}, \quad j=0, \thinspace \dfrac{1}{2}, \thinspace 1, \thinspace \dotso.
\end{align*}

*** Finite rotations in hilbert space
\(\hat{\theta} \cdot \vec{J} \equiv J_{\hat{\theta}}\) is the generator of rotations about the direction \(\hat{n}\). Finite rotation operators are found by exponentiation. Thus

\begin{align*}
U \left[ R \left( \vec{\theta} \right) \right] = \exp \left \lbrace - i \theta J_{\hat{\theta}} / \hbar  \right \rbrace = \exp \left \lbrace -i \theta \hat{\theta} \cdot \vec{J}/ \hbar  \right \rbrace = \exp \left \lbrace - i \vec{\theta} \cdot \vec{J}/ \hbar  \right \rbrace
\end{align*}

The law of combination for rotation operators is not analogous to one for translations:

\begin{align*}
U \left[ R \left( \vec{\vartheta} \right) \right] U \left[ R \left( \vec{\varphi} \right) \right]  &\neq \exp \left \lbrace - i \vec{\vartheta} \cdot \vec{J}/ \hbar  \right \rbrace \exp \left \lbrace - i \vec{\varphi} \cdot \vec{J}/ \hbar  \right \rbrace \\
&\neq \exp \left \lbrace - i \left( \vec{\varphi} + \vec{\vartheta} \right) \cdot \vec{J}/ \hbar \right \rbrace \\
&\neq U \left[ R \left( \vec{\varphi} + \vec{\vartheta} \right) \right].
\end{align*}

This is because \(\left[ J_{\vartheta}, J_{\varphi} \right] \neq 0\) and they behave like \(q\) numbers. If \(\vec{\vartheta} || \vec{\varphi}\) however, they behave like \(c\) numbers and \(U \left[ R \left( \vec{\vartheta} \right) \right] U \left[ R \left( \vec{\varphi} \right) \right] = U \left[ R \left( \vec{\vartheta} + \vec{\varphi} \right) \right]\).

/All/ rotation operators \(U \left[ R \left( \vec{\theta} \right) \right]\) are /block diagonal/. This is because \(J_{i}\) is block diagonal, and thus \(\vec{\theta} \cdot \vec{J}\) is block diagonal and its exponential is block diagonal.

The \((2j + 1)\) -dimensional block at a given \(j\) is denoted by \(D^{(j)} \left[ R \right]\). The block diagonal form of the rotation matrices implies that any vector \(\vert \psi_j \rangle\) in the subspace \(\mathbb{V}_{j}\) spanned by the \((2j + 1)\) vectors \(\vert j,j \rangle, \dotso, \vert j,-j \rangle\) goes into another element \(\vert \psi_{j}^{\prime} \rangle\) of \(\mathbb{V}_{j}\): \(\mathbb{V}_{j}\) are /irreducible, invariant subspaces/. This is because \(\left[ J^2, U \left[ R \right] \right] = 0\), so \(U \left[ R \right]\) (a rotation) cannot change the eigenvalue (magnitude of a vector) of \(J^{2}\): /each subspace contains states of a definite magnitude of angular momentum squared/ \(j \left( j + 1 \right) \hbar^{2}\). Thus if \(\vert \psi \rangle\) has components only in \(\mathbb{V}_{0}, \thinspace \mathbb{V}_{1}, \mathbb{V}_{2}, \dotso, \mathbb{V}_{j}\), we need the first \(j+1\) matrices \(D^{(j)}\). The block diagonal matrices representing the rotation operators \(U \left[ R \right]\) are said to provide an irreducible (matrix) representation of these operators.

The series representing \(D^{(j)}\) is:

\begin{align*}
D^{(j)} \left[ R \left( \vec{\theta} \right) \right] = \exp \left \lbrace - i \vec{\theta} \cdot \vec{J^{(j)}} / \hbar  \right \rbrace = \sum_{0}^{\infty} \left( \dfrac{-i \theta}{\hbar} \right)^{n} \left( \hat{\theta} \cdot \vec{J^{(j)}} \right)^{n} \dfrac{1}{n!}.
\end{align*}

\((\hat{\theta} \cdot \vec{J^{(j)}})^{n}\) for \(n > 2j\) can be written as a linear combination of the first \(2j\) powers of \(\hat{\theta} \cdot \vec{J}^{(j)}\) (See =Exercise 12.5.4=). Therefore:

\begin{align*}
D^{(j)} = \sum_{0}^{2j} f_{n} \left( \theta \right) \left( \hat{\theta} \cdot \vec{J}^{(j)} \right)^{n}.
\end{align*}

*** \(L_{i}\), \(L^{2}\) eigenkets in coordinate basis: spherical harmonics_
We deal with \(J_{i} \to L_{i}\), \(J^{2} \to L^{2}\). Living at the extremity of the irreducible invariant subspace corresponding to \(l\) is \(\vert ll \rangle\) and it cannot be /raised/ for it will start toppling from the top:

\begin{align*}
L_{\pm} \vert ll \rangle = \vert 0 \rangle.
\end{align*}

We have the following representations for \(L_{\pm} = L_{x} \pm i L_{y}\) in spherical coordinates:

\begin{align*}
L_{\pm} \xrightarrow[]{\text{spherical coordinate basis}} \pm \hbar \exp \left \lbrace \pm i \phi  \right \rbrace \left( \partial_{\theta} \pm i \cot \theta \right) \partial_{\phi} \right),
\end{align*}

and for \(\vert ll \rangle\)

\begin{align*}
\vert ll \rangle \xrightarrow[]{\text{spherical coordinate basis}} \psi_{l}^{l} \left( r, \theta, \phi \right).
\end{align*}

Because \(L_{z} \to -i \hbar \partial_{\phi}\) and \(L_{z} \vert ll \rangle = l \hbar \vert ll \rangle\), we use an ansatz of the form:

\begin{align*}
\psi_{l}^{l} \left( r, \theta, \phi \right) = U_{l}^{l} \left( r, \theta \right) \exp \left \lbrace i l \phi  \right \rbrace.
\end{align*}

Feeding to \(L_{\pm} \vert ll \rangle = \vert 0 \rangle\) and descending to coordinate basis:

\begin{align*}
\hbar \exp \left \lbrace \pm i \phi  \right \rbrace \left( \partial_{\theta} \pm i \cot \theta \right) \partial_{\phi} \right) \left[ U_{l}^{l} \left( r, \theta \right) \exp \left \lbrace i l \phi  \right \rbrace \right] = 0.
\end{align*}

Simplification furnishes:

\begin{align*}
\left( \partial_{\theta} - l \cot \theta \right) U_{l}^{l} = 0,
\end{align*}

and is solved by:

\begin{align*}
U_{l}^{l} \left( r, \theta \right) = R \left( r \right) \left( \sin \theta \right)^{l}
\end{align*}

where \(R \left( r \right)\) is an arbitrary (normalizable) function of \(r\). Shave off that \(R (r)\); we'll pick it later. The solutions to \(L_{\pm} \vert ll \rangle = \vert 0 \rangle\) are:

\begin{align*}
\psi_{l}^{l} \left( r, \theta, \phi \right) = R \left( r \right) Y_{l}^{l} \left( \theta, \phi \right),
\end{align*}

where

\begin{align*}
Y_{l}^{l} \left( \theta, \phi \right) = \left( -1 \right)^{l} \left[ \dfrac{\left( 2l + 1 \right)!}{4 \pi} \right]^{1/2} \dfrac{1}{2^{l} l!} \left( \sin \theta \right)^{l} \exp \left \lbrace i l \phi \right \rbrace.
\end{align*}

We have:

\begin{align*}
\int \left \lvert Y_{l}^{l} \right \rvert^{2} d \Omega \equiv \int_{-1}^{1} \int_{0}^{2 \pi} \left \lvert Y_{l}^{l}  \right \rvert^{2} d \left( \cos \theta \right) d \phi = 1.
\end{align*}

From here on out, we can /lower/ and go wherever we want. To go to \(\vert lm \rangle\):

\begin{align*}
Y_{l}^{m} \left( \theta, \phi \right) = \left( -1 \right)^{l} \left[ \dfrac{(2l + 1)!}{4 \pi} \right]^{1/2} \dfrac{1}{2^{l} l!} &\left[ \dfrac{\left( l + m \right)!}{\left( 2l \right)! \left( l - m \right)!} \right]^{1/2} \\
&\times \exp \left \lbrace i m \phi  \right \rbrace \left( \sin \theta \right)^{-m} \qquad m \geq 0,
\end{align*}

\begin{align*}
Y_{l}^{m} \left( \theta, \phi \right) = \left( -1 \right)^{-m} \left( Y_{l}^{-m} \right)^{\ast} \qquad m \leq 0.
\end{align*}


These functions are called /spherical harmonics/ and satisfy the orthonormality conditions:

\begin{align*}
\int Y_{l}^{m}^{\ast} \left( \theta, \phi \right) Y_{l^{\prime}}^{m^{\prime}} \left( \theta, \phi \right) d \Omega = \delta_{ll^{\prime}} \delta_{m m^{\prime}}.
\end{align*}

The \(Y_{l}^{m}\) functions are mutually orthogonal because they are /nondegenerate/ eigenfunctions of \(L^{2}\) /and/ \(L_{z}\) which are Hermitian on single-valued functions of \(\theta\) and \(\phi\).

Closely related to the spherical harmonics are the /associated Legendre polynomials/ \(P_{l}^{m}\) (with \(0 \leq m \leq l\)) defined by:

\begin{align*}
Y_{l}^{m} \left( \theta, \phi \right) = \left[ \dfrac{\left( 2l + 1 \right) \left( l - m \right)!}{4 \pi \left( l + m \right)!} \right]^{1/2} \left( -1 \right)^{m} \exp \left \lbrace i m \phi \right \rbrace P_{l}^{m} \left( \cos \theta \right).
\end{align*}

If \(m = 0\), \(P_{l}^{0} \left( \cos \theta \right) \equiv P_{l} \left( \cos \theta \right)\) is called the a /Legendre polynomial/.

For large values of \(l\), the functions \(\left \lvert Y_{l}^{m} \right \rvert\) exhibit many classical features: \(\left \lvert Y_{l}^{l}  \right \rvert \propto \left \lvert \sin^{l} \theta \right \rvert\). For large \(l\), \(\left \lvert Y^{\pm l}_{l}  \right \rvert\) it is almost entirely confined to the \(x-y\) plane, as one would expect of a classical particle with all its angular momentum pointing along the \(z\) axis. \(\left \lvert Y_{l}^{0}  \right \rvert\) for large \(l\) is almost entirely confined to the \(z\) axis.

The first few spherical harmonics are:

\begin{align*}
Y_{0}^{0} = \left( 4 \pi \right)^{-1/2},
\end{align*}

\begin{align*}
Y_{1}^{\pm 1} = \mp \left( \dfrac{3}{8 \pi} \right)^{1/2} \sin \theta \exp \left \lbrace \pm i \phi  \right \rbrace,
\end{align*}

\begin{align*}
Y_{1}^{0} = \left( \dfrac{3}{4 \pi} \right)^{1/2} \cos \theta,
\end{align*}

\begin{align*}
Y_{2}^{\pm 2} = \left( \dfrac{15}{32 \pi} \right)^{1/2} \sin^{2} \theta \exp \left \lbrace \pm 2 i \phi  \right \rbrace,
\end{align*}

\begin{align*}
Y_{2}^{\pm 1} = \mp \left( \dfrac{15}{8 \pi} \right)^{1/2} \sin \theta \cos \theta \exp \left \lbrace \pm i \phi  \right \rbrace,
\end{align*}

\begin{align*}
Y_{2}^{0} = \left( \dfrac{5}{16 \pi} \right)^{1/2} \left( 3 \cos^{2} \theta - 1 \right).
\end{align*}

Any arbitrary \(\psi \left( r, \theta, \phi \right)\) may be expanded in terms of the spherical harmonics \(Y_{l}^{m} \left( \theta, \phi \right)\) using \(r\)-/dependent coefficients/:

\begin{align*}
\psi \left( r, \theta, \phi \right) = \sum_{l=0}^{\infty} \sum_{m=-l}^{l} C_{l}^{m} \left( r \right) Y_{l}^{m} \left( \theta, \phi \right),
\end{align*}

where

\begin{align*}
C_{l}^{m} \left( r \right) = \int Y_{l}^{m^{\ast}} \left( \theta, \phi \right) \psi \left( r, \theta, \phi \right) d \Omega.
\end{align*}

Assuming \(\psi\) is normalized to unity:

\begin{align*}
P \left( L^{2} = l \left( l + 1 \right) \hbar^{2}, L_{z} = m \hbar \right) = \int_{0}^{\infty} \left \lvert C_{l}^{m} \left( r \right)  \right \rvert^{2} r^{2} dr.
\end{align*}

\(C_{l}^{m}\) is the amplitude to find the particle at a radial distance \(r\) with angular momentum \((l,m)\).
*** Rotational invariance
A Hamiltonian with rotational invariance along \(\hat{\theta}\) satisfies:

\begin{align*}
U^{\dagger} \left[ R_{\hat{\theta}} \right] H \left( X, P_{x}; Y, P_{y} \right) U \left[ R_{\hat{\theta}} \right] &= H \left( X, P_{x}; Y, P_{y} \right) \\
&\Jongrightarrow \left[ J_{\hat{\theta}}, H \right] = 0.
\end{align*}

1) There exists a common basis for \(J_{\hat{\theta}}\) and \(H\) or \(J_{\hat{\theta}}\) and \(H\) are simultaneously diagonalizable.
2) \(\left \langle J_{\hat{\theta}}  \right \rangle\) is a conserved quantity.

A Hamiltonian with rotational invariance under arbitrary rotations satisfies:

\begin{align*}
U^{\dagger} \left[ R \right] H U \left[ R \right] = H \Longrightarrow \left[ J_{i}, H \right] = \left[ J^{2}, H \right] = 0 \text{ for} \thinspace i = x, \thinspace y, \thinspace z.
\end{align*}

1) There exists a common basis for each of the components of \(\vec{J}\) and \(H\) and for \(J^{2}\) and \(H\). In other words, \(J_{x}\) and \(H\) or \(J_{y}\) and \(H\) or \(J_{z}\) and \(H\) or \(J^{2}\) and \(H\) are simultaneously diagnonalizable. Since \(\left[ J^2, J_i \right] = 0\), \(J^{2}\), \(J_{i}\) and \(H\) are simultaneously diagonalizable for a Hamiltonian that is rotationally invariant under arbitrary rotations.
2) \(\left \langle J_{x}  \right \rangle\), \(\left \langle J_{y}  \right \rangle\), \(\left \langle J_{z}  \right \rangle\), and \(\left \langle J^{2}  \right \rangle\) are conserved quantities.

Since \(\left[ \vec{J}, H \right] = 0\), \(H\) has the same form as \(J^{2}\):

1) \(H\) is diagonal (since \(\left[ H, J^2 \right] = 0\), \(\left[ H, J_z \right] = 0\)).
2) Within each block, \(H\) has the same eigenvalue \(E_{j}\) (since \(\left[ H, J_{\pm} \right] = 0\)), i.e., \(\mathbb{V}_{j}\) is an eigenspace of \(H\) with eigenvalue \(E_{j}\): /all states with a given/ \(j\) /are degenerate eigenkets of/ \(H\).

Arbitrary degenerate states are not accessible from a given degenerate state /only/ via rotations: the combined action of \(J_{\pm}\) and \(U \left[ R \right]\) is necessary when the magnetic quantum numbers differ. This is a purely quantum mechanical effect: in classical mechanics /all/ degenerate states from a given state are accessible via smooth rotations, but in quantum mechanics, you can be smooth with \(\vert jm \rangle\), but if you want to /change/ \(m\), you can only do it in fits and jumps using \(J_{\pm}\). \(j\) you cannot change, you're stuck in this subspace, remember? (Don't even begin!)

\(H\) is invariant under arbitrary rotations when \(V \left( r, \theta, \phi \right) = V \left( r \right)\). The time-independent Schrodinger equation is:

\begin{align*}
&-\dfrac{\hbar^2}{2 \mu} \left( r^{-2} \partial_{r} \thinspace r^{2} \thinspace \partial_{r} + r^{-2} \left( \sin \theta \right)^{-1} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + r^{-2} \left( \sin \theta \right)^{-2} \partial_{\phi}^{2} \right) \psi_{E} \left( r, \theta, \phi \right) \\
&+ V(r) \psi_{E} \left( r, \theta, \phi \right) = E \psi_{E} \left( r, \theta, \phi \right).
\end{align*}

We seek the simultaneous eigenfunctions of \(H\), \(L^{2}\), and \(L_{z}\) in the coordinate basis so our ansatz is (picking out the \(R_{l}^{m} (r)\) from the trash; we discarded it while solving for the spherical harmonics remember?):

\begin{align*}
\psi_{Elm} \left( r, \theta, \phi \right) = R_{Elm} \left( r \right) Y_{l}^{m} \left( \theta, \phi \right).
\end{align*}

Feed it. You'll get the /radial equation/:

\begin{align*}
\left \lbrace - \dfrac{\hbar^{2}}{2 \mu} \left[ r^{-2} D_{r} r^{2} D_{r} - \dfrac{l \left( l + 1 \right)}{r^{2}} \right] + V(r) \right \rbrace R_{El} = E R_{El}.
\end{align*}

The /magnetic quantum number/ has dropped out: neither the energy nor the radial functions depends on it. The had concluded earlier that all states with a given \(j\) are degenerate eigenkets of \(H\). We have now verified it. \(H\) has \(2l + 1\) -fold degeneracy. Now recast \(R_{El}\) as \(R_{El} = U_{El}/r\). A necessary condition for

\begin{align*}
\int_{0}^{\infty} \left \lvert R_{El} \right \rvert^{2} r^{2} dr = \int_{0}^{\infty} \left \lvert U_{El}  \right \rvert^{2} dr
\end{align*}

to be normalizable to unity or the Dirac delta function is that

\begin{align*}
U_{El} \xrightarrow[]{r \to \infty} 0 \quad \text{ or } \quad U_{El} \xrightarrow[]{r \to \infty} \exp \left \lbrace i k r  \right \rbrace,
\end{align*}

corresponding to /bound/ and /unbound/ states respectively. With \(R_{El} = U_{El}/r\) the radial equation reduces to:


\begin{align*}
\left \lbrace D_{r}^{2} + \dfrac{2 \mu}{\hbar^{2}} \left[ E - V \left( r \right) - \dfrac{l \left( l + 1 \right) \hbar^{2}}{2 \mu r^{2}} \right]  \right \rbrace U_{El} = 0,
\end{align*}

and has the properties:

1) The independent variable \((r)\) goes from \(0\) to \(\infty\) and not from \(-\infty\) to \(\infty\).
2) In addition to the actual potential \(V (r)\), there is a /repulsive centrifugal barrier/, \(l \left( l + 1 \right) \hbar^{2}/ 2 \mu r^{2}\), in all but the \(l = 0\) states.
3) The boundary condition on \(U\) are different from the one-dimensional case. To see this start with a rewrite:

\begin{align*}
\left[ - \dfrac{\hbar^{2}}{2 \mu} D_{r}^{2} + V(r) + \dfrac{l \left( l + 1 \right) \hbar^{2}}{2 \mu r^{2}} \right] U_{El} \equiv D_{l} \left( r \right) U_{El} = E U_{El},
\end{align*}

and demand that \(U_{El}\) be such that \(D_{l}\) is Hermitian with respect to them. If \(U_{1}\) and \(U_{2}\) are two such functions, demand:

\begin{align*}
\int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) dr = \left[ \int_{0}^{\infty} U_{2}^{\ast} \left( D_{l} U_{1} \right) dr \right]^{\ast} \equiv \int_{0}^{\infty} \left( D_{l} U_{1} \right)^{\ast} U_{2} dr.
\end{align*}

This reduces to (see =Exercise 12.6.3=):

\begin{align*}
\left( U_{1}^{\ast} D_{r} U_{2} - U_{2} D_{r} U_{1}^{\ast} \right) \vert_{0}^{\infty} = 0.
\end{align*}

Because \(U_{El} \xrightarrow[]{r \to \infty} 0 \quad \text{ or } \quad U_{El} \xrightarrow[]{r \to \infty} \exp \left \lbrace i k r  \right \rbrace\), Hermiticity of \(D_{l}\) hinges on

\begin{align*}
\left( U_{1}^{\ast} D_{r} U_{2} - U_{2} D_{r} U_{1}^{\ast} \right) \vert_{0}^{\infty} = 0 \to \left[ U_{1}^{\ast}(0) D_{r} U_{2}(0) - U_{2}(0) D_{r} U_{1}^{\ast}(0) \right] = 0.
\end{align*}

\begin{align*}
\left[ U_{1}^{\ast}(0) D_{r} U_{2}(0) - U_{2}(0) D_{r} U_{1}^{\ast}(0) \right] = 0 \Longrightarrow U_{El} \xrightarrow[]{r \to 0} c, \qquad c = \text{constant}.
\end{align*}

If \(c\) is non-zero, then

\begin{align*}
R \sim \dfrac{U}{r} \sim \dfrac{c}{r} \Longrightarrow \psi \sim \dfrac{c}{r} Y_{0}^{0}
\end{align*}

which violates Schrodinger equation at \(r = 0\) because (see =Exercise 12.6.4=):

\begin{align*}
\nabla^{2} \left( 1/r \right) = - 4 \pi \delta^{3} \left( \vec{r} \right).
\end{align*}

Thus unless \(V(r)\) contains a delta function at the origin (which we assume it does not, but will lift when we add a correction to the hydrogen atom) the choice \(c \neq 0\) is untenable. Thus \(c \to 0\), cause ours hands are tied. The Hermiticity condition reduces to:

\begin{align*}
\left[ U_{1}^{\ast}(0) D_{r} U_{2}(0) - U_{2}(0) D_{r} U_{1}^{\ast}(0) \right] = 0 \Longrightarrow U_{El} \xrightarrow[]{r \to 0} 0.
\end{align*}

/Assume/ \(V(r)\) falls slower than \(r^{-2}\).

In the \(r \to 0\) limit, the centrifugal barrier dominates the equation

\begin{align*}
D_{r}^{2} U_{l} \simeq \dfrac{l \left( l + 1 \right)}{r^{2}} U_{l} \qquad l \neq 0.
\end{align*}

\(E\) has been dropped from the subscript because it is inconsequential in this limit. Feeding \(U_{l} \sim r^{\alpha}\)

\begin{align*}
\alpha \left( \alpha - 1 \right) = l \left( l + 1 \right) \Longrightarrow \alpha = l+1 \text{ or } -l.
\end{align*}

Thus

\begin{align*}
U_{l} \sim
\begin{cases}
r^{l+1} \qquad \text{regular} \\
r^{-l} \qquad \text{irregular}
\end{cases}.
\end{align*}

Discard \(U_{l} \sim r^{-l}\) since then \(U(0) \neq 0\). Thus \(U_{l} \sim r^{l+1}\): as the angular momentum increases the particle should avoid the origin more and more.

In the \(r \to \infty\) limit, \(V(r)\) dominates the equation if it does not vanish in this limit, nothing general can be said.

/Assume/ \(r V \left( r \right) \to 0\) as \(r \to \infty\).

In the \(r \to \infty\) limit,

\begin{align*}
D_{r}^{2} U_{E} = - \left( \dfrac{2 \mu E}{\hbar^{2}} \right) U_{E}.
\end{align*}

\(l\) has been dropped from the subscript because it is inconsequential in this limit. There are two cases:

1) \(E > 0\): /scattering states/ - \(U_{E}\) oscillates as \(r \to \infty\).

The solution is:
\begin{align*}
U_{E} = A \exp \left \lbrace i k r  \right \rbrace + B \exp \left \lbrace - i k r  \right \rbrace, \qquad k = \left( \dfrac{2 \mu E}{\hbar^{2}} \right)^{1/2}.
\end{align*}

We assumed \(r V \left( r \right) \to 0\) as \(r \to \infty\) because if \(V (r) \sim r^{-1}\) or \(V (r) \sim r^{-s}, s>1\), there are /no scattering states/. An example is the Coulomb potential of equal and opposite charges \(e\) at a distance \(r\):

\begin{align*}
V(r) = - \dfrac{e^{2}}{r}.
\end{align*}

No matter how far away the particle is from the origin (the influence of the other particle), it is never /completely free/ of the Coulomb potential. If the fall of \(V(r)\) is even more sluggish than the Coulomb potential, /freedom/ is further restricted.
   
2) \(E < 0\): /bound states/ - \(U_{E}\) falls off exponentially as \(r \to \infty\).

With the transformation \(k \to i \kappa\) the solution is:

\begin{align*}
U_{E} \xrightarrow[]{r \to \infty} A \exp \left \lbrace - \kappa r  \right \rbrace + B \exp \left \lbrace + \kappa r \right \rbrace \qquad \kappa = \left( 2 \mu \left \lvert E  \right \rvert / \hbar^{2} \right)^{1/2}.
\end{align*}

\(B/A\) is not arbitrary, \(U_{E} \to 0 \text{ as } r \to 0\) and \(U_{E} \to 0 \text{ as } r \to \infty\) constrains them. For arbitrary \(E < 0\), both \(\exp \left \lbrace kr  \right \rbrace\) and \(\exp \left \lbrace - k r  \right \rbrace\) are present in \(U_{E}\). Only for certain discrete values of \(E\) will the \(\exp \left \lbrace \kappa r  \right \rbrace\) drop out: these are the allowed bound states.

The assumption \(r V \left( r \right) \to 0\) as \(r \to \infty\) is necessary for the solution above, else an \(r\) dependence will creep in on \(U_{E}\).

The energy eigenfunctions are normalizable to unity when \(E < 0\). Since the operator \(D_{l} (r)\) is /non-degenerate/ (see =Exercise 12.6.5=), we have:

\begin{align*}
\int_{0}^{\infty} U_{E^{\prime}l} \left( r \right) U_{El} \left( r \right) dr = \delta_{E E^{\prime}}
\end{align*}

and

\begin{align*}
\psi_{Elm} \left( r, \theta, \phi \right) = R_{El} \left( r \right) Y_{l}^{m} \left( \theta, \phi \right)
\end{align*}

obeys

\begin{align*}
\iiint \psi_{Elm}^{\ast} \left( r, \theta, \phi \right) \psi_{E^{\prime} l^{\prime} m^{\prime}} \left( r, \theta, \phi \right) \thinspace r^{2} \thinspace dr \thinspace d\Omega = \delta_{EE^{\prime}} \delta_{ll^{\prime}} \delta_{mm^{\prime}}.
\end{align*}

** SOLVED Problem 12.1.1
CLOSED: [2022-11-22 Tue 09:10]
:LOGBOOK:
CLOCK: [2022-11-22 Tue 08:59]--[2022-11-22 Tue 09:10] =>  0:11
:END:

\begin{align*}
\left \langle x, y \left \lvert I - \dfrac{i}{\hbar} \vec{\delta a} \cdot \vec{P} \right \rvert \psi \right \rangle &= \left \langle x, y \left \lvert I - \dfrac{i}{\hbar} (\delta a_{x} P_{x} + \delta a_{y} P_{y}) \right \rvert \psi \right \rangle \\
&= \left \langle x, y \left \lvert I - \dfrac{i}{\hbar} (-\delta a_{x} i \hbar \partial_{x} - \delta a_{y} i \hbar \partial_{y}) \right \rvert \psi \right \rangle \\
&= \left \langle x, y \left \lvert I - \delta a_{x} \partial_{x} - \delta a_{y} \partial_{y} \right \rvert \psi \right \rangle \\
&= \left \langle x, y \left \lvert I \vert \psi \rangle - \langle x, y \vert \delta a_{x} \partial_{x} \vert \psi \rangle - \langle x, y \vert \delta a_{y} \partial_{y} \right \rvert \psi \right \rangle \\
&= \psi \left( x, y \right) - \delta a_{y} \partial_{y} \psi \left( x, y \right) - \delta a_{x} \partial_{x} \psi \left( x, y \right) \\
&= \psi \left( x - \delta a_{x}, y - \delta a_{y} \right).
\end{align*}

In the final step we have identified \(\psi \left( x, y \right) - \delta a_{y} \partial_{y} \psi \left( x, y \right) - \delta a_{x} \partial_{x} \psi \left( x, y \right)\) as the Taylor series for \(\psi \left( x - \delta a_{x}, y - \delta a_{y} \right)\) upto the first order.
** SOLVED Problem 12.2.1
CLOSED: [2022-10-26 Wed 13:23]
:LOGBOOK:
CLOCK: [2022-10-26 Wed 13:03]--[2022-10-26 Wed 13:21] =>  0:18
:END:
*Starting from \(U[R] \vert xy \rangle = \vert x - y \epsilon_z, x \epsilon_z + y \rangle\) show that \(\langle xy \vert I - \dfrac{i \epsilon_z L_z}{\hbar} \vert \psi \rangle = \psi \left( x + y \epsilon_z, y - x \epsilon_z \right)\).*

\begin{align*}
&U[R] \vert xy \rangle = \vert x - y \epsilon_z, x \epsilon_z + y \rangle \Longrightarrow \langle x - y \epsilon_z, x \epsilon_z + y \vert = \langle xy \vert U^{\dagger} [R].
\end{align*}

Now

\begin{align*}
\langle xy \vert U^{\dagger} [R] &= \langle xy \vert \left(I + \dfrac{i \epsilon_z L_z^{\dagger}}{\hbar}  \right) \\
&= \langle xy \vert \left(I + \dfrac{i \epsilon_z L_z}{\hbar}  \right) \\
&= \langle x + y \epsilon_z, y - x \epsilon_z \vert.
\end{align*}

In the second step we have used the hermiticity of \(L_{z}\). Therefore

\begin{align*}
&\langle xy \vert \left(I + \dfrac{i \epsilon_z L_z}{\hbar}  \right) \vert \psi \rangle = \langle x + y \epsilon_z, y - x \epsilon_z \vert \psi \rangle = \psi \left( x + y \epsilon_z, y - x \epsilon_z \right).
\end{align*}

** SOLVED Problem 12.2.2
CLOSED: [2022-10-26 Wed 18:14]
:LOGBOOK:
CLOCK: [2022-10-26 Wed 13:37]--[2022-10-26 Wed 17:56] =>  4:19
:END:
*Using the commutation relations*

\begin{equation*}
\left[ X, L_{z} \right] = - i \hbar Y,
\end{equation*}

\begin{equation*}
\left[ Y, L_{z} \right] = i \hbar X,
\end{equation*}

\begin{equation*}
\left[ P_{x}, L_{z} \right] = - i \hbar P_{y},
\end{equation*}

\begin{equation*}
\left[ P_{y}, L_{z} \right] = i \hbar P_{x}.
\end{equation*}

*show that \(L_{z} = X P_{y} - Y P_{x}\).*

\begin{align*}
\left[ L_z, P_x \right] &= i \hbar P_y \\
&= P_y \left[ X, P_x \right] = \left[ X P_y, P_x \right] = \left[ X P_y, P_x \right] - \left[ Y P_x, P_x \right] = \left[ X P_y - Y P_x, P_x \right].
\end{align*}

Now we can simply identify \(L_z\) as \(L_z = X P_y - Y P_x\).

** SOLVED Problem 12.2.3
CLOSED: [2022-10-26 Wed 20:38]
:LOGBOOK:
CLOCK: [2022-10-26 Wed 19:25]--[2022-10-26 Wed 20:38] =>  1:13
:END:
*Derive*

\begin{equation*}
L_z \xrightarrow[]{\text{coordinate basis}} - i \hbar \dfrac{\partial }{\partial \phi},
\end{equation*}

by doing a coordinate transformation on

\begin{equation*}
L_z \xrightarrow[]{\text{coordinate basis}} x \left( - i \hbar \dfrac{\partial }{\partial y} \right)- y \left( - i \hbar \dfrac{\partial }{\partial x} \right),
\end{equation*}

*and also by demanding that under an infinitestimal rotaion \(\epsilon_z \vec{k}\), \(\psi \left( x, y \right) = \psi \left( \rho, \phi \right)\) becomes \(\psi \left( \rho, \phi - \epsilon_z \right)\).*

The equations governing the coordinate transform from Cartesian to Polar coordinates are

\begin{equation*}
\rho = \sqrt{x^2 + y^2}, \quad \phi = \tan^{-1} \left( y/x \right),
\end{equation*}

so that

\begin{equation*}
x = \rho \cos \phi, \quad y = \rho \sin \phi.
\end{equation*}

The Jacobian matrix is

\begin{equation*}
\dfrac{\partial \left( \rho, \phi \right)}{\partial \left( x, y \right)} =
\begin{pmatrix}
\dfrac{x}{\sqrt{x^{2} + y^{2}}} & \dfrac{y}{\sqrt{x^{2} + y^{2}}} \\
- \dfrac{y}{x^{2} + y^{2}} & \dfrac{x}{x^{2} + y^{2}}
\end{pmatrix} =
\begin{pmatrix}
\cos \phi & \sin \phi \\
- \sin \phi/ \rho & \cos \phi / \rho
\end{pmatrix}.
\end{equation*}

\begin{align*}
L_{z} &\xrightarrow[]{\text{polar coordinates}} \rho \cos \phi \left( - i \hbar \dfrac{\partial \rho}{\partial y} \dfrac{\partial }{\partial \rho} - i \hbar \dfrac{\partial \phi}{\partial y} \dfrac{\partial }{\partial \phi} \right) - \rho \sin \phi \left( - i \hbar \dfrac{\partial \rho}{\partial x} \dfrac{\partial }{\partial \rho} - \dfrac{\partial \phi}{\partial x} \dfrac{\partial }{\partial \phi} \right) \\
&= \rho \cos \left( - i \hbar \sin \phi \dfrac{\partial }{\partial \rho} - i \hbar \dfrac{\cos \phi}{\rho} \dfrac{\partial }{\partial \phi} \right) - \rho \sin \phi \left( - i \hbar \cos \phi \dfrac{\partial }{\partial \rho} + i \hbar \dfrac{\sin \phi}{\rho} \dfrac{\partial }{\partial \phi} \right) \\
&= \rho \dfrac{\left( \cos^{2} + \sin^{2} \right)}{\rho} \left( - i \hbar \dfrac{\partial }{\partial \phi} \right) \\
&= - i \hbar \dfrac{\partial }{\partial \phi}.
\end{align*}

We now derive the polar coordinate representation of \(L_{z}\) in a more direct manner. An infinitesimal rotation \(\epsilon_{z} \vec{k}\) corresponds to a unitary transformation represented by \(U \left[ R \left( \epsilon_{z} \vec{k} \right) \right] = I - \frac{i \epsilon_{z} L_{z}}{\hbar}\) whose action on the ket \(\vert \rho \phi \rangle\) is \(U \left[ R \left( \epsilon_{z} \vec{k} \right) \right] \vert \rho \phi \rangle = \vert \rho , \phi + \epsilon_{z} \rangle\) so that

\begin{equation*}
\langle \rho \phi \vert U \vert \psi \rangle = \psi \left( \rho , \phi - \epsilon_{z} \right).
\end{equation*}

Writing \(U\) out explicitly

\begin{align*}
\langle \rho \phi \vert I - \dfrac{i \epsilon_{z} L_{z}}{\hbar} \vert \psi \rangle
&= \left \langle \rho \phi \left \lvert I  \right \rvert \psi \right \rangle
- \left \langle \rho \phi \left \lvert \dfrac{i \epsilon_{z} L_{z}}{\hbar}  \right \rvert \psi \right \rangle \\
&= \psi \left( \rho , \phi \right)
- \dfrac{i}{\hbar} \epsilon_{z} \left \langle \rho \phi \left \lvert L_{z} \right \rvert \psi \right \rangle
= \psi \left( \rho, \phi \right)
- \epsilon_{z} \dfrac{\partial \psi}{\partial \phi},
\end{align*}

from which we identify

\begin{equation*}
L_{z} \xrightarrow[]{\text{polar coordinates}} - i \hbar \dfrac{\partial }{\partial \phi}.
\end{equation*}

** SOLVED Problem 12.2.4
CLOSED: [2022-10-27 Thu 00:15]
:LOGBOOK:
CLOCK: [2022-10-26 Wed 20:47]--[2022-10-27 Thu 00:15] =>  3:28
:END:
*Rederive the equivalent of*

\begin{align*}
\begin{bmatrix}
x \\
y 
\end{bmatrix}
&\xrightarrow[]{\epsilon}
\begin{bmatrix}
x + \epsilon_x \\
y + \epsilon_y 
\end{bmatrix}
\xrightarrow[]{R \left( \epsilon_z \vec{k} \right)}
\begin{bmatrix}
\left( x + \epsilon_x \right) - \left( y + \epsilon_y \right) \epsilon_z \\
\left( x + \epsilon_x \right) \epsilon_z + \left( y + \epsilon_y \right)
\end{bmatrix} \\
&\xrightarrow[]{- \epsilon}
\begin{bmatrix}
x- \left( y + \epsilon_y \right) \epsilon_z \\
\left( x + \epsilon_x \right) \epsilon_z + y
\end{bmatrix}
\xrightarrow[]{R \left( - \epsilon_z \vec{k} \right)}
\begin{bmatrix}
x - \epsilon_y \epsilon_z \\
y + \epsilon_x \epsilon_z 
\end{bmatrix},
\end{align*}

*keeping terms of order \(\epsilon_x \epsilon_z^2\). (You may assume \(\epsilon_y = 0\).) Use this information to rewrite*

\begin{equation*}
U \left[ R \left( - \epsilon_z \vec{k} \right) \right] T \left( - \epsilon \right) U \left[ R \left( \epsilon_z \vec{k} \right) \right] T \left( \epsilon \right) = T \left( - \epsilon_y \epsilon_z \vec{i} + \epsilon_x \epsilon_z \vec{j} \right)
\end{equation*}

*to order \(\epsilon_x \epsilon_z^2\). By equating coefficients of this term deduce the constraint*

\begin{equation*}
- 2 L_z P_x L_z + P_x L_z^2 + L_z^2 P_x = \hbar^2 P_x.
\end{equation*}

*Use the identity*

\begin{equation*}
- 2 \Lambda \Omega \Lambda + \Omega \Lambda^2 + \Lambda^2 \Omega \equiv \left[ \Lambda, \left[ \Lambda, \Omega \right] \right],
\end{equation*}

*to verify that the new constraint coming from the \(\epsilon_x \epsilon_z^2\) term is satisfied given the commutation relations between \(P_{x}\), \(P_y\), and \(L_z\).*

We will need to expand the infinitesimal rotation upto second order. We thus write
\begin{equation*}
$U[R(\epsilon_{z} \vec{k})] =
\begin{pmatrix}
1 - \frac{\epsilon_{z}^{2}}{2} & -\epsilon_{z} \\
\epsilon_{z} & 1 - \frac{\epsilon_{z}^{2}}{2}
\end{pmatrix}.
\end{equation*}

Note that the rotation is passive. Assuming \(\epsilon_{y} = 0\), we will effect the four transformations now, refusing to pick up any terms of order greater than \(\epsilon_{x} \epsilon_{z}^{2}\) and products of infinitesimals with finite values.

\begin{align*}
\begin{bmatrix}
x \\
y 
\end{bmatrix}
&\xrightarrow[]{\epsilon}
\begin{bmatrix}
x + \epsilon_x \\
y
\end{bmatrix}
\xrightarrow[]{R \left( \epsilon_z \vec{k} \right)}
\begin{bmatrix}
x - \frac{1}{2} \epsilon_{x} \epsilon_{z}^{2} + \epsilon_{x} - y \epsilon_{z} \\
\epsilon_{z} (x + \epsilon_{x}) + y
\end{bmatrix} \\
&\xrightarrow[]{- \epsilon}
\begin{bmatrix}
x - \frac{1}{2} \epsilon_{x} \epsilon_{z}^{2} - y \epsilon_{z} \\
\epsilon_{z} (x + \epsilon_{x}) + y
\end{bmatrix}
\xrightarrow[]{R \left( - \epsilon_z \vec{k} \right)}
\begin{bmatrix}
x + \frac{1}{2} \epsilon_{x} \epsilon_{z}^{2} \\
y + \epsilon_x \epsilon_z
\end{bmatrix}.
\end{align*}

Thus, \(U \left[ R \left( - \epsilon_z \vec{k} \right) \right] T \left( - \epsilon \right) U \left[ R \left( \epsilon_z \vec{k} \right) \right] T \left( \epsilon \right) = T \left( \dfrac{1}{2} \epsilon_{x} \epsilon_{z}^{2} \vec{i} + \epsilon_{x} \epsilon_{z} \vec{j} \right)\), i.e.,

\begin{align*}
\left( I + \dfrac{i}{\hbar} \epsilon_{z} L_{z} - \dfrac{1}{2\hbar^{2}} \epsilon_{z}^{2} L_{z}^{2} \right) &\left[ I + \dfrac{i}{\hbar} \epsilon_{x} P_{x} \right] \left( I - \dfrac{i}{\hbar} \epsilon_{z} L_{z} - \dfrac{1}{2\hbar^{2}} \epsilon_{z}^{2} L_{z}^{2} \right) \left[ I - \dfrac{i}{\hbar} \epsilon_{x} P_{x} \right] \\
&= I - \dfrac{i}{2\hbar} \epsilon_{x} \epsilon_{z}^{2} P_{x} - \dfrac{i}{\hbar} \epsilon_{x} \epsilon{z} P_{y}.
\end{align*}

From the expansion of the left hand side, we retain terms of the order \(\epsilon_{x} \epsilon_{z}^{2}\) and match it with the coefficient of \(\epsilon_{x} \epsilon_{z}^{2}\) on the right hand side to obtain

\begin{equation*}
- \dfrac{i}{2\hbar^{3}} L_{z}^{2} P_{x} - \dfrac{i}{2 \hbar^{3}} P_{x} L_{z}^{2} + L_{z} P_{x} L_{z} = - \dfrac{i}{2 \hbar} P_{x},
\end{equation*}

which on rearrangement yields

\begin{equation*}
L_{z}^{2} P_{x} + P_{x} L_{z}^{2} - 2 L_{z} P_{x} L_{z} = \hbar^{2} P_{x},
\end{equation*}

same as the ask. We now wish to reduce this operator identity to a relation between the commutators of the generators. To this end we invoke \(- 2 \Lambda \Omega \Lambda + \Omega \Lambda^2 + \Lambda^2 \Omega \equiv \left[ \Lambda, \left[ \Lambda, \Omega \right] \right]\)

\begin{equation*}
\left[ L_{z}, \left[ L_{z}, P_{z} \right] \right] = \hbar^{2} P_{x},
\end{equation*}

and substitute \(\left[ L_{z}, P_{x} \right] = \left[L_{z}, i \hbar P_{y}  \right] = i \hbar \left[L_{z}, P_{y} \right]\) to obtain

\begin{equation*}
i \hbar \left[ L_{z}, P_{y} \right] = \hbar^{2} P_{x},
\end{equation*}

which should satisfy the ask.

** SOLVED Problem 12.3.1
CLOSED: [2022-10-27 Thu 01:08]
*Starting from the Hermiticity condition*

\begin{equation*}
\left \langle \psi_1 \left \lvert L_z  \right \rvert \psi_2 \right \rangle = \left \langle \psi_2 \left \lvert L_z  \right \rvert \psi_1 \right \rangle^{\ast}
\end{equation*}

*derive the condition*

\begin{equation*}
\psi \left( \rho, 0 \right) = \psi \left( \rho, 2 \pi \right).
\end{equation*}

In polar coordinate basis, the Hermiticity condition takes the form

\begin{equation*}
\int_{0}^{\infty} \int_{0}^{2 \pi} \psi_{1}^{\ast} \left( - i \hbar \dfrac{d}{d \phi}  \right) \psi_{2} \thinspace \rho \thinspace d \rho \thinspace d \phi = \left[ \int_{0}^{\infty} \int_{0}^{2 \pi} \psi_{2}^{\ast} \left( - i \hbar \dfrac{d}{d \phi} \right) \psi_{1} \rho \thinspace d \rho \thinspace d \phi \right]^{\ast}.
\end{equation*}

Integrate the inner integral of the left hand side by parts

\begin{equation*}
\int_{0}^{\infty} \rho \thinspace d \rho  \left[ - i \hbar \left[ \psi_{1}^{\ast} \psi_{2} \right]_{0}^{2 \pi}  + i \hbar \int_{0}^{2 \pi} \dfrac{\partial \psi_{1}^{\ast}}{\partial \phi} \psi_{2} \thinspace d \phi \right] = \left[ \int_{0}^{\infty} \int_{0}^{2 \pi} \psi_{2}^{\ast} \left( - i \hbar \dfrac{d}{d \phi} \right) \psi_{1} \rho \thinspace d \rho \thinspace d \phi \right]^{\ast},
\end{equation*}

followed by some rearrangement

\begin{align*}
-i \hbar \left[ &\psi_{1}^{\ast} \psi_{2} \right]_{0}^{2 \pi} \left[ \int_{0}^{\infty} \rho \thinspace d \rho  \right] + i \hbar \left[ \int_{0}^{\infty} \rho d \rho \int_{0}^{2 \pi} \dfrac{\partial \psi_{1}^{\ast}}{\partial \phi} \psi_{2} \thinspace d \phi \right]  \\
&= \left[ \int_{0}^{\infty} \int_{0}^{2 \pi} \psi_{2}^{\ast} \left( - i \hbar \dfrac{d}{d \phi} \right) \psi_{1} \rho \thinspace d \rho \thinspace d \phi \right]^{\ast}.
\end{align*}

See that first integral inside the square bracket? That's trouble brewing right there. To quash it at the get go we demand

\begin{equation*}
\left[ \psi_{1}^{\ast} \psi_{2} \right]_{0}^{2 \pi} = 0,
\end{equation*}

which immediately furnishes the requirement

\begin{equation*}
\psi_{1}^{\ast} \left( \rho, 2 \pi \right) \psi_{2} \left( \rho, 2 \pi \right) = \psi_{1}^{\ast} \left( \rho, 0 \right) \psi_{2} \left( \rho, 0 \right).
\end{equation*}

Demanding \(\psi_{1}^{\ast} \left( \rho, 2 \pi \right) = \psi_{1}^{\ast} \left( \rho, 0 \right)\) and \(\psi_{2} \left( \rho, 2 \pi \right) = \psi_{2} \left( \rho, 0 \right)\) (upto of course a phase factor) makes this work.
** SOLVED Problem 12.3.2
CLOSED: [2022-10-27 Thu 02:11]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 01:08]--[2022-10-27 Thu 02:10] =>  1:02
:END:
*Let us try to deduce the restriction on \(l_z\) from another angle. Consider a superposition of two allowed \(l_z\) eigenstates:*

\begin{equation*}
\psi \left( \rho, \phi \right) = A \left( \rho \right) \exp \left \lbrace i \phi l_z / \hbar  \right \rbrace + B \left( \rho \right) \exp \left \lbrace i \phi l_z^{\prime} / \hbar  \right \rbrace.
\end{equation*}

*By demanding that upon a \(2 \pi\) rotation we get the same physical state (not necessarily the same state vector), show that \(l_z - l_z^{\prime} = m \hbar\), where \(m\) is an integer. By arguing on the grounds of symmetry that the allowed values of \(m\) must be symmetric about zero, show that these values are /either/* \(\dotso, 3 \hbar/2, \hbar /2, - \hbar/2, - 3 \hbar/2, \dotso\) *or* \(\dotso, 2 \hbar, \hbar, 0, \hbar, - 2 \hbar, \dotso\). *It is not possible to restrict* \(l_z\) *any further this way.*

Just multiply each side with its complex conjugate.

\begin{equation*}
\left \lvert \psi \left( \rho, \phi \right)  \right \rvert^{2} = A \left( \rho \right) B \left( \rho \right) \exp \left \lbrace i \phi \left( l_{z} - l_{z}^{\prime} \right) / \hbar \right \rbrace + A \left( \rho \right) B \left( \rho \right) \exp \left \lbrace i \phi \left( l_{z}^{\prime} - l_{z} \right) / \hbar \right \rbrace.
\end{equation*}

Demand \(\left \lvert \psi \left( \rho, \phi \right)  \right \rvert^{2} = \left \lvert \psi \left( \rho, \phi + 2 \pi \right)  \right \rvert^{2}\). We then need

\begin{align*}
&\exp \left \lbrace i 2 \pi \left( l_{z} - l_{z}^{\prime} \right) / \hbar \right \rbrace A \left( \rho \right) B \left( \rho \right)  \exp \left \lbrace i \phi \left( l_{z} - l_{z}^{\prime} \right) / \hbar \right \rbrace \\
&+ \exp \left \lbrace i 2 \pi \left( l_{z} - l_{z}^{\prime} \right) / \hbar \right \rbrace A \left( \rho \right) B \left( \rho \right) \exp \left \lbrace i \phi \left( l_{z}^{\prime} - l_{z} \right) / \hbar \right \rbrace \\
&= A \left( \rho \right) B \left( \rho \right) \exp \left \lbrace i \phi \left( l_{z} - l_{z}^{\prime} \right) / \hbar \right \rbrace + A \left( \rho \right) B \left( \rho \right) \exp \left \lbrace i \phi \left( l_{z}^{\prime} - l_{z} \right) / \hbar \right \rbrace.
\end{align*}

Two necessary conditions emerge: one that  \((l_{z} - l_{z}^{\prime})/ \hbar\) be an integer (say \(m\)) so that \(l_{z} - l_{z}^{\prime} = m \hbar\), and that the values of \(l_{z}\) must be symmetric about \(0\). The latter condition emerges from the the invariance of the previous equation under the transformation \(l_{z} \to l_{z}^{\prime}\) and \(l_{z}^{\prime} \to l_{z}\). Imagine starting in both directions from \(l_{z} = 0\). The first time the difference will be equal to an integer is when the two values are \(-1/2\) and \(1/2\). The second time the difference will be equal to an integer is when the two values are \(-1\) and \(1\). All further occurences are integer multiples of these two occurences. Therefore the allowed values of \(m\) must be symmetric about zero, show that these values are /either/ \(\dotso, 3 \hbar/2, \hbar /2, - \hbar/2, - 3 \hbar/2, \dotso \quad \text{or} \quad \dotso, 2 \hbar, \hbar, 0, \hbar, - 2 \hbar, \dotso\).
** SOLVED Problem 12.3.3
CLOSED: [2022-10-27 Thu 04:32]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 02:30]--[2022-10-27 Thu 04:24] =>  1:54
CLOCK: [2022-10-27 Thu 02:59]--[2022-10-27 Thu 03:31] =>  0:32
:END:
*A particle is described by a wave function*

\begin{equation*}
\psi \left( \rho, \phi \right) = A \exp \left \lbrace - \dfrac{\rho^2}{2 \Delta^2}  \right \rbrace \cos^2 \phi.
\end{equation*}

*Show (by expressing \(\cos^2 \phi\) in terms of \(\Phi_{m}\)) that*

\begin{equation*}
P \left( l_z = 0 \right) = 2/3,
\end{equation*}

\begin{equation*}
P \left( l_z = 2 \hbar \right) = 1/6,
\end{equation*}

\begin{equation*}
P \left( l_z = - 2 \hbar \right) = 1/6.
\end{equation*}

*Hint: Argue that the radial part \(\exp \left \lbrace - \dfrac{\rho^2}{2 \Delta^2} \right \rbrace\) is irrelevant here.*

The radial part is irrelevant because the angular momentum operator (whose eigenstates are of interest here) in coordinate space has has no \(\rho\) dependence:

\begin{equation*}
L_{z} = - i \hbar \dfrac{\partial }{\partial \phi}.
\end{equation*}

Now, expressing \(\cos^{2} \phi\) in terms of \(\Phi_{m}(\phi)\)

\begin{align*}
\cos^{2} \phi &\propto 2 + \exp \left \lbrace 2 i \phi  \right \rbrace + \exp \left \lbrace - 2 i \phi  \right \rbrace \\
&\propto 2 \Phi_{0} + \Phi_{-2} + \Phi_{+2},
\end{align*}

so that

\begin{align*}
\left \lvert \psi \left( \rho, \phi \right)  \right \rvert^{2} &\propto 4 \Phi^{\ast}_{0} \Phi_{0} + \Phi^{\ast}_{2} \Phi_{2} + \Phi^{\ast}_{-2} \Phi_{-2} \\
& \propto 4 + 1 + 1.
\end{align*}

The probabilities are

\begin{equation*}
P \left( l_{z} = 0 \right) = \dfrac{4}{4 + 1 + 1} = \dfrac{2}{3},
\end{equation*}

\begin{equation*}
P \left( l_{z} = 2 \hbar \right) = \dfrac{1}{4 + 1 + 1} = \dfrac{1}{6},
\end{equation*}

\begin{equation*}
P \left( l_{z} = - 2 \hbar \right) = \dfrac{1}{4 + 1 + 1} = \dfrac{1}{6}.
\end{equation*}

** SOLVED Problem 12.3.4
CLOSED: [2022-10-27 Thu 05:17]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 04:59]--[2022-10-27 Thu 05:17] =>  0:18
:END:

*A particle is described by a wave function*

\begin{equation*}
\psi \left( \rho, \phi \right) = A \exp \left \lbrace - \dfrac{\rho^2}{2 \Delta^2} \right \rbrace \left( \dfrac{\rho}{\Delta} \cos \phi + \sin \phi \right).
\end{equation*}

*Show that*

\begin{equation*}
P \left( l_z = \hbar \right) = P \left( l_z = - \hbar \right) = \dfrac{1}{2}.
\end{equation*}

Same trick as before.

\begin{align*}
\cos \phi &\propto \exp \left \lbrace i \phi  \right \rbrace + \exp \left \lbrace - i \phi \right \rbrace \\
&\propto \Phi_{1} + \Phi_{-1},
\end{align*}

and

\begin{align*}
\sin \phi &\propto \exp \left \lbrace i \phi  \right \rbrace + \exp \left \lbrace - i \phi  \right \rbrace \\
&\propto \Phi_{1} - \Phi_{-1},
\end{align*}

so that

\begin{align*}
\left \lvert \psi \right \rvert^{2} &\propto \dfrac{\rho}{\Delta} \Phi^{\ast}_{1} \Phi_{1} + \dfrac{\rho}{\Delta} \Phi^{\ast}_{-1} \Phi_{-1} + \Phi^{\ast}_{1} \Phi_{1} - \Phi^{\ast}_{-1} \Phi_{-1} \\
&\propto \left( \dfrac{\rho}{\Delta} + 1  \right) \left[ \Phi^{\ast}_{1} \Phi_{1} + \Phi^{\ast}_{-1} \Phi_{-1} \right] \\
&\propto \left( \dfrac{\rho}{\Delta} + 1  \right) \left[ 1 + 1 \right]
\end{align*}

The probabilities are

\begin{equation*}
P \left( l_z = \hbar \right) = \dfrac{1}{1 + 1} = \dfrac{1}{2}, \quad  P \left( l_z = - \hbar \right) = \dfrac{1}{1 + 1} = \dfrac{1}{2}.
\end{equation*}

** SOLVED Problem 12.3.5
CLOSED: [2022-10-27 Thu 05:54]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 05:17]--[2022-10-27 Thu 05:52] =>  0:35
:END:
*Consider the time-independent Schrodinger Equation for the radial part of a wave function:*

\begin{equation*}
\left[ - \dfrac{\hbar^2}{2 \mu} \left( \dfrac{d^2}{d \rho^2} + \dfrac{1}{\rho} \dfrac{d}{d \rho} - \dfrac{m^2}{\rho^2} \right) + V \left( \rho \right) \right] R_{Em} \left( \rho \right) = E R_{Em} \left( \rho \right).
\end{equation*}

*The angular momentum seems to generate a repulsive potential. Calculate its gradient and identify it as the centrifugal force.*

Here's the negative of the gradient

\begin{equation*}
- \left( \dfrac{\partial }{\partial \rho} + \dfrac{1}{\rho} \dfrac{\partial }{\partial \phi} \right) \left( \dfrac{\hbar^{2} m^{2}}{2 \mu \rho^{2}} \right) = + \dfrac{\hbar^{2} m^{2}}{\mu \rho^{3}}.
\end{equation*}

The potential is central. The gradient of the potential is a positive 
quantity; it has dimensions of a force, it is a repulsive force.

** SOLVED Problem 12.3.6
CLOSED: [2022-10-27 Thu 17:59]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 17:28]--[2022-10-27 Thu 17:59] =>  0:31
:END:
*Consider a particle of mass \(\mu\) constrained to move on a circle of radius \(a\). Show that \(H = L_z^2 / 2 \mu a^2\). Solve the eigenvalue problem of \(H\) and interpret the degeneracy.*

By definition

\begin{equation*}
L = \vec{r} \times \vec{p} = \left \lvert r  \right \rvert \left \lvert p  \right \rvert \sin \theta \thinspace \hat{n},
\end{equation*}

where \(\theta\) is the included angle between the position and momentum vectors and \(\hat{n}\) is a unit vector perpendicular to \(\vec{r}\) and \(\vec{p}\). For a particle moving along a circle of radius \(a\) on a plane perpendicular to the \(z\) axis, \(\sin \theta = 1\) and thus

\begin{equation*}
L_{z} = a p \Longrightarrow p = L_{z}/a
\end{equation*}

The Hamiltonian for the particle is thus

\begin{equation*}
H = \dfrac{L_{z}^{2}}{2 \mu a^{2}}.
\end{equation*}

The eigenvalue problem of \(H\) is

\begin{equation*}
H \vert \psi \rangle = E \vert \psi \rangle.
\end{equation*}

Substituting \(H\)

\begin{equation*}
L_{z}^{2} \vert \psi \rangle = 2 \mu a^{2} E \vert \psi \rangle \Longrightarrow m^{2} \hbar^{2} \vert \psi \rangle = 2 \mu a^{2} E \vert \psi \rangle,
\end{equation*}

where \(m\) is an integer. Solving for \(E\)

\begin{equation*}
E = \dfrac{m^{2} \hbar^{2}}{2 \mu a^{2}}.
\end{equation*}

The energy eigenvalues have two fold degeneracy: states that on measurement of \(L_{z}\) yield \(m \hbar\), where \(m = \pm n\) ,\(n\) is an integer, have the same energy. This corresponds the orientation of the rotation around the circle about which the energy eigenvalue couldn't care less.

** SOLVED Problem 12.3.7
CLOSED: [2022-10-28 Fri 02:16]
:LOGBOOK:
CLOCK: [2022-10-27 Thu 22:45]--[2022-10-28 Fri 02:16] =>  3:31
CLOCK: [2022-10-27 Thu 21:30]--[2022-10-27 Thu 22:42] =>  1:12
CLOCK: [2022-10-27 Thu 19:11]--[2022-10-27 Thu 21:26] =>  2:15
:END:

*Consider the Hamiltonian*

\begin{equation*}
H = \dfrac{P_x^2 + P_y^2}{2 \mu} + \dfrac{1}{2} \mu \omega^2 \left( X^2 + Y^2 \right).
\end{equation*}

*(1) Convince yourself \([H, L_z] = 0\) and reduce the eigenvalue problem of \(H\) to the radial differential equation for \(R_{Em} \left( \rho \right)\).*

Start with a coordinate transform to polar coordinates

\begin{equation*}
H = \left[ -\dfrac{\hbar^2}{2 \mu} \left( \dfrac{\partial^{2} }{\partial \rho^{2}} + \dfrac{1}{\rho} \dfrac{\partial }{\partial \rho}} + \dfrac{1}{\rho^{2}}\dfrac{\partial^{2} }{\partial \phi^{2}} \right) + \dfrac{1}{2} \mu \omega^{2} \rho^{2} \right] \psi_{E} \left( \rho, \phi \right) = E \psi_{E} \left( \rho, \phi \right).
\end{equation*}

The Hamiltonian is /rotationally invariant/, \(\phi \to \phi + \phi^{\prime}\) for arbitrary constant \(\phi^{\prime}\) leaves the the form of the Eigenvalue equation unchanged, \(\left[ H, L_{z} \right]\) vanishes. If that wasn't obvious, how about ``the Hamiltonian operator doesn't care (has no way to know) whether it's being fed a state or its rotated (about \(z\), by measurement of \(L_{z}\)) comrade.`` Better? Assume an ansatz of the form

\begin{equation*}
\psi \left( \rho, \phi \right) = R_{Em} \left( \rho \right) \Phi_{m} \left( \phi \right),
\end{equation*}

where

\begin{equation*}
\Phi_{m} \left( \phi \right) = \dfrac{1}{\sqrt{2 \pi}} \exp \left \lbrace i m \phi  \right \rbrace.
\end{equation*}

Feeding it in yields the /radial differential equation/ via a separation of variables

\begin{equation*}
\left[ -\dfrac{\hbar^2}{2 \mu} \left( \dfrac{d^{2} }{d \rho^{2}} + \dfrac{1}{\rho} \dfrac{d }{d \rho}} - \dfrac{m^{2}}{\rho^{2}} \right) + \dfrac{1}{2} \mu \omega^{2} \rho^{2} \right] R_{Em} \left( \rho \right) = E R_{Em} \left( \rho \right).
\end{equation*}

*(2) Examine the equation as \(\rho \to 0\) and show that*

\begin{equation*}
R_{Em} \left( \rho \right) \xrightarrow[]{\rho \to 0} \rho^{\left \lvert m  \right \rvert}
\end{equation*}

Suppose \(R_{Em} \sim \rho^{\alpha} + \mathcal{O} \left( \rho^{\alpha + 1} \right)\) as \(\rho \to 0\). Feeding in

\begin{equation*}
- \dfrac{\hbar^{2}}{2 \mu} \left[ \alpha \left( \alpha - 1 \right) \rho^{\alpha - 2} + \alpha \rho^{\alpha-2} - m^{2} \rho^{\alpha - 2}\right] + \dfrac{1}{2} \mu \omega^{2} \rho^{\alpha + 2} = E \rho^{\alpha} + \mathcal{O} \left( \rho^{\alpha + 1} \right).
\end{equation*}

As \(\rho \to 0\) the leading term is \(\sim \rho^{\alpha-2}\) whose vanishment requires us to make the demand

\begin{equation*}
\left[ \alpha \left( \alpha - 1 \right) + \alpha - m^{2} \right] = 0 \Longrightarrow \alpha^{2} = m^{2} \Longrightarrow \alpha = \left \lvert m  \right \rvert.
\end{equation*}

The absolute value appears because if it /didn't/ and suppose that \(m\) were negative, we will end up with divergent solution as \(\rho \to 0\) which is a turn off on physical grounds. It must be that

\begin{equation*}
R_{Em} \left( \rho \right) \xrightarrow[]{\rho \to 0} \rho^{\left \lvert m  \right \rvert}.
\end{equation*}

*(3) Show likewise that up to powers of \(\rho\)*

\begin{equation*}
R_{Em} \left( \rho \right) \xrightarrow[]{\rho \to \infty} \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar  \right \rbrace
\end{equation*}

On physical grounds we also need \(R_{Em} \to 0\) as \(\rho \to \infty\). We need the \(\rho \to \infty\) behaviour to be made of a function \(f(\rho)\) that can kill arbitrary /finite/ positive powers of \(\rho\) as would appear in \(\rho^{\left \lvert m  \right \rvert}\). To state the obvious, we need the falling exponential, i.e.,

\begin{equation*}
f(\rho) = \exp \left \lbrace - a \thinspace \rho^{\left \lvert k  \right \rvert}  \right \rbrace,
\end{equation*}

for arbitrary \(k\). \(a\) shall be via dimensional considerations. Why not the Gaussian? It's nice. To satisfy the ask

\begin{equation*}
R_{Em} \left( \rho \right) \xrightarrow[]{\rho \to \infty} \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar \right \rbrace.
\end{equation*}

*So assume that \(R_{Em} \left( \rho \right) = \rho^{|m|} \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar  \right \rbrace U_{Em} \left( \rho \right)\).*

Ok.

*(4) Switch to dimensionless variables \(\epsilon = E / \hbar \omega\), \(y = \left( \mu \omega / \hbar \right)^{1/2} \rho\).*

The radial equation in terms of dimensionless variables \(\epsilon = E / \hbar \omega\) and \(y = \left( \mu \omega / \hbar \right)^{1/2} \rho\) is

\begin{equation*}
\left(- \dfrac{d^{2}}{dy^{2}}  - \dfrac{1}{y} \dfrac{d}{dy}  + \dfrac{m^2}{y^2} +  y^{2} - 2 \epsilon\right) R = 0.
\end{equation*}

*(5) Convert the equation for \(R\) into an equation for \(U\) (I suggest proceeding in two stages: \(R = y^{\left \lvert m  \right \rvert} \omega\), \(\omega = \exp \left \lbrace - y^2 /2  \right \rbrace U\)). You should end up with*

\begin{equation*}
U^{\prime \prime} + \left[ \left( \dfrac{2 \left \lvert m  \right \rvert + 1}{y} \right) - 2 y \right] U^{\prime} + \left( 2 \epsilon - 2 \left \lvert m  \right \rvert - 2 \right) U = 0.
\end{equation*}

Following the suggestion let \(R = y^{\left \lvert m  \right \rvert} \omega\), with \(\omega = \exp \left \lbrace - y^{2} / 2 \right \rbrace U\). Clear the area, we're about to make a mess. One at a time,

\begin{align*}
\dfrac{d^{2}}{dy^{2}} \left( y^{\left \lvert m  \right \rvert} \omega \right) &= \dfrac{d}{dy} \left[ \omega \left \lvert m  \right \rvert y^{\left \lvert m  \right \rvert - 1} + y^{\left \lvert m  \right \rvert} \dfrac{d \omega}{dy} \right] \\
&= \omega \left \lvert m  \right \rvert \left( \left \lvert m  \right \rvert - 1 \right) y^{\left \lvert m  \right \rvert - 2}
+ 2 \left \lvert m  \right \rvert y^{\left \lvert m  \right \rvert - 1} \dfrac{d \omega}{dy}
+ y^{\left \lvert m  \right \rvert} \dfrac{d^{2} \omega}{dy^{2}},
\end{align*}

\begin{equation*}
\dfrac{d}{dy} \left( y^{\left \lvert m  \right \rvert} \omega \right) = \omega \left \lvert m  \right \rvert y^{\left \lvert m  \right \rvert - 1} + y^{\left \lvert m  \right \rvert} \dfrac{d \omega}{dy},
\end{equation*}

\begin{equation*}
\dfrac{d \omega}{dy} = \exp \left \lbrace -y^{2}/2 \right \rbrace \left[  U^{\prime} - y U \right],
\end{equation*}

\begin{equation*}
\dfrac{d^{2} \omega}{d y^{2}} = \exp \left \lbrace - y^{2} /2  \right \rbrace \left[ - y \left(  U^{\prime} - y U \right) + \left( U^{\prime \prime} - U - y U^{\prime} \right) \right].
\end{equation*}

Substitute \(d \omega / dy\) and \(d^2\omega / dy^{2}\) in \(\dfrac{d^2}{dy^2} \left( y^{\left \lvert m  \right \rvert} \omega \right)\) and \(\frac{d}{dy} \left( y^{\left \lvert m  \right \rvert} \omega \right)\) to obtain

\begin{align*}
\dfrac{d^{2}}{dy^{2}} \left( y^{\left \lvert m  \right \rvert} \omega \right) &= \omega \left \lvert m  \right \rvert \left( \left \lvert m  \right \rvert - 1 \right) y^{\left \lvert m  \right \rvert - 2} \\
&+ 2 \left \lvert m  \right \rvert y^{\left \lvert m  \right \rvert - 1} \left[ \exp \left \lbrace -y^{2}/2 \right \rbrace \left(  U^{\prime} - y U \right)\right] \\
&+ y^{\left \lvert m  \right \rvert} \exp \left \lbrace - y^{2} /2  \right \rbrace \left[ U^{\prime \prime} - (1 + y) U - 2 y U^{\prime} \right],
\end{align*}

\begin{equation*}
\dfrac{d}{dy} \left( y^{\left \lvert m  \right \rvert} \omega \right) = \omega \left \lvert m  \right \rvert y^{\left \lvert m  \right \rvert - 1} + y^{\left \lvert m  \right \rvert} \exp \left \lbrace -y^{2}/2 \right \rbrace \left[  U^{\prime} - y U \right].
\end{equation*}

The radial equation

\begin{equation*}
\dfrac{d^{2}}{dy^{2}} \left( y^{\left \lvert m  \right \rvert} \omega \right) + \dfrac{1}{y} \dfrac{d}{dy} \left( y^{\left \lvert m  \right \rvert} \omega \right)  - \dfrac{m^2}{y^2} y^{\left \lvert m  \right \rvert} \omega -  y^{2} y^{\left \lvert m  \right \rvert} \omega  + 2 \epsilon y^{\left \lvert m  \right \rvert} \omega  = 0,
\end{equation*}

on substituting the values above and simplifying becomes

\begin{equation*}
U^{\prime \prime} + \left[ \left( \dfrac{2 \left \lvert m  \right \rvert + 1}{y} \right) - 2 y \right] U^{\prime} + \left( 2 \epsilon - 2 \left \lvert m  \right \rvert - 2 \right) U = 0.
\end{equation*}

*(6) Argue that a power series for \(U\) of the form*

\begin{equation*}
U (y) = \sum_{r = 0}^{\infty} C_{r} y^{r}
\end{equation*}

*will lead to a /two-term/ recursion relation.*

\(U^{\prime \prime}\) will kill a couple of powers of \(U\). \(U^{\prime}\) will kill a lone power but one of the factors multiplying it will restore it while the other will kill another; the net effect being a killing of a couple of powers. Matching coeffcients will thus yield two-term recurrence.

*(7) Find the relation between \(C_{r + 2}\) and \(C_{r}\). Argue that the series must terminate at some finite \(r\) if the \(y \to \infty\) behaviour of the solution is to be acceptable. Show that \(\epsilon = r + \left \lvert m  \right \rvert + 1\) leads  to termination after \(r\) terms. Now argue that \(r\) is necessarily even - i.e., \(r = 2k\). (Show that if \(r\) is odd, the behaviour of \(R\) as \(\rho \to 0\) is not \(\rho^{\left \lvert m  \right \rvert}\).) So finally you must end up with*

\begin{equation*}
E = \left( 2k + \left \lvert m  \right \rvert + 1 \right) \hbar \omega, \quad k = 0,1,2, \dotso
\end{equation*}

Feed \(U (y) = \sum_{r = 0}^{\infty} C_{r} y^{r}\) to

\begin{equation*}
U^{\prime \prime} + \left[ \left( \dfrac{2 \left \lvert m  \right \rvert + 1}{y} \right) - 2 y \right] U^{\prime} + \left( 2 \epsilon - 2 \left \lvert m  \right \rvert - 2 \right) U = 0.
\end{equation*}

to obtain

\begin{equation*}
\sum_{r=2}^{\infty} r \left( r - 1 \right) C_{r} y^{r-2} + \left( 2 \left \lvert m  \right \rvert + 1 \right) \sum_{r=2}^{\infty} r C_{r} y^{r-2} - 2 \sum_{r=0}^{\infty} r C_{r} y^{r} - 2 \left(1 + \left \lvert m  \right \rvert - \epsilon \right) \sum_{r=0}^{\infty} C_{r} x^{r} = 0
\end{equation*}

Re-index

\begin{equation*}
\sum_{r=0}^{\infty} \left[ (r + 2) \left( r + 1 \right) C_{r+2} + \left( 2 \left \lvert m  \right \rvert + 1 \right) (r + 2) C_{r+2} - 2 r C_{r} - 2 \left(1 + \left \lvert m  \right \rvert - \epsilon \right) C_{r} \right] x^{r} = 0.
\end{equation*}

Imposing identical vanishment of the coefficients yields the desired recurrence

\begin{equation*}
C_{r+2} = \dfrac{2 \left( 1 + \left \lvert m  \right \rvert - \epsilon + r\right)}{(r+2)(r + 2 + 2 \left \lvert m  \right \rvert)} C_{r}, \quad r \geq 0.
\end{equation*}

The series must terminate at some finite \(r\) because if it /didn't/, the falling exponential won't be able to kill it (as a multiplicative factor to a polynomial of its argument, the falling exponential can only kill, for sufficiently large values of its argument, polynomials of /finite/ order) and we will end up with a diverging solution for \(y \to \infty\). Our hands are tied; we must demand

\begin{equation*}
\epsilon = 1 + r + \left \lvert m  \right \rvert.
\end{equation*}

Fulfillment would mean that the series vanishes after \(r\) terms. Now \(r\) must necessarily be even because if it /were'nt/, the order of the leading term in the series for \(y \to \infty\) (say \(p\)) would be odd: it's non-zero coefficient must have been obtained by unrolling the recurrence from the seed \(C_{1}\) - no way around it. But if \(C_{1}\) were non-zero, the \(y \to 0\) behaviour would take the form

\begin{equation*}
U(y) \sim y \Longrightarrow R \sim \rho^{\left \lvert m  \right \rvert + 1}
\end{equation*}

inconsistent with

\begin{equation*}
R_{Em} \left( \rho \right) \xrightarrow[]{\rho \to 0} \rho^{\left \lvert m  \right \rvert}.
\end{equation*}

Thus, we arrive at the additional conclusion that the solution \(U\) only has even powers of \(y\), the odd powers are dead because the seed that would have led to their survival was killed by construction.

*Define \(n = 2k + \left \lvert m  \right \rvert\), so that*

\begin{equation*}
E_{n} = \left( n + 1 \right) \hbar \omega.
\end{equation*}

Ok.

*(8) For a given \(n\), what are the allowed values of \(\left \lvert m  \right \rvert\)? Given this information show that for a given \(n\), the degeneracy is \(n + 1\). Compare this to what you found in Cartesian coordinates.*

Solve \(n = 2k + \left \lvert m  \right \rvert\) for \(\left \lvert m  \right \rvert\) to obtain \(\left \lvert m  \right \rvert = n - 2k\). \(k\) being a positive integer, the possible values of \(m\) are from \(-n\) to \(n\) with hops of \(2\). Depending on whether \(n\) is even (or odd), \(m\) may take the value \(0\) (or \(1\)), i.e., energy levels \(E_{n}\) where \(n\) is even permit rotation free states (this is circular, can you see how?). In either case, the degeneracy is \(n + 1\): standing on /any/ integer on the number line, claim \(n\) integers on either side as yours, how many you got? \(2n\). Now give half of them away. You still got the one you are standing on for a total of \(n + 1\). It just so happens that you'll be standing on either \(0\) or \(1\) for this situation.

*(9) Write down all the normalized eigenfunctions corresponding to \(n = 0, 1\).*

For \(n = 0\), \(m = 0\), \(\Phi_{0} = 1/\sqrt{2 \pi}\), \(C_{2} = 0\), \(U(y) = C_{0} \sim 1\), \(R_{0,0} \sim \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar  \right \rbrace\) so that \(\psi_{00}(\rho, \phi) = \psi_{00}(\rho) =  \frac{1}{\sqrt{2 \pi}} \exp \left \lbrace - \left( \frac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace\). Using the Gaussian integral result \(\int_{-\infty}^{\infty} dx \thinspace \exp \left \lbrace - a x^{2}  \right \rbrace = \sqrt{\frac{\pi}{a}}\), the normalized wavefunction for \(n = m = 0\) is

\begin{equation*}
\psi_{0,0} \left( \rho, \phi \right) = \psi_{0,0} \left( \rho \right) = \sqrt{\dfrac{\mu \omega}{\pi \hbar}} \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace.
\end{equation*}

For \(n =1, \quad m = -1, \thinspace 0, \thinspace 1\), \(\Phi_{0} = 1/ \sqrt{2 \pi}\), \(\Phi_{1} = 1/\sqrt{2 \pi} \exp \left \lbrace i \phi \right \rbrace\), \(\Phi_{-1} = 1/\sqrt{2 \pi} \exp \left \lbrace - i \phi \right \rbrace\). For \(m = 0\), \(C_{2} = 0\), \(U(y) = C_{0} \sim 1\), \(R_{10} \sim \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar  \right \rbrace\) so that \(\psi_{10}(\rho, \phi) = \frac{1}{\sqrt{2 \pi}} \exp \left \lbrace - \left( \frac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace\). For \(m = \pm 1\), \(C_{2} = 0\) \(U(y) = C_{0} \sim 1\), \(R_{1, \pm 1} \sim \rho \exp \left \lbrace - \mu \omega \rho^{2} / 2 \hbar  \right \rbrace\) so that \(\psi_{1, \pm 1}\) \(\left( \rho, \phi \right) = \frac{1}{\sqrt{2}} \rho \exp \left \lbrace - \left( \frac{\mu \omega}{2 \hbar} \right) \rho^2  \right \rbrace \exp \left \lbrace \pm i \phi  \right \rbrace\). Using the result

\begin{equation*}
\int _{0}^{\infty }x^{n}e^{-ax^{2}}\,dx={\begin{cases}{\dfrac {\Gamma \left({\frac {n+1}{2}}\right)}{2\left(a^{\frac {n+1}{2}}\right)}} \quad (n > -1,\ a > 0)\\\\{\dfrac {(2k-1)!!}{2^{k+1}a^{k}}}{\sqrt {\dfrac {\pi }{a}}}; \quad (n=2k,\ k{\text{ integer}},\ a > 0)\\\\{\dfrac {k!}{2(a^{k+1})}}; \quad (n=2k+1,\ k{\text{ integer}},\ a > 0)\end{cases}}},
\end{equation*}

the normalized wave functions are

\begin{equation*}
\psi_{1,0} = \sqrt{\dfrac{\mu \omega}{\pi \hbar}} \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace,
\end{equation*}

\begin{equation*}
\psi_{1, \pm 1} = \dfrac{1}{\sqrt{\pi}} \left(\dfrac{\mu \omega}{\hbar}\right) \rho \thinspace \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \pm i \phi \right \rbrace.
\end{equation*}

*(10) Argue that the \(n = 0\) function /must/ equal the corresponding one found in Cartesian coordinates. Show that the two \(n = 1\) solutions are linear combinations of their counterparts in Cartesian coordinates. Verify that the parity of the states is \((-1)^{n}\) as you found in Cartesian coordinates.*

\begin{equation*}
\psi_{0,0} \left( \rho, \phi \right) = \psi_{0,0} \left( \rho \right) = \sqrt{\dfrac{\mu \omega}{\pi \hbar}} \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace.
\end{equation*}

Because thee energy levels of this problem have a degeneracy of \(n + 1\), for \(n = 1\) the degeneracy is \(1\) i.e., there is a unique state corresponding to \(E_{0}\) and it must to be the one we found. The one in Cartesian coordinates better be equal to this. As for the two \(n = 1\) solutions, some rearrangement followed by use of Euler's formula yields the ask

\begin{align*}
\psi_{1, \pm 1} &= \dfrac{1}{\sqrt{\pi}} \left(\dfrac{\mu \omega}{\hbar}\right) \rho \thinspace \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \pm i \phi \right \rbrace \\
& \dfrac{1}{\sqrt{\pi}} \left(\dfrac{\mu \omega}{\hbar}\right) \rho \exp \left \lbrace  \pm i \phi \right \rbrace \thinspace \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace \\
&= \dfrac{1}{\sqrt{\pi}} \left(\dfrac{\mu \omega}{\hbar}\right) \left( \rho \cos \phi \pm  \rho \sin \phi \right) \thinspace \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \rho^{2} \right \rbrace \\
&\xrightarrow[]{\rho, \phi \to x, y} \dfrac{1}{\sqrt{\pi}} \left(\dfrac{\mu \omega}{\hbar}\right) \left( x \pm i y \right) \thinspace \exp \left \lbrace - \left( \dfrac{\mu \omega}{2 \hbar} \right) \left[ x^{2} + y^{2} \right] \right \rbrace.
\end{align*}

The action of the parity operator in \(\psi_{n,m} \left( \rho, \phi \right)\) is

\begin{align*}
P \psi_{n,m} \left(\rho,\phi\right) &= \psi_{n,m} \left(\rho,\phi + \pi \right) \\
&= R \left( \rho \right) \Phi_{m} \left( \phi + \pi \right) \\
&= \dfrac{1}{\sqrt{2 \pi}} R \left( \rho \right) \exp \left \lbrace i m (\phi + \pi)  \right \rbrace \\
&= \dfrac{1}{\sqrt{2 \pi}} R \left( \rho \right) \left( -1 \exp \left \lbrace i \phi \right \rbrace \right)^{m} \\
&= \left( -1 \right)^{m} R \left( \rho \right) \Phi_{m} \left( \phi \right)\\
&= \left( -1 \right)^{n} \psi_{n,m}.
\end{align*}

In the last step we have used the definition \(n = \left \lvert m  \right \rvert + 2k\) to conclude that if \(n\) is even (or odd) then \(m\) is even (or odd). Thus the parity of the states is \((-1)^{n}\).
** SOLVED Problem 12.3.8
CLOSED: [2022-11-04 Fri 03:54] SCHEDULED: <2022-11-03 Thu>
:LOGBOOK:
CLOCK: [2022-11-04 Fri 00:20]--[2022-11-04 Fri 03:53] =>  3:33
CLOCK: [2022-11-03 Thu 22:34]--[2022-11-03 Thu 23:23] =>  0:49
CLOCK: [2022-11-03 Thu 17:00]--[2022-11-03 Thu 22:34] =>  5:34
:END:
*Consider a particle of charge \(q\) in a vector potential*

\begin{equation*}
\vec{A} = \dfrac{B}{2} \left( - y \vec{i} + x \vec{j} \right).
\end{equation*}

*(1) Show that the magnetic field is \(B = B \vec{k}\).*

By definition

\begin{equation*}
\vec{B} = \nabla \times \vec{A} = \dfrac{B}{2}
\begin{vmatrix}
\vec{i} & \vec{j} & \vec{k} \\
\partial_{x} & \partial_{y} & \partial_{z} \\
-y & x & 0
\end{vmatrix} =
\dfrac{B}{2} \thinspace 2 \vec{k} = B \vec{k}.
\end{equation*}

*(2) Show that a classical particle in this potential will move in circles at an angular frequency \(\omega_{0} = q B / \mu c\).*

Let's do it like a brute first. For simplicity, assume \(v_{z}(0) = 0\), i.e., the particle is restricted to the \(xy\) -plane. This changes the physics of the system only to the extent that a /space curve/ transforms into a /plane curve/ (If the only degrees of freedom for your eye were translations along \(\vec{k}\) - you're looking at the \(xy\) - plane straight down (or up) and can't shift your gaze, basically - would you be able to tell if the charge is moving toward (away) from you or not? Well if you can't tell, does it matter?) which will be useful later. The Lorentz force

\begin{equation*}
\vec{F} = q \left( \vec{E} + \vec{v} \times \vec{B} \right),
\end{equation*}

in the lack of an electric field reduces to

\begin{equation*}
\vec{F(t)} = q \vec{v(t)} \times \vec{B} \right) = q
\begin{vmatrix}
\vec{i} & \vec{j} & \vec{k} \\
v_{x}(t) & v_{y}(t) & v_{z}(t) \\
0 & 0 & B
\end{vmatrix}
= q B [v_y(t) \vec{i} - v_x(t) \vec{j}].
\end{equation*}

Courtesy of Newton

\begin{equation*}
\mu \vec{a}(t) = q B \left( v_{y}(t) \vec{i} - v_{x}(t) \vec{j} \right) \quad \text{and} \quad \mu a (t) = q B v(t),
\end{equation*}

where \(\mu\) is the charge's mass, \(a(t) \equiv \sqrt{a_{x}(t) + a_{y}(t)}\) and \(v(t) \equiv \sqrt{v_{x}(t) + v_{y}(t)}\), the second equation obtained by constructing the dot product of each side of the first equation with itself.

In component form, the first vector equation yields the following two ODEs

\begin{equation*}
\mu \thinspace D_{t}^{2} x(t) = q B \thinspace D_{t} y(t) \quad \text{and} \quad \mu \thinspace D_{t}^{2} y(t) = - q B \thinspace D_{t} x(t).
\end{equation*}

Now, note that

\begin{align*}
\mu D_{t} a(t) &= \dfrac{1}{\sqrt{a_{x}(t) + a_{y}(t)}} \left[ \mu a_{x} (t) D_{t} a_{x}(t) + \mu a_{y} (t) D_{t} a_{y}(t) \right] \\
&= \dfrac{1}{\sqrt{a_{x}(t) + a_{y}(t)}} \left[ \mu a_{x}(t) D_{t}^{3} x(t) + \mu a_{y}(t) D_{t}^{3} y(t) \right] \\
&= \dfrac{1}{\sqrt{a_{x}(t) + a_{y}(t)}} \left[ a_{x}(t) q B D_{t}^{2} y(t) - a_{y}(t) q B D_{t}^{2} x(t) \right] \\
&= \dfrac{1}{\sqrt{a_{x}(t) + a_{y}(t)}} \left[ a_{x}(t) q B a_{y}(t) - a_{y}(t) q B a_{x}(t) \right] = 0.
\end{align*}

So we obtain the new rewrite

\begin{equation*}
\mu \vec{a}(t) = q B \left( v_{y}(t) \vec{i} - v_{x}(t) \vec{j} \right) \quad \text{and} \quad \mu a = q B v
\end{equation*}

for the equations of motion: the magnitude of the particle's velocity and acceleration are time-invariant.

That the particle moves in circles is now easily made obvious by noting that the radius of curvature \(R(t)\) is time-invariant. The particle's trajectory, being a /plane curve/ has the radius of curvature

\begin{align*}
R(t) \equiv \left \lvert \dfrac{\left( D_{t} x(t) + D_{t} y(t) \right)^{3/2}}{D_{t} x(t) D_{t}^{2} y(t) - D_{t} y(t) D_{t}^{2} x(t)}  \right \rvert &= \left \lvert \dfrac{(v(t))^{3}}{qB(v(t)^{2})/ \mu} \right \rvert \\
&= \dfrac{\mu v(t)}{\left \lvert q  \right \rvert B} \\
&= \dfrac{\mu v}{\left \lvert q  \right \rvert B} \equiv r \Longrightarrow D_{t} R = 0.
\end{align*}

Incidentally, this also furnishes the radius of the circular path as \(r =\frac{\mu v}{\left \lvert q  \right \rvert B}\).

That the angular frequency is given by \(\omega_{0} = q B/ \mu c\) is made obvious by using \(r =\frac{\mu v}{\left \lvert q  \right \rvert B}\) to eliminate \(q B\) in \(\mu a = q B v\) so that

\begin{equation*}
a = \dfrac{\mu v^{2}}{r}.
\end{equation*}

Via a connection to the physics of /uniform circular motion/ use

\begin{equation*}
\dfrac{\mu v^{2}}{r} = q B v \Longrightarrow \omega_{0} \equiv \dfrac{v}{r} = \dfrac{qB}{\mu},
\end{equation*}

along with the fact that when \(B\) is expressed in units \([B] = \text{g}^{1/2} \text{cm}^{-1/2} \text{s}^{-1}\)

\begin{equation*}
\omega_{0} = q B / \mu \xrightarrow[]{[B] = \text{g}^{1/2} \text{cm}^{-1/2} \text{s}^{-1}} q B / \mu c.
\end{equation*}

Note that satisfying the ask /did not/ require us to actually solve the equations of motion, but we relied on results of uniform circular motion. The price of ignorance of the physics of uniform circular motion (or just acting out really and insisting on being a rather remarkable brute, even for a brute) is having to solve the ODEs. Keeping in mind that we want \(\Im x(t) = \Im y(t) = 0\), and that \(\sqrt{(D_{x}^{2} x(t))^{2} + (D_{y}^{2} y(t))^{2}} = q B v/ \mu\), the solutions are

\begin{equation*}
x(t) = x_{0} - \left( \mu v /qB \right) \sin \left( [qB/ \mu] t - \varphi \right) \quad \text{and} \quad y(t) = y_{0} + \left( \mu v/qB \right) \cos \left( [qB/ \mu] t - \varphi \right).
\end{equation*}

These are periodic functions of time \(t\) with periodicity \(\omega_{0} \equiv qB/ \mu\) - the physical interpretation of \(\omega_{0}\) being that \(1/ \omega_{0}\) is the /angular time-period/ \(T_{\omega_{0}}\) - the time it takes the particle to complete one revolution (sweeping \(2 \pi\)), so that \(\omega_{0}\) is called the /angular frequency/. A \(2 \pi\) sweep scales to a distance of \(2 \pi \mu v / \left \lvert q  \right \rvert B\) at a radius \(\mu v / \left \lvert q  \right \rvert B\) which is crunched by a velocity \(v\) in time

\begin{equation*}
T = (2 \pi \mu v / \left \lvert q  \right \rvert B)/v = \dfrac{2 \pi \mu}{\left \lvert q  \right \rvert B} = \dfrac{2 \pi}{\omega_{0}} = \dfrac{1}{f}, \quad \text{where} \quad f \equiv \dfrac{\omega_{0}}{2 \pi},
\end{equation*}

is the /frequency/, or in units \([B] = \text{g}^{1/2} \text{cm}^{-1/2} \text{s}^{-1}\),

\begin{equation*}
T = (2 \pi \mu c v / \left \lvert q  \right \rvert B)/v = \dfrac{2 \pi \mu c}{\left \lvert q  \right \rvert B} = \dfrac{2 \pi}{\omega_{0}},
\end{equation*}

/independent/ of the radius of the trajectory - which, if not in the grips of an existential crisis or alcohol intoxication, should not be (too) surprising. The kinetic energy is \(T \equiv (1/2) \mu v^{2} = q^{2} B^{2} r^{2} / 2 \mu c\), /inversely proportional/ to the mass. I'm tired. I'll leave the non-brute version for a later date, concluding with:

#+begin_quote
*``The language of physics is math. And as every useful language, there is some sort of slang. Just get over it, mathematicians."* - Marcel Weber, 2 years ago on YouTube. [2022-11-03 Thu 20:50]
#+end_quote

#+begin_quote
*``My physics teacher explained us the difference between a mathematician and a physicist. Imagine both are at a traffic light, the mathematician will wait until the traffic light indicates he can cross the street and he will even check whether all cars are stopped, and he will arrive safely at the other end. On the other hand, the physicist won't even look at the traffic light and will directly cross the street, if he arrives safely, it means the traffic light was likely to be green and if he doesn't, it means it wasn't green."* - Yikes, 3 years ago on YouTube. [2022-11-03 Thu 20:50]
#+end_quote

#+begin_quote
*Mathematician:  You can't divide by 0.
Physicist:  It will cancel out with another infinity later on.* - kmb bmj, 2 years ago on YouTube. [2022-11-03 Thu 20:50]
#+end_quote

*(3) Consider the Hamiltonian for the corresponding quantum problem:*

\begin{equation*}
H = \dfrac{\left[ P_x + q Y B / 2 c \right]^{2}}{2 \mu} + \dfrac{\left[ P_y - q X B / 2c \right]^{2}}{2 \mu}.
\end{equation*}

*Show that \(Q = \left( c P_{x} + q Y B /2 \right)/ q B\) and \(P = \left( P_{y} - q X B / 2c \right)\) are canonical. Write \(H\) in terms of \(P\) and \(Q\) and show that allowed levels are \(E = \left( n + \frac{1}{2} \right) \hbar \omega_{0}\).*

Because

\begin{align*}
\left[ Q, Q \right] &= \left[ P, P \right] = 0, \quad \text{and} \\
&\left[ Q, P \right] = \left[ \left( c/qB \right) P_{x} + Y/2, P_{y} - \left( qB/c \right) X/2  \right] \\
&= - \dfrac{1}{2} \left[ P_{x}, X \right] + \dfrac{1}{2} \left[ Y, P_{y} \right] = i \hbar,
\end{align*}

the transformation is canonical. THe Hamiltonian in terms of \(P\) and \(Q\) is

\begin{equation*}
H(P,Q) = \left( \dfrac{qB}{c} \right)^{2} \dfrac{Q^{2}}{2 \mu} + \dfrac{P^{2}}{2 \mu} = \dfrac{P^{2}}{2 \mu} + \dfrac{1}{2} \mu \omega_{0}^{2} Q^{2}.
\end{equation*}

If you're stuck, I got only one question for you: did you do your commutators? Go commute some and then come use some. Once you're nodding in agreement, we'll be prodding forth, identifying \(H(Q,P)\) as an oscillator Hamiltonian and writing as the energy levels:

\begin{equation*}
E = \hbar \omega_{0} \left(n + \dfrac{1}{2} \right).
\end{equation*}

*Hold on a second, is this allowed?* Yes, why not? Go retrace (better yet reconstruct) the steps for the quantum harmonic oscillator. Nowhere was it /essential/ to identify \(P\) and \(Q\) as the momentum and position operators, nor is it anywhere necessary to invoke the /correspondence principle/. \(P\) and \(Q\) can travel through the rigmarole simply as /operators/ and have associated with them some /ladder like/ (or carpet, whatever) operators \(a\) and \(a^{\dagger}\), so that finding the energy levels reduces to solving the eigenvalue problem of some /occupation number like/ operator \(\hat{n}\). Goes without saying that the /spectrum/ of \(\hat{n}\) is under no obligation to match the spectrum of the occupation number operator of harmonic oscillator proper, where identification of the momentum and position operators rendered it non-degenerate.

*(4) Expand \(H\) out in terms of the original variables and show*

\begin{equation*}
H = H \left( \dfrac{\omega_{0}}{2}, \mu \right) - \dfrac{\omega_{0}}{2} L_{z}.
\end{equation*}

*where \(H \left( \omega_{0}/2 , \mu \right)\) is the Hamiltonian for an isotropic two-dimensional harmonic oscillator of mass \(\mu\) and frequency \(\omega_{0}/2\). Argue that the same basis that diagonalized \(H \left(  \omega_{0} /2, \mu \right)\) will diagonalize \(H\). By thinking in terms of this basis, show that the allowed levels of \(H\) are \(E = \left( k + \dfrac{1}{2} \left \lvert m  \right \rvert  - \dfrac{m}{2} + \dfrac{1}{2} \right) \hbar \omega_{0}\), where \(k\) is any integer and \(m\) is the angular momentum. Convince yourself that you get the same levels from this formula as from the earlier one \(E = \left( n + \frac{1}{2} \right) \hbar \omega_{0}\).*

Just expand

\begin{equation*}
H = \dfrac{\left[ P_x + q Y B / 2 c \right]^{2}}{2 \mu} + \dfrac{\left[ P_y - q X B / 2c \right]^{2}}{2 \mu},
\end{equation*}

so that

\begin{align*}
H &= P_{x}^{2}/2 \mu + P_{y}^{2}/2 \mu + \dfrac{1}{2} \mu \left(\dfrac{\omega_{0}}{2}\right)^{2} \left( X^{2} + Y^{2} \right) + \dfrac{\omega_{0}}{4} \left( P_{x} Y + Y P_{x} - P_{y} X - X P_{y} \right) \\
&= P_{x}^{2}/2 \mu + P_{y}^{2}/2 \mu + \dfrac{1}{2} \mu \left(\dfrac{\omega_{0}}{2}\right)^{2} \left( X^{2} + Y^{2} \right) + \dfrac{\omega_{0}}{2} \left( Y P_{x} - P_{y} X \right) \\
&= P_{x}^{2}/2 \mu + P_{y}^{2}/2 \mu + \dfrac{1}{2} \mu \left(\dfrac{\omega_{0}}{2}\right)^{2} \left( X^{2} + Y^{2} \right) - \dfrac{\omega_{0}}{2} L_{z} \\
&= H \left( \dfrac{\omega_{0}}{2}, \mu \right) - \dfrac{\omega_{0}}{2} L_{z}.
\end{align*}

Now consider

\begin{equation*}
\left[ H(\omega_{0}/2, \mu), H \right] = \left[ H(\omega_{0}/2, \mu), H(\omega_{0}/2, \mu)  \right] - \left[ H(\omega_{0}/2, \mu), \left( \omega_0/2 \right) L_{z} \right].
\end{equation*}

Both of these commutators vanish: the first trivially, the second by recognizing that the isotropic oscillator Hamiltonian is invariant under rotations about \(z\) (the first part of the previous question). Thus

\begin{equation*}
\left[ H(\omega_{0}/2, \mu), H \right] = 0,
\end{equation*}

and there exist a /unique/ basis that achieves the simultaneous diagonalization of \(H\) and \(H(\omega_{0}/2, \mu)\). It must therefore be the basis that diagonalized \(H(\omega_{0}/2, \mu)\). The eigenkets of \(H\) are /simultaneous eigenvectors/ of \(H(\omega_{0}/2, \mu)\) and \(L_{z}\) and have eigenvalues \((2k + \left \lvert m  \right \rvert + 1) \hbar \omega_{0}/2\) and \(m \hbar\) so that

\begin{equation*}
H \vert \psi \rangle_{H} = \hbar \omega_{0} \left[ k +  \dfrac{\left \lvert m  \right \rvert}{2} + \dfrac{1}{2} - \dfrac{m}{2} \right] \vert \psi \rangle_{H} = E \vert \psi \rangle_{H} \Longrightarrow E = \left(k +  \dfrac{\left \lvert m  \right \rvert}{2} + \dfrac{1}{2} - \dfrac{m}{2} \right) \hbar \omega_{0}.
\end{equation*}
Adding/subtracting a half-integer to/from a half integer yields an integer: \(\left \lvert m  \right \rvert/2 - m/2\) is /always/ an integer. With \(n \equiv k + m\), \(E\) reduces to

\begin{equation*}
E = \left( n + \dfrac{1}{2} \right) \hbar \omega_{0}.
\end{equation*}

** SOLVED Problem 12.4.1
CLOSED: [2022-11-04 Fri 05:37]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 04:42]--[2022-11-04 Fri 05:35] =>  0:53
:END:
*(1)* *Verify that \(\text{Eqs.} (12.4.9)\) and \(\text{Eqs.} (12.4.8)\) are equivalent, given the definition of \(\epsilon_{ijk}\).*

Turn on /Einstein summation convention/. We need to evaluate

\begin{equation*}
\vec{c} = \vec{a} \times \vec{b} \stackrel{?}{\Longleftrightarrow}  c_{i} = \epsilon_{ijk} a_{j} b_{k}.
\end{equation*}

\begin{align*}
c_{1} &= \epsilon_{ijk} a_{j} b_{k} =  (\epsilon_{111} a_{1} b_{1} + \epsilon_{112} a_{1} b_{2} + \epsilon_{113} a_{1} b_{3} \\
&+ \epsilon_{121} a_{2} b_{1} + \epsilon_{122} a_{2} b_{1} + \epsilon_{123} a_{2} b_{3} \\
&+ \epsilon_{131} a_{3} b_{1} + \epsilon_{132} a_{3} b_{2} + \epsilon_{133} a_{3} b_{3}) \\
&= \left( \epsilon_{123} a_{2} b_{3} + \epsilon_{132} a_{3} b_{2} \right) \vec{i} = a_{2} b_{3} - a_{3} b_{2}.
\end{align*}

Similarly

\begin{equation*}
c_{2} = a_{3} b_{1} - a_{1} b_{2},
\end{equation*}

and

\begin{equation*}
c_{3} = a_{1} b_{2} - a_{2} b_{1}.
\end{equation*}

But these are precisely the components of the cross product of \(\vec{a}\) and \(\vec{b}\):

\begin{equation*}
\vec{c} =
\begin{vmatrix}
\vec{1} & \vec{2} & \vec{3} \\
a_{1} & a_{2} & a_{3} \\
b_{1} & b_{2} & b_{3}
\end{vmatrix}
= \left( a_2 b_3 - a_3 b_2 \right) \vec{1} + \left( a_3 b_1 - a_1 b_3 \right) \vec{2} + \left( a_1 b_2 - a_2 b_1 \right) \vec{3} = c_{1} \vec{1} + c_{2} \vec{2} + c_{3} \vec{3}.
\end{equation*}

Running this argument in reverse is trivial. Our expression thus evaluates as true.

*(2)* *Let \(U_{1}\), \(U_{2}\), \(U_{3}\) be three energy eigenfunctions of a single particle in some potential. Construct the wave function \(\psi_{A}(x_{1}, x_{2}, x_{3})\) of three fermions in this potential, one of which is in \(U_{1}\), one in \(U_{2}\), and one in \(U_{3}\), using the \(\epsilon_{ijk}\) tensor.*

\begin{align*}
\vert \psi \rangle_{A} = (3!)^{-1/2} &[ \vert U_{1} U_{2} U_{3} \rangle - \vert U_{1} U_{3} U_{2} \rangle \\
+ &\vert U_{2} U_{3} U_{1} \rangle - \vert U_{2} U_{1} U_{3} \rangle \\
+ &\vert U_{3} U_{1} U_{2} \rangle - \vert U_{3} U_{2} U_{1} \rangle ].
\end{align*}

The analogy with the cross product is obvious and we may write

\begin{equation*}
\vert \psi \rangle_{A} = \left( 3! \right)^{-1/2} \epsilon_{ijk} \vert U_{i} U_{j} U_{k} \rangle.
\end{equation*}

** SOLVED Problem 12.4.2
CLOSED: [2022-11-04 Fri 08:37]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 06:56]--[2022-11-04 Fri 08:37] =>  1:41
:END:
*(1)* *Verify* \(\text{Eq.} (12.4.2)\) *by first constructing the* \(3 \times 3\) *matrices corresponding to* \(R (\epsilon_{x} \vec{i})\) *and* \(R(\epsilon_{y} \vec{j})\), *to order* \(\epsilon\).

We get going from

\begin{equation*}
R \left( - \epsilon_{y} \vec{j} \right) R \left( - \epsilon_{x} \vec{i} \right) R \left( \epsilon_{y} \vec{j} \right) R \left( \epsilon_x \vec{i} \right) = R \left( - \epsilon_{x} \epsilon_{y} \vec{k} \right).
\end{equation*}

\begin{align*}
R \left( \epsilon_{x} \vec{i} \right) =
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & -\epsilon_{x} \\
0 & \epsilon_{x} & 1 \\
\end{pmatrix},
R \left( \epsilon_{y} \vec{j} \right) =
\begin{pmatrix}
1 & 0 & \epsilon_{y} \\
0 & 1 & 0 \\
- \epsilon_{y} & 0 & 1
\end{pmatrix},
R \left( \epsilon_{z} \vec{k} \right) =
\begin{pmatrix}
1 & -\epsilon_{z} & 0 \\
\epsilon_z & 1 & 0 \\
0 & 0 & 1
\end{pmatrix},
\end{align*}

and
\begin{equation*}
R \left( - \epsilon_{x} \vec{i} \right) =
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & \epsilon_{x} \\
0 & - \epsilon_{x} & 1
\end{pmatrix},
R \left( - \epsilon_{y} \vec{j} \right) =
\begin{pmatrix}
1 & 0 & -\epsilon_{y} \\
0 & 1 & 0 \\
\epsilon_{y} & 0 & 1
\end{pmatrix},
R \left( \epsilon_{z} \vec{k} \right) =
\begin{pmatrix}
1 & \epsilon_{z} & 0 \\
-\epsilon_z & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}.
\end{equation*}

Stop fretting, we gotta do it:

\begin{align*}
R \left( - \epsilon_{y} \vec{j} \right) R \left( - \epsilon_{x} \vec{i} \right) R \left( \epsilon_{y} \vec{j} \right) R \left( \epsilon_x \vec{i} \right) &=
\begin{pmatrix}
1 & 0 & -\epsilon_{y} \\
0 & 1 & 0 \\
\epsilon_{y} & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & \epsilon_{x} \\
0 & - \epsilon_{x} & 1
\end{pmatrix} \times \\
&\begin{pmatrix}
1 & 0 & \epsilon_{y} \\
0 & 1 & 0 \\
- \epsilon_{y} & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & -\epsilon_{x} \\
0 & \epsilon_{x} & 1 \\
\end{pmatrix} \\
&=
\begin{pmatrix}
1 & \epsilon_{x} \epsilon_{y} & -\epsilon_{y} \\
0 & 1 & \epsilon_{x} \\
\epsilon_y & -\epsilon_{x}  & 1
\end{pmatrix}
\begin{pmatrix}
1 & \epsilon_{x} \epsilon_{y} & \epsilon_{y} \\
0 & 1 & -\epsilon_{x} \\
- \epsilon_y & \epsilon_{x}  & 1
\end{pmatrix} \\
&=
\begin{pmatrix}
1 + \epsilon_{y}^{2} & \epsilon_{x} \epsilon_{y} & -\epsilon_{x}^{2} \epsilon_{y} \\
- \epsilon_{x} \epsilon_{y} & 1 + \epsilon_{x}^{2} & 0 \\
0 & \epsilon_{x} \epsilon_{y}^{2} & 1 + \epsilon_{x}^{2} + \epsilon_{y}^{2}
\end{pmatrix} \\
&=
\begin{pmatrix}
1 & \epsilon_{y} \epsilon_{x} & 0 \\
-\epsilon_{x} \epsilon_y & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}
= R \left( -\epsilon_x \epsilon_y \vec{k} \right).
\end{align*}


*(2)* *Provide the steps connecting* \(\text{Eqs.} (12.4.3)\) *and* \(\text{Eqs.} (12.4.4\text{a})\).

\begin{equation*}
U \left[R \left( - \epsilon_{y} \vec{j} \right)\right] U \left[R \left( - \epsilon_{x} \vec{i} \right) \right] U \left[R \left( \epsilon_{y} \vec{j} \right)\right] U \left[ R \left( \epsilon_x \vec{i} \right) \right] = U \left[ R \left( - \epsilon_{x} \epsilon_{y} \vec{k} \right) \right].
\end{equation*}

Using \(U \left[ R \left( \epsilon_{e} \hat{e} \right) \right] = \exp \left \lbrace - i \epsilon_{e} L_{e}} / \hbar \right \rbrace = I - \dfrac{i}{\hbar} \epsilon_{e} \right) L_{e}\), we demand

\begin{equation*}
\left( I + \dfrac{i}{\hbar} \epsilon_y L_{y} \right) \left( I + \dfrac{i}{\hbar} \epsilon_x L_{x} \right) \left( I - \dfrac{i}{\hbar} \epsilon_y L_{y} \right) \left( I - \dfrac{i}{\hbar} \epsilon_x L_{x} \right) = \left( I + \dfrac{i}{\hbar} \epsilon_x \epsilon_y L_{k} \right).
\end{equation*}

Shattering the left hand side and, apart from \(I\), discarding anything and everything devoid of \(\epsilon_{x} \epsilon_{y}\) we have

\begin{equation*}
I - \dfrac{1}{\hbar^{2}} \epsilon_{y} \epsilon_{x} L_{y} L_{z} + \epsilon_{y} \epsilon_{x} L_{y} L_{x} = I + \dfrac{\epsilon_{y} \epsilon_{x}}{\hbar^{2}} \left[ L_{x}, L_{y} \right] = I + \dfrac{i}{\hbar} \epsilon_{x} \epsilon_{y} L_{k}.
\end{equation*}

Matching coefficients immediately furnishes

\begin{equation*}
i \hbar L_{k} = \left[ L_{x}, L_{y} \right].
\end{equation*}

*(3)* *Verify that* \(L_{x}\) *and* \(L_{y}\) *defined in* \(\text{Eq.} (12.4.1)\) *satisfy* \(\text{Eq.} (12.4.4\text{a})\). *The proof for other commutators follows by cyclic permutation.*

We want to evaluate

\begin{equation*}
\left[ Y P_{z} - Z P_{y}, Z P_{x} - X P_{z} \right] \stackrel{?}{=} i \hbar \left( X P_{y} - Y P_{x} \right),
\end{equation*}

so begin with the left hand side and write

\begin{equation*}
\left[ Y P_{z} - Z P_{y}, Z P_{x} - X P_{z} \right] = \left[ Y P_{z}, Z P_{x} \right] - \left[ Y P_{z}, X P_{z} \right] - \left[ Z P_{y}, Z P_{x} \right] + \left[ Z P_{y}, X P_{z} \right].
\end{equation*}

This will shatter to \(4 \times 4 = 16\) pieces, what cruelty! Relax and notice that /all/ 16 pieces involve canonical commutation relations and that the /second/ and /third/ term leave no survivors. The first and last term leave as lone survivors \(Y \left[ P_{z}, Z \right] P_{x} = - i \hbar Y P_{x}\) and \(X \left[ Z, P_{z} \right] P_{y} = i \hbar X P_{y}\), so that

\begin{equation*}
\left[ Y P_{z} - Z P_{y}, Z P_{x} - X P_{z} \right] = i \hbar \left( X P_{y} - Y P_{x} \right).
\end{equation*}

** SOLVED Problem 12.4.3
CLOSED: [2022-11-04 Fri 06:48]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 05:56]--[2022-11-04 Fri 06:48] =>  0:52
:END:
*We would like to show that* \(\hat{\theta} \cdot \vec{L}\) *generates rotations about the axis parallel to* \(\hat{\theta}\).

*(1)* *Show that when a vector* \(\vec{r}\) *rotated by an angle* \(\delta \vec{\theta}\), *it changes to* \(\vec{r} + \delta \vec{\theta} \times \vec{r}\).

As suggested start with \(\vec{r} \bot \delta \vec{\theta}\). Interpret \(\vec{r}\) as the radius vector of a circle. Rotation by an infinitesimal angle \(\delta \theta\) means that the tip of the radius vector \(\vec{r}\) has been progressed along the circumference by an infinitesimal distance \(r \delta \theta\) so that it is now at \(\vec{r^{\prime}}\). In polar coordinate \(\vec{r^{\prime}} = r \thinspace \hat{r} + r \delta \theta \thinspace \hat{\theta}\). Note that \(\hat{\theta} \bot \hat{r}\).  Now \(\delta \vec{\theta} \times \vec{r} = r \delta \theta \thinspace \hat{\theta}\) so that \(\vec{r^{\prime}} = r \thinspace \hat{r} + r \delta \theta \thinspace \hat{\theta} = \vec{r} + \delta \vec{\theta} \times \vec{r}\), as advertised. To remove the qualifier \(\vec{r} \bot \delta \vec{\theta}\), we need only note that if \(\vec{r}\) makes some angle \(\vartheta\) with \(\delta \vec{\theta}\), we may interpret \(\vec{r_{\bot}} = r \sin \vartheta \hat{r}\), as a radius vector perpendicular to \(\delta \vec{\theta}\) that undergoes an infinitesimal rotation by an angle \(\delta \theta\). To obtain it's whereabouts after the rotation we need add \(r_{\bot} \delta \theta \thinspace \hat{\theta} = r \sin \vartheta \thinspace \delta \theta \thinspace \hat{\theta} = \delta \vec{\theta} \times \vec{r}\) to \(\vec{r_{\bot}}\).The tip of \(\vec{r_{\bot}}\) and \(\vec{r}\) are co-localized: whatever we add to \(\vec{r_{\bot}}\), may be added to \(\vec{r}\) to obtain \(\vec{r^{\prime}}\) so \(\vec{r^{\prime}} = \vec{r} + \delta \vec{\theta} \times \vec{r}\) as advertised.

*(2)* *We therefore demand that (to first order, as usual)*

\begin{equation*}
\psi \left( \vec{r} \right) \xrightarrow[]{U \left[ R \left( \delta \vec{\theta} \right) \right]} \psi \left( \vec{r} - \delta \vec{\theta} \times \vec{r} \right) = \psi \left( \vec{r} \right) - \left( \delta \vec{\theta} \times \vec{r} \right) \cdot \nabla \psi.
\end{equation*}

*Comparing to* \(U \left[ R \left( \delta \vec{\theta} \right) \right] = I - \left( i \delta \theta / \hbar \right) L_{\hat{\theta}}\), *show that* \(L_{\hat{\theta}}= \hat{\theta} \cdot \vec{L}\).

\begin{align*}
U \left[ R \left( \delta \vec{\theta} \right) \right] \psi \left( \vec{r} \right) &= \left(I - \left( i \delta \theta / \hbar \right) L_{\hat{\theta}}\right) \psi \left( \vec{r} \right)  \\
&= \psi \left( \vec{r} - \delta \vec{\theta} \times \vec{r} \right) \\
&= \psi \left( \vec{r} \right) - \left( \delta \vec{\theta} \times \vec{r} \right) \cdot \nabla \psi \\
&= \left( I - \delta \vec{\theta} \times \vec{r} \cdot \nabla \right) \psi \left( \vec{r} \right) \\
&= \left( I - \delta \vec{\theta} \cdot \vec{r} \times \nabla \right) \psi \left( \vec{r} \right) \\
&= \left( I - \left( i \delta \vec{\theta} / \hbar \right) \cdot \left( \vec{r} \times \dfrac{\hbar}{i} \nabla \right) \right) \psi \left( \vec{r} \right) \\
&= \left( I - \left( i \delta \theta / \hbar \right) \left[ \hat{\theta} \cdot \left( \vec{r} \times \dfrac{\hbar}{i} \nabla \right) \right] \right) \psi \left( \vec{r} \right) \\
&= \left( I - \left( i \delta \theta / \hbar \right) \left[ \hat{\theta} \cdot \vec{L} \right] \right) \psi \left( \vec{r} \right).
\end{align*}

Comparing the first and last equality of this chain immediately furnishes the ask: \(L_{\hat{\theta}} = \hat{\theta} \cdot \vec{L}\).

** SOLVED Problem 12.4.4
CLOSED: [2022-11-04 Fri 09:19]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 08:38]--[2022-11-04 Fri 09:19] =>  0:41
:END:
*Recall that* \(\vec{V}\) is a vector operator if its components \(V_{i}\) transform as

\begin{equation*}
U^{\dagger} \left[ R \right] \thinspace V_{i} \thinspace U \left[ R \right] = \sum_{j} R_{ij} \thinspace V_{j}.
\end{equation*}
*(1)* *For an infinitesimal rotation* \(\delta \vec{\theta}\), *show, on the basis of the previous exercise, that*

\begin{equation*}
\sum_{j} R_{ij} \thinspace V_{j} = V_{i} + \left( \delta \vec{\theta} \times \vec{V} \right)_{i} = V_{i} + \sum_{j} \sum_{k} \epsilon_{ijk} \left( \delta \theta \right)_{j} V_{k}.
\end{equation*}

This is straightforward. \(R\) effects the infinitesimal rotation \(\delta \vec{\theta}\) here.

\begin{equation*}
R \vec{V} = \vec{V} + \delta \vec{\theta} \times V \Longrightarrow R_{ij} V_{j} = V_{i} + \left( \delta \vec{\theta} \times \vec{V} \right)_{i} = V_{i} + \epsilon_{ijk} \left( \delta \theta \right)_{j} V_{k}.
\end{equation*}

*(2)* *Feed in* \(U \left[ R \right] = 1 - \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}\) *into the left-hand side of* \(\text{Eq.} (12.4.13)\) *and deduce that*

\begin{equation*}
\left[ V_{i}, L_{j} \right] = i \hbar \sum_{k} \epsilon_{ijk} V_{k}.
\end{equation*}

Feeding, we have

\begin{equation*}
\exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace V_{i} \exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace = R_{ij} V_{j}.
\end{equation*}

Yes this is the same as feeding \(U \left[ R \right] = 1 - \left( i / \hbar \right) \delta \vec{\theta} \cdot \vec{L}\). Invoke now that sweetness of a mouthful /Baker-Campbell-Hausdorff/ to write

\begin{equation*}
\exp \left \lbrace A  \right \rbrace B \exp \left \lbrace - A  \right \rbrace = B + \left[ A, B \right] + \dfrac{1}{2!} \left[ A, \left[ A, B \right] \right] + \dotso
\end{equation*}

Apply to \(\exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace V_{i} \exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace\) and discard everything except \(V_{i} + \left( i/ \hbar \right) \delta \vec{\theta} \cdot \left[ \vec{L}, V_{i} \right]\) (the reason becomes clear now, do you see it?) to obtain

\begin{equation*}
\exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace V_{i} \exp \left \lbrace \left( i/ \hbar \right) \delta \vec{\theta} \cdot \vec{L}  \right \rbrace = V_{i} + \left( i / \hbar \right) \delta \vec{\theta} \cdot \left[ \vec{L}, V_{i} \right] = R_{ij} V_{j}.
\end{equation*}

But from the previous part \(R_{ij} V_{j} = V_{i} + \epsilon_{ijk} \left( \delta \theta \right)_{j} V_{k}\), so

\begin{equation*}
\left( i/ \hbar \right) \delta \vec{\theta} \cdot \left[ \vec{L}, V_{i} \right] = \left( i/ \hbar \right) \left( \delta \theta \right)_{j} \left[ L_{j}, V_{i} \right] = \epsilon_{ijk} \left( \delta \theta \right)_{j} V_{k} \Longrightarrow \left[ V_{i}, L_{j} \right] = i \hbar \epsilon_{ijk} V_{k}.
\end{equation*}

*This is as good definition of a vector operator as* \(\text{Eq.} (12.4.13)\). *By setting* \(\vec{V} = \vec{L}\), *we can obtain the commutation rules among the* \(L\)'s.

How very cool.

** SOLVED Problem 12.5.1
CLOSED: [2022-11-04 Fri 11:20]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 09:59]--[2022-11-04 Fri 11:20] =>  1:21
:END:
*Consider a vector field* \(\vec{\Psi} (x, y)\) *in two dimensions.* *From* =Fig.12.1= *it follows that under an infinitesimal rotation* \(\epsilon_{z} \vec{k}\),

\begin{equation*}
\Psi_{x} \to \Psi_{x}^{\prime} (x, y) = \Psi_{x} \left( x + y \epsilon_{z}, y - x \epsilon_{z} \right) - \Psi_{y} \left( x + y \epsilon_{z}, y - x \epsilon_{z} \right) \epsilon_{z},
\end{equation*}

\begin{equation*}
\Psi_{y} \to \Psi_{y}^{\prime}(x,y) = \Psi_{x} \left( x + y \epsilon_{z}, y - x \epsilon_{z} \right) \epsilon_{z} + \Psi_{y} \left( x + y \epsilon_{z}, y - x \epsilon_{z} \right).
\end{equation*}

*Show that (to order* \(\epsilon_{z}\) *)*

\begin{equation*}
\begin{bmatrix}
\Psi_{x}^{\prime} \\
\Psi_{y}^{\prime}
\end{bmatrix} =
\left[
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
- \dfrac{i \epsilon_z}{\hbar}
\begin{pmatrix}
L_{z} & 0 \\
0 & L_{z}
\end{pmatrix}
- \dfrac{i \epsilon_z}{\hbar}
\begin{pmatrix}
0 & - i \hbar \\
i \hbar & 0
\end{pmatrix}
\right]
\begin{bmatrix}
\Psi_{x} \\
\Psi_{y} 
\end{bmatrix},
\end{equation*}

*so that*

\begin{equation*}
J_{z} = L_{z}^{(1)} \otimes I^{(2)} + I^{(1)} \otimes S_{z}^{(2)} = L_{z} + S_{z}.
\end{equation*}

*where* \(I^{(2)}\) is a \(2 \times 2\) *identity matrix with respect to the vector components,* \(I^{(1)}\) *is the identity operator with respect to the argument* \((x, y)\) *of* \(\Psi(x, y)\). *This example only illustrates the fact that* \(J_{z} = L_{z} + S_{z}\) *if the wave function is not a scalar*. *An example of half-integral eigenvalues will be provided when we consider spin in a later chapter. (In the present example,* \(S_{z}\) *has eigenvalues* \(\pm \hbar\) *.)*

We have

\begin{align*}
\Psi_{x}^{\prime} (x, y) &= \Psi_{x} \left( x, y \right) + y \epsilon_{z} \partial_{x} \Psi_{x} (x, y) - x \epsilon_{z} \partial_{y} \Psi_{x} \left( x, y \right) \\
& - \epsilon_{z} \Psi_{y} \left( x, y \right) - y \epsilon_{z}^{2} \partial_{x} \Psi_{y} (x, y) + x \epsilon_{z}^{2} \partial_{y} \Psi_{y} \left( x, y \right).
\end{align*}

To order \(\epsilon_{z}\)

\begin{equation*}
\Psi_{x}^{\prime} (x, y) &= \Psi_{x} \left( x, y \right) + y \epsilon_{z} \partial_{x} \Psi_{x} (x, y) - x \epsilon_{z} \partial_{y} \Psi_{x} \left( x, y \right) \\
& - \epsilon_{z} \Psi_{y} \left( x, y \right).
\end{equation*}

Multiply and divide each term the right with in the right hand side with \(i \hbar\) and simplify to obtain

\begin{align*}
\Psi_{x}^{\prime} (x, y) &= \left[ 1 - \dfrac{i \epsilon_{z}}{\hbar} \left[ x P_{y} - y P_{x} \right] \right] \Psi_{x} - \dfrac{i \epsilon_{z}}{\hbar} \left( - i \hbar  \right) \Psi_{y} \left( x, y \right) \\
&= \left[ 1 - \dfrac{i \epsilon_{z}}{\hbar} L_{z} \right] \Psi_{x} - \dfrac{i \epsilon_{z}}{\hbar} \left( -i \hbar \right) \Psi_{y} \left( x, y \right).
\end{align*}

Similarly we have

\begin{align*}
\Psi_{y}^{\prime} (x, y) &= \left[ 1 - \dfrac{i \epsilon_{z}}{\hbar} \left[ x P_{y} - y P_{x} \right] \right] \Psi_{y} - \dfrac{i \epsilon_{z}}{\hbar} \left( - i \hbar  \right) \Psi_{x} \left( x, y \right) \\
&= \left[ 1 - \dfrac{i \epsilon_{z}}{\hbar} L_{z} \right] \Psi_{y} - \dfrac{i \epsilon_{z}}{\hbar} \left( -i \hbar \right) \Psi_{x} \left( x, y \right).
\end{align*}

Shattering

\begin{equation*}
\begin{bmatrix}
\Psi_{x}^{\prime} \\
\Psi_{y}^{\prime}
\end{bmatrix} =
\left[
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
- \dfrac{i \epsilon_z}{\hbar}
\begin{pmatrix}
L_{z} & 0 \\
0 & L_{z}
\end{pmatrix}
- \dfrac{i \epsilon_z}{\hbar}
\begin{pmatrix}
0 & - i \hbar \\
i \hbar & 0
\end{pmatrix}
\right]
\begin{bmatrix}
\Psi_{x} \\
\Psi_{y} 
\end{bmatrix},
\end{equation*}

produces the two equations obtained above so it must have arose from them.
** SOLVED Problem 12.5.2
Closed: [2022-11-04 Fri 13:58]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 11:26]--[2022-11-04 Fri 13:43] =>  2:17
:END:
*(1)* *Verify that the* \(2 \times 2\) *matrices* \(J_{x}^{(1/2)}\), \(J_{y}^{(1/2)}\), *and* \(J_{z}^{(1/2)}\) *obey the commutation rule* \(\left[ J_x^{(1/2)}, J_{y}^{(1/2)} \right] = i \hbar J_{z}^{(1/2)}\).

We have

\begin{equation*}
J_{x}^{(1/2)} =
\begin{pmatrix}
0 & \hbar/2 \\
\hbar/2 & 0
\end{pmatrix},
\quad
J_{y}^{(1/2)} =
\begin{pmatrix}
0 & -i \hbar/2 \\
i \hbar/2 & 0
\end{pmatrix},
\quad
J_{z}^{(1/2)} =
\begin{pmatrix}
\hbar/2 & 0 \\
0 & - \hbar/2
\end{pmatrix}.
\end{equation*}


Now

\begin{align*}
- \dfrac{i}{\hbar} \left[ J_{x}^{(1/2)}, J_{y}^{(1/2)} \right] &=
- \dfrac{i}{\hbar}
\left[
\begin{pmatrix}
0 & \hbar/2 \\
\hbar/2 & 0
\end{pmatrix}
\begin{pmatrix}
0 & -i \hbar/2 \\
i \hbar/2 & 0
\end{pmatrix}
-
\begin{pmatrix}
0 & -i \hbar/2 \\
i \hbar/2 & 0
\end{pmatrix}
\begin{pmatrix}
0 & \hbar/2 \\
\hbar/2 & 0
\end{pmatrix}
\right] \\
&= - \dfrac{i}{\hbar}
\left[
\begin{pmatrix}
i \hbar^{2}/4 & 0 \\
0 & - i \hbar^{2}/4
\end{pmatrix}
-
\begin{pmatrix}
-i \hbar^{2}/4 & 0 \\
0 & i \hbar^{2}/4
\end{pmatrix}
\right] \\
&=
-\dfrac{i}{\hbar}
\begin{pmatrix}
i \hbar^{2}/2 & 0 \\
0 & - i \hbar^{2}/2
\end{pmatrix} \\
&=
\begin{pmatrix}
\hbar/2 & 0 \\
0 & - \hbar/2
\end{pmatrix} = J_{z}^{(1/2)}.
\end{align*}

*(2)* *Do the same for the* \(3 \times 3\) *matrices* \(J_{i}^{(1)}\).

We have

\begin{equation*}
J_{x}^{(1)} =
\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix},
\end{equation*}

\begin{equation*}
J_{y}^{(1)} =
\begin{pmatrix}
0 & -i \hbar/2^{1/2} & 0 \\
i \hbar/2^{1/2} & 0 & -i \hbar/2^{1/2} \\
0 & i \hbar/2^{1/2} & 0
\end{pmatrix},
\end{equation*}

\begin{equation*}
J_{z}^{(1)} =
\begin{pmatrix}
\hbar & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & -\hbar
\end{pmatrix}.
\end{equation*}

What a horror show. Anyway, 

\begin{align*}
- \dfrac{i}{\hbar} \left[ J_{x}^{(1)}, J_{y}^{(1)} \right] =
- \dfrac{i}{\hbar}
&\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix}
\begin{pmatrix}
0 & -i \hbar/2^{1/2} & 0 \\
i \hbar/2^{1/2} & 0 & -i \hbar/2^{1/2} \\
0 & i \hbar/2^{1/2} & 0
\end{pmatrix} \\
+ \dfrac{i}{\hbar}
&\begin{pmatrix}
0 & -i \hbar/2^{1/2} & 0 \\
i \hbar/2^{1/2} & 0 & -i \hbar/2^{1/2} \\
0 & i \hbar/2^{1/2} & 0 \\
\end{pmatrix}
\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix}
\right].
\end{align*}

Not really, cause foresight (hindsight? dishonesty?) speeds up compute.

\begin{equation*}
- \dfrac{i}{\hbar} \left[ J_{x}^{(1)}, J_{y}^{(1)} \right] =
\begin{pmatrix}
\hbar & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & - \hbar
\end{pmatrix}.
\end{equation*}

*(3)* *Construct the* \(4 \times 4\) *matrices and verify that*

\begin{equation*}
\left[ J_{x}^{(3/2)}, J_{y}^{(3/2)} \right] = i \hbar J_{z}^{(3/2)}.
\end{equation*}

Can't read these off the book. Need to construct them. Can't be that bad

\begin{align*}
\left \langle 3/2, m^{\prime} \left \lvert J_x  \right \rvert 3/2, m \right \rangle &= \left \langle 3/2, m^{\prime} \left \lvert \dfrac{J_{+}+J_{-}}{2}  \right \rvert 3/2, m \right \rangle \\
&= \dfrac{\hbar}{2} \delta_{m^{\prime}, m+1} \left[\left(3/2-m\right)\left(3/2+m+1\right)\right]^{1/2} \\
&+ \dfrac{\hbar}{2} \delta_{m^{\prime}, m-1} \left[\left(3/2+m\right)\left(3/2-m+1\right)\right]^{1/2}.
\end{align*}

\begin{align*}
\left \langle 3/2, m^{\prime} \left \lvert J_y  \right \rvert 3/2, m \right \rangle &= \left \langle 3/2, m^{\prime} \left \lvert \dfrac{J_{+}-J_{-}}{2}  \right \rvert 3/2, m \right \rangle \\
&= \dfrac{\hbar}{2i} \delta_{m^{\prime}, m+1} \left[\left(3/2-m\right)\left(3/2+m+1\right)\right]^{1/2} \\
&- \dfrac{\hbar}{2i} \delta_{m^{\prime}, m-1} \left[\left(3/2+m\right)\left(3/2-m+1\right)\right]^{1/2}.
\end{align*}

\begin{equation*}
\left \langle 3/2, m^{\prime} \left \lvert J_z  \right \rvert 3/2, m \right \rangle = \hbar m \delta_{m^{\prime}, m}.
\end{equation*}

\(m\) runs from \(-j\) to \(j\) i.e., it takes values \(-3/2, \thinspace -1/2, \thinspace 1/2, \quad \text{and} \quad  \thinspace 3/2\). Straight off the bat, \(J_{z}\) is diagonal with entries \(-3 \hbar /2, \thinspace -\hbar/2, \thinspace \hbar/2, \quad \text{and} \quad  \thinspace 3\hbar/2\), i.e.,

\begin{equation*}
J_{z} =
\begin{pmatrix}
-3 \hbar/2 & 0 & 0 & 0 \\
0 & - \hbar/2 & 0 & 0 \\
0 & 0 & \hbar/2 & 0 \\
0 & 0 & 0 & 3 \hbar/2
\end{pmatrix}.
\end{equation*}

As for \(J_{x}\) and \(J_{y}\), first note that only non-zero elements (of both \(J_{x}\) and \(J_{y}\)) live on the sub and super diagonal. Then note that \(J_{x}\) is /symmetric/, and /persymmetric/ while \(J_{y}\) is /anti-symmetric/ and /perantisymmetric/. So for \(J_{x}\) (and \(J_{y}\)) determining half of the elements of either the sub or superdiagonal is sufficient to populate the entire matrix. So for a \(2j + 1\) dimensional matrix (the degeneracy of \(m\)), so that \(2j + 1\) is even \(j + 1/2\) matrix elements completely specify \(J_{x}\) and \(J_{y}\). For \(J_{x}^{(3/2)}\) and \(J_{y}^{(3/2)}\) we thus need /only/ \(2\) appropriately chosen elements to completely specify the matrix. Let's calculate the matrix elements  \(\left \langle 3/2, -1/2 \left \lvert J_{x}  \right \rvert 3/2, -3/2 \right \rangle\), \(\left \langle 3/2, 1/2 \left \lvert J_{x}  \right \rvert 3/2, -1/2 \right \rangle\), \(\left \langle 3/2, -1/2 \left \lvert J_{y}  \right \rvert 3/2, -3/2 \right \rangle\), and \(\left \langle 3/2, 1/2 \left \lvert J_{y}  \right \rvert -1/2, -3/2 \right \rangle\). They are \(\sqrt{3} \hbar/2\), \(\hbar/2\), \(-i \sqrt{3} \hbar/2\) and \(- i \hbar/2\) respectively. The matrices are immediately generated:

\begin{equation*}
J_{x}^{(3/2)} =
\begin{pmatrix}
0 & \sqrt{3} \hbar/2 & 0 & 0  \\
\sqrt{3} \hbar/2 & 0 & \hbar/2 & 0 \\
0 & \hbar/2 & 0 & \sqrt{3} \hbar /2 \\
0 & 0 & \sqrt{3} \hbar /2 & 0
\end{pmatrix}
\end{equation*}

\begin{equation*}
J_{y}^{(3/2)} =
\begin{pmatrix}
0 &  i \sqrt{3} \hbar/2 & 0 & 0  \\
- i \sqrt{3} \hbar/2 & 0 & i \hbar/2 & 0 \\
0 & - i \hbar/2 & 0 & i \sqrt{3} \hbar /2 \\
0 & 0 & - i \sqrt{3} \hbar /2 & 0
\end{pmatrix}.
\end{equation*}

/Make your life even easier/: in evaluating the commutators simply double the product of the corresponding superdiagonal elements and place it on the that row's diagonal (a ``left shift"). Alternatively, double the product of the the corresponding subdiagonal elements and place it on that row's diagonal (a ``right shift"). In edge cases where one's not possible do the other. In this case we need to multiply the entire thing with another \(i/ \hbar\) because we're trying to see if \([J_{x}^{(3/2)}, J_{y}^{(3/2)}] \stackrel{?}{=} i \hbar J_{z}^{(3/2)}\). Immediately furnish for this case:

\begin{equation*}
(i / \hbar)\left[ J_{x}^{(3/2)}, J_{y}^{(3/2)} \right] =
\begin{pmatrix}
-3 \hbar/2 & 0 & 0 & 0 \\
0 & - \hbar/2 & 0 & 0  \\
0 & 0 & \hbar/2 & 0 \\
0 & 0 & 0 & 3 \hbar/2
\end{pmatrix}.
\end{equation*}

Baam! Should have played with matrices instead of Legos as a kid.
** SOLVED Problem 12.5.3
CLOSED: [2022-11-04 Fri 16:02]
:LOGBOOK:
CLOCK: [2022-11-04 Fri 14:15]--[2022-11-04 Fri 16:02] =>  1:47
:END:
*(1)* *Show that* \(\left \langle J_{x}  \right \rangle = \left \langle J_{y}  \right \rangle = 0\) *in a state* \(\vert j m \rangle\).

\(J_{x}\) and \(J_{y}\) being Hermitian

\begin{align*}
\left \langle J_{x}  \right \rangle \equiv \left \langle jm \left \lvert J_{x}  \right \rvert jm \right \rangle &= \dfrac{1}{i \hbar} \left \langle jm \left \lvert \left[ J_{y}, J_{z} \right]  \right \rvert jm \right \rangle \\
&= \dfrac{1}{i \hbar} \left[ \left \langle jm \left \lvert J_{y} J_{z}  \right \rvert jm \right \rangle - \left \langle jm \left \lvert J_{z} J_{y}  \right \rvert jm \right \rangle\right] \\
&= \dfrac{m}{i} \left[ \left \langle jm \left \lvert J_y  \right \rvert jm \right \rangle - \left \langle jm \left \lvert J_{y}  \right \rvert jm \right \rangle\right] = 0.
\end{align*}

\begin{align*}
\left \langle J_{y}  \right \rangle \equiv \left \langle jm \left \lvert J_{y}  \right \rvert jm \right \rangle &= \dfrac{1}{i \hbar} \left \langle jm \left \lvert \left[ J_{z}, J_{x} \right]  \right \rvert jm \right \rangle \\
&= \dfrac{1}{i \hbar} \left[ \left \langle jm \left \lvert J_{z} J_{x}  \right \rvert jm \right \rangle - \left \langle jm \left \lvert J_{x} J_{z}  \right \rvert jm \right \rangle\right] \\
&= \dfrac{m}{i} \left[ \left \langle jm \left \lvert J_{x}  \right \rvert jm \right \rangle - \left \langle jm \left \lvert J_{x}  \right \rvert jm \right \rangle\right] = 0.
\end{align*}

*(2)* *Show that in these states*

\begin{equation*}
\left \langle J_{x}^{2}  \right \rangle = \left \langle J_{y}^{2}  \right \rangle = (1/2) \hbar^{2} \left[ j \left( j + 1 \right) - m^{2} \right].
\end{equation*}

*(use symmetry arguments to relate* \(\left \langle J_{x}^{2}  \right \rangle\) *to* \(\left \langle J_{y}^{2}  \right \rangle\) *)*.

We start with

\begin{align*}
\left \langle jm \left \lvert J_{x}^{2} + J_{y}^{2} + J_{z}^{2}  \right \rvert jm \right \rangle &= j \left( j + 1 \right) \hbar^{2} \\
&= \left \langle jm \left \lvert J_{x}^{2} + J_{y}^{2} \right \rvert jm \right \rangle + \left \langle jm \left \lvert J_{z}^{2}  \right \rvert jm \right \rangle \\
&= \left \langle jm \left \lvert J_{x}^{2} + J_{y}^{2} \right \rvert jm \right \rangle + m^{2} \hbar^{2}.
\end{align*}

It follows that

\begin{equation*}
\left \langle jm \left \lvert J_{x}^{2} + J_{y}^{2}  \right \rvert jm \right \rangle = \hbar^{2} \left[ j \left( j + 1 \right) - m^{2} \right].
\end{equation*}

Now \(\left \langle jm \left \lvert J_{x}^{2} \right \rvert jm \right \rangle = \left \langle jm \left \lvert J_{y}^{2}  \right \rvert jm \right \rangle\) because of rotational symmetry about the \(z\) eigendirection: so we have

\begin{equation*}
\left \langle J_{x}^{2}  \right \rangle = \left \langle J_{y}^{2}  \right \rangle = (1/2) \hbar^{2} \left[ j \left( j + 1 \right) - m^{2} \right].
\end{equation*}

*(3)* *Check that* \(\Delta J_{x} \cdot \Delta J_{y}\) *from part (ii) satisfies the inequality imposed by the uncertainty principle* \([\text{Eq.} (9.2.9)]\).

The inequality imposed by the uncertainty principle is

\begin{equation*}
\left( \Delta J_{x} \right)^{2} \left( \Delta J_{y} \right)^{2} \geq
\left \lvert \left \langle jm \left \lvert J_{x} J_{y}  \right \rvert jm \right \rangle  \right \rvert^{2}
\end{equation*}

which via

\begin{equation*}
J_{x} J_{y} = \dfrac{1}{2} \left[ J_x, J_y \right] + \dfrac{1}{2} \left[ J_{x}, J_{y} \right]_{+}
\end{equation*}

becomes

\begin{align*}
\left( \Delta J_{x} \right)^{2} \left( \Delta J_{y} \right)^{2} &\geq \dfrac{1}{4}
\left \lvert \left \langle jm \left \lvert \left[ J_{x}, J_{y} \right] + \left[ J_{x} + J_{y} \right]_{+} \right \rvert jm \right \rangle  \right \rvert^{2} \\
& \geq \dfrac{1}{4} \left \lvert \left \langle jm \left \lvert \left[ J_{x}, J_{y} \right]  \right \rvert jm \right \rangle \right \rvert 
\end{align*}

or

\begin{equation*}
\Delta J_{x} \Delta J_{y} \geq \dfrac{1}{2} \left \lvert \left \langle \left[ J_{x}, J_{y} \right]  \right \rangle  \right \rvert.
\end{equation*}

Using \([J_{x}, J_{y}] = i \hbar J_{z}\) and \(\Delta J_{x} \Delta J_{y} = (1/2) \hbar^{2} \left[ j \left( j + 1 \right) - m^{2} \right]\),

\((1/2) \hbar^{2} \left[ j \left( j + 1 \right) - m^{2} \right] \geq \dfrac{\left \lvert m  \right \rvert \hbar^2}{2}\),

clearly true.

*(4)* *Show that the uncertainty bound is saturated in the state* \(\vert j, \pm j \rangle\).

*When* \(m = \pm j\) *so that* \(\ket{jm} \to \vert j, \pm j \rangle\), the uncertainty relation reduces to

\begin{equation*}
\hbar^{2} /2 \left[ j \left( j + 1 \right) - j^{2} \right] = \dfrac{\hbar}{2} \left \lvert j  \right \rvert \geq \dfrac{\hbar^{2}}{2} \left \lvert m \right \rvert.
\end{equation*}

The uncertainty bound is saturated in this state.
** SOLVED Problem 12.5.4
CLOSED: [2022-11-05 Sat 19:14]
:LOGBOOK:
CLOCK: [2022-11-05 Sat 17:32]--[2022-11-05 Sat 19:14] =>  1:42
:END:
*(1)* *Argue that the eigenvalues of* \(J_{x}^{(j)}\) *and* \(J_{y}^{(j)}\) *are the same as those of* \(J_{z}^{(j)}\), *namely,* \(j\hbar, \thinspace (j-1)\hbar, \thinspace \dotso, \thinspace - j \hbar\). *Generalize the result to* \(\hat{\theta} \cdot \vec{J}^{(j)}\).

Say I made a measurement of \(J_{x}^{(j)}\) (or \(J_{y}^{(j)}\)) and got some eigenvalue. Then I act up and say what I /really/ wanted was to use a coordinate system in which \(z\) was along the previous \(x\) axis (or \(y\) axis). What would I be measuring then? \(J_{z}^{(j)}\). Would the eigenvalue have changed? No, the outcome of the experiment couldn't care less about my reference frame: the experimental condition remains exactly the same. So the eigenvalue I found for \(J_{x}^{(j)}\) (or \(J_{y}^{(j)}\)) must also be an eigenvalue of \(J_{z}^{(j)}\) - it /better/ be. The \(\hat{\theta} \cdot \vec{J}^{(j)}\) case is a trivial extension of this argument - in acting up, I say \(z\) was along  \(\hat{\theta}\) was what I /really/ wanted. Thus a measurement of the component of the total angular momentum in /any/ arbitrary direction must yield the same eigenvalues as that of \(J_{z}^{(j)}\):

\begin{equation*}
j\hbar, \thinspace (j-1)\hbar, \thinspace \dotso, \thinspace - j \hbar.
\end{equation*}

It's just the eigenvectors that are basis dependent; an eigenvector with a given eigenvalue is related to the eigenvector of the /same eigenvalue/ in a /different basis/ via a unitary transformation that effects the corresponding change of basis.

*(2)* *Show that*

\begin{equation*}
\left( J - j \hbar \right) \left[ J - \left( j - 1 \right) \hbar \right] \left[ J - \left( j - 2 \right) \hbar \right] \dotso \left( J + j \hbar \right) = 0
\end{equation*}

*where* \(J \equiv \hat{\theta} \cdot \vec{J}^{(j)}\). *(Hint: In the case* \(J = J_{x}\) *what happens when both sides are applied to an arbitrary eigenket* \(\ket{jm}\) *?* *What about an arbitrary superpositions of such kets?*

As each component of the superposition cascades through the operators, it'll find - guaranteed for one of the \((J-m^{\prime} \hbar)\), that its eigenvalue matches the most recent scalar it latched on to, with which it now forms a difference. Oh-oh.

If that wasn't pallatable, consider the arbitrary superposition \(a_{i} \vert jm \rangle_{i}\). When \(J-m^{\prime} \hbar\) is applied to this we have

\begin{align*}
\left( J - m^{\prime} \hbar \right) a_{i} \vert j m \rangle_{i} &= a_{i} \left( J - m^{\prime} \hbar \right) \vert j m \rangle_{i} \\
&= a_{i} \left(m \hbar \vert j m \rangle_{i} - m^{\prime} \hbar \vert j m \rangle_{i} \right) \\
&= a_{i} \hbar \left( m - m^{\prime} \right) \vert j m \rangle_{i}.
\end{align*}

Now consider the operator \(\left( J - j \hbar \right) \left[ J - \left( j - 1 \right) \hbar \right] \left[ J - \left( j - 2 \right) \hbar \right] \dotso \left( J + j \hbar \right)\) acting on this superposition. We must have

\begin{align*}
& \left( J - j \hbar \right) \left[ J - \left( j - 1 \right) \hbar \right] \left[ J - \left( j - 2 \right) \hbar \right] \dotso \left( J + j \hbar \right) \left \lbrace a_{i} \vert jm \rangle_{i}  \right \rbrace \\
&= \hbar^{2j + 1} \left \lbrace \left( m - j \right) \left( m - (j-1) \right) \dotso \left( m + j \right)  \right \rbrace a_{i} \vert j m \rangle_{i} = 0 \times \left \lbrace a_{i} \vert j m \rangle_{i} \right \rbrace \\
&\Longrightarrow \left( J - j \hbar \right) \left[ J - \left( j - 1 \right) \hbar \right] \left[ J - \left( j - 2 \right) \hbar \right] \dotso \left( J + j \hbar \right) = 0.
\end{align*}

In the last step before the implication we have noted that since \(m\) is one among \(-j, \thinspace - (j-1) \thinspace \dotso, \thinspace (j-1), \thinspace j\), one of the factors - and thus the entire product - is bound to vanish.

*(3)* *It follows from (2) that* \(J^{2j + 1}\) *is a linear combination of* \(J^{0}, \thinspace J^{1}, \dotso, J^{2j}\). *Argue that the same goes for* \(J^{2j + k}\), \(k = 1, \thinspace 2, \dotso\).

What is \(J^{2j+k}\) but \(J^{2(j+ (k-1)/2) +1} = J^{2j^{\prime} + 1}\), where \(j^{\prime} = j + (k-1)/2\)? \(j^{\prime}\) is a (positive) integer or half integer just like \(j\); \(J^{2j+k}\) is thus a linear combination of \(j^{0}, \thinspace J^{1}, \thinspace J^{2j^{\prime}}\).
** SOLVED Problem 12.5.5
CLOSED: [2022-11-06 Sun 03:11]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 01:33]--[2022-11-06 Sun 02:36] =>  1:03
CLOCK: [2022-11-05 Sat 23:28]--[2022-11-06 Sun 01:03] =>  1:35
CLOCK: [2022-11-05 Sat 19:49]--[2022-11-05 Sat 21:52] =>  2:03
:END:
*(Hard).* *Using results from the previous exercise and* \(\text{Eq.}(12.5.23)\), *show that*

*(1)* \(D^{(1/2)} (R) = \exp \left \lbrace - i \hat{\theta} \cdot \vec{J}^{(1/2)} / \hbar \right \rbrace = \cos \left( \theta /2 \right) I^{(1/2)} - \left( 2 i / \hbar \right) \sin \left( \theta/2 \right) \hat{\theta} \cdot \vec{J}^{(1/2)}\).

For \(n\) even

\begin{equation*}
\left( \hat{\theta} \cdot \vec{J}^{(j)} \right)^{n} = (\vec{J}^{(j)})^{n} = [(J_{x}^{(j)})^{2} + (J_{y}^{(j)})^{2} + (J_{z}^{(j)})^{2}]^{n/2}.
\end{equation*}

and for \(n\) odd and \(n > 1\)

\begin{equation*}
\left( \hat{\theta} \cdot \vec{J}^{(j)} \right)^{n} = \left( (J_{x}^{(j)})^{2} + (J_{y}^{(j)})^{2} + (J_{z}^{(j)})^{2} \right)^{(n-1)/2} \hat{\theta}  \cdot \vec{J}^{(j)}.
\end{equation*}

In =Exercise 12.5.2= we found

\begin{equation*}
J_{x}^{(1/2)} =
\begin{pmatrix}
0 & \hbar/2 \\
\hbar/2 & 0
\end{pmatrix},
\quad
J_{y}^{(1/2)} =
\begin{pmatrix}
0 & -i \hbar/2 \\
i \hbar/2 & 0
\end{pmatrix},
\quad
J_{z}^{(1/2)} =
\begin{pmatrix}
\hbar/2 & 0 \\
0 & - \hbar/2
\end{pmatrix}.
\end{equation*}

so

\begin{equation*}
(J_{x}^{(j)})^{2} + (J_{y}^{(j)})^{2} + (J_{z}^{(j)})^{2} =
\begin{pmatrix}
\hbar^{2}/2 & 0 \\
0 & \hbar^{2}/2
\end{pmatrix} = \left(\dfrac{\hbar}{2}\right)^{2} I^{(1/2)}.
\end{equation*}

Now

\begin{equation*}
D^{(1/2)} \left[ R \right] = \exp \left \lbrace - i \hat{\theta} \cdot \vec{J}^{(1/2)}/ \hbar  \right \rbrace = \sum_{0}^{\infty} \left( \dfrac{-i \theta}{\hbar} \right)^{n} \left( \hat{\theta} \cdot \vec{J}^{(1/2)} \right)^{n} \dfrac{1}{n!}.
\end{equation*}

Accumulate separately the odd and even terms so that

\begin{align*}
D^{(1/2)} \left[ R \right] &= \exp \left \lbrace - i \hat{\theta} \cdot \vec{J}^{(1/2)}/ \hbar  \right \rbrace \\
&= \sum_{0}^{\text{even}} \left( \dfrac{-i \theta}{\hbar} \right)^{n} \left( \hat{\theta} \cdot \vec{J}^{(1/2)} \right)^{n} \dfrac{1}{n!} +
\sum_{1}^{\text{odd}} \left( \dfrac{-i \theta}{\hbar} \right)^{n} \left( \hat{\theta} \cdot \vec{J}^{(1/2)} \right)^{n} \dfrac{1}{n!},
\end{align*}

and substitute

\begin{equation*}
(\hat{\theta} \cdot \hat{J}^{(1/2)})^{n} = I^{(1/2)} \left( \dfrac{\hbar}{2} \right)^{n-1} \hat{\theta}  \cdot \vec{J}^{(j)} \quad n \thinspace \thinspace \text{odd} \quad \text{and} \quad n > 1,
\end{equation*}

\begin{equation*}
(\hat{\theta} \cdot \hat{J}^{(1/2)})^{n} = \left( \dfrac{\hbar}{2} \right)^{n} I^{(1/2)} \quad n \thinspace \thinspace \text{even}.
\end{equation*}

to obtain

\begin{align*}
D^{(1/2)} \left[ R \right] = \exp \left \lbrace - i \hat{\theta} \cdot \vec{J}^{(1/2)}/ \hbar  \right \rbrace &=
\sum_{0}^{\text{even}} \left( \dfrac{-i \theta}{\hbar} \right)^{n} \dfrac{1}{n!} \left( \dfrac{\hbar}{2} \right)^{n} I^{(1/2)} \\
&+\sum_{1}^{\text{odd}} \left( \dfrac{-i \theta}{\hbar} \right)^{m} \dfrac{1}{m!} I^{(1/2)} \left( \dfrac{\hbar}{2} \right)^{m-1} \hat{\theta}  \cdot \vec{J}^{(j)} \\
&=
I^{(1/2)} \sum_{0}^{\text{even}} \left( -1 \right)^{n} \left(\theta/2 \right)^{n} \dfrac{1}{n!} \\
&+ \left( \dfrac{2i}{\hbar} \right) \sum_{1}^{\text{odd}} \left( -1 \right)^{m+1} \left(\theta/2 \right)^{m} \dfrac{1}{m!} \hat{\theta}  \cdot \vec{J}^{(j)} \\
&= I^{(1/2)} \cos \left( \theta/2 \right) + \left( \dfrac{2i}{\hbar} \right) \sin \left( \theta/2 \right) \hat{\theta} \cdot \vec{J}^{(1/2)}.
\end{align*}

*(2)*

\begin{align*}
D^{(1)} (R) &= \exp \left \lbrace - i \theta_{x} \cdot J_{x}^{(1)} / \hbar \right \rbrace \\
&= \left(\cos \theta_{x} - 1\right) \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} - i \sin \theta_{x} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right) + I^{(1)}
\end{align*}

In =Exercise 12.5.2= we found

\begin{equation*}
J_{x}^{(1)} =
\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix},
\end{equation*}

Let's calculate a few powers of this matrix:

\begin{equation*}
(J_{x}^{(1)})^{1} =
\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix},
\end{equation*}

\begin{equation*}
(J_{x}^{(1)})^{2} =
\begin{pmatrix}
\hbar^{2}/(2^{1/2})^{2} & 0 & \hbar^{2}/(2^{1/2})^{2} \\
0 & \hbar^2 & 0 \\
\hbar^{2}/(2^{1/2})^{2} & 0 & \hbar^{2}/(2^{1/2})^{2}
\end{pmatrix},
\end{equation*}

\begin{equation*}
(J_{x}^{(1)})^{3} =
\begin{pmatrix}
0 & \hbar^{3}/2^{1/2} & 0 \\
\hbar^{3}/2^{1/2} & 0 & \hbar^{3}/2^{1/2} \\
0 & \hbar^{3}/2^{1/2} & 0
\end{pmatrix},
\end{equation*}

\begin{equation*}
(J_{x}^{(1)})^{4} =
\begin{pmatrix}
\hbar^{4}/(2^{1/2})^{2} & 0 & \hbar^{4}/(2^{1/2})^{2} \\
0 & \hbar^4 & 0 \\
\hbar^{4}/(2^{1/2})^{2} & 0 & \hbar^{4}/(2^{1/2})^{2}
\end{pmatrix},
\end{equation*}


\begin{equation*}
(J_{x}^{(1)})^{5} =
\begin{pmatrix}
0 & \hbar^{5}/2^{1/2} & 0 \\
\hbar^{5}/2^{1/2} & 0 & \hbar^{5}/2^{1/2} \\
0 & \hbar^{5}/2^{1/2} & 0
\end{pmatrix}.
\end{equation*}

Why does this remind me of LSD? This is so /trippy/! Anyway, now

\begin{equation*}
D^{(1)} \left[ R \right] = \exp \left \lbrace - i \theta_{x} J^{(1)}_{x}/\hbar  \right \rbrace = \sum_{0}^{\infty} \left( -i \theta_{x} \right)^{n} \left( J^{(1)}_{x}/ \hbar \right)^{n} \dfrac{1}{n!}.
\end{equation*}

Accumulate separately the odd and even terms so that

\begin{align*}
D^{(1/2)} \left[ R \right] &= \exp \left \lbrace - i \theta_{x} J^{(1)}_{x}/ \hbar  \right \rbrace \\
&= \sum_{0}^{\text{even}} \left( -i \theta_{x} \right)^{n} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{n} \dfrac{1}{n!} +
\sum_{1}^{\text{odd}} \left( -i \theta_{x} \right)^{m} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{m} \dfrac{1}{m!} \\
&= I^{(1)} + \sum_{2}^{\text{even}} \left( -i \theta_{x} \right)^{n} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{n} \dfrac{1}{n!} +
\sum_{1}^{\text{odd}} \left( -i \theta_{x} \right)^{m} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{m} \dfrac{1}{m!} \\
&= I^{(1)} + \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} \sum_{2}^{\text{even}} \left( -i \theta_{x} \right)^{n} \dfrac{1}{n!} +
\left( \dfrac{J_{x}^{(1)}}{\hbar} \right) \sum_{1}^{\text{odd}} \left( -i \theta_{x} \right)^{m} \dfrac{1}{m!} \\
&= I^{(1)} + \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} \left[ -1 + \sum_{0}^{\text{even}} \left( -i \theta_{x} \right)^{n} \dfrac{1}{n!} \right] + \left( \dfrac{J_{x}^{(1)}}{\hbar} \right) \left[ \sum_{1}^{\text{odd}} \left( -i \theta_{x} \right)^{m} \dfrac{1}{m!} \right] \\
&= \left[ \cos \theta_{x} -1 \right] \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2}  + i \sin \theta_{x} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right) + I^{(1)}.
\end{align*}

** TOSOLVE Problem 12.5.6                                          :mistake:
CLOSED: [2022-11-06 Sun 05:14]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 03:12]--[2022-11-06 Sun 05:11] =>  1:59
CLOCK: [2022-11-06 Sun 02:38]--[2022-11-06 Sun 03:11] =>  0:33
:END:
*Consider the family of states* \(\vert jj \rangle, \dotso, \vert jm \rangle, \dotso, \vert j, -j \rangle\). *One refers to them as states of the same magnitude but different orientation of angular momentum. If ones takes this remark literally, i.e., in the classical sense, one is led to believe that one may rotate these into each other, as is the case for classical states with these properties. Consider, for instance, the family* \(\vert 1,1 \rangle, \vert 1, 0 \rangle, \vert 1, -1 \rangle\). *It may seem, for example, that the state with zero angular momentum along the* \(z\) *axis,* \(\vert 1, 0 \rangle\), *may be obtained by rotating* \(\vert 1, 1 \rangle\) *by some suitable (* \(\pi / 2\) *?) angle about the* \(x\) *axis. Using* \(D^{(1)} \left[ R \left( \theta_{x} \vec{i} \right) \right]\) *from part (2) in the last exercise show that*

\begin{equation*}
\vert 1, 0 \rangle \neq D^{(1)} \left[ R \left( \theta_{x} \vec{i} \right) \right] \vert 1, 1 \rangle \quad \text{for any} \quad \theta_{x}
\end{equation*}

Suppose that it were. Then

\begin{equation*}
\vert 1, 0 \rangle = \vert 1, 1 \rangle + \left[ \cos \theta_{x} -1 \right] \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} \vert 1, 1 \rangle  + i \sin \theta_{x} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right) \vert 1, 1 \rangle.
\end{equation*}

In a basis that diagonalizes \(J_{z}^{(1)}\)

\begin{equation*}
J_{z}^{(1)} \leftrightarrow
\begin{pmatrix}
\hbar & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & - \hbar
\end{pmatrix}
\end{equation*}

so

\begin{equation*}
\vert 1, 1 \rangle \leftrightarrow
\begin{bmatrix}
1 \\
0 \\
0 \\
\end{bmatrix}.
\end{equation*}

In this basis we have

\begin{equation*}
\left( \dfrac{J_{x}^{(1)}}{\hbar} \right) \vert 1, 1 \rangle \leftrightarrow
\begin{pmatrix}
0 & 1/2^{1/2} & 0 \\
1/2^{1/2} & 0 & 1/2^{1/2} \\
0 & 1/2^{1/2} & 0
\end{pmatrix}
\begin{bmatrix}
1 \\
0 \\
0 \\
\end{bmatrix} \leftrightarrow
\begin{bmatrix}
0 \\
1/2^{1/2} \\
0 
\end{bmatrix},
\end{equation*}

and

\begin{equation*}
\left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} \vert 1, 1 \rangle \leftrightarrow
\begin{pmatrix}
1/(2^{1/2})^{2} & 0 & 1/(2^{1/2})^{2} \\
0 & 1 & 0 \\
1/(2^{1/2})^{2} & 0 & 1/(2^{1/2})^{2}
\end{pmatrix}
\begin{bmatrix}
1 \\
0 \\
0 \\
\end{bmatrix} \leftrightarrow
\begin{bmatrix}
1/2 \\
0 \\
1/2
\end{bmatrix}.
\end{equation*}

which leads us to the conclusion that

\begin{equation*}
\vert 1, 0 \rangle \leftrightarrow
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
 =
\begin{bmatrix}
+ \left( \cos \theta_x + 1\right) / 2 \\
- i \sin \theta_x / 2^{1/2} \\
+ \left( \cos \theta_x - 1\right) / 2
\end{bmatrix}
\end{equation*}

\((\cos \theta_{x}-1)/2 = (\cos \theta_{x}+1)/2\) is an impossibility. We have reached a contradiction and consequently established:

\begin{equation*}
\vert 1, 0 \rangle \neq D^{(1)} \left[ R \left( \theta_{x} \vec{i} \right) \right] \vert 1, 1 \rangle \quad \text{for any} \quad \theta_{x}.
\end{equation*}

*The error stems from the fact that classical reasoning should be applied to* \(\left \langle \vec{J}  \right \rangle\), *which responds to rotations like an ordinary vector, and not direcly to* \(\vert jm \rangle\), *which is a vector in Hilbert space. Verify that* \(\left \langle J  \right \rangle\) *responds to rotations like its classical counterpart, by showing that* \(\left \langle \vec{J}  \right \rangle\) *in the state* \(D^{(1)} \left[ R \left( \theta_{x} \vec{i} \right)\right] \vert 1,1 \rangle\) is \(\hbar \left[ - \sin \theta_{x} \vec{j} + \cos \theta_{x} \vec{k} \right]\).

In a basis that diagonalizes \(J_{z}^{(1)}\) we found

\begin{equation*}
D^{(1)} \left[ R \left( \theta_{x} \vec{i} \right)\right] \vert 1,1 \rangle \leftrightarrow
\begin{bmatrix}
+ \left( \cos \theta_x + 1\right) / 2 \\
- i \sin \theta_x / 2^{1/2} \\
+ \left( \cos \theta_x - 1\right) / 2
\end{bmatrix}.
\end{equation*}

\begin{align*}
\left \langle 1, 1 \left \lvert J_{x}^{(1)}  \right \rvert 1, 1 \right \rangle &=
[\left( \cos \theta_x + 1\right)/2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix}
\begin{bmatrix}
+ \left( \cos \theta_x + 1\right) / 2 \\
- i \sin \theta_x / 2^{1/2} \\
+ \left( \cos \theta_x - 1\right) / 2
\end{bmatrix} \\
&=
[\left( \cos \theta_x + 1\right)/2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{bmatrix}
- i \hbar \sin \theta_x / 2 \\
\hbar \thinspace (\cos \theta_x + 1) / 2^{3/2} + \hbar \thinspace (\cos \theta_x - 1) / 2^{3/2} \\
- i \hbar \sin \theta_x / 2
\end{bmatrix} \\
&= \vert 0, 0 \rangle.
\end{align*}

\begin{align*}
\left \langle 1, 1 \left \lvert J_{y}^{(1)}  \right \rvert 1, 1 \right \rangle &=
[\left( \cos \theta_x + 1\right)/2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{pmatrix}
0 & - i \hbar/2^{1/2} & 0 \\
i \hbar/2^{1/2} & 0 & -i \hbar/2^{1/2} \\
0 & i \hbar/2^{1/2} & 0
\end{pmatrix}
\begin{bmatrix}
+\left( \cos \theta_x + 1\right)/2 \\
- i \sin \theta_x / 2^{1/2} \\
+ \left( \cos \theta_x - 1\right) / 2
\end{bmatrix} \\
&=
[+\left( \cos \theta_x + 1\right)/2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{bmatrix}
- \hbar \sin \theta_x / 2 \\
i \thinspace \hbar \thinspace (\cos \theta_x + 1) / 2^{3/2} - i \thinspace \hbar \thinspace (\cos \theta_x - 1) / 2^{3/2} \\
 \hbar \sin \theta_x / 2
\end{bmatrix} \\
&= - \hbar \sin \theta_x /2 - \hbar \sin \theta_x /2 = - \hbar \sin \theta_x.
\end{align*}

\begin{align*}
\left \langle 1, 1 \left \lvert J_{z}^{(1)}  \right \rvert 1, 1 \right \rangle &=
[+ \left( \cos \theta_x + 1\right) / 2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{pmatrix}
\hbar &  0 & 0 \\
0 & 0 & 0 \\
0 & 0 & - \hbar
\end{pmatrix}
\begin{bmatrix}
+ \left( \cos \theta_x + 1\right) / 2 \\
- i \sin \theta_x / 2^{1/2} \\
+ \left( \cos \theta_x - 1\right) / 2
\end{bmatrix} \\
&=
[+ \left( \cos \theta_x + 1\right) / 2, \thinspace - i \sin \theta_x / 2^{1/2}, \thinspace + \left( \cos \theta_x - 1\right)/2]
\begin{bmatrix}
\hbar \left( \cos \theta_x + 1\right) / 2 \\
0 \\
\hbar \left( 1 - \cos \theta_{x} \right)/2
\end{bmatrix} \\
&= \dfrac{\hbar}{4} \left[ \left( \cos \theta_x + 1\right)^{2} + \left( \cos \theta_x - 1\right)^{2} \right] = \hbar \cos \theta_x.
\end{align*}

The expectation value \(\left \langle \vec{J}  \right \rangle\) is

\begin{equation*}
\left \langle \vec{J}  \right \rangle = \hbar \left[ - \sin \theta_{x} \vec{j} + \cos \theta_{x} \vec{k} \right].
\end{equation*}

*It is not too hard to see why we can't always satisfy*

\begin{equation*}
\vert j m^{\prime} \rangle = D^{(j)} \left[ R \right] \vert jm \rangle
\end{equation*}

*or more generally, for two normalized kets* \(\vert \psi_j^{\prime} \rangle\) and \(\vert \psi_j \rangle\), *satisfy*

\begin{equation*}
\vert \psi_{j}^{\prime} \rangle = D^{j} \left[ R \right] \vert \psi_{j} \rangle
\end{equation*}

*by any choice of* \(R\). *These abstract equations imply* \((2j + 1)\) *linear, complex relations between the components of* \(\vert\psi_{j}^{\prime}\rangle\) *and* \(\vert \psi_{j} \rangle\) *that can't be satisfied by varying* \(R\), *which depends on only three parameters,* \(\theta_{x}\), \(\theta_{y}\), *and* \(\theta_{z}\). *(Of course one can find a unitary matrix in* \(\mathbb{V}_{j}\), *that takes* \(\vert jm \rangle\) *into* \(\vert j m^{\prime} \rangle\) *or* \(\vert \psi_{j} \rangle\) *into* \(\vert \psi_{j}^{\prime}\rangle\), *but it will not be a* /rotation/ *matrix corresponding to* \(U[R]\). *)*
** SOLVED Problem 12.5.7 Euler Angles
CLOSED: [2022-11-06 Sun 08:43]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 08:12]--[2022-11-06 Sun 08:43] =>  0:31
CLOCK: [2022-11-06 Sun 07:21]--[2022-11-06 Sun 08:05] =>  0:44
CLOCK: [2022-11-06 Sun 05:23]--[2022-11-06 Sun 07:17] =>  1:54
:END:
*Rather than parametrize an arbitrary rotation by the angle* \(\vec{\theta}\), *which describes a* /single/ *rotation by* \(\theta\) *about an axis parallel to* \(\vec{\theta}\), *we may parametrize it by three angles* \(\gamma\), \(\beta\), *and* \(\alpha\) *called* /Euler angles/, *which define three successive rotations:*

\begin{equation*}
U \left[ R \left( \alpha, \beta, \gamma \right) \right] = \exp \left \lbrace - i \alpha J_{z} / \hbar  \right \rbrace \exp \left \lbrace - i \beta J_{y} / \hbar  \right \rbrace \exp \left \lbrace - i \gamma J_{z} / \hbar  \right \rbrace.
\end{equation*}

*(1)* *Construct* \(D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right]\) *explicitly as a product of three* \(3 \times 3\) *matrices. (Use the result from* =Exercise 12.5.5= *with* \(J_{x} \to J_{y}\) *.)*

\begin{align*}
\exp \left \lbrace - i \alpha J_{z} / \hbar  \right \rbrace \leftrightarrow
\begin{pmatrix}
\exp \left \lbrace - i \alpha/ \hbar  \right \rbrace & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & \exp \left \lbrace i \alpha / \hbar  \right \rbrace
\end{pmatrix},
\end{align*}

\begin{align*}
\exp \left \lbrace - i \beta J_{y} / \hbar  \right \rbrace &= \left(\cos \beta - 1\right) \left( \dfrac{J_{y}^{(1)}}{\hbar} \right)^{2} - i \sin \beta \left( \dfrac{J_{y}^{(1)}}{\hbar} \right) + I^{(1)} \\
&\leftrightarrow
\left(\cos \beta - 1\right)
\begin{pmatrix}
1/(2^{1/2})^{2} & 0 & -1/(2^{1/2})^{2} \\
0 & -1 & 0 \\
-1/(2^{1/2})^{2} & 0 & 1/(2^{1/2})^{2}
\end{pmatrix} \\
&- i \sin \beta
\begin{pmatrix}
0 & - i /2^{1/2} & 0 \\
i /2^{1/2} & 0 & -i /2^{1/2} \\
0 & i /2^{1/2} & 0
\end{pmatrix}
+
I^{(1)} \\
&\leftrightarrow
\begin{pmatrix}
\left( 1 + \cos \beta \right)/2 & - \sin \beta / 2^{1/2} & \left( 1 - \cos \beta \right)/2 \\
\sin \beta / 2^{1/2} & \cos \beta  & -\sin \beta / 2^{1/2} \\
\left( 1 - \cos \beta \right)/2 & \sin \beta / 2^{1/2}  & \left( 1 + \cos \beta \right)/2
\end{pmatrix}.
\end{align*}

\begin{align*}
\exp \left \lbrace - i \gamma J_{z} / \hbar  \right \rbrace &\leftrightarrow
\begin{pmatrix}
\exp \left \lbrace - i \gamma/ \hbar  \right \rbrace & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & \exp \left \lbrace i \gamma / \hbar  \right \rbrace
\end{pmatrix}.
\end{align*}


\begin{align*}
&D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \\
&=
\begin{pmatrix}
\exp \left \lbrace - i \alpha/ \hbar  \right \rbrace & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & \exp \left \lbrace i \alpha / \hbar  \right \rbrace
\end{pmatrix}
\begin{pmatrix}
\left( 1 + \cos \beta \right)/2 & - \sin \beta / 2^{1/2} & \left( 1 - \cos \beta \right)/2 \\
\sin \beta / 2^{1/2} & \cos \beta  & -\sin \beta / 2^{1/2} \\
\left( 1 - \cos \beta \right)/2 & \sin \beta / 2^{1/2}  & \left( 1 + \cos \beta \right)/2
\end{pmatrix} \times \\
&\begin{pmatrix}
\exp \left \lbrace - i \gamma/ \hbar  \right \rbrace & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & \exp \left \lbrace i \gamma / \hbar  \right \rbrace
\end{pmatrix} \\
&=
\begin{pmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 & -\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \exp \left \lbrace - i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \cos \beta  & -\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 & \exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}  & \exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2
\end{pmatrix}.
\end{align*}

*(2)* *Let it act on* \(\vert 1,1 \rangle\) *and show that* \(\left \langle \vec{J}  \right \rangle\) *in the resulting state is*

\begin{equation*}
\left \langle \vec{J}  \right \rangle = \hbar \left( \sin \beta \cos \alpha \vec{i} + \sin \beta \sin \alpha \vec{j} + \cos \beta \vec{k} \right).
\end{equation*}

\begin{equation*}
\vert 1, 1 \rangle \leftrightarrow
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}.
\end{equation*}

\begin{equation*}
&D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle \leftrightarrow
\begin{bmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2
\end{bmatrix}
\end{equation*}

\begin{align*}
&\langle 1, 1 \vert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \\
&\leftrightarrow
\left[
\exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2, \thinspace
\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}, \thinspace
\exp \left \lbrace -i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \thinspace
\right]
\end{align*}

Now

\begin{align*}
J_{x}  \right \rvert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle &= \\
&\begin{pmatrix}
0 & \hbar/2^{1/2} & 0 \\
\hbar/2^{1/2} & 0 & \hbar/2^{1/2} \\
0 & \hbar/2^{1/2} & 0
\end{pmatrix}
\begin{bmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2
\end{bmatrix} \\
&=
\begin{bmatrix}
\hbar \exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{3/2} \\
\hbar \exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 + \hbar \exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2^{3/2}\\
\hbar \exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{3/2}
\end{bmatrix},
\end{align*}

so that

\begin{align*}
\langle 1, 1 \vert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \left \lvert J_{x}  \right \rvert J_{x}  \right \rvert D^{(1)} &\left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle =\\
& \hbar \exp \left \lbrace i \alpha  \right \rbrace \sin \beta \left( 1 + \cos \beta \right)/ 2^{2}\\
&+ \hbar \exp \left \lbrace - i \alpha  \right \rbrace \sin \beta \left( 1 + \cos \beta \right) /2^{2} \right) \\
&+ \hbar \exp \left \lbrace i \alpha  \right \rbrace \sin \beta \left( 1 - \cos \beta \right) /2^{2} \\
&+ \hbar \exp \left \lbrace - i \alpha  \right \rbrace \sin \beta \left( 1 - \cos \beta \right)/2^{2} \\
&= \hbar\sin \beta ( \exp \left \lbrace i \alpha  \right \rbrace \left( 1 + \cos \beta \right) /2^{2} + \exp \left \lbrace i \alpha  \right \rbrace \left( 1 - \cos \beta \right) /2^{2} \\
&+ \exp \left \lbrace - i \alpha  \right \rbrace \left( 1 + \cos \beta \right)/2^{2} + \exp \left \lbrace - i \alpha  \right \rbrace \left( 1 - \cos \beta \right)/2^{2}) \\
&= \hbar \sin \beta \left[ \exp \left \lbrace i \alpha  \right \rbrace/2 + \exp \left \lbrace - i \alpha  \right \rbrace/2 \right] \\
&= \hbar \sin \beta \cos \alpha;
\end{align*}

and

\begin{align*}
\langle 1, 1 \vert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \left \lvert J_{y}  \right \rvert J_{x}  \right \rvert D^{(1)} &\left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle =\\
&- i\hbar \exp \left \lbrace i \alpha  \right \rbrace \sin \beta \left( 1 + \cos \beta \right)/ 2^{2}\\
&+ i\hbar \exp \left \lbrace - i \alpha  \right \rbrace \sin \beta \left( 1 + \cos \beta \right) /2^{2} \right) \\
&- i\hbar \exp \left \lbrace i \alpha  \right \rbrace \sin \beta \left( 1 - \cos \beta \right) /2^{2} \\
&+ i\hbar \exp \left \lbrace - i \alpha  \right \rbrace \sin \beta \left( 1 - \cos \beta \right)/2^{2} \\
&= i\hbar\sin \beta ( - \exp \left \lbrace i \alpha  \right \rbrace \left( 1 + \cos \beta \right) /2^{2} - \exp \left \lbrace i \alpha  \right \rbrace \left( 1 - \cos \beta \right) /2^{2} \\
&+ \exp \left \lbrace - i \alpha  \right \rbrace \left( 1 + \cos \beta \right)/2^{2} + \exp \left \lbrace - i \alpha  \right \rbrace \left( 1 - \cos \beta \right)/2^{2}) \\
&= i\hbar \sin \beta \left[ -\exp \left \lbrace i \alpha  \right \rbrace/2 + \exp \left \lbrace - i \alpha  \right \rbrace/2 \right] \\
&= \hbar \sin \beta \sin \alpha.
\end{align*}

Further

\begin{equation*}
\langle 1, 1 \vert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \left \lvert J_{z}  \right \rvert J_{x}  \right \rvert D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle &= \hbar \left[ \left( 1 + \cos \beta \right)^{2}/2 - \left( 1 - \cos \beta  \right)^{2}/2 \right] = \hbar \cos \beta.
\end{equation*}

We then have

\begin{equation*}
\left \langle \vec{J}  \right \rangle = \hbar \left( \sin \beta \cos \alpha \vec{i} + \sin \beta \sin \alpha \vec{j} + \cos \beta \vec{k} \right).
\end{equation*}

*(3)* *Show that for no value of* \(\alpha\), \(\beta\), *and* \(\gamma\) *can one rotate* \(\vert 1,1 \rangle\) *into just* \(\vert 1, 0 \rangle\).

Suppose that we could. Then

\begin{align*}
&\vert 1, 0 \rangle = \\
&\begin{pmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 & -\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \exp \left \lbrace - i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \cos \beta  & -\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 & \exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}  & \exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2
\end{pmatrix}
\vert 1, 1 \rangle
\end{align*}

for some \(\alpha\), \(\beta\), and \(\gamma\). Now

\begin{equation*}
\vert 1, 0 \rangle \leftrightarrow
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
\quad \text{and} \quad
\vert 1, 1 \rangle \leftrightarrow
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}
\end{equation*}

in the basis in which \(L_{z}\) is diagonal so

\begin{align*}
&\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
= \\
&\begin{pmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 & -\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \exp \left \lbrace - i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \cos \beta  & -\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 & \exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}  & \exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2
\end{pmatrix}
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}.
\end{align*}


Shattering it yields

\begin{equation*}
\left( 1 + \cos \beta \right)/2 = 0,
\end{equation*}

\begin{equation*}
\sin \beta /2^{1/2} = 1,
\end{equation*}

\begin{equation*}
\left( 1 - \cos \beta \right)/2 = 0.
\end{equation*}

But \((1+\cos \beta)/2 = \left( 1 - \cos \beta \right)/2\) is a mistruth, so our supposition is incorrect. By contradiction we have

\begin{align*}
&\vert 1, 0 \rangle \neq \\
&\begin{pmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 & -\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \exp \left \lbrace - i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} & \cos \beta  & -\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 & \exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}  & \exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2
\end{pmatrix}
\vert 1, 1 \rangle
\end{align*}

for any \(\alpha\), \(\beta\), and \(\gamma\).

*(4)* *Show that one can always rotate any* \(\vert 1, m  \rangle\) *into a linear combination that involves* \(\vert 1, m^{\prime} \rangle\), *i.e.,*

*for some* \(\alpha\), \(\beta\), \(\gamma\) *and any* \(m\), \(m^{\prime}\).

We need to show

\begin{equation*}
D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle = \delta \vert 1, 0 \rangle + \kappa \vert 1, -1 \rangle,
\end{equation*}

\begin{equation*}
D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 0 \rangle = \sigma \vert 1, 1 \rangle + \mu \vert 1, -1 \rangle,
\end{equation*}

\begin{equation*}
D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, -1 \rangle = \epsilon \vert 1, 0 \rangle + \omega \vert 1, 1 \rangle.
\end{equation*}

for some \(\delta\), \(\kappa\), \(\sigma\), \(\mu\), \(\epsilon\), and \(\omega\). Equivalently

\begin{equation*}
\begin{bmatrix}
\exp \left \lbrace -i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2 \\
\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2
\end{bmatrix} =
\begin{bmatrix}
0 \\
\delta \\
\kappa
\end{bmatrix},
\end{equation*}

\begin{equation*}
\begin{bmatrix}
-\exp \left \lbrace - i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\cos \beta \\
\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2}
\end{bmatrix} =
\begin{bmatrix}
\sigma \\
0 \\
\mu
\end{bmatrix},
\end{equation*}

\begin{equation*}
\begin{bmatrix}
\exp \left \lbrace - i \left( \alpha - \gamma \right)  \right \rbrace \left( 1 - \cos \beta \right)/2 \\
-\exp \left \lbrace i \gamma  \right \rbrace \sin \beta / 2^{1/2} \\
\exp \left \lbrace i \left( \alpha + \gamma \right)  \right \rbrace \left( 1 + \cos \beta \right)/2
\end{bmatrix} =
\begin{bmatrix}
\epsilon \\
\omega \\
0
\end{bmatrix}.
\end{equation*}

Sure I can make the first, second and third all be truths by choosing \(\alpha = \gamma\), \(\beta = \pi\), \(\delta = 0\), and \(\kappa = 1\); \(\beta = \pi/2\), arbitrary \(\alpha\) and \(\gamma\), \(\sigma = - \exp \left \lbrace - i \gamma  \right \rbrace/2^{1/2}\), and \(\mu = \exp \left \lbrace i \gamma  \right \rbrace/ 2^{1/2}\); and \(\beta = \pi\), \(\alpha = \gamma\), \(\epsilon = 1\), and \(\omega = 0\) respectively.

*(5)* *To see that one can occasionally rotate* \(\vert j m \rangle\) *into* \(\vert j m^{\prime} \rangle\), *verify that a* \(180^{\circ}\) rotation about the \(y\) axis applied to \(\vert 1, 1 \rangle\) turns it to \(\vert 1, -1 \rangle\).

Did that already; \(D^{(1)} \left[ R \left( \alpha, \beta, \gamma \right) \right] \vert 1, 1 \rangle = \delta \vert 1, 0 \rangle + \kappa \vert 1, -1 \rangle\) for \(\alpha = \gamma\), \(\beta = \pi\), \(\delta = 0\), and \(\kappa = 1\).

** SOLVED Problem 12.5.8
CLOSED: [2022-11-06 Sun 11:51]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 08:49]--[2022-11-06 Sun 10:59] =>  2:10
:END:
*(Optional)*. *Verify that*

\begin{equation*}
L_{x} \xrightarrow[\text{coordinate basis}]{} i \hbar \left( \sin \phi \thinspace \partial_{\theta} + \cos \phi \cot \theta \thinspace \partial_{\phi} \right),
\end{equation*}

\begin{equation*}
L_{y} \xrightarrow[\text{coordinate basis}]{} i \hbar \left( - \cos \phi \thinspace \partial_{\theta} + \sin \phi \cot \theta \thinspace \partial_{\phi} \right).
\end{equation*}

In cartesian coordinates

\begin{equation*}
L_{x} = Y P_{z} - Z P_{y} \xrightarrow[]{\text{cartesian coordinates}} y \left( -i \hbar \partial_{z} \right) - z \left( - i \hbar \partial_{y} \right),
\end{equation*}

and

\begin{equation*}
L_{y} = Z P_{z} - X P_{x} \xrightarrow[]{\text{cartesian coordinates}} z \left( -i \hbar \partial_{z} \right) - x \left( - i \hbar \partial_{x} \right).
\end{equation*}

The equations governing the coordinate transform from Cartesian to spherical polar coordinates are

\begin{equation*}
\rho = \sqrt{x^2 + y^2 + z^{2}}, \quad \phi = \tan^{-1} \left( y/x \right), \quad \theta = \tan^{-1} \left( \sqrt{x^{2} + y^{2}}/z \right)
\end{equation*}

so that

\begin{equation*}
x = \rho \sin \theta \cos \phi, \quad y = \rho \sin \theta \sin \phi, \quad z = \rho \cos \theta.
\end{equation*}

The Jacobian matrix is

\begin{align*}
\dfrac{\partial \left( \rho, \theta, \phi \right)}{\partial \left( x, y, z \right)} &=
\begin{pmatrix}
\dfrac{x}{\sqrt{x^{2} + y^{2} + z^{2}}} & \dfrac{y}{\sqrt{x^{2} + y^{2} + z^{2}}} & \dfrac{z}{\sqrt{x^{2} + y^{2} + z^{2}}} \\
\dfrac{xz}{(x^2 + y^2 + z^2)^2 \sqrt{x^{2} + y^{2}}} & \dfrac{yz}{(x^2 + y^2 + z^2)^2 \sqrt{x^{2} + y^{2}}} & - \dfrac{\sqrt{x^{2} + y^{2}}}{\left( x^{2} + y^{2} z^{2} \right)^{2}} \\
\dfrac{-y}{x^2 + y^2} & \dfrac{x}{x^2 + y^2} & 0
\end{pmatrix} \\
&=
\begin{pmatrix}
\sin \theta \cos \phi & \sin \theta \sin \phi & \cos \theta \\
\rho^{-1} \cos \theta \cos \phi & \rho^{-1} \sin \phi \cos \theta & - \rho^{-1} \sin \theta \\
- \rho^{-1} \sin \phi \left( \sin \theta \right)^{-1} & \rho^{-1} (\sin \theta)^{-1} \left( \cos \phi \right) & 0
\end{pmatrix}.
\end{align*}

\begin{align*}
L_{x} &= y \left( -i \hbar \partial_{z} \right) - z \left( - i \hbar \partial_{y} \right) \\
&=- i \hbar \thinspace \rho \sin \theta \sin \phi \left(\partial_{z} \rho \partial_{\rho}
+ \partial_{z} \theta \partial_{\theta}
+ \partial_{z} \phi \partial_{\phi}  \right)
+ i \hbar \thinspace \rho \cos \theta \left(
\partial_{y} \rho \partial_{\rho}
+ \partial_{y} \theta \partial_{\theta}
+ \partial_{y} \phi \partial_{\phi}  \right) \\
&=- i \hbar \thinspace \rho \sin \theta \sin \phi \left( \cos \theta \partial_{\rho}
+ - \rho^{-1} \sin \theta \partial_{\theta} \right) \\
&+ i \hbar \thinspace \rho \cos \theta \left(
\sin \theta \sin \phi \thinspace \partial_{\rho}
+ \rho^{-1} \sin \phi \cos \theta \partial_{\theta}
+ \rho^{-1} \left( \sin \theta \right)^{-1} \left( \cos \phi \right) \partial_{\phi} \right) \\
&= i \hbar \left[\sin \phi \thinspace \partial_{\theta} + \cot \theta \cos \phi \thinspace \partial_{\phi}  \right] 
\end{align*}

\begin{align*}
L_{y} &= z \left( -i \hbar \partial_{x} \right) - x \left( - i \hbar \partial_{z} \right) \\
&= - i \hbar \rho \cos \theta \left(
\partial_{x} \rho \partial_{\rho}
+ \partial_{x} \theta \partial_{\theta}
+ \partial_{x} \phi \partial_{\phi}  \right)
+ i \hbar \rho \sin \theta \cos \phi \left(
\partial_{z} \rho \partial_{\rho}
+ \partial_{z} \theta \partial_{\theta}
+ \partial_{z} \phi \partial_{\phi}  \right) \\
&= - i \hbar \rho \cos \theta \left( \sin \theta \cos \phi \partial_{\rho} + \rho^{-1} \cos \theta \cos \phi \partial_{\theta} - \rho^{-1} \sin \phi \left( \sin \theta \right)^{-1} \partial_{\phi} \right) \\
&+ i \hbar \rho \sin \theta \cos \phi \left( \cos \theta \thinspace \partial_{\rho} - \rho^{-1} \sin \theta \thinspace \partial_{\theta} \right) \\
&= i \hbar \left[ - \cos \phi \thinspace \partial_{\theta} + \sin \phi \cot \theta \thinspace \partial_{\phi} \right].
\end{align*}

** SOLVED Problem 12.5.9
CLOSED: [2022-11-06 Sun 15:53]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 12:05]--[2022-11-06 Sun 15:53] =>  3:48
:END:
*Show that* \(L^{2}\) *above is Hermitian in the sense*

\begin{equation*}
\int \psi_{1}^{\ast} \left( L^{2} \psi_{2} \right) \thinspace d \Omega = \left[ \int \psi_{2}^{\ast} \left( L^{2} \psi_{1} \right) \thinspace d \Omega \right]^{\ast}
\end{equation*}

*The same goes for* \(L_{z}\), *which is insensitive to* \(\theta\) *and is Hermitian with respect to the* \(\phi\) *integration.*

Let's find out the representation of \(L^{2}\) in polar coordinates. We have what we need.

\begin{equation*}
L_{x} \leftrightarrow i \hbar \left( \sin \phi \thinspace \partial_{\theta} + \cos \phi \cot \theta \thinspace \partial_{\phi} \right),
\end{equation*}

\begin{equation*}
L_{y} \leftrightarrow i \hbar \left( - \cos \phi \thinspace \partial_{\theta} + \sin \phi \cot \theta \thinspace \partial_{\phi} \right),
\end{equation*}

\begin{equation*}
L_{z} \leftrightarrow - i \hbar \partial_{\phi}.
\end{equation*}

Let's ``square" them

\begin{align*}
L_{x}^{2} &\leftrightarrow - \hbar^{2} \left( \sin \phi \thinspace \partial_{\theta} + \cos \phi \cot \theta \thinspace \partial_{\phi} \right) \left( \sin \phi \thinspace \partial_{\theta} + \cos \phi \cot \theta \thinspace \partial_{\phi} \right) \\
&\leftrightarrow - \hbar^{2} ( \sin^{2} \phi \thinspace \partial_{\theta}^{2} - \sin \phi \cos \phi \left(\sin^{2} \phi \right)^{-2} \thinspace \partial_{\phi} \\
&+ \sin \phi \cos \phi \cot \theta \thinspace \partial_{\theta} \partial_{\phi} + \cos^{2} \phi \cot \theta \partial_{\theta} \\
&+ \cos \phi \cot \theta \sin \phi \partial_{\phi} \partial_{\theta} -\sin \phi \cos \phi \cot^{2} \theta \partial_{\phi} + \cos^{2} \phi \thinspace \cot^{2} \theta \thinspace \partial_{\phi}^{2}).
\end{align*}

\begin{align*}
L_{y}^{2} &\leftrightarrow - \hbar^{2} \left( - \cos \phi \thinspace \partial_{\theta} + \sin \phi \cot \theta \thinspace \partial_{\phi} \right) \left( -\cos \phi \thinspace \partial_{\theta} + \sin \phi \cot \theta \thinspace \partial_{\phi} \right) \\
&\leftrightarrow - \hbar^{2} ( \cos^{2} \phi \thinspace \partial_{\theta}^{2} + \sin \phi \cos \phi \left(\sin^{2} \phi \right)^{-2} \thinspace \partial_{\phi} \\
&- \sin \phi \cos \phi \cot \theta \thinspace \partial_{\theta} \partial_{\phi} + \sin^{2} \phi \cot \theta \partial_{\theta} \\
&- \cos \phi \cot \theta \sin \phi \partial_{\phi} \partial_{\theta} +\sin \phi \cos \phi \cot^{2} \theta \partial_{\phi} + \sin^{2} \phi \thinspace \cot^{2} \theta \thinspace \partial_{\phi}^{2}).
\end{align*}

\begin{align*}
L_{z}^{2} &\leftrightarrow - i \hbar \partial_{\phi} \\
&\leftrightarrow - \hbar^{2} \partial_{\phi}^{2}.
\end{align*}

To tidy things up a little, let me just cancel the terms in transit okay?

\begin{align*}
L^{2} &\leftrightarrow L_{x}^{2} + L_{y}^{2} + L_{z}^{2} \\
&\leftrightarrow - \hbar^{2} \left[ \partial_{\theta}^{2} + \cot \theta \thinspace \partial_{\theta} + \partial_{\phi}^{2} + \cot^{2} \theta \partial_{\phi}^{2} \right] \\
&\leftrightarrow - \hbar^{2} \left[ \left( \sin \theta \right)^{-1} \partial_{\theta} \sin \theta \thinspace \partial_{\theta} + (\sin^{2} \theta)^{-1} \thinspace \partial_{\phi}^{2} \right].
\end{align*}

To perform the integral start by substituting \(L^{2}\) in the left integral to obtain

\begin{align*}
I \equiv - &\hbar^{2} \int \psi_{1}^{\ast} \left(\left[ \left( \sin \theta \right)^{-1} \partial_{\theta} \sin \theta \thinspace \partial_{\theta} + (\sin^{2} \theta)^{-1} \thinspace \partial_{\phi}^{2} \right] \psi_{2} \right) \thinspace \sin \theta \thinspace d \theta \thinspace d \phi.
\end{align*}

Break the integral up and take thier adjoints (getting rid of that annoying \(- \hbar^{2}\) momentarily)

\begin{equation*}
I_{1}^{\ast} = \int d \phi  \int d \theta \left \lbrace \left[\left \lbrace \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} \right \rbrace \psi_{2}^{\ast} \left( \theta, \phi \right) \right] \psi_{1}(\theta, \phi) \right \rbrace,
\end{equation*}

\begin{equation*}
I_{2}^{\ast} = \int d \theta \thinspace (\sin \theta)^{-1} \int d \phi \thinspace \left \lbrace \left[\partial_{\phi}^{2} \thinspace \psi_{2}^{\ast} \left( \theta, \phi \right) \right] \psi_{1} \left( \theta, \phi \right) \right \rbrace.
\end{equation*}

Jump a derivative to the right by integrating by parts. Surface term vanishes because the the value at the limits are the same (duh. Ok well, you evaluate a function at some point in the \(x-y\) plane, do a full swivel and evaluate it again, what's the answer? The same. What's the difference? Zero (we assume that the wavefunction is not a multi-valued function). As for the integral over the colatitude \(\theta\), the \(\sin \theta\) term survives in the surface term and causes vanishment at \(\theta = 0\) and \(\theta = \pi\)).

\begin{equation*}
I_{1}^{\ast} = -\int d \phi  \int d \theta \left \lbrace \left[\left \lbrace \partial_{\theta} \thinspace \sin \theta \thinspace \right \rbrace \psi_{2}^{\ast} \left( \theta, \phi \right) \right] \partial_{\theta} \thinspace \psi_{1}(\theta, \phi) \right \rbrace.
\end{equation*}

\begin{equation*}
I_{2}^{\ast} = -\int d \theta \thinspace (\sin \theta)^{-1} \int d \phi \thinspace \left \lbrace \left[\partial_{\phi} \thinspace \psi_{2}^{\ast} \left( \theta, \phi \right) \right] \partial_{\phi} \psi_{1} \left( \theta, \phi \right) \right \rbrace.
\end{equation*}

``Pull out" an adjoint from the right hand side and ``cancel" it with one on the left

\begin{equation*}
I_{1} = -\int d \phi  \int d \theta \left \lbrace \partial_{\theta} \thinspace \psi_{1}^{\ast}(\theta, \phi) \left[\left \lbrace \partial_{\theta} \sin \theta \thinspace \right \rbrace \psi_{2} \left( \theta, \phi \right) \right] \right \rbrace.
\end{equation*}

\begin{equation*}
I_{2} = -\int d \theta \thinspace (\sin \theta)^{-1} \int d \phi \thinspace \left \lbrace \partial_{\phi} \psi_{1}^{\ast} \left( \theta, \phi \right) \left[\partial_{\phi} \thinspace \psi_{2} \left( \theta, \phi \right) \right] \right \rbrace.
\end{equation*}

Now jump a derivative to the left (yes it's legal)

\begin{equation*}
I_{1} = \int d \phi  \int d \theta \left \lbrace \left[\left \lbrace \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} \right \rbrace \psi_{1}^{\ast} \left( \theta, \phi \right) \right] \psi_{2}(\theta, \phi) \right \rbrace,
\end{equation*}

\begin{equation*}
I_{2} = \int d \theta \thinspace (\sin \theta)^{-1} \int d \phi \thinspace \left \lbrace \left[\partial_{\phi}^{2} \thinspace \psi_{1}^{\ast} \left( \theta, \phi \right) \right] \psi_{2} \left( \theta, \phi \right) \right \rbrace.
\end{equation*}

Pull one last adjoint out from the right

\begin{equation*}
I_{1} = \int d \phi  \int d \theta \left \lbrace \psi_{2}^{\ast}(\theta, \phi) \left[\left \lbrace \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} \right \rbrace \psi_{1} \left( \theta, \phi \right) \right] \right \rbrace^{\ast},
\end{equation*}

\begin{equation*}
I_{2} = \int d \theta \thinspace (\sin \theta)^{-1} \int d \phi \thinspace \left \lbrace \psi_{2}^{\ast} \left( \theta, \phi \right) \left[\partial_{\phi}^{2} \thinspace \psi_{1} \left( \theta, \phi \right) \right] \right \rbrace^{\ast}.
\end{equation*}

Glue it together (don't forget the \(-\hbar^{2}\)) and you have

\begin{align*}
I &\equiv \left[- \hbar^{2} \int \psi_{2}^{\ast} \left(\left[ \left( \sin \theta \right)^{-1} \partial_{\theta} \sin \theta \thinspace \partial_{\theta} + (\sin^{2} \theta)^{-1} \thinspace \partial_{\phi}^{2} \right] \psi_{1} \right) \thinspace \sin \theta \thinspace d \theta \thinspace d \phi \right]^{\ast}.
\end{align*}

Therefore

\begin{equation*}
\int \psi_{1}^{\ast} \left( L^{2} \psi_{2} \right) \thinspace d \Omega = \left[ \int \psi_{2}^{\ast} \left( L^{2} \psi_{1} \right) \thinspace d \Omega \right]^{\ast}.
\end{equation*}

** SOLVED Problem 12.5.10
CLOSED: [2022-11-06 Sun 19:36]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 18:13]--[2022-11-06 Sun 19:36] =>  1:23
:END:
*Write the differential equation corresponding to*

\begin{equation*}
L^{2} \vert \alpha \beta \rangle = \alpha \vert \alpha \beta \rangle
\end{equation*}

*in the coordinate basis, using the* \(L^{2}\) *operator given in* \(\text{Eq.}(12.5.36)\). *We already know* \(\beta = m \hbar\) *from the analysis of* \(- i \hbar \partial_{\phi}\). *So assume that the simultaneous eigenfunctions have the form*

\begin{equation*}
\psi_{\alpha m} \left( \theta, \phi \right) = P_{\alpha}^{m} \left( \theta \right) \exp \left \lbrace i m \phi  \right \rbrace.
\end{equation*}

*and show that* \(P_{a}^{m}\) *satisfies the equation*

\begin{equation*}
\left[\left( 1/ \sin \theta \right) \partial_{\theta} \sin \theta \thinspace \partial_{\theta} + \left( \alpha/ \hbar^{2} \right) - m^{2}/\sin^{2} \theta\right] P_{\alpha}^{m} \left( \theta \right) = 0.
\end{equation*}

In the coordinate basis

\begin{equation*}
L^{2} \to \left( - \hbar \right)^{2} \left( \dfrac{1}{\sin \theta} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + \dfrac{1}{\sin^{2} \theta} \partial_{\phi}^{2} \right).
\end{equation*}

Feed the ansatz \(\psi_{\alpha m} \left( \theta, \phi \right) = P_{\alpha}^{m} \left( \theta \right) \exp \left \lbrace i m \phi  \right \rbrace\) to \(L^{2}\):

\begin{align*}
\left( - \hbar \right)^{2} &\left( \dfrac{1}{\sin \theta} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + \dfrac{1}{\sin^{2} \theta} \partial_{\phi}^{2} \right) P_{\alpha}^{m} \left( \theta \right) \exp \left \lbrace i m \phi  \right \rbrace \\
&= \left( - \hbar \right)^{2} \dfrac{\exp \left \lbrace i m \phi  \right \rbrace}{\sin \theta} \partial_{\theta} \sin \theta \partial_{\theta} P_{\alpha}^{m} \left( \theta \right) + \dfrac{m^{2} \exp \left \lbrace i m \phi  \right \rbrace}{\sin^{2} \theta} P_{\alpha}^{m} \left( \theta \right) = \alpha P_{\alpha}^{m} \left( \theta \right) \exp \left \lbrace i m \phi  \right \rbrace.
\end{align*}

Tidy up to get

\begin{align*}
\left[ \left( 1/ \sin \theta \right) \partial_{\theta} \sin \theta \partial_{\theta} + \left( \alpha / \hbar^{2} \right) - m^{2} / \sin^{2} \theta \right] P_{\alpha}^{m} \left( \theta \right) = 0.
\end{align*}

*We need to show that*

*(1)* \(\alpha / \hbar^{2} = l (l + 1)\), \(l = 0, 1, 2, \dotso\)

*(2)* \(\left \lvert m  \right \rvert \leq l\).

*We will consider only part (1) and that too for the case* \(m=0\). *By rewriting the equation in terms of* \(u=cos \theta\), *show that* \(P_{\alpha}^{0}\) *satisfies*

\begin{equation*}
\left[ \left( 1 - u^{2} \right) D_{u}^{2} - 2 u D_{u} + \left( \alpha / \hbar^{2} \right) \right] P_{\alpha}^{0} = 0.
\end{equation*}

\begin{align*}
&\left[ \left( 1/ \sin \theta \right) \partial_{\theta} \sin \theta \partial_{\theta} + \left( \alpha / \hbar^{2} \right) - m^{2} / \sin^{2} \theta \right] P_{\alpha}^{m} \left( \theta \right) = 0 \\
&\xrightarrow[du = - sin \theta d \theta]{u = \cos \theta, m = 0} \left[ D_{u} (1 - u^{2}) D_{u} + \left( \dfrac{\alpha}{\hbar^{2}} \right) \right] P_{\alpha}^{0} = 0 \\
&\xrightarrow[]{} \left[ \left( 1 - u^{2} \right) D_{u}^{2} - 2 u D_{u} + \left(\dfrac{\alpha}{\hbar^{2}}\right)\right] P_{\alpha}^{0} = 0
\end{align*}

*Convince yourself that a power series solution*

\begin{equation*}
P_{\alpha}^{0} = \sum_{n=0}^{\infty} C_{n} u^{m}.
\end{equation*}

*will lead to a two-term recursion relation. Show that* \((C_{n+2}/C_{n}) \to 1\) *as* \(n \to \infty\). *Thus the series diverges when* \(\left \lvert u  \right \rvert \to 1\) \((\theta \to 0 \thinspace\text{or} \thinspace \pi)\). *Show that if* \(\alpha / \hbar^{2} = (l) (l + 1)\); \(l = 0, 1, 2, \dotso\), *the series will terminate and be either an even or odd function of* \(u\). *The functions* \(P_{\alpha}^{0}(u) = P_{l(l+1)\hbar^{2}}^{0}(u) \equiv P_{l}^{0} (u) \equiv P_{l} (u)\) *are just the Legendre polynomials up to a scale factor. Determine* \(P_{0}\), \(P_{1}\), *and* \(P_{2}\) *and compare (ignoring overall scales) with the* \(Y_{l}^{0}\) *functions.*

Feed \(P_{\alpha}^{0} = \sum_{n=0}^{\infty} C_{n} u^{m}\) in \(\left[ \left( 1 - u^{2} \right) D_{u}^{2} - 2 u D_{u} + \left(\dfrac{\alpha}{\hbar^{2}}\right)\right] P_{\alpha}^{0} = 0\) to obtain

\begin{align*}
\sum_{n=0}^{\infty} C_{n} n \left( n - 1 \right) u^{n-2} - \sum_{n=0}^{\infty} C_{n} n \left( n - 1 \right) u^{n} - 2 \sum_{0}^{\infty} C_{n} n u^{n} + \left( \dfrac{\alpha}{\hbar^{2}} \right) \sum_{0}^{\infty} C_{n} u^{n} = 0.
\end{align*}

Matching coefficients of \(m\)

\begin{align*}
C_{m+2} \left( m + 2 \right) \left( m + 1 \right) - C_{m} m \left( m - 1 \right) - 2 C_{m} m + \left( \dfrac{\alpha}{\hbar^{2}} \right) C_{m} = 0.
\end{align*}

Rearranging

\begin{align*}
C_{m+2} = \dfrac{m \left( m - 1 \right) + 2 m - \left( \alpha / \hbar^{2} \right)}{(m+2)(m+1)} C_{m} = \dfrac{m \left( m + 1 \right) - \left( \alpha / \hbar^{2} \right)}{(m+2)(m+1)} C_{m}.
\end{align*}

\begin{align*}
\frac{C_{m+2}}{C_{m}} = \dfrac{m \left( m + 1 \right) - \left( \alpha / \hbar^{2} \right)}{(m+2)(m+1)} = \dfrac{m \left( m + 1 \right)}{(m+2)(m+1)} - \dfrac{\left( \alpha / \hbar^{2} \right)}{(m + 2)(m + 1)}.
\end{align*}

In the \(m \to \infty\) limit, the second term vanishes and the first one converges to \(1\) so \((C_{n+2}/C_{n}) \to 1\) as \(n \to \infty\). If \(\alpha/ \hbar^{2} = \left( l \right) \left( l + 1 \right)\); \(l = 0, 1, 2, \dotso\) this series will terminate for \(l = m\), as one look at the recurrence will make obvious. Depending on whether \(C_{0}\) seed to used to unroll the recurrence or the \(C_{1}\) seed, one obtains even or odd functions of \(u\), given that in each case the other seed is set to \(0\) by construction.

To lay birth the specified Legendre polynomials set \(C_{1} = 0\), \(C_{0} = 1\) for \(P_{0}\), \(C_{1}= 0, \thinspace C_{0} = -1/2\) for \(P_{2}\), \(c_{1}=1\) \(C_{0} = 0\)  for \(P_{1}\), and \(C_{1}=-3/2\) \(C_{0} = 0\) for \(P_{3}\):

\(P_{0} = 1\),

\(P_{1} = x\),

\(P_{2} = \dfrac{1}{2} \left( 3 x^{2} - 1 \right)\),

\(P_{3} = \dfrac{1}{2} \left( 5 x^{3} - 3x \right)\).
** SOLVED Problem 12.5.11
CLOSED: [2022-11-06 Sun 21:09]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 19:38]--[2022-11-06 Sun 21:09] =>  1:31
:END:
*Derive* \(Y_{1}^{1}\) *starting from* \(\text{Eq.}(12.5.28)\) *and normalize it yourself. [Remember the* \((-1)^{l}\) *factor from* \(\text{Eq.}(12.5.32)\) *.] Lower it to get* \(Y_{l}^{0}\) *and* \(Y_{l}^{-1}\) *and compare it with* \(\text{Eq.}(12.5.39)\).

We are to derive \(Y_{1}^{1}\) starting from

\begin{align*}
\left[ \partial_{\theta} + i \cot \theta \thinspace \partial_{\phi} \right] \psi^{1}_{1} \left( r, \theta, \phi \right) = 0.
\end{align*}

Since \(\psi_{1}^{1}\) is an eigenfunction of \(L_{z}\) with eigenvalue \(l \hbar\), we get

\begin{align*}
\psi_{1}^{1} \left( r, \theta, \phi \right) = U_{1}^{1} \left( r, \theta \right) \exp \left \lbrace i \phi  \right \rbrace
\end{align*}

and find that

\begin{align*}
\left(\partial_{_{\theta}} - I \cot \theta\right) U_{1}^{1} = 0,
\end{align*}

\begin{align*}
\dfrac{d U_{1}^{1}}{U_{1}^{1}} = \dfrac{d \left( \sin \theta \right)}{\sin \theta}.
\end{align*}

or

\begin{align*}
U_{1}^{1} \left( r, \theta \right) = R \left( r \right) \left( \sin \theta \right)^{1} = R \left( r \right) \left( \sin \theta \right)
\end{align*}

so that

\begin{align*}
Y_{1}^{1} \left( \theta, \phi \right) = - \sin \theta \exp \left \lbrace i \phi  \right \rbrace
\end{align*}

ignoring the radial coordinate and remembering \(\text{Eq.} (12.5.32)\) as advised. On now to normalizing it. \(\int \left \lvert Y_{1}^{1}  \right \rvert^{2} \equiv 1\).

\begin{align*}
\int_{0}^{2\pi} d \phi \int_{0}^{\pi} d \theta \thinspace \sin^{3} \theta = 8 \pi/3.
\end{align*}

#+NAME: solve-maxima
#+HEADER: :exports none
#+begin_src maxima :results raw
  sol: integrate((sin(x))^3, x, a, b);
  tex(sol);
#+end_src

#+RESULTS: solve-maxima
\[2\,x\,e^ {- {{x}\over{a}} }-{{x^2\,e^ {- {{x}\over{a}} }}\over{a}}\]
\[2\,x\,e^ {- {{x}\over{a}} }-{{x^2\,e^ {- {{x}\over{a}} }}\over{a}}\]
\[{{\cos ^3b-3\,\cos b}\over{3}}-{{\cos ^3a-3\,\cos a}\over{3}}\]

so \(Y_{1}^{1}\) after normalization is

\begin{align*}
Y_{1}^{1} = - \left( \dfrac{3}{8 \pi} \right)^{1/2} \sin \theta \exp \left \lbrace i \phi  \right \rbrace.
\end{align*}

We want to lower it so feed \(Y_{1}^{1}\) to

\begin{align*}
L_{-} = L_{x} - i L_{y} = - \hbar \exp \left \lbrace - i \phi  \right \rbrace \left( \partial_{\theta} - i \cot \theta \partial_{\phi} \right).
\end{align*}
 
The action of \(L_{-}\) on ket \(\vert ll \rangle\) is \(L_{-} \vert ll \rangle = \hbar \left( 2l \right)^{1/2} \vert l, l-1 \rangle\). It's action on \(Y_{1}^{1}\) thus must be

\begin{align*}
L_{-} Y_{1}^{1} = \hbar 2^{1/2} Y_{1}^{0}.
\end{align*}

Feeding \(Y_{1}^{1}\) to \(L_{-}\) we get

\begin{align*}
Y_{1}^{1} &= \hbar \left( \dfrac{3}{8 \pi} \right)^{1/2} \exp \left \lbrace - i \phi  \right \rbrace \left( \partial_{\theta} - i \cot \theta \partial_{\phi} \right) \sin \theta \exp \left \lbrace i \phi  \right \rbrace \\
&= \dfrac{\hbar}{2} \left( \dfrac{3}{2 \pi} \right)^{1/2} \cos \theta \\
&= \hbar 2^{1/2} \left( \dfrac{3}{4 \pi} \right)^{1/2} \cos \theta.
\end{align*}

We now read off \(Y_{1}^{0}\) as

\begin{align*}
Y_{1}^{0} = \left( \dfrac{3}{4 \pi} \right)^{1/2} \cos \theta.
\end{align*}

Lower it again.

\begin{align*}
Y_{1}^{-1} &= \hbar \left( \dfrac{3}{4 \pi} \right)^{1/2} \exp \left \lbrace - i \phi  \right \rbrace \left( \partial_{\theta} - i \cot \theta \partial_{\phi} \right) \cos \theta \\
&= \hbar \left( \dfrac{3}{4 \pi} \right)^{1/2} \sin \theta \exp \left \lbrace - i \phi  \right \rbrace \\
&= \hbar 2^{1/2} \left( \dfrac{3}{8 \pi} \right)^{1/2} \sin \theta \exp \left \lbrace - i \phi  \right \rbrace.
\end{align*}

We now read off \(Y_{1}^{-1}\) as

\begin{align*}
Y_{1}^{-1} = \left( \dfrac{3}{8 \pi} \right)^{1/2} \sin \theta \exp \left \lbrace - i \phi  \right \rbrace.
\end{align*}

** SOLVED Problem 12.5.12
CLOSED: [2022-11-06 Sun 23:09]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 21:14]--[2022-11-06 Sun 23:09] =>  1:55
:END:
*Since* \(L^{2}\) *and* \(L_{z}\), *commute with* \(\Pi\), *they should share a basis with it. Verify that* \(Y_{l}^{m} \xrightarrow[]{\Pi} \left( -1 \right)^{l} Y_{l}^{m}\). *(First show that* \(\theta \to \pi - \theta\), \(\phi \to \phi + \pi\) *under parity. Prove the result for* \(Y_{l}^{l}\). *Verify that* \(L_{-}\) *does not alter the parity, thereby proving the result for all* \(Y_{l}^{m}\) *.)*.

The following formulae relate rectangular and spherical polar coordinate systems:

\begin{align*}
x = r \sin \theta \cos \phi, \qquad y = r \sin \theta \sin \phi, \qquad z = r \cos \theta,
\end{align*}

\begin{align*}
r = x^{2} + y^{2} + z^{2}, \qquad  \tan \theta = \left( z/ \sqrt{x^{2} + y^{2}} \right), \qquad \tan \phi = \left( y/x \right).
\end{align*}

Under the action \(\Pi\) we have

\begin{align*}
x \xrightarrow[]{\text{parity}} - x, \qquad y \xrightarrow[]{\text{parity}} - y, \qquad z \xrightarrow[]{\text{parity}} - z.
\end{align*}

It should be clear now that the action in spherical polar coordinates is

\begin{align*}
r \xrightarrow[]{\text{parity}} r, \qquad \theta \xrightarrow[]{\text{parity}} \pi - \theta, \qquad \phi \xrightarrow[]{\text{parity}} \pi + \phi.
\end{align*}

An expression for \(Y_{l}^{l}\) is

\begin{align*}
Y_{l}^{l} \left( \theta, \phi \right) = \left( - 1 \right)^{l} \left[ \dfrac{\left( 2l + 1 \right)!}{4 \pi} \right]^{1/2} \dfrac{1}{2^{l} l!} \left( \sin \theta \right)^{l} \exp \left \lbrace i l \phi  \right \rbrace.
\end{align*}

Under parity

\begin{align*}
\exp \left \lbrace i l \phi  \right \rbrace \xrightarrow[]{\text{parity}} \exp \left \lbrace i l \pi  \right \rbrace \exp \left \lbrace i l \phi  \right \rbrace = \left( -1 \right)^{l} \exp \left \lbrace i l \phi  \right \rbrace
\end{align*}

\begin{align*}
\sin \theta \xrightarrow[]{\text{parity}} \sin (\pi - \theta) = \sin \theta.
\end{align*}

\begin{align*}
\cos \theta \xrightarrow[]{\text{parity}} \cos \left( \pi - \theta \right) = - \cos \theta.
\end{align*}

Therefore

\begin{align*}
Y_{l}^{l} \left( \theta, \phi \right) \xrightarrow[]{\Pi} Y_{l}^{l} \left( \pi - \theta, \phi + \pi \right) = \left( - 1 \right)^{l} Y_{l}^{l} \left( \theta, \phi \right).
\end{align*}
** SOLVED Problem 12.5.13
CLOSED: [2022-11-07 Mon 00:30]
:LOGBOOK:
CLOCK: [2022-11-06 Sun 23:09]--[2022-11-06 Sun 23:17] =>  0:08
:END:
*Consider a particle in a state described by*

\begin{equation*}
\psi = N \left( x + y + 2 z \right) \thinspace \exp \left \lbrace - \alpha r  \right \rbrace
\end{equation*}

*where* \(N\) *is a normalization factor.*

*(1)* *Show, by rewriting the* \(Y_{1}^{\pm 1, 0}\) *functions in terms of* \(x\), \(y\), \(z\), *and* \(r\), *that*

\begin{equation*}
Y_{l}^{\pm 1} = \mp \left( 3/ 4 \pi \right)^{1/2} \dfrac{x \pm i y}{2^{1/2} r},
\end{equation*}

\begin{equation*}
Y_{1}^{0} = \left( \dfrac{3}{4 \pi} \right)^{1/2} \dfrac{z}{r}.
\end{equation*}

We have

\begin{align*}
Y_{1}^{\pm 1} &= \mp \left( 3/ 8 \pi \right)^{1/2} \sin \theta \exp \left \lbrace \pm i \phi  \right \rbrace \\
&= \mp \left( 3/ 8 \pi \right)^{1/2} \sin \theta \left( \cos \phi \pm i \sin \phi \right) \\
&= \mp \left( 3/ 8 \pi \right)^{1/2} \left(\sin \theta \cos \phi \pm i \sin \theta \sin \phi \right) \\
&= \mp \left( 3/ 4 \pi \right)^{1/2} \left(r \sin \theta \cos \phi \pm i r \sin \theta \sin \phi \right)/2^{1/2}r \\
&= \mp \left( 3/ 4 \pi \right)^{1/2} \dfrac{x \pm i y}{2^{1/2} r},
\end{align*}

and

\begin{align*}
Y_{1}^{0} = \left(\dfrac{3}{4 \pi}\right)^{1/2} \cos \theta = \left(\dfrac{3}{4 \pi}\right)^{1/2} \dfrac{z}{r}.
\end{align*}

*(2)* *Using this result, show that for a particle described by* \(\psi\) *above,* \(P(l_{z} = 0) = 2/3\); \(P(l_{z}= + \hbar) = 1/6 = P \left( l_{z} = - \hbar \right)\).

Solving for \(x\), \(y\), \(z\) and \(r\) we get

\begin{align*}
x = \left( \dfrac{4 \pi}{3} \right)^{1/2} r \thinspace \left(Y_{l}^{1} + Y_{l}^{-1}\right)/\sqrt{2},
\end{align*}

\begin{align*}
y = \left( \dfrac{4 \pi}{3} \right)^{1/2} r \thinspace \left(i Y_{l}^{-1} - i Y_{l}^{1} \right)/ i \sqrt{2},
\end{align*}

\begin{align*}
z = \left( \dfrac{4 \pi}{3} \right)^{1/2} Y_{1}^{0} r.
\end{align*}

The wave function may thus be written as

\begin{align*}
\psi = N \left( 4 \pi / 3 \right)^{1/2} r \left( 2 Y_{1}^{0} + [1 + i] Y_{1}^{1}/2^{1/2} + [1 + i] Y_{1}^{-1}/2^{1/2} \right) \thinspace \exp \left \lbrace - \alpha r  \right \rbrace
\end{align*}

so that 

\begin{align*}
&P \left( l_{z} = \hbar \right) \cong P \left( l_{z} = - \hbar \right) \cong 4 P \left( l_{z} = 0 \right).
\end{align*}

The probabilities are:

\begin{align*}
P \left( l_{z} = \hbar \right) = \dfrac{1}{1 + 1 + 4} = 1/6,
\end{align*}

\begin{align*}
P \left( l_{z} = -\hbar \right) = \dfrac{1}{1 + 1 + 4} = 1/6,
\end{align*}

\begin{align*}
P \left( l_{z} = 0 \right) = \dfrac{4}{1 + 1 + 4} = 2/3.
\end{align*}

** SOLVED Problem 12.5.14
CLOSED: [2022-11-07 Mon 16:46]
:LOGBOOK:
CLOCK: [2022-11-07 Mon 15:32]--[2022-11-07 Mon 16:46] =>  1:14
:END:
*Consider a rotation* \(\theta_{x} \vec{i}\). *Under this*

\begin{align*}
x &\to x, \\
y &\to y \cos \theta_{x} - z \sin \theta_{x}, \\
z &\to z \cos \theta_{x} + y \sin \theta_{x}.
\end{align*}

*Therefore we must have*

\begin{equation*}
\psi \left( x, y, z \right) \xrightarrow[]{U \left[ R \left( \theta_{x} \vec{i} \right) \right]} \psi_{R} = \psi \left( x, y \cos \theta_{x} + z \sin \theta_{x}, z \cos \theta_{x} - y \sin \theta_{x} \right).
\end{equation*}

*Let us verify this prediction for a special case*

\begin{equation*}
\psi = A z \thinspace \exp \left \lbrace - r^{2} / a^{2}  \right \rbrace
\end{equation*}

*which must go into*

\begin{equation*}
\psi_{R} = A \left( z \cos \theta_{x} - y \sin \theta_{x} \right) \exp \left \lbrace - r^{2} / a^{2}  \right \rbrace.
\end{equation*}

*(1)* *Expand* \(\psi\) *in terms of* \(Y_{1}^{1}, Y_{1}^{0}, Y_{1}^{-1}\).

In the previous question we obtained:

\begin{align*}
z = \left( \dfrac{4 \pi}{3} \right)^{1/2} Y_{1}^{0} r.
\end{align*}

so just eliminate that \(z\):

\begin{align*}
\psi \left( x, y, z \right) = A \left( \dfrac{4 \pi}{3} \right)^{1/2} r \thinspace Y_{1}^{0} \exp \left \lbrace - r^{2}/a^{2}  \right \rbrace.
\end{align*}

*(2)* *Use the matrix* *to find the fate of* \(\psi\) *under this rotation. Check your result against that anticipated above. [Hint: (1)* \(\psi \sim Y_{1}^{0}\), *which corresponds to*

\begin{equation*}
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix},
\end{equation*}

*(2) Use* \(\text{Eq.}(12.5.42)\) *.]*

The rotation by \(\exp \left \lbrace - i \theta_{x} L_{x}^{(1)}/ \hbar \right \rbrace\) is effected by the matrix:

\(D^{(1)} (R) = \exp \left \lbrace - i \theta_{x} \cdot J_{x}^{(1)} / \hbar \right \rbrace = \left(\cos \theta_{x} - 1\right) \left( \dfrac{J_{x}^{(1)}}{\hbar} \right)^{2} - i \sin \theta_{x} \left( \dfrac{J_{x}^{(1)}}{\hbar} \right) + I^{(1)}\)

as we showed in =Exercise.12.5.5=. Don't tell me you forgot. So

\begin{align*}
\exp \left \lbrace - i \theta_{x} L_{x}/ \hbar \right \rbrace &=
\left( \cos \theta_{x} - 1 \right)
\begin{pmatrix}
1/2 & 0 & 1/2 \\
0 & 1 & 0 \\
1/2 & 0 & 1/2
\end{pmatrix} \\
&- i \sin \theta_x
\begin{pmatrix}
0 & 1/2^{1/2} & 0 \\
1/2^{1/2} & 0 & 1/2^{1/2} \\
0 & 1/2^{1/2} & 0
\end{pmatrix}
+
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix},
\end{align*}


All that's needed now is the hint \(\psi \sim Y_{1}^{0}\), and

\begin{equation*}
Y_{1}^{0} =
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix},
\end{equation*}

and therefore

\begin{align*}
Y_{1}^{1} =
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix},
\qquad
Y_{1}^{-1} =
\begin{bmatrix}
0 \\
0 \\
1
\end{bmatrix}.
\end{align*}

What are those three matrices of \(\exp \left \lbrace - i \theta_{x} L_{x}/ \hbar \right \rbrace\) going to do to \(Y_{1}^{0}\)? It's perfectly clear

\begin{align*}
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
\to
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
&+
\begin{bmatrix}
0 \\
(\cos \theta_{x} - 1) \\
0
\end{bmatrix}
-
\begin{bmatrix}
i \sin \theta_{x}/ 2^{1/2} \\
0 \\
i \sin \theta_{x}/ 2^{1/2}
\end{bmatrix} \\
&=
\begin{bmatrix}
- i \sin \theta_{x}/ 2^{1/2} \\
\cos \theta_{x} \\
- i \sin \theta_{x}/ 2^{1/2} \\
\end{bmatrix}
= \cos \theta_x Y_0^1 - i \sin \theta_x \right \left( Y_{0}^{1} + Y_{0}^{-1} \right)/2^{1/2}.
\end{align*}

Where now? In the previous question we /also/ obtained:

\begin{align*}
Y_{l}^{\pm 1} = \mp \left( 3/ 4 \pi \right)^{1/2} \dfrac{x \pm i y}{2^{1/2} r},
\end{align*}

surely you didn't forget /that/? It's use with \(z = \left( \dfrac{4 \pi}{3} \right)^{1/2} Y_{1}^{0} r\) immediately yields
\begin{align*}
z \to z \cos \theta_{x} - y \sin \theta_{x},
\end{align*}

so that

\begin{align*}
\psi \xrightarrow[]{U \left[ R \left( \theta_{x} \vec{i} \right) \right]} \psi_{R} = A \left( z \cos \theta_{x} - y \sin \theta_{x} \right) \exp \left \lbrace - r^{2} / a^{2}  \right \rbrace,
\end{align*}

and the lord of consistency nods in approval.

** SOLVED Problem 12.6.1
CLOSED: [2022-11-07 Mon 21:21]
:LOGBOOK:
CLOCK: [2022-11-07 Mon 16:49]--[2022-11-07 Mon 18:18] =>  1:29
:END:
*A particle is described by the wave function*

\begin{equation*}
\psi_{E} \left( r, \theta, \phi \right) = A \exp \left \lbrace - r/ a_{0}  \right \rbrace \qquad \text{(\(a_{0}\) = const.)} 
\end{equation*}

*(1) What is the angular momentum content of the state?*

Make a measurement. Don't bother, just ``see" that it is not a function of \(\theta\) and \(\phi\): the spherical harmonic associated with it must be \(Y_{0}^{0}\) and as such claim the angular momentum content as \(l = 0\).

*(2) Assuming* \(\psi_{E}\) *is an eigenstate in a potential that vanishes as* \(r \to \infty\), *find* \(E\). *(Match leading terms in Schrodinger's equation.)*

The time-independent Schrodinger equation \(H \psi_{E} = E \psi_{E}\) in a more helpful form is

\begin{align*}
&- \left( \hbar^2/ 2 \mu \right) \left[ r^{-2} \partial_{r} r^{2} \partial_{r} + r^{-2} \left( \sin \theta \right)^{-1} \partial_{\theta} \sin \theta \partial_{\theta} \\
&+ r^{-2} \left( \sin^{2} \theta \right)^{-1} \partial_{\phi}^{2} + (2 \mu / \hbar^{2}) V(r) \right] \psi_E = E \psi_E,
\end{align*}

but is rendered even more useful by taking note of facts already mentioned and crunching out the partial derivatives with respect to \(r\):

\begin{align*}
\left( \dfrac{1}{a_{0}^{2} r} \right) \left( r - 2 a_{0} \right) \exp \left \lbrace - r/ a  \right \rbrace + (2 \mu / \hbar^{2}) V(r) \exp \left \lbrace - r/ a \right \rbrace = - \left( \dfrac{2 \mu E}{\hbar^{2}} \right) \exp \left \lbrace - r/ a  \right \rbrace.
\end{align*}

In the \(r \to \infty\) limit this equation reduces to

\begin{align*}
r \exp \left \lbrace - r / a  \right \rbrace = - a_{0}^{2} \left( 2 \mu E / \hbar^{2} \right) r \exp \left \lbrace - r/ a  \right \rbrace.
\end{align*}

It follows that

\begin{align*}
E = - \hbar^{2} / 2 \mu a_{0}^{2}.
\end{align*}

*(3) Having found* \(E\), *consider finite* \(r\) *and find* \(V(r)\).

In the \(r \to 0\) limit

\begin{align*}
\left( \dfrac{1}{a_{0}^{2} r} \right) \left( r - 2 a_{0} \right) \exp \left \lbrace - r/ a  \right \rbrace + (2 \mu / \hbar^{2}) V(r) \exp \left \lbrace - r/ a \right \rbrace = - \left( \dfrac{2 \mu E}{\hbar^{2}} \right) \exp \left \lbrace - r/ a  \right \rbrace.
\end{align*}

reduces to

\begin{align*}
- 2 a_0 \exp \left \lbrace - r / a  \right \rbrace / r = \left( 2 \mu / \hbar^2 \right) V(r) \exp \left \lbrace - r / a  \right \rbrace.
\end{align*}

It follows that

\begin{align*}
V(r) = - \hbar^{2}/ \mu a_{0} r.
\end{align*}

** SOLVED Problem 12.6.2
CLOSED: [2022-11-08 Tue 03:31]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 01:01]--[2022-11-08 Tue 03:31] =>  2:30
CLOCK: [2022-11-07 Mon 23:02]--[2022-11-08 Tue 00:12] =>  1:10
CLOCK: [2022-11-07 Mon 21:25]--[2022-11-07 Mon 22:35] =>  1:10
:END:
*Provide the steps connecting* \(\text{Eq.} (12.6.3)\) *and* \(\text{Eq.} (12.6.5)\).

The Laplacian and its various forms are

\begin{align*}
\left[ r^{-2} \partial_{r} \thinspace r^{2} \thinspace \partial_{r} + r^{-2} \left( \sin \theta \right)^{-1} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + r^{-2} \left( \sin \theta \right)^{-2} \partial_{\phi}^{2} \right],
\end{align*}

\begin{align*}
\left[ r^{-1} \partial_{r}^{2} \thinspace r + r^{-2} \left( \sin \theta \right)^{-1} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + r^{-2} \left( \sin \theta \right)^{-2} \partial_{\phi}^{2} \right],
\end{align*}

\begin{align*}
\left[ r^{-1} \partial_{r} + \partial_{r}^{2} + r^{-2} \left( \sin \theta \right)^{-1} \partial_{\theta} \thinspace \sin \theta \thinspace \partial_{\theta} + r^{-2} \left( \sin \theta \right)^{-2} \partial_{\phi}^{2}\right].
\end{align*}

Using the second we obtain a rewrite of

\begin{align*}
\left \lbrace - \dfrac{\hbar^{2}}{2 \mu} \left[ \dfrac{1}{r^{2}} D_r \thinspace r^{2} \thinspace D_{r} - \dfrac{l \left( l + 1 \right)}{r^{2}} \right] + V(r) \right \rbrace R_{El} = E R_{El},
\end{align*}

as

\begin{align*}
\left \lbrace - \dfrac{\hbar^{2}}{2 \mu} \left[ r^{-1} D_{r}^{2} r - r^{-2} l \left( l + 1 \right) \right] + V(r) \right \rbrace R_{El} = E R_{El}.
\end{align*}

With ansatz \(R_{El} = r^{-1} U_{El}\) life is ridiculously simple:

\begin{align*}
\left \lbrace - \dfrac{\hbar^{2}}{2 \mu} \left[ D_{r}^{2} - r^{-2} l \left( l + 1 \right) \right] + V(r) \right \rbrace U_{El} = E U_{El}.
\end{align*}

Rearrangement furnishes:

\begin{align*}
\left \lbrace D_{r}^{2} + \dfrac{2 \mu}{\hbar^{2}} \left[ E - V(r) - \dfrac{l \left( l + 1 \right) \hbar^{2}}{2 \mu r^{2}} \right] \right \rbrace U_{El} = 0.
\end{align*}

** SOLVED Problem 12.6.3
CLOSED: [2022-11-08 Tue 05:34]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 03:31]--[2022-11-08 Tue 05:34] =>  2:03
:END:
*Show that* \(\text{Eq.} (12.6.7\text{b})\) *follows from* \(\text{Eq.}(12.6.7\text{a})\).

Start with the /requirement/

\begin{align*}
\int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) \thinspace dr = \left[ \int_{0}^{\infty} U_{2}^{\ast} \left( D_{l} U_{1} \right) \thinspace dr \right]^{\ast} \equiv \int_{0}^{\infty} \left( D_{l} U_{1} \right)^{\ast} U_{2} \thinspace dr.
\end{align*}

Write

\begin{align*}
I \equiv \int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) \thinspace dr.
\end{align*}

Take adjoint of both sides

\begin{align*}
I^{\ast} = \int_{0}^{\infty} \left( D_{l} U_{2}^{\ast} \right) U_{1} \thinspace dr.
\end{align*}

\begin{align*}
I^{\ast} &= \left[ U_{1} D_{l-1} U_{2}^{\ast} \right]_{0}^{\infty} - \int_{0}^{\infty} \left( D_{l-1} U_{2}^{\ast} \right) D U_{1} \thinspace dr \\
\end{align*}

Integrate by parts \(l-1\) more times to get

\begin{align*}
I^{\ast} &= \sum_{m = 0}^{l-1} \left( - 1 \right)^{m} \left[ U_{1} D_{m-1} U_{2}^{\ast} \right]_{0}^{\infty} - \int_{0}^{\infty} \left( U_{2}^{\ast} \right) D_{l} U_{1} \thinspace dr.
\end{align*}

Take adjoint of both sides

\begin{align*}
\int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) \thinspace dr &= \sum_{m = 0}^{l-1} \left( - 1 \right)^{m} \left[ D_{m} U_{2} U_{1}^{\ast}  \right]_{0}^{\infty} +
\left( -1 \right)^{l} \int_{0}^{\infty} \left( D_{l} U_{1} \right) U_{2}^{\ast} \thinspace dr.
\end{align*}

Rearrange

\begin{align*}
\int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) \thinspace dr - \left( -1 \right)^{l} \int_{0}^{\infty} \left( D_{l} U_{1} \right) U_{2}^{\ast} \thinspace dr &= \sum_{m = 0}^{l-1} \left( - 1 \right)^{m} \left[ D_{m} U_{2} U_{1}^{\ast}  \right]_{0}^{\infty}.
\end{align*}

Substitute the requirement to get

\begin{align*}
\left( 1 - \left( - 1 \right)^{l} \right) \int_{0}^{\infty} \left( D_{l} U_{1} \right) U_{2}^{\ast} \thinspace dr &= \sum_{m = 0}^{l-1} \left( - 1 \right)^{m} \left[ D_{m} U_{2} U_{1}^{\ast}  \right]_{0}^{\infty}.
\end{align*}

By a similar set steps, it is easily established

\begin{align*}
\left( 1 - \left( - 1 \right)^{l} \right) \int_{0}^{\infty} U_{1}^{\ast} \left( D_{l} U_{2} \right) \thinspace dr = \sum_{m=0}^{l-1} \left( -1 \right)^{m} \left[ U_{2}^{\ast} D_{m} U_{1} \right]_{0}^{\infty}.
\end{align*}

Obtain the difference:

\begin{align*}
\sum_{m = 0}^{l-1} \left( - 1 \right)^{m} \left[ D_{m} U_{2} U_{1}^{\ast}  - U_{2}^{\ast} D_{m} U_{1} \right]_{0}^{\infty} = 0.
\end{align*}

For \(m = 0\),

\begin{align*}
U_{1}^{\ast} U_{2} - U_{2}^{\ast} U_{1} = 0.
\end{align*}

For \(m = 1\),

\begin{align*}
U_{1}^{\ast} D U_{2} - U_{2}^{\ast} D U_{1} \Big \vert_{0}^{\infty} = 0.
\end{align*}

If this term vanishes, the rest of the terms in the series vanish as well. Now we wish to ascertain

\begin{align*}
U_{2}^{\ast} D U_{1} \stackrel{?}{=}  U_{2} D U_{1}^{\ast}.
\end{align*}

Of course it is, we just found that \(U_{1}^{\ast} U_{2}\) (\(m = 0\)) is Hermitian, as is \(D_{l}\). Therefore substitute \(U_{2}^{\ast} D U_{1} =  D U_{1}^{\ast} U_{2}\) in \(U_{1}^{\ast} D U_{2} - U_{2}^{\ast} D U_{1} \Big \vert_{0}^{\infty} = 0\) to obtain

\begin{align*}
U_{1}^{\ast} D U_{2} - U_{2} D U_{1}^{\ast} \Big \vert_{0}^{\infty} = 0.
\end{align*}

** SOLVED Problem 12.6.4
CLOSED: [2022-11-08 Tue 06:56]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 06:30]--[2022-11-08 Tue 06:56] =>  0:26
CLOCK: [2022-11-08 Tue 05:34]--[2022-11-08 Tue 06:07] =>  0:33
:END:
*(1)* *Show that*

\begin{equation*}
\delta^{3} \left( \vec{r} - \vec{r^{\prime}} \right) \equiv \delta \left( x - x^{\prime} \right) \delta \left( y - y^{\prime} \right) \delta \left( z - z^{\prime} \right) = \dfrac{1}{r^{2} \sin \theta} \delta \left( r - r^{\prime} \right) \delta \left( \theta - \theta^{\prime} \right) \delta \left( \phi - \phi^{\prime} \right).
\end{equation*}

*(consider a test function).*

Just note the change in the /measure/

\begin{align*}
\int dx \thinspace dy \thinspace dz \xrightarrow[\text{to spherical}]{\text{from rectangular}} \int r^{2} \thinspace \sin \theta \thinspace d r \thinspace d \theta \thinspace d \phi,
\end{align*}

and it is all but obvious that for some test function \(f(x,y,z)\) such that

\begin{align*}
f(x,y,z) \xrightarrow[]{\text{spherical}} f \left( r, \theta, \phi \right),
\end{align*}

\begin{align*}
f (x, y, z) &= \int dx \thinspace dy \thinspace dz \thinspace f \left( x, y, z \right) \delta \left( x - x^{\prime} \right) \delta \left( y - y^{\prime} \right) \delta \left( z - z^{\prime} \right) \\
&= \int r^{2} \thinspace \sin \theta \thinspace d r \thinspace d \theta \thinspace d \phi \thinspace f \left( r, \theta, \phi \right) \thinspace \dfrac{1}{r^{2} \sin \theta} \delta \left( r - r^{\prime} \right) \delta \left( \theta - \theta^{\prime} \right) \delta \left( \phi - \phi^{\prime} \right) \\
&= \int d r \thinspace d \theta \thinspace d \phi \thinspace f \left( r, \theta, \phi \right) \thinspace \delta \left( r - r^{\prime} \right) \delta \left( \theta - \theta^{\prime} \right) \delta \left( \phi - \phi^{\prime} \right) \\
&= f \left( r, \theta, \phi \right).
\end{align*}

*(2)* *Show that*

\begin{equation*}
\nabla^{2} \left( 1/r \right) = - 4 \pi \delta^{3} \left( \vec{r} \right).
\end{equation*}

*(* /Hint:/ *First show that* \(\nabla^{2}(1/r) = 0\) *if* \(r \neq 0\). *To see what happens at* \(r = 0\), *consider a small sphere centered at the origin and use Gauss's law and the identity* \(\nabla^{2} \phi = \nabla \cdot \nabla \phi\) *).*

\begin{align*}
\nabla^{2} (1/r) = \left[ r^{-1} \partial_{r}^{2} \thinspace r \dfrac{1}{r} \right] = \left[ r^{-1} \partial_{r}^{2} \thinspace \right] = 0, \qquad r \neq 0.
\end{align*}

\begin{align*}
\int \nabla^{2} \left( 1/r \right) &= \iiint_{V} \nabla \cdot \nabla \left( 1/r \right) \thinspace d V\\
&= - \iint_{S} r^{2} \thinspace d \vec{\Omega} \cdot \thinspace \nabla \left( 1/r \right) \\
&= -\iint_{S} r^{2} \thinspace d \Omega \thinspace r^{-2} = \iint_{S} d \Omega = - 4 \pi.
\end{align*}

In the second step. we have used the /divergence theorem/. We thus have

\begin{align*}
\nabla^{2} \left( 1/r \right) = - 4 \pi \delta^{3} \left( \vec{r} \right).
\end{align*}

** SOLVED Problem 12.6.5
CLOSED: [2022-11-08 Tue 08:55]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 08:44]--[2022-11-08 Tue 08:55] =>  0:11
CLOCK: [2022-11-08 Tue 07:31]--[2022-11-08 Tue 08:28] =>  0:57
:END:
*Show that* \(D_{l}\) *is nondegenerate in the space of functions* \(U\) *that vanish as* \(r \to 0\). *(Recall the proof of Theorem 15, Section 5.6) Note that* \(U_{El}\) *is nondegenerate even for* \(E > 0\). *This means that* \(E\), \(l\), *and* \(m\), *label a state fully in three dimensions.*

\begin{align*}
D_{l} \left( r \right) \equiv \left[ - \dfrac{\hbar^{2}}{2 \mu} D_{r}^{2} + V(r) + \dfrac{l \left( l + 1 \right) \hbar^{2}}{2 \mu r^{2}} \right].
\end{align*}

To show that \(D_{l}\) is non-degenrate in the space of functions \(U\) that vanish as \(r \to 0\), we need show

\begin{align*}
D_{l} U_{El} = \lambda_{El} U_{El}, \quad D_{l} U_{El^{\prime}} = \lambda_{El} U_{El^{\prime}}, \quad \Longrightarrow U_{El} \sim U_{El^{\prime}},
\end{align*}

so let's show it. Multiply the first equation with \(U_{El^{\prime}}\), the second with \(U_{El}\) and take the difference:

\begin{align*}
\dfrac{\hbar^{2}}{2 \mu} \left[ U_{l^{\prime}} D_{r}^{2} U_{l} - U_{l} D_{r}^{2} U_{l^{\prime}} \right] + \left( V(r) + \dfrac{l \left( l + 1 \right) \hbar^{2}}{2 \mu r^{2}}  \right) \left[ U_{El} U_{El^{\prime}} - U_{El^{\prime}} U_{El} \right] = 0
\end{align*}

For bound states, \(E < 0\) as \(r \to \infty\), \(U_{El^{\prime}} \to 0\) and \(U_{El} \to 0\) so the equation reduces to


\begin{align*}
\left( U_{El^{\prime}} D_{r}^{2} U_{El} - U_{El} D_{r}^{2} U_{El^{\prime}} \right) = D_{r} \left( U_{El^{\prime}} D_{r} U_{El} - U_{El} D_{r} U_{El^{\prime}} \right) = 0,
\end{align*}

and we get

\begin{align*}
U_{El^{\prime}} D_{r} U_{El} - U_{El} D_{r} U_{El^{\prime}} = C,
\end{align*}

where \(C\) is a matrix of constants. In a space where \(U\) vanishes as \(r \to 0\), the limit of the equation above necessitates

\begin{align*}
C = \mathbf{0} \Longrightarrow U_{El^{\prime}} D_{r} U_{El} = U_{El} D_{r} U_{El^{\prime}}.
\end{align*}

Let's now descend to coordinate space to write

\begin{align*}
U_{El^{\prime}} (r) \dfrac{d}{dr} U_{El} (r) = U_{El} (r) \dfrac{d}{dr} U_{El^{\prime}} \left( r \right),
\end{align*}

separate variables,

\begin{align*}
\dfrac{1}{U_{El}(r)} \dfrac{d}{dr} U_{El}(r) = \dfrac{1}{U_{El^{\prime}}(r)} \dfrac{d}{dr} U_{El^{\prime}}(r),
\end{align*}

and solve to furnish

\begin{align*}
\ln U_{El} \left( r \right) = \ln U_{El^{\prime}} \left( r \right) + d \quad \text{\text{\(d\) is a constant}}, \quad E < 0.
\end{align*}

Alternatively

\begin{align*}
U_{El} \left( r \right) = \exp \left \lbrace d  \right \rbrace U_{El^{\prime}} \left( r \right) \qquad E < 0.
\end{align*}

Ascend back now to Hilbert space and write

\begin{align*}
U_{El^{\prime}} = \exp \left \lbrace - d  \right \rbrace U_{El} \sim U_{El} \qquad E < 0.
\end{align*}

This completes our demonstration of

\begin{align*}
D_{l} U_{El^{\prime}} = \lambda_{El} U_{El^{\prime}}, \quad D_{l} U_{El} = \lambda_{El} U_{El}, \quad \Longrightarrow U_{El^{\prime}} \sim U_{El}, \qquad \text{for} \quad E < 0.
\end{align*}

** SOLVED Problem 12.6.6
CLOSED: [2022-11-08 Tue 14:06]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 13:41]--[2022-11-08 Tue 14:06] =>  0:25
:END:
*(1) Verify that* \(\text{Eqs.} (12.6.21)\) *and* \((12.6.22)\) *are equivalent to* \(\text{Eq.} (12.6.20)\).

We need to show

\begin{align*}
d_{l} = D_{\rho} + \dfrac{l + 1}{\rho},
\end{align*}

and its adjoint

\begin{align*}
d_{l}^{\dagger} = - D_{\rho} + \dfrac{l + 1}{\rho},
\end{align*}

in the expression

\begin{align*}
\left( d_{l} \thinspace d_{l}^{\dagger} \right) U_{l} = U_{l},
\end{align*}

are equivalent to

\begin{align*}
\left[ - D^{2}_{\rho} + \dfrac{l \left( l + 1 \right)}{\rho^{2}} \right] U_{l} = U_{l}.
\end{align*}

Then just form the product \(d_{l} d_{l}^{\dagger}\)

\begin{align*}
\left( D_{\rho} + \dfrac{l + 1}{\rho} \right) \left( - D_{\rho} + \dfrac{l + 1}{\rho} \right) &= - D_{\rho}^{2} - \dfrac{(l+1)}{\rho^{2}} - \dfrac{(l+1)}{\rho} D_{\rho} + \dfrac{\left( l + 1 \right)^2}{\rho^{2}} + \dfrac{\left( l + 1 \right)}{\rho} D_{\rho} \\
&=- D_{\rho}^{2} + \dfrac{\left( l + 1 \right)^{2} - \left( l + 1 \right)}{\rho^{2}} = - D_{\rho}^{2} + \dfrac{l \left( l + 1 \right)}{\rho^{2}}.
\end{align*}

*(2) Verify* \(\text{Eq.} (12.6.24)\).
** SOLVED Problem 12.6.7
CLOSED: [2022-11-08 Tue 14:24]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 14:06]--[2022-11-08 Tue 14:24] =>  0:18
:END:
*Verify that* \(j_{0}\) *and* \(j_{1}\) *have the limits given by* \(\text{Eq.} (12.6.33)\).

\begin{align*}
j_{0} \left( \rho \right) = \dfrac{\sin \rho}{\rho}, \quad \text{and} \quad j_{1} \left( \rho \right) = \dfrac{\sin \rho}{\rho^{2}} - \dfrac{\cos \rho}{\rho}.
\end{align*}

We need to verify the limit

\begin{align*}
j_{l} \left( \rho \right) \xrightarrow[?]{\rho \to 0} \dfrac{\rho^{l}}{\left( 2l + 1 \right)!!},
\end{align*}

for \(j_{0}\) and \(j_{1}\), i.e.,

\begin{align*}
j_{0} \left( \rho \right) \xrightarrow[?]{\rho \to 0} \dfrac{\rho^{0}}{1!!}, \quad \text{and} \quad j_{1} \left( \rho \right) \xrightarrow[?]{\rho \to 0} \dfrac{\rho^{1}}{3!!}.
\end{align*}

What are the leading terms?

\begin{align*}
j_{0} \sim \dfrac{\rho^{0}}{1!} - \dfrac{\rho^{2}}{3!} \dotso \quad \text{and} \quad j_{1} \sim \dfrac{3! \times \rho - 2! \times \rho}{3! 2!}.
\end{align*}

Hence verified.

** SOLVED Problem 12.6.8
CLOSED: [2022-11-08 Tue 15:06]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 14:37]--[2022-11-08 Tue 15:06] =>  0:29
:END:
*Find the energy levels of a particle in a spherical box of radius* \(r_{0}\) *in the* \(l = 0\) *sector.*

The ansatz is /assumed/ to be of the form \(U_{E0} \left( r \right) Y_{0}^{m} \left( \theta, \phi \right)/r\) and the ODE for \(U_{El}\) is

\begin{align*}
\left( d_{0} d_{0}^{\dagger} \right) U_{l} = U_{l}, \quad \text{where} \quad d_{0} = D_{\rho} + \dfrac{1}{\rho} \quad \text{and} \quad d_{0}^{\dagger} = - D_{\rho} + \dfrac{1}{\rho}.
\end{align*}

The solutions are

\begin{align*}
U_{0}^{A} \left( \rho \right) = \sin r, \qquad U_{0}^{B} = - \cos r.
\end{align*}

We are not going to consider \(U_{0}^{B}\), they misbehave: \(U_{0}^{B}\) does /not/ tend to \(0\) as \(r \to 0\). With \(U_{0}^{A} = \sin r\),

\begin{align*}
\psi_{E0} = \left(\dfrac{\sin r}{r} \right) Y_{0}^{m} \left( \theta, \phi \right) \equiv j_{0} \left( r /k \right) Y_{0}^{m}, \qquad E = \dfrac{\hbar^{2} k^{2}}{2 \mu}.
\end{align*}

Now just demand the Bessel function \(j_{0} \left( k r\right)\) to coincide one of it's nodes with \(k r_{0}\), i.e., \(j_{0} \left( k r_{0}\right) = \sin k r_{0}/ k r_{0} = 0\) at \(r = k r_{0}\). We need

\begin{align*}
k r_{0} = n \pi \quad \text{with} \quad  n = 1, \thinspace, 2, \thinspace 3, \thinspace \dotso
\end{align*}

The quantization of \(E\) emerges from /boundary conditions/. Solve for \(k\) and feed in the expression for energy obtained earlier to get:

\begin{align*}
E = \dfrac{\hbar^{2} \pi^{2} n^{2} }{2 \mu r_{0}^{2}}, \quad \text{with} \quad n = 1, \thinspace, 2, \thinspace 3, \thinspace \dotso
\end{align*}

** SOLVED Problem 12.6.9
CLOSED: [2022-11-08 Tue 16:24]
:LOGBOOK:
CLOCK: [2022-11-08 Tue 15:06]--[2022-11-08 Tue 16:24] =>  1:18
:END:
*Show that the quantization condition for* \(l=0\) *bound states in a spherical well of depth* \(-V_{0}\) *and radius* \(r_{0}\) *is*

\begin{align*}
k^{\prime} / \kappa = - \tan k^{\prime} r_{0}.
\end{align*}

*where* \(k^{\prime}\) *is the wave number inside the well and* \(i \kappa\) *is the complex wave number for the exponential tail outside. Show that there are no bound states for* \(V_{0} < \pi^{2} \hbar^{2}/ 8 \mu r_{0}^{2}\). *(Recall* =Execise 5.2.6= *.)*

The wave function bleeds out (the well being finite), so we'll need to consider the region inside the well and outside the well separately. The solutions are

\begin{align*}
\psi_{E,0,m} \left( r < r_{0}, \theta, \phi \right) = A j_{0} \left( r k^{\prime} \right) Y_{0}^{m}, \qquad E - V_{0} = \dfrac{\hbar^{2} k^{\prime}^{2}}{2 \mu}.
\end{align*}

and

\begin{align*}
\psi_{E,0,m} \left( r > r_{0}, \theta, \phi \right) = B \exp \left \lbrace - \kappa r  \right \rbrace/r \qquad E = \dfrac{\hbar^{2} \kappa^2}{2 \mu}.
\end{align*}

The quantization of \(E\) emerges from /continuity conditions/ at \(r = k^{\prime} r_{0}\), which are

\begin{align*}
A \sin \left( k^{\prime} r_{0} \right) = B \exp \left \lbrace - \kappa r_{0}  \right \rbrace,
\end{align*}

\begin{align*}
A k^{\prime} \cos \left( k^{\prime} r_{0} \right) = - B \kappa \exp \left \lbrace - \kappa r_{0}  \right \rbrace.
\end{align*}

You know what to do, furnish that transcendental:


\begin{align*}
\tan (k^{\prime} r_{0}) &= - \dfrac{k^{\prime}}{\kappa} = - k^{\prime} r_{0} \left [ \dfrac{r_{0}}{\hbar} \left ( 2 \mu (-E) \right)^{1/2} \right ]^{-1} \\
&= - k^{\prime} r_{0} \left [ \left( \dfrac{r_{0}^{2}}{\hbar^{2}} 2 \mu V_{0}-(k^{\prime} r_{0})^{2} \right )^{1/2} \right ]^{-1} \\
&\equiv - k^{\prime} r_{0} \left [ \left ( \zeta^{2} - k^{\prime} r_{0}^{2} \right)^{1/2} \right ]^{-1}, \quad 0 \leq k^{\prime} r_{0} \leq \zeta, \quad \tan (k^{\prime} r_{0}) \leq 0.
\end{align*}

\begin{align*}
\tan (k^{\prime} r_{0}) = \dfrac{\kappa}{k^{\prime}} &=  (k^{\prime} r_{0})^{-1} \left [ \dfrac{r_{0}}{\hbar} \left ( 2 \mu (-E) \right)^{1/2} \right ] \\
&= (k^{\prime} r_{0})^{-1} \left [ \left( \dfrac{a^{2}}{\hbar^{2}} 2 \mu V_{0}-(k^{\prime} r_{0})^{2} \right )^{1/2} \right ] \\
&\equiv (k^{\prime} r_{0})^{-1} \left [ \left ( \zeta^{2} - k^{\prime} r_{0}^{2} \right)^{1/2} \right ], \quad 0 \leq k^{\prime} r_{0} \leq \zeta, \quad \tan (k^{\prime} r_{0}) \geq 0.
\end{align*}

where

\begin{align*}
\zeta = \dfrac{r_{0}}{\hbar} \sqrt{2 \mu V_{0}}.
\end{align*}

At least one bound state with *odd symmetry* exists if and only if \(\zeta^{2} > \dfrac{\pi^{2}}{4}\). For \(\zeta^{2} \leq \dfrac{\pi^{2}}{4}\), there are no bound states with odd symmetry. This is same as the condition demanded by the ask: substitute \(\zeta = \dfrac{r_{0}}{\hbar} \sqrt{2 \mu V_{0}}\) in \(\zeta^{2} \leq \dfrac{\pi^{2}}{4}\) to obtain \(V_{0} \leq \pi^{2} \hbar^{2}/ 8 \mu r_{0}^{2}\).
** TOSOLVE Problem 12.6.10                                        
:LOGBOOK:
CLOCK: [2022-11-08 Tue 16:49]--[2022-11-08 Tue 17:00] =>  0:11
CLOCK: [2022-11-08 Tue 16:45]--[2022-11-08 Tue 16:45] =>  0:00
:END:
*(Optional).* *Verify* \(\text{Eq.} (12.6.41)\) *given that*

*(1)* \(\int_{-1}^{1} P_{l} \left( \cos \theta \right) P_{l^{\prime}} \left( \cos \theta \right) d \left( \cos \theta \right) = \left[ 2/(2l + 1) \right] \delta_{ll^{\prime}}\)

*(2)* \(P_{l}(x) = \frac{1}{2^{l} l!} D_{x}^{l} \left( x^{2} - 1 \right)^{l}\),

*(3)* \(\int_{0}^{1} \left( 1 - x^{2} \right)^{m} dx = \dfrac{(2m)!!}{(2m + 1)!!}\)

/Hint:/ *Consider the limit* \(kr \to 0\) *after projecting out* \(C_{l}\).

We need to verify

\begin{align*}
\exp \left \lbrace i k r \cos \theta  \right \rbrace = \sum_{l = 0}^{\infty} i^{l} \left( 2l + 1 \right) j_{l} \left( k r \right) P_{l} \left( \cos \theta \right).
\end{align*}

** TOSOLVE Problem 12.6.11                                        
*(1)* *By combining* \(\text{Eqs.} (12.6.48)\) *and* \(\text{Eqs.}(12.6.9)\) *derive the two-term recursion relation. Argue that* \(C_{0} \neq 0\) *if* \(U\) *is to have the right properties near* \(y=0\). *Derive the quantizations condition,* \(\text{Eq.}(12.6.50)\).

*(2)* *Calculate the degeneracy and parity at each* \(n\) *and compare with* =Exercise 10.2.3=, *where the problem was solved in Cartesian coordinates.*

*(3)* *Construct the normalized eigenfunction* \(\psi_{nlm}\) *for* \(n = 0\) *and* \(1\). *Write them as linear combinations of the* \(n=0\) *and* \(n=1\) *eigenfunctions obtained in Cartesian coordinates.*
* The Hydrogen Atom
CLOSED: [2022-11-10 Thu 17:47]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 12:52]--[2022-11-09 Wed 13:15] =>  0:23
CLOCK: [2022-11-09 Wed 12:39]--[2022-11-09 Wed 12:40] =>  0:01
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-26 Sat 15:49]--[2022-11-26 Sat 18:54] =>  3:05
:END:
*** The eigenvalue problem
/Setup/: A two-body problem of an electron of charge \(-e\) and mass \(m\) and a proton of charge \(+e\) and mass \(M\). Using Jacobi coordinates we reduce the problem to the dynamics of a single /reduced mass/ \(\mu\):

\begin{align*}
\mu = \dfrac{m M}{m + M}.
\end{align*}

with coordinate \(\vec{r} = \vec{r}_{e}- \vec{r}_{p}\). To start with /assume/ \(M \to \infty\) so that the electron is moving in the field of the immobile proton. The potential energy of the electron in the Coulomb potential

\begin{align*}
\phi = \dfrac{e}{r},
\end{align*}

due to the proton is

\begin{align*}
V = -\dfrac{e^{2}}{r}.
\end{align*}

The Schrodinger equation is:

\begin{align*}
\left \lbrace D_{r}^{2} + \dfrac{2m}{\hbar^{2}} \left[ E + \dfrac{e^{2}}{r} - \dfrac{l \left( l + 1 \right) \hbar^2}{2 m r^{2}} \right]  \right \rbrace U_{El} = 0.
\end{align*}

The wavefunctions are:

\begin{align*}
\psi_{Elm} \left( r, \theta, \phi \right) = R_{El} \left( r \right) Y_{l}^{m} \left( \theta, \phi \right) = \dfrac{U_{El} (r)}{r} Y_{l}^{m} \left( \theta, \phi \right).
\end{align*}

We are looking for bound states so:

\begin{align*}
U_{El} \sim \exp \left \lbrace - \left( \dfrac{2 m W}{\hbar^{2}} \right)^{1/2} r \right \rbrace \quad \text{as} \quad r \to \infty, \quad \text{where} \quad W = - E.
\end{align*}

\(W\) is the /binding energy/ (which is the energy it would take to liberate the electron) and:

\begin{align*}
U_{El} \sim r^{l+1} \qquad r \to 0.
\end{align*}

With an auxiliary function \(v_{El}\) and 

\begin{align*}
\rho \equiv \left( \dfrac{2 m W}{\hbar^{2}} \right)^{1/2} r
\end{align*}

\begin{align*}
U_{El} = \exp \left \lbrace - \rho  \right \rbrace v_{El}.
\end{align*}

Feeding to the Schrodinger equation:

\begin{align*}
D_{\rho}^{2} v - 2 D_{\rho} v + \left[ \dfrac{e^{2} \lambda}{\rho} - \dfrac{l \left( l + 1 \right)}{\rho^{2}} \right] v = 0 \quad \text{where} \quad \lambda = \left(\dfrac{2 m}{\hbar^{2} W}\right)^{1/2}.
\end{align*}

Feed the ansatz

\begin{align*}
v_{El} = \rho^{l+1} \sum_{k=0}^{\infty} C_{k} \rho^{k}
\end{align*}

to obtain the recurrence:

\begin{align*}
C_{k+1} = \dfrac{-e^{2} \lambda + 2 \left( k + l + 1 \right)}{\left( k + l + 2 \right) \left( k + l + 1 \right)- l \left( l + 1 \right)} C_{k}.
\end{align*}
*** The energy levels
We can't let

\begin{align*}
v_{El} = \rho^{l+1} \sum_{k=0}^{\infty} C_{k} \rho^{k}
\end{align*}

unroll forever via

\begin{align*}
C_{k+1} = \dfrac{-e^{2} \lambda + 2 \left( k + l + 1 \right)}{\left( k + l + 2 \right) \left( k + l + 1 \right)- l \left( l + 1 \right)} C_{k}.
\end{align*}

Remember \(\exp \left \lbrace - \rho  \right \rbrace\) can only kill /finite/ positive powers of \(\rho\)? We have to ask it to fold over somewhere; ask for a vanishing numerator:

\begin{align*}
e^{2} \lambda = 2 \left( k + l + 1 \right) \Longrightarrow E = - W = \dfrac{- m e^{4}}{2 \hbar^{2} \left( k + l + 1 \right)^{2}}, \quad k = 0, \thinspace 1, \thinspace 2, \dotso: l = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

Define the /principal quantum number/

\begin{align*}
n \equiv k + l + 1.
\end{align*}

The energy levels are:

\begin{align*}
E_{n} = \dfrac{- m e^{4}}{2 \hbar^{2} n^{2}}, \quad n = 1, \thinspace 2, \thinspace 3, \dotso.
\end{align*}

For each value of \(n\), \(l\) will hop over:

\begin{align*}
l = n - k - 1 = n - 1, \thinspace n - 2, \thinspace \dotso, 1 , 0.
\end{align*}

Isn't that strange? What this means is that the eigenkets of \(H\) in the  \(n-1\) irreducible invariant subspaces \(\mathbb{V}_{l} \quad l = 0, \thinspace 1, \thinspace \dotso, n -1\) in the Hilbert space of total angular momentum vectors are degenerate and have the eigenvalue \(E_{n}\). Note that this is different from the eigenkets of \(H\) being degenerate /within/ such a subspace which is a consequence of rotational invariance (\(\left[ H, \vec{L} \right] = 0\)). \(H\) /must contain more symmetries besides rotational invariance./ The degeneracy at each \(n\) is (a pass over all of these subspaces \(\mathbb{V}_{l}\), each of which hold \(2l + 1\) eigenkets of \(H\)):

\begin{align*}
\sum_{l=0}^{n-1} \left( 2l + 1 \right) = n^{2}.
\end{align*}

A natural unit of energy called a /Rydberg/ \((\text{Ry})\), for measuring the energy levels of hydrogen:

\begin{align*}
\text{Ry} = \dfrac{m e^{4}}{2 \hbar^{2}}.
\end{align*}

The energy levels in this unit are:

\begin{align*}
E_{n} = - \dfrac{\text{Ry}}{n^{2}}.
\end{align*}

*** The wavefunctions
Consider a given \(n\) and \(l\). \(v_{l}\) is \(\rho^{l+1}\) times a polynomial of degree \(n-l-1\). This polynomial is called the /associated Laguerre polynomial/, \(L_{n-l-1}^{2l+1} \left( 2 \rho \right)\) which satisfy:

\begin{align*}
L_{p}^{k} \left( x \right) = \left( -1 \right)^{k} D_{x}^{k} L_{p+k}^{0}, \qquad L_{p}^{0} = \exp \left \lbrace x  \right \rbrace D_{x}^{p} \left(\exp \left \lbrace -x  \right \rbrace x^{p} \right).
\end{align*}

The corresponding radial function is:

\begin{align*}
R_{nl} \left( \rho \right) \sim \rho^{l} \exp \left \lbrace - \rho  \right \rbrace L_{n-l-1}^{2l+1} \left( 2 \rho \right).
\end{align*}

Now

\begin{align*}
\rho \equiv r \left( \dfrac{2 m W}{\hbar^{2}} \right)^{1/2} = r \left[ \dfrac{2m}{\hbar^{2}} \cdot \left( \dfrac{me^{4}}{2 \hbar^{2} n^{2}} \right) \right]^{1/2} = \left( \dfrac{me^{2}}{\hbar^{2}} \right) \dfrac{r}{n}.
\end{align*}

Defining the /Bohr radius/

\begin{align*}
a_{0} \equiv \dfrac{\hbar^{2}}{m e^{2}}
\end{align*}

\begin{align*}
R_{nl} \left( r \right) \sim \left( \dfrac{r}{n a_{0}} \right)^{l} \exp \left \lbrace - \dfrac{r}{n a_{0}}  \right \rbrace L_{n-l-1}^{2l+1} \left( \dfrac{2r}{n a_{0}} \right).
\end{align*}

/The Bohr radius provides a natural length scale for the hydrogen atom./ Consider the state described by:

\begin{align*}
\psi_{n, n-1, m} \propto r^{n-1} \exp \left \lbrace - \dfrac{r}{n a_{0}}  \right \rbrace Y_{n-1}^{m} \left( \theta, \phi \right).
\end{align*}

What is the probability of finding the electron in a spherical shell of radius \(r\) and thickness \(dr\)?

\begin{align*}
\int_{\Omega} P \left( \vec{r} \right) r^{2} \thinspace dr \thinspace d \Omega \propto \exp \left \lbrace - \dfrac{2r}{n a_{0}}  \right \rbrace r^{2n} dr
\end{align*}

The mode is found by demanding:

\begin{align*}
D_{r} \left( \exp \left \lbrace - \dfrac{2r}{n a_{0}}  \right \rbrace r^{2n} \right) = 0 \Longrightarrow r_{\text{max}} = n^{2} a_{0}.
\end{align*}

When \(n=1\), \(r_{\text{max}} = a_{0}\). Thus the Bohr radius gives the most probable value of \(r\) in the ground state. For \(l = n -1\), and \(n > 1\) the radial function grows as \(n^{2}\). For \(l \neq n - 1\), the radial function has \(n - l - 1\) zeros and the density in \(r\) has several bumps. In this case, a expectation value \(\left \langle r  \right \rangle_{nlm}\) characterizes the electron's whereabouts. Using the properties of the Laguerre polynomials \(L_{n-l-1}^{2l+1}\)

\begin{align*}
\left \langle r  \right \rangle_{nlm} = \dfrac{a_{0}}{2} \left[ 3 n^{2} - l \left( l + 1 \right) \right].
\end{align*}

Tack on a spherical harmonic to \(R_{nl} \left( r \right)\) and normalize to get a honest to god (approximate, there is a zoo of corrections coming up, hang tight) hydrogen wavefunction. For \(r \to \infty\) \(L\) is dominated by the highest power, \(r^{n-l-1}\) and

\begin{align*}
R_{nl} \sim r^{n-1} \exp \left \lbrace - \dfrac{r}{n a_{0}}  \right \rbrace \qquad \text{as } r \to \infty.
\end{align*}

For the ``maximum angular momentum" state \(l = n-1\) for a given \(n\), the form above is valid for /all/ \(r\) since \(L_{0}^{2l+1}\) is a constant. The first few normalized eigenfunctions \(\psi_{Elm} \equiv \psi_{nlm}\) are:

\begin{align*}
\psi_{1,0,0} = \left( \dfrac{1}{\pi a_{0}^{3}} \right)^{1/2} \exp \left \lbrace - \dfrac{r}{a_{0}}  \right \rbrace,
\end{align*}

\begin{align*}
\psi_{2,0,0} = \left( \dfrac{1}{32 \pi a_{0}^{3}} \right)^{1/2} \left( 2 - \dfrac{r}{a_{0}} \right) \exp \left \lbrace - \dfrac{r}{2 a_{0}}  \right \rbrace,
\end{align*}

\begin{align*}
\psi_{2,1,0} = \left( \dfrac{1}{32 \pi a_{0}^{3}} \right)^{1/2} \dfrac{r}{a_{0}} \exp \left \lbrace - \dfrac{r}{2 a_{0}}  \right \rbrace \cos \theta,
\end{align*}

\begin{align*}
\psi_{2,1,\pm 1} = \mp \left( \dfrac{1}{64 \pi a_{0}^{3}} \right)^{1/2} \dfrac{r}{a_{0}} \exp \left \lbrace - \dfrac{r}{2 a_{0}}  \right \rbrace \sin \theta \exp \left \lbrace \pm i \phi \right \rbrace.
\end{align*}
*** Degeneracy of hydrogen spectrum
The Hydrogen atom Hamiltonian has other symmetries besides rotational invariance. The symmetries of \(H\) imply the conservation of the generators of the symmetries. Consequently, if there is an extra symmetry (besides rotational invariance) there must be some extra conserved quantities (besides angular momentum). This quantity is the quantum analogue \(\vec{N}\) of the /Runge-Lenz vector/

\begin{align*}
\vec{n} \equiv \dfrac{\vec{p} \times \vec{l}}{m} - \dfrac{e^{2}}{r} \vec{r}
\end{align*}

which in classical mechanics is a conserved quantity for the motion of a mass in a Coulomb potential. The conservation of \(\vec{n}\) implies that not only is the orbit confined to a plane perpendicular to \(\vec{l}\) (as in any rotationally invariant problem) it is also /closed/. \(\vec{N}\) is

\begin{align*}
\vec{N} \equiv \dfrac{1}{2m} \left[ \vec{P} \times \vec{L} - \vec{L} \times \vec{P} \right] - \dfrac{e^{2} \vec{R}}{\left( X^{2} + Y^{2} + Z^{2} \right)^{1/2}},
\end{align*}

and we have

\begin{align*}
\left[ \vec{N}, H \right] = 0.
\end{align*}

The conservation of \(\vec{L}\) implies that \(\left[ L_{\pm}, H \right] = 0\), which means it is possible to raise and lower the \(m\) values at a given \(l\) without changing the energy. Similarly, the conservation of \(\vec{N}\) implies that \(\left[ N_{\pm}, H \right] = 0\) which means it is possible to raise and lower the \(l\) values at a given \(n\) without changing the energy. We will construct \(N_{\pm}\) later.
*** Numerical estimates
\begin{align*}
m c^{2} \text{ (rest energy of electron)} \simeq 0.5 \text{ M eV}
\end{align*}

\begin{align*}
Mc^{2} \text{ (rest energy of proton)} \simeq 1000 \text{ M eV}
\end{align*}

\begin{align*}
\dfrac{m}{M} \text{ (ratio of electron mass to proton mass)} \simeq \dfrac{1}{2000}
\end{align*}

\begin{align*}
\hbar \text{ (Planck's constant)} = 1.054 \times 10^{-27} \text{erg sec}
\end{align*}

\begin{align*}
\hbar c \text{ (totally dope thing to remember)} \simeq 2000 \text{ eV \textup{\AA}}
\end{align*}

\begin{align*}
\alpha \thinspace \text{(fine structure constant)} = \dfrac{e^{2}}{\hbar c} \simeq \dfrac{1}{137}
\end{align*}

\begin{align*}
a_{0} \text{ (Bohr radius)} \simeq \dfrac{\hbar^{2}}{m e^{2}} = \dfrac{\hbar c}{m c^{2}} \left( \dfrac{\hbar c}{e^{2}} \right) = \dfrac{\left( 2000 \right) \left( 137 \right)}{0.5 \times 10^{6}} \textup{\AA} \simeq 0.55 \textup{\AA}
\end{align*}

\begin{align*}
\text{Ry} \text{ (Unit of Energy)} &= \dfrac{me^{4}}{2 \hbar^{2}} = \dfrac{m c^{2}}{2} \left( \dfrac{e^{2}}{\hbar c} \right)^{2} \\
&= \dfrac{0.25 \times 10^{6}}{(137)^{2}} \text{ eV} \simeq 13.3 \text{ eV}.
\end{align*}

\begin{align*}
E_{n} \text{ (Energy)} = -\dfrac{me^4}{2 \hbar^{2}} \dfrac{1}{n^{2}} = -\dfrac{e^{2}}{2 a_{0}} \left( \dfrac{1}{n^{2}} \right) = \dfrac{-13.6}{n^{2}} \text{ eV}.
\end{align*}

The /Compton wavelength/ is the lower limit on how well a particle can be localized. In non-relativistic quantum mechanics this limit is \(0\). But in reality, as we try to localize the particle better and better, we use more and more energetic probes, say photons to be specific. To locate it to some \(\Delta X\), we need a photon of momentum

\begin{align*}
\Delta P \sim \dfrac{\hbar}{\Delta X}.
\end{align*}

Since the photon in massless, the corresponding energy is

\begin{align*}
\Delta E \sim \dfrac{\hbar c}{\Delta X},
\end{align*}

where we have used \(E^{2} = c^{2} p^{2} + m^{2} c^{4}\). We don't want this energy to exceed twice the rest energy of the particle because in that regime, relativity allows the production of a particle-antiparticle pair in the measurement process. So we demand:

\begin{align*}
\Delta E \lesssim 2 m c^{2} \Longrightarrow \dfrac{\hbar c}{\Delta X} \lesssim 2 m c^{2} \Longrightarrow \Delta X \gtrsim \dfrac{\hbar}{2 m c} \sim \dfrac{\hbar}{m c}.
\end{align*}

\begin{align*}
\lambda_{e} \text{ (Compton wavelength of electron)} &\equiv \dfrac{\hbar}{mc} = \dfrac{\hbar^{2}}{me^{2}} \centerdot \dfrac{e^{2}}{\hbar c} = a_{0} \alpha \\
&\simeq 0.5 \times \dfrac{1}{137} \textup{\AA} \simeq 4 \times 10^{-3} \textup{\AA}
\end{align*}

If we imagine the electron to be a spherical charge distribution, the Coulomb energy of the distribution (the energy it takes to assemble it) will be of the order \(e^{2}/r_{e}\), where \(r_{e}\) is the radius of the sphere. If we attribute the rest energy of the electron to this Coulomb energy, we arrive at the classical radius.

\begin{align*}
r_{e} \text{ (classical radius of the electron)} = \alpha \lambda_{e} = \dfrac{\hbar}{mc} \centerdot \dfrac{e^{2}}{\hbar c} = \dfrac{e^{2}}{m c^{2}} \simeq 3 \times 10^{-5} \textup{\AA}.
\end{align*}

#+begin_quote
*``In principle, one can measure the energy by simply weighing the atom."* - Ramamurthy Shankar.
#+end_quote

In practice, we measure /differences in energy/:
*** Predictions
The /emission spectrum/ will have frequency \(\omega_{n n^{\prime}}\) corresponding to a transition between energy levels \(n\) and \(n^{\prime}\):

\begin{align*}
\omega_{n n^{\prime}} = \dfrac{E_{n} - E_{n^{\prime}}}{\hbar} = \dfrac{\text{Ry}}{\hbar} \left( \dfrac{1}{n^{\prime}^{2}} - \dfrac{1}{n^{2}} \right).
\end{align*}

For a fixed value of \(n^{\prime} = 1, \thinspace 2, \thinspace 3, \dotso\), we obtain a family of lines as we vary \(n\). The \(n^{\prime} = 1\) family is called the /Lyman series/, the \(n^{\prime} = 2\) family is called the /Balmer series/, the \(n^{\prime} = 3\) family is called the /Paschen series/, etc.

On applying an external perturbation \(H^{1}\) for a short time \(\epsilon\), the system goes from \(\vert nlm \rangle\) to

\begin{align*}
\vert \psi \left( \epsilon \right) \rangle &= \left[ I - \dfrac{i \epsilon}{\hbar} \left( H^{0} + H^{1} \right) \right] \vert nlm \rangle \\
&= \vert nlm \rangle - \left( \dfrac{i \epsilon E_{n}}{\hbar} + \dfrac{i \epsilon H^{1}}{\hbar} \right) \vert nlm \rangle.
\end{align*}

The probability of it being in a state \(\vert n^{\prime} l^{\prime} m^{\prime} \rangle\) (assuming \(\vert n^{\prime} l^{\prime} m^{\prime} \rangle\) is different from \(\vert n l m \rangle\)) is:

\begin{align*}
\left \lvert \left \langle n^{\prime} l^{\prime} m^{\prime} \vert \psi \left( \epsilon \right)  \right \rangle  \right \rvert^{2} = \left \lvert - \dfrac{i \epsilon}{\hbar} \left \langle n^{\prime} l^{\prime} m^{\prime} \left \lvert H^{1}  \right \rvert nlm \right \rangle  \right \rvert^{2}.
\end{align*}

Thus the transition rate between states \(\vert nlm \rangle\) and \(\vert n^{\prime} l^{\prime} m^{\prime} \rangle\) is controlled by the matrix element \(\left \langle n^{\prime} l^{\prime} m^{\prime} \left \lvert H^{1}  \right \rvert nlm \right \rangle\), which is calculable by the prescriptions of quantum theory and act as testable predictions.

Our treatment of the Hydrogen atom is to the most part impressively accurate. There are however corrections:

1) the proton is /not/ immobile, this is a two-body problem. Simply replace \(m\) with \(\mu = mM/(m+M)\), the reduced mass.
2) the kinetic energy of the electron is not \(m v^{2}/2 = p^{2}/2m\) in Einstein's theory, but instead \(mc^{2} \left[ \left( 1 - \frac{v^{2}}{c^{2}} \right)^{-1/2} - 1 \right]\). This is a correction of order \(\alpha^{2}\).
3) there are other corrections of the order \(\alpha^{2}\) that go by the name of /fine-structure corrections/.
4) there are relativistic corrections to all orders in \(\alpha\) which the Dirac equation takes into account.
5) there are tiny corrections due to quantum fluctuations of the electromagnetic field which are taken into account by the theory of Quantum Eletrodynamics.

After all of these are taken into account, the match between theory and experiment is spectacular.
** SOLVED Problem 13.1.1
CLOSED: [2022-11-09 Wed 13:57]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 13:15]--[2022-11-09 Wed 13:57] =>  0:42
:END:
*Derive* \(\text{Eqs.}(13.1.11)\) *and* \((13.1.14)\) *starting from* \(\text{Eqs.}(13.1.8)-(13.1.10)\).

Start from:

\begin{align*}
\left \lbrace D^{2}_{\rho} - 2 D_\rho + \left[ \dfrac{e^{2} \lambda}{\rho} - \dfrac{l \left( l + 1 \right)}{\rho^{2}} \right] \right \rbrace v_{El} = 0, \quad \text{where} \quad \lambda = \left( 2m / \hbar^{2} W \right)^{1/2}.
\end{align*}

\begin{align*}
v_{El} = \rho^{l + 1} \sum_{k=0}^{\infty} C_{k} \rho^{k}.
\end{align*}

End at:

\begin{align*}
\dfrac{C_{k+1}}{C_{k}} = \dfrac{- e^{2} \lambda + 2 \left( k + l + 1 \right)}{\left( k + l + 2 \right) \left( k + l + 1 \right) - l \left( l + 1 \right)},
\end{align*}

\begin{align*}
E = - W = \dfrac{-m e^4}{2 \hbar^{2} \left( k + l + 1 \right)^{2}}, \qquad k = 0, \thinspace 1, \thinspace 2, \dotso : \quad l = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

Just feed it.

\begin{align*}
&\sum_{k=0}^{\infty} \left( l + k + 1 \right) \left( l + k \right) C_{k} \rho^{l + k - 1} \\
&- 2 \sum_{k=0}^{\infty} \left( l + k + 1 \right) C_{k} \rho^{l+k} + e^{2} \lambda \sum_{k=0}^{\infty} C_{k} \rho^{l + k} \\
&- l \left( l + 1 \right) \sum_{k=0}^{\infty} C_{k} \rho^{l + k - 1} = 0.
\end{align*}

Re-label indices, ferry some across the equality, and match coefficients:

\begin{align*}
C_{k+1} [ \left( l + k + 2 \right) \left( l + k + 1 \right) &- l \left( l + 1 \right) ] \\
&= \left[- e^{2} \lambda + 2 \left( l + k + 1 \right) \right] C_{k}.
\end{align*}

It follows:

\begin{align*}
\dfrac{C_{k+1}}{C_{k}} = \dfrac{- e^{2} \lambda + 2 \left( k + l + 1 \right)}{\left( k + l + 2 \right) \left( k + l + 1 \right) - l \left( l + 1 \right)}.
\end{align*}

Gotta truncate this series else \(\rho \to \infty\) limit of the wavefunction will be charged of misdemeanour so (as a multiplicative factor, a falling exponential can only kill /finite/ powers of its argument):

\begin{align*}
e^{2} \lambda = 2 \left( k + l + 1 \right).
\end{align*}

Solve \(\lambda = \left( 2m / \hbar^{2} W \right)^{1/2}\) for \(W\) to obtain:

\begin{align*}
W = \dfrac{2m}{\hbar^{2} \lambda^{2}},
\end{align*}

and substitute \(\lambda^{2} = 4 \left( k + l + 1 \right)^{2}/e^{4}\) to obtain

\begin{align*}
E = - W = \dfrac{-m e^4}{2 \hbar^{2} \left( k + l + 1 \right)^{2}}, \qquad k = 0, \thinspace 1, \thinspace 2, \dotso : \quad l = 0, \thinspace 1, \thinspace 2, \dotso.
\end{align*}

** SOLVED Problem 13.1.2
CLOSED: [2022-11-09 Wed 14:09]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 14:57]--[2022-11-09 Wed 14:09] => -1:12
:END:
*Derive the degeneracy formula,* \(\text{Eq.}(13.1.18)\).

The ask:

\begin{align*}
S_{n} = \sum_{l=0}^{n-1} \left( 2l + 1 \right) = n^{2}.
\end{align*}

Well,

\begin{align*}
2 S_{n}  &=  (0 + 0) +\dotso \left( k + 2n - 1 - k  \right) +\dotso \left(2n - 1 + 1\right) \\
&= n \left( 2n \right) = 2 n^{2} \Longrightarrow S_{n} = n^{2}.
\end{align*}

** SOLVED Problem 13.1.3
CLOSED: [2022-11-09 Wed 15:43]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 14:10]--[2022-11-09 Wed 15:43] =>  1:33
:END:
*Starting from the recursion relation, obtain* \(\psi_{210}\) *(normalized).*

Here it is:

\begin{align*}
\dfrac{C_{k+1}}{C_{k}} = \dfrac{- e^{2} \lambda + 2 \left( k + l + 1 \right)}{\left( k + l + 2 \right) \left( k + l + 1 \right) - l \left( l + 1 \right)}.
\end{align*}

By definition the /principal quantum number/ \(n\) is

\begin{align*}
n = \left( k + l + 1 \right),
\end{align*}

meaning the series truncates at \(C_{1}\). With \(C_{0} \equiv 1\),

\begin{align*}
U_{21} \left( \rho \right) \sim \exp \left \lbrace - \rho  \right \rbrace \rho^{2}
\end{align*}

Recall that \(\rho = \frac{m e^2}{\hbar^{2} n} r\), introduce the /Bohr radius/ \(a_{0} = \hbar^{2}/m e^{2}\) to rewrite:

\begin{align*}
U_{21} \left( r \right) \sim \left( \dfrac{1}{4a_{0}^{2}} \right) r^{2} \exp \left \lbrace -r/2a_{0}  \right \rbrace.
\end{align*}

I hope we are allowed to take

\begin{align*}
Y_{1}^{0} =  \left(\dfrac{3}{4 \pi}\right)^{1/2} \cos \theta
\end{align*}

as granted. Then

\begin{align*}
\psi_{210} \sim \thinspace r \thinspace \exp \left \lbrace -r / 2 a_{0}  \right \rbrace \cos \theta.
\end{align*}

Now for the normalization constant \(A\):

\begin{align*}
A = \left \lbrace \left[ \iiint \left \lvert \psi^{\prime}  \right \rvert^{2} \right]^{-1}  \right \rbrace^{1/2},
\end{align*}

where \(\psi^{\prime}\) is the un-normalized wavefunction.

\begin{align*}
\iiint \left \lvert \psi  \right \rvert^{2} &= \int_{0}^{2 \pi} d \phi \int_{0}^{\pi} \sin \theta d \theta \int_{0}^{\infty} r^{2} dr \thinspace \left[ r^{2} \exp \left \lbrace - r/ a_{0}  \right \rbrace \cos^{2} \theta \right] \\
&= \int_{0}^{2 \pi} d \phi \int_{0}^{\pi} \cos^{2} \theta \sin \theta d \theta \int_{0}^{\infty} r^{4} \exp \left \lbrace - r/ a_{0}  \right \rbrace \thinspace dr \\
& \xrightarrow[]{\int_{0}^{\infty} r^{4} \exp \left \lbrace -r / a_{0}  \right \rbrace dr = 24 a_{0}^{5}} 24 a_{0}^{5} \int_{0}^{2 \pi} d \phi \int_{0}^{\pi} \cos^{2} \theta \sin \theta d \theta \\
& \xrightarrow[]{\int_{0}^{\pi} d \theta \cos^{2} \theta \sin \theta = 2/3} 16 a_{0}^{5} \int_{0}^{2 \pi} d \phi = 32 \pi a_{0}^{5}.
\end{align*}

The normalized wave function is

\begin{align*}
\psi_{210} = \left( \dfrac{1}{32 \pi a_{0}^{3}} \right)^{1/2} \dfrac{r}{a_{0}} \exp \left \lbrace - r/ 2 a_{0}  \right \rbrace \cos \theta.
\end{align*}

** SOLVED Problem 13.1.4
CLOSED: [2022-11-09 Wed 16:07]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 15:43]--[2022-11-09 Wed 16:06] =>  0:23
:END:
*Recall from the last chapter [* \(\text{Eq.}(12.6.19)\) *] that as* \(r \to \infty\), \(U_{E} \sim r^{me^{2}/\kappa \hbar^{2}} \exp \left \lbrace - \kappa r  \right \rbrace\) *in a Coulomb potential* \(V = - e^{2}/ r\) *[* \(\kappa = \left( 2m W/ \hbar^{2} \right)^{1/2}\) *]. Show that this agrees with* \(\text{Eq.}(13.1.26)\).

Just need to evaluate \(\kappa\) given \(W = \frac{m e^4}{2 \hbar^{2} \left( k + l + 1 \right)^2}\). We get

\begin{align*}
\kappa = \left(\dfrac{m^{2} e^{4}}{\hbar^{4} \left( k + l + 1 \right)^{2}}\right)^{1/2} = \left(\dfrac{m^{2} e^{4}}{\hbar^{4} n^{2}}\right)^{1/2} = \dfrac{m e^{2}}{\hbar^{2} n} = \dfrac{1}{a_{0} n},
\end{align*}

where we have used the definition of the principal quantum number \(n \equiv \left( k + l + 1 \right)\) and the definition of the Bohr radius \(a_{0} \equiv \hbar^{2}/ m e^{2}\). Thus

\begin{align*}
R_{nl} \equiv U_{nl}/r \sim r^{n} \exp \left \lbrace - r/ a_{0}  \right \rbrace /r = r^{n-1} \exp \left \lbrace - r/ a_{0}  \right \rbrace
\end{align*}

which is \(\text{Eq.}(13.1.26)\) from the text.

** SOLVED Problem 13.1.5 Virial Theorem
CLOSED: [2022-11-09 Wed 20:23]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 16:20]--[2022-11-09 Wed 20:22] =>  4:02
:END:
*(Virial Theorem).* *Since* \(\vert n, l, m \rangle\) *is a stationary state,* \(\left \langle \dot{\Omega}  \right \rangle = 0\) *for any* \(\Omega\). *Consider* \(\Omega = \vec{R} \cdot \vec{P}\) *and use Ehrenfest's theorem to show that* \(\left \langle T  \right \rangle = (-1/2) \left \langle V  \right \rangle\) *in the state* \(\vert n, l, m \rangle\).

Here's Ehrenfest's theorem

\begin{align*}
D_{t} \left \langle \Omega  \right \rangle = - \left( i/ \hbar \right) \left \langle \left[ \Omega, H \right]  \right \rangle.
\end{align*}

Substitute  \(\Omega = \vec{R} \cdot \vec{P} = R_{i} P_{i}\).

\begin{align*}
0 = D_{t} \left \langle \Omega  \right \rangle &= - \left( i/ \hbar \right) \left \langle \left[ R_{i} P_{i}, H \right]  \right \rangle \\
&= - \left( i / \hbar \right) \left \langle R_{i} \left[P_{i}, H  \right] + \left[ R_{i}, H \right] P_{i} \right \rangle
\end{align*}

Let's evaluate those commutators in turn:

\begin{align*}
R_{i} \left[ P_{i}, H \right] = - i \hbar R_{i} \partial_{i} V \left( \left \lbrace R_{i}  \right \rbrace \right),
\end{align*}

where we have used \(\left[ P_{i}, f \right] = - i \hbar \partial_{i} f\) for some arbitrary function \(f\) and that \(\left[ P_{i}, T \right] = \left[ P_{i}, P_{j} P_{j} \right]/2m = 0\).

\begin{align*}
\left[ R_{i}, H \right] P_{i} = i \hbar 2 T,
\end{align*}

where we have used \(\left[R_{i}, V \left( \left \lbrace R_{i}  \right \rbrace \right) \right] = 0\) (if not obvious descend to coordinate space and come back, I'll wait) and \(\left[ R_{i}, T \right] = \left[ R_{i}, P_{jj} \right]/2m = - P_{j}\left[ P_{j}, R_{i} \right]/2m - \left[ P_{j}, R_{i}  \right] P_{j}/2m = i \hbar P_{i}/m\).

Thence furnish the Virial theorem:

\begin{align*}
0 = \left \langle R_{i} \partial_{i} V - 2 T  \right \rangle \Longrightarrow 2 \left \langle T  \right \rangle = \left \langle R_{i} \partial_{i} V  \right \rangle.
\end{align*}

For the Coulomb potential \(V = - e/ r\) it so happens that \(\left \langle R_{i} \partial_{i} V  \right \rangle = - \left \langle V  \right \rangle\) so the Virial theorem reduces to

\begin{align*}
\left \langle T  \right \rangle = \left( - 1/2 \right) \left \langle V  \right \rangle.
\end{align*}

** SOLVED Problem 13.2.1
CLOSED: [2022-11-10 Thu 09:00]
:LOGBOOK:
CLOCK: [2022-11-09 Wed 21:28]--[2022-11-09 Wed 23:19] =>  1:51
CLOCK: [2022-11-09 Wed 20:34]--[2022-11-09 Wed 21:00] =>  0:26
:END:
*Let us see why the consevation of the Runge-Lenz vector* \(\vec{n}\) *implies closed orbits.*

*(1)* *Express* \(\vec{n}\) *in terms of* \(\vec{r}\) *and* \(\vec{p}\) *alone (get rid of* \(\vec{l}\) *).*

The /Runge-Lenz vector/ is

\begin{align*}
\vec{n} \equiv \dfrac{\vec{p} \times \vec{l}}{m} - \dfrac{e^{2}}{r} \vec{r}.
\end{align*}

But \(\vec{l} \equiv \vec{r} \times \vec{p}\) so rewrite

\begin{align*}
\vec{n} \equiv \dfrac{\vec{p} \times \left( \vec{r} \times \vec{p} \right) }{m} - \dfrac{e^{2}}{r} \vec{r}.
\end{align*}

Now use the identity

\begin{align*}
\vec{a} \times \left( \vec{b} \times \vec{c} \right) = \vec{b} \left( \vec{c} \cdot \vec{a} \right) - \vec{a} \left( \vec{b} \cdot \vec{c} \right).
\end{align*}

of the /vector triple product/ to reduce \(\vec{n}\) to

\begin{align*}
\vec{n} = \left(\dfrac{p^{2}}{m} - \dfrac{e^{2}}{r}\right)\vec{r} - \dfrac{\left( \vec{r} \cdot \vec{p} \right)}{m} \vec{p} = \vec{r} \left(2 E + \dfrac{e^{2}}{r} \right) - \dfrac{\left( \vec{r} \cdot \vec{p} \right)}{m}.
\end{align*}

*(2)* *Since the particle is bound, it cannot escape to infinity. So, as we follow it from some arbitrary time onward, it must reach a point* \(r_{\text{max}}\) *where its distance from the origin stops growing. Show that (Use the law of conservation of energy to eliminate* \(p^{2}\) *):*

\begin{align*}
\vec{n} = r_{\text{min}} \left( 2 E + \dfrac{e^{2}}{r_{\text{min}}} \right),
\end{align*}

*Show that, for similar reasons, if we wait some more, it will come to* \(\vec{r_{\text{min}}}\), *where*

\begin{equation*}
\vec{n} = r_{\text{max}} \left( 2 E + \dfrac{e^{2}}{r_{\text{max}}} \right).
\end{equation*}

*Thus* \(\vec{r}_{\text{max}}\) *and* \(\vec{r}_{\text{min}}\) *are parallel to each other and to* \(\vec{n}\). *The conservation or constancy of* \(\vec{n}\) *implies that the maximum (minimum) separation is alway reached at the same point* \(\vec{r}_{\text{max}}\) *(* \(\vec{r}_{\text{min}}\) *),* *i.e., the orbit is closed. In fact, all three vectors* \(\vec{r}_{\text{max}}\), \(\vec{r}_{\text{min}}\), *and* \(\vec{n}\) *are aligned with the major axis of the ellipse along which the particle moves:* \(\vec{n}\) *and* \(\vec{r}_{\text{min}}\) *are parallel, while* \(\vec{n}\) *and* \(\vec{r}_{\text{max}}\) *are antiparallel. (Why?) Convince yourself that for a circular orbit,* \(n\) *must and does vanish.*

At \(r_{\text{min}}\) and \(r_{\text{max}}\), \(\vec{r} \cdot \vec{p}\) vanishes and the Runge-Lenz vector reduces to

\begin{align*}
\vec{n} = r_{\text{min}} \left( 2 E + \dfrac{e^{2}}{r_{\text{min}}} \right),
\end{align*}


\begin{equation*}
\vec{n} = r_{\text{max}} \left( 2 E + \dfrac{e^{2}}{r_{\text{max}}} \right),
\end{equation*}

respectively.

Why does \(\vec{r} \cdot \vec{p}\) vanish? A consequence of Kepler's first law is that \(r_{\text{max}}\) and \(r_{\text{min}}\) are at the ends of the major axis of an ellipse. When the tip of \(\vec{r}\) is at these points \(\vec{p}\) is perpendicular to \(\vec{r}\) (the component of \(\vec{p}\) along the major axis vanishes, because the rate of change of the component of \(\vec{r}\) along the major axis vanishes (the rate of change of \(\vec{r}\) vanishes at the ends of the major axis because /across/ it, it changes sign).

To see that \(\vec{r}_{\text{max}}\) and \(\vec{r}_{\text{min}}\) are parallel to each other and to \(\vec{n}\) simple position yourself at the tip of \(\vec{p}\) and watch its tail trot along the circumference of a circle with radius \(p\). The instant when \(\vec{r} \cdot \vec{p}\) vanishes, \(\vec{r}\) is tangent to the circle /and/ perpendicular to \(\vec{p}\). There are only two such tangents and they are parallel to each other.



Check this out: [[https://en.wikipedia.org/wiki/Laplace%E2%80%93Runge%E2%80%93Lenz_vector#/media/File:Laplace_Runge_Lenz_vector.svg][Laplace Runge Lenz vector]].

For a circular orbit \(r\) stays fixed. So \(p_{x} = 0\) at all times.

** SOLVED Problem 13.3.1
CLOSED: [2022-11-10 Thu 14:15]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 13:39]--[2022-11-10 Thu 14:15] =>  0:36
:END:
*The pion has a range of* \(1 \thinspace \thinspace \text{Fermi} = 10^{-5} \textup{~\AA}\) *as a mediator of nuclear force. Estimate its rest energy.*

This just means \(\Delta X \sim 10^{-5} \thinspace \textup{~\AA}\).

From the relations \(\Delta E \sim \dfrac{\hbar c}{\Delta X}\) and \(\Delta E \lesssim 2 m c^{2}\) we have

\begin{align*}
\dfrac{\hbar c}{\Delta X} \lesssim 2 m c^{2}.
\end{align*}

Saying \(\Delta X\) can be no smaller is saying that this inequality is saturated, so:

\begin{align*}
m c^{2} \sim \dfrac{\hbar c}{\Delta X}.
\end{align*}

Using \(\hbar c \simeq 2000 \thinspace \text{eV} \textup{~\AA}\), we get

\begin{align*}
m c^{2} \sim 200 \text{MeV}.
\end{align*}

** SOLVED Problem 13.3.2
CLOSED: [2022-11-10 Thu 14:37]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 14:22]--[2022-11-10 Thu 14:37] =>  0:15
:END:
*Estimate the de Broglie wavelength of an electron of kinetic energy* \(200 \thinspace \text{eV}\). *(Recall* \(\lambda = 2 \pi \hbar / p\). *)*

We have

\begin{align*}
T = \dfrac{p^{2}}{2m} \Longrightarrow p = \sqrt{2m T}.
\end{align*}

Using \(\lambda = 2 \pi \hbar / p\), we get

\begin{align*}
\lambda = \dfrac{2 \pi \hbar}{\sqrt{2m T}} = \dfrac{2 \pi \hbar c}{\sqrt{2m c^{2} T}}.
\end{align*}

Using \(mc^{2} \simeq 0.5 \thinspace \text{MeV}\), \(\hbar c \simeq 2000 \thinspace \text{eV} \textup{~\AA}\), \(T = 200 \text{eV}\) we get

\begin{align*}
\lambda \simeq \dfrac{2 \times 3.14 \times 2000 \thinspace \text{eV} \textup{~\AA}}{\sqrt{10^{6} \thinspace \text{eV} \times 200 \thinspace \text{eV}}} \simeq \dfrac{2 \times 3.14}{\sqrt{2} \times \thinspace 10} \textup{~\AA} \sim 0.5 \thinspace \textup{\AA}.
\end{align*}

** SOLVED Problem 13.3.3
CLOSED: [2022-11-10 Thu 16:22]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 15:38]--[2022-11-10 Thu 16:22] =>  0:44
:END:
*Instead of looking at the emission spectrum, we can also look at the absorption spectrum of hydrogen. Say some hydrogen atoms are sitting at the surface of the sun. From the interior of the sun, white light tries to come out and the atoms at the surface absorb what they can. The atoms in the ground state will now absorb the Lyman series and this will lead to dark lines if we analyze the light coming from the sun. The presence of these lines will tell us that there is hydrogen at the surface of the sun. We can also estimate the surface temperature as follows. Let* \(T\) *be the surface temperature. The probabilities* \(P(n=1)\) *and* \(P(n=2)\) *of an atom being at* \(n=1\) *and* \(n=2\), *respectively, are related by Boltzmann's formula*

\begin{align*}
\dfrac{P \left( n = 2 \right)}{P \left( n = 1 \right)} = 4 \exp \left \lbrace - \left( E_{2} - E_{1} \right)/kT  \right \rbrace
\end{align*}

*where the factor* \(4\) *is due to the degeneracy of the* \(n=2\) *level. Now only atoms in* \(n=2\) *can produce the Balmer lines in the absorption spectrum. The relative strength of the Balmer and Lyman lines will tell us* \(P(n=2)/P(n=1)\), *from which we may infer* \(T\). *Show that for* \(T= 6000 \text{K}\), \(P(n=2)/P(n=1)\) *is negligible and that it becomes significant only for* \(T \simeq 5 K\). *(The Boltzmann constant is* \(k \simeq 9 \times 10^{-5} \thinspace \text{eV/K}\). *A mnemonic is* \(kT \simeq \frac{1}{40} \thinspace \text{eV}\) *at room temperature,* \(T=300 \thinspace \text{K}\). *)*

We have

\begin{align*}
E_{2} - E_{1} = \text{Ry} \left( \dfrac{1}{1^{2}} - \dfrac{1}{2^{2}} \right) = \dfrac{3 \thinspace \text{Ry}}{4} \sim \text{Ry} = 13.3 \thinspace \text{eV}.
\end{align*}
   
Feeding into /Boltzmann's formula/ and using \(k T \simeq 0.5 \thinspace \text{eV}\) for \(T = 6000 \thinspace \text{K}\)

\begin{align*}
\dfrac{P \left( n = 2 \right)}{P \left( n = 1 \right)} \sim 4 \exp \left \lbrace - 26.6 \right \rbrace \sim 10^{-11}.
\end{align*}

It's negligible. For \(T = 5 \thinspace \text{K}\), using \(k T \simeq 0.0004 \thinspace \text{eV}\), so \(P \left( n = 2 \right)/ P \left( n = 1 \right)\) is even smaller, I don't know why the ask insists on it being significant.
** SOLVED Problem 13.4.1
CLOSED: [2022-11-10 Thu 16:46]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 16:25]--[2022-11-10 Thu 16:46] =>  0:21
:END:
*Show that if we ignore interelectron interactions, the energy levels of a multielectron atom go as* \(Z^{2}\). *Since the Coulomb potential is* \(Ze/r\), *why is the energy* \(\propto Z^{2}\)?

For a multi-electron atom (on ignoring interelectron itneractions):

\begin{align*}
\dfrac{e}{r} \to \dfrac{Ze}{r}, \qquad \dfrac{e^{2}}{r} \to \dfrac{Ze^{2}}{r},
\end{align*}

so,

\begin{align*}
Ze^{2} \lambda = 2 \left( k + l + 1 \right), \qquad \lambda = \left( 2m / \hbar^{2} W \right)^{1/2}, \qquad E = - W = \dfrac{2m}{\hbar^{2} \lambda^{2}}.
\end{align*}

Since \(\lambda \propto 1/Z\), and \(E \propto 1/ \lambda^{2}\), \(E \propto Z^{2}\).
\begin{align*}

\end{align*}

** SOLVED Problem 13.4.2
CLOSED: [2022-11-10 Thu 17:36]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 16:30]--[2022-11-10 Thu 17:36] =>  1:06
:END:
*Compare (roughly) the sizes of the uranium atom and the hydrogen atom. Assume levels fill in the order of increasing* \(n\), *and that the nonrelativistic description holds. Ignore interelectron effects.*

*For a multielectron atom (ignoring electron electron interactions) the formula for the Bohr radius is is modified as* \(a_{0, Z} = \frac{\hbar^{2}}{Zme^{2}}\). *For Uranium* \(Z = 92\). *The degeneracy for each* \(n\) is \(2 n^{2}\) *where we* *have accounted for the degeneracy due to spin. To host* \(92\) *electrons, the number of* /shells/ \(k\) *needed is obtained by solving*

\begin{align*}
\sum_{n=0}^{k} 2 n^{2} \geq 92,
\end{align*}

for \(k\). We get \(k = 5\) for \(U\). For \(H\), \(k = 1\). Now

\begin{align*}
\left \langle r  \right \rangle_{n, \text{U}}/\left \langle r  \right \rangle_{n, \text{H}} = k_{U}^{2} a_{0, \text{U}}/ k_{H}^{2} a_{0, \text{H}} = \dfrac{k_{U}^{2}}{k_{H}^{2} Z} = \left( 25/92 \right).
\end{align*}

Using \(\left \langle r  \right \rangle_{1, H} = 0.55 \thinspace \textup{\AA}\), we get \(\left \langle r  \right \rangle_{5, U} = \left( 25/92 \right) \left \langle r  \right \rangle_{1, H} \sim 0.15 \textup{\AA}\).
** SOLVED Problem 13.4.3
CLOSED: [2022-11-10 Thu 17:47]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 17:37]--[2022-11-10 Thu 17:47] =>  0:10
:END:
*Visible light has a wavelength of approximately* \(5000 \thinspace \textup{\AA}\). *Which of the series—Lyman, Balmer, Paschen—do you think was discovered first?*

A wavelength \(\lambda\) corresponds to an energy \(E = 2 \pi \hbar c/ \lambda\) (De Broglie formula). For \(\lambda = 5000 \thinspace \textup{\AA}\), we have \(E \sim 2 \times 3.13 \times 2000 \thinspace \text{eV} \thinspace \textup{\AA}/ 5000 \thinspace \textup{\AA} \sim 3 \thinspace \text{eV}\). This transition belongs to the /Balmer series/ - it was the first to be discovered, in the year 1885 by Johann Balmer.
* Spin
CLOSED: [2022-11-13 Sun 04:25]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 19:58]--[2022-11-10 Thu 20:22] =>  0:24
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-27 Sun 17:20]--[2022-11-27 Sun 21:48] =>  4:28
:END:
*** Spinor
There is a class of quantum phenomena that involve a quantum degree of freedom called /spin/ that has no classical counterpart. The best way to characterize spin is as a /form of angular momentum not associated with orbital motion/. It so because observations indicate that measuring the angular momentum of an electron that has no linear momentum gives a value \(\pm \hbar/2\). The spin of an electron (or anything else that has spin) is it's /intrinsic/ property, like mass, charge, etc. A direct consequence of this observation is that the wavefunction for an electron is not a scalar but in fact a vector. Consider a /vector valued wavefunction/ with \(n\) components. Under an infinitesimal rotation about the \(z\) direction /two/ things happen:

1) the values at each spatial point are re-assigned to the rotated point,
2) the components of the wavefunction get transformed into linear combinations of each other.

\(\vec{L}\) does the first, \(\vec{S}\) does the second and the whole thing is done by \(\vec{J} = \vec{L} + \vec{S}\): it is the generator of infinitesimal rotations for a vector-valued wavefunction. Therefore

\begin{align*}
\vert \psi^{\prime} \rangle = \left[ I - \dfrac{i \epsilon}{\hbar} J_{z} \right] \vert \psi \rangle.
\end{align*}

What is \(n\) and what is \(\vec{S}\)? Since \(J_{i}\) are generator of rotations, they must obey the consistency condition

\begin{align*}
\left[ J_{i}, J_{j} \right] = i \hbar \epsilon_{ijk} J_{k} \quad \text{or} \quad \left[ L_{i}, L_{j} \right] + \left[ S_{i}, S_{j} \right] = i \hbar \left[ \epsilon_{ijk} L_{k} + \epsilon_{ijk} S_{k} \right].
\end{align*}


But \(\left[ L_i, L_j \right] = i \hbar \epsilon_{ijk} L_{k}\) so \(\left[ S_{i}, S_{j} \right] = i \hbar \epsilon_{ijk} S_{k}\).

For an electron lacking linear momentum \(\vec{J} = \vec{S}\). Using the empirical fact that a measurement of \(J_{z} = S_{z}\) gives \(\pm \hbar/2\), we can assert that \(n = 2\) for an electron so that it is a two-component wavefunction - a /spinor/:

\begin{align*}
\vert \psi \rangle =
\begin{bmatrix}
\psi_{+} \left( x, y, z \right) \\
\psi_{-} \left( x, y, z \right)
\end{bmatrix}
\equiv
\psi_{+}
\begin{bmatrix}
1 \\
0 
\end{bmatrix}
+
\psi_{-}
\begin{bmatrix}
0 \\
1 
\end{bmatrix}.
\end{align*}

*** Hilbert space for spin
The Hilbert space \(\mathbb{V}_{e}\) of the electron may be viewed as a direct product of an infinite-dimensional space \(\mathbb{V}_{0}\) which describes a particle with just orbital degrees of freedom, and a two-dimensional space \(\mathbb{V}_{s}\), which describes a particle with just spin degrees of freedom:

\begin{align*}
\mathbb{V}_{e} = \mathbb{V}_{0} \otimes \mathbb{V}_{s}.
\end{align*}

If the orbital and spin degrees of freedom evolve independently, meaning the Hamiltonian factorizes as:

\begin{align*}
H = H_{0} + H_{s}
\end{align*}

the state vector factorizes as:

\begin{align*}
\vert \psi \left( t \right) \rangle = \vert \psi_{0} \left( t \right) \rangle \otimes \vert \chi_{s} \left( t \right) \rangle.
\end{align*}

\(\vert \psi_{0} \left( t \right) \rangle\) lives in \(\mathbb{V}_{0}\) and \(\vert \chi_{s} \left( t \right) \rangle\) lives in \(\mathbb{V}_{s}\).
*** Vectors in spin Hilbert space
The kets \(\vert s, s_z \rangle = \vert s, m \hbar \rangle \equiv \vert s, m \rangle\) form a complete basis that spans \(\mathbb{V}_{s}\).

\begin{align*}
\vert s, m \rangle = \vert 1/2, 1/2 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
1 \\
0 
\end{bmatrix}
\end{align*}

\begin{align*}
\vert s, m \rangle = \vert 1/2, -1/2 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
0 \\
1 
\end{bmatrix}
\end{align*}

A representation for \(\vert \chi \rangle\) in \(\mathbb{V}_{s}\) is:

\begin{align*}
\vert \chi \rangle = \alpha \vert 1/2, 1/2 \rangle + \beta \vert 1/2, -1/2 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\alpha \\
\beta 
\end{bmatrix},
\end{align*}

with the normalization

\begin{align*}
1 = \left \langle \chi \vert \chi \right \rangle \xrightarrow[]{S_{z} \text{basis}} 1 = \left \lvert \alpha  \right \rvert^{2} + \left \lvert \beta  \right \rvert^{2}.
\end{align*}

The expectation value of \(\vec{S}\) in the eigenstates \(\vert \hat{n}, \pm \rangle\) of \(\hat{n} \cdot \vec{S}\) is:

\begin{align*}
\left \langle \vec{S} \right \rangle = \left \langle \hat{n}, \pm \left \lvert \vec{S} \right \rvert \hat{n}, \pm \right \rangle = \pm \left( \hbar/2 \right) \hat{n}.
\end{align*}

The kets \(\vert \hat{n}, + \rangle\), \(\vert \hat{n}, - \rangle\) are said to be states with spin up/down along the direction \(\hat{n}\). In the \(S_{z}\) basis \(\vert \hat{n}, + \rangle\), \(\vert \hat{n}, - \rangle\) have representations:

\begin{align*}
\vert \hat{n}, + \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right) \exp \left \lbrace i \phi/2 \right \rbrace
\end{bmatrix},
\end{align*}

\begin{align*}
\vert \hat{n}, - \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
-\sin \left( \theta/2 \right) \exp \left \lbrace -i \phi/2  \right \rbrace \\
\cos \left( \theta/2 \right) \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}.
\end{align*}
*** Spin operators in spin Hilbert space: Pauli matrices
A representation of \(\vec{S}\) for an electron in the \(\vert sm \rangle\) basis is

\begin{align*}
S_{x} = \dfrac{\hbar}{2}
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}
\quad
S_{y} = \dfrac{\hbar}{2}
\begin{pmatrix}
0 & -i \\
i & 0
\end{pmatrix}
\quad
S_{z} = \dfrac{\hbar}{2}
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}.
\end{align*}

These were just read off from the representations of matrices for \(\vec{J}\) in the \(\vert jm \rangle\) which are available. We introduce the /Pauli matrices/ \(\vec{\sigma}\): 

\begin{align*}
\sigma_{x} =
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}
\quad
\sigma_{y} =
\begin{pmatrix}
0 & -i \\
i & 0
\end{pmatrix}
\quad
\sigma_{z} =
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}.
\end{align*}

so that the spin operators in \(\mathbb{V}_{s}\) become:

\begin{align*}
\vec{S} = \dfrac{\hbar}{2} \vec{\sigma}.
\end{align*}
*** Rotation operators in spin Hilbert space
The rotation operator in \(\mathbb{V}_{s}\) in the \(S_{z}\) basis is:

\begin{align*}
U \left[ R \left( \vec{\theta} \right) \right] = \cos \left( \theta/2 \right) I - i \sin \left( \theta/2 \right) \hat{\theta} \cdot \vec{\sigma}.
\end{align*}

This result is a direct consequence of the property \((\hat{n} \cdot \vec{\sigma})^{2}\) of the Pauli matrices. It rotates a state vector in \(\mathbb{V}_{s}\) by an angle \(\theta\) about the direction \(\hat{\theta}\). Suppose we want to rotate the ket \(\vert 1/2, 1/2 \rangle\) so that it ends up at \(\vert \hat{n}, + \rangle\). \(\hat{n} = \left( \sin \theta \cos \phi, \sin \theta \sin \phi, \cos \theta \right)\) so we need:

\begin{align*}
\hat{\theta} = \dfrac{1}{\sin \theta} \left( - \sin \theta \sin \phi, \sin \theta \cos \phi, 0 \right) = \left( - \sin \phi, \cos \phi, 0 \right).
\end{align*}

The rotation matrix then is:

\begin{align*}
D \left[ R \left( \vec{\theta} \right) \right] =
\begin{pmatrix}
\cos \left( \theta/2 \right) & - \sin \left( \theta/2 \right) \exp \left \lbrace - i \phi  \right \rbrace \\
\sin \left( \theta/2 \right) \exp \left \lbrace i \phi \right \rbrace & \cos \left( \theta/2 \right)
\end{pmatrix}.
\end{align*}

Armed with this, arbitrary rotations in \(\mathbb{V}_{s}\) are accessible now.
*** Orbital magnetic moment
The magnitude of the /magnetic moment/ \(\vec{\mu}\) for a particle of mass \(m\), charge \(q\), cruising in a circular orbit of radius \(r\) with velocity \(v\) is:

\begin{align*}
\mu = \dfrac{qv}{2 \pi r} \dfrac{\pi r^{2}}{c} = \dfrac{qvr}{2c} = \left( \dfrac{q}{2mc} \right) m v r = \dfrac{ql}{2mc}.
\end{align*}

where \(l\) is the magnitude of the angular momentum. This has been derived by analogy with the formula for the magnetic moment of a current carrying loop:

\begin{align*}
\qquad \vec{\mu} = \dfrac{I \cdot A}{c} \vec{e_{\bot}}.
\end{align*}

Here \(A\) is the area of the loop, \(c\) is the velocity of light, and \(\vec{e_{\bot}}\) is the unit vector perpendicular to the plane of the loop. Since \(\vec{\mu}\) and \(\vec{l}\) are parallel

\begin{align*}
\vec{\mu} = \left( \dfrac{q}{2 m c} \right) \vec{l}.
\end{align*}

The ratio of \(\mu\) to \(l\) is called the /gyromagnetic ratio/ \(\gamma\). In this case:

\begin{align*}
\gamma = \dfrac{q}{2 m c}.
\end{align*}

Why is it cruising anyway? Because there is a magnetic field \(\vec{B}\). At one time it was the case that \(\vec{\mu} || \vec{B}\). Then came along some pervert and nudged it. Now it /precesses/, cause it can't help it. The equation of motion is

\begin{align*}
\vec{T} = D_{t} \vec{l} = \vec{\mu} \times \vec{B} = \gamma \left( \vec{l} \times \vec{B} \right).
\end{align*}

In a small time \(\Delta t\),

\begin{align*}
\Delta \vec{l} = \gamma \left( \vec{l} \times \vec{B} \right) \Delta t \quad \text{or} \quad \Delta l = \gamma l B \sin \theta \Delta t.
\end{align*}

Since \(\Delta \vec{l}\) is perpendicular to \(\vec{l}\), the tip of \(\vec{l}\) vector moves by an angle

\begin{align*}
\Delta \phi = \left( \dfrac{-\Delta l}{l \sin \theta} \right) = \left( - \gamma B \right) \Delta t,
\end{align*}

i.e., precesses at a frequency:

\begin{align*}
\vec{\omega_{0}} = -\gamma \vec{B}.
\end{align*}

The interaction energy  is:

\begin{align*}
H_{\text{int}} \int T \left( \theta \right) d \theta = \int \mu B \sin \theta \thinspace d \theta = - \mu B \cos \theta = - \vec{\mu} \cdot \vec{B}
\end{align*}

The quantum mechanical Hamiltonian for a particle of mass \(m\) and charge \(q\) in a magnetic field is

\begin{align*}
H = \dfrac{(\vec{P} - q \vec{A}/c)^{2}}{2m} = \dfrac{\left \lvert \vec{P} \right \rvert^{2}}{2m} - \dfrac{q}{2mc} \left( \vec{P} \cdot \vec{A} + \vec{A} \cdot \vec{P} \right) + \dfrac{q^{2} \left \lvert \vec{A}  \right \rvert^2}{2mc^{2}}.
\end{align*}

If \(\vec{A} = \dfrac{B}{2} \left( -y \vec{i} + x \vec{j} \right)\) so that \(\nabla \times \vec{A} = \vec{B} = B \vec{k}\) is constant and along the \(z\) axis. We will drop the last term proportional to \(B^{2}\) by /assuming/ \(B\) is small. Now since \(\nabla \cdot \vec{A} = 0\)

\begin{align*}
\left( \vec{P} \cdot \vec{A} \right) \vert \psi \rangle &\to - i \hbar \nabla \cdot \left( A \psi \right) \\
&= i \hbar \left[ \left( \nabla \cdot \vec{A} \right) \psi + \vec{A} \cdot \nabla \psi \right] \\
&= \left( - i \hbar \vec{A} \cdot \nabla \right) \psi \to \left( \vec{A} \cdot \vec{P} \right) \vert \psi \rangle,
\end{align*}

so that the interaction Hamiltonian becomes:

\begin{align*}
H_{\text{int}} &= - \dfrac{q}{2mc} \left( 2 \vec{A} \cdot \vec{P} \right) \\
&= - \dfrac{q}{mc} \dfrac{B}{2} \left( - Y P_{x} + X P_{y} \right) \\
&= - \dfrac{q}{2mc} \vec{L} \cdot \vec{B} \equiv - \vec{\mu} \cdot \vec{B}.
\end{align*}

The interaction energy is the same as in the classical case. This allows us to make the correspondence:

\begin{align*}
\vec{\mu} = \dfrac{q}{2 m c} \vec{L}.
\end{align*}

\begin{align*}
\vec{\mu} = \dfrac{q}{2 m c} \vec{L} \xrightarrow[]{L_{z} \text{basis}} \dfrac{q}{2mc} L_{z} = \dfrac{q \hbar}{2 m c} \left( 0, \thinspace \pm 1, \pm 2, \dotso \right)
\end{align*}

The quantity \(q \hbar/ 2 m c\) is called the /Bohr magneton/ of the particle. The /electron Bohr magneton/, simply called the /Bohr magneton/, has a magnitude:

\begin{align*}
\dfrac{e \hbar}{2 m c} \simeq 0.6 \times 10^{-8} \text{ eV/G},
\end{align*}

where \(m\) is the mass of the electron and \(G\) stands for gauss. The /nucleon Bohr magneton/ is about 2000 times smaller:

\begin{align*}
\dfrac{e \hbar}{2 M c} \simeq 0.3 \times 10^{-11} \text{ eV/G},
\end{align*}

where \(M\) is the nucleon (proton or neutron) mass. By use of Ehrenfest theorem it is easily seen that \(\left \langle \vec{L}  \right \rangle\) precesses around the constant field \(\vec{B}\) just as \(\vec{l}\) would.
*** Spin magnetic moment
We /assume/ that there is a /magnetic moment operator/ \(\vec{\mu}\) associated with the spin angular momentum. It is a operator of the spin Hilbert space:

\begin{align*}
\vec{\mu} = \gamma \vec{S}
\end{align*}

where \(\gamma\) is a constant. Since \(\gamma = e/2mc\) for the orbital case, we /assume/:

\begin{align*}
\vec{\mu} = g \left( \dfrac{e}{2mc} \right) \vec{S}
\end{align*}

where \(g\) is a constant. We also /assume/ that:

\begin{align*}
H_{\text{int}} &= - \vec{\mu} \cdot \vec{B} = \dfrac{ge}{2mc} \vec{S} \cdot \vec{B} \\
&= \left(\dfrac{g e \hbar}{4 m c}\right) \vec{\sigma} \cdot \vec{B}.
\end{align*}

Since \(e \hbar / 2 mc\) is the Bohr magneton, the inrinsic magnetic moment due to spin is \(g/2\) magnetons. We will /assume/ \(g=2\). Then

\begin{align*}
H_{\text{int}} = \left( \dfrac{e \hbar}{2 m c} \right) \vec{\sigma} \cdot \vec{B} = -\gamma \vec{S} \cdot \vec{B}, \qquad \gamma = \dfrac{-e}{mc}.
\end{align*}
*** The propagator in spin Hilbert space
We have

\begin{align*}
\vert \psi \left( t \right) \rangle = U \left( t \right) \vert \psi \left( 0 \right) \rangle
\end{align*}

where

\begin{align*}
U \left( t \right) &= \exp \left \lbrace - i H t/ \hbar \right \rbrace \\
&= \exp \left \lbrace + i \gamma t \left( \vec{S} \cdot \vec{B} \right)/ \hbar \right \rbrace
\end{align*}

Comparison with \(\exp \left \lbrace - i \vec{\theta} \cdot \vec{S}/ \hbar \right \rbrace\), which is the operator that rotates by \(\vec{\theta}\), the /effect of/ \(U \left( t \right)\) /is clearly to rotate the state by an angle/:

\begin{align*}
\vec{\theta} \left( t \right) = - \gamma \vec{B} t.
\end{align*}

Thus \(\left \langle \vec{S}  \right \rangle\) will precess around \(\vec{B}\) at a frequency \(\vec{\omega}_{0} = - \gamma \vec{B}\). Naturally, if there is no magnetic field, the spin stands still.
*** Paramagnetic resonance
Say we had a magnetic field:

\begin{align*}
\vec{B} = B \cos \left(\omega t\right) \vec{i} - B \sin \left(\omega t \right) \vec{j} + B_{0} \vec{k} \qquad \left( B \lll B_{0} \right).
\end{align*}

and at \(t = 0\),

\begin{align*}
\vec{\mu} \left( 0 \right) = \mu \vec{k}.
\end{align*}

We escape the lab frame of reference and mount one that's spinning with frequency \(\vec{\omega} = \omega \vec{k}\). In this rotating frame, the rotating component of \(\vec{B}\) gets frozen along the \(x\) axis and the precession frequency about \(\vec{k}\) will be

\begin{align*}
\omega_{r} = - \gamma B_{0} \vec{k} - \vec{\omega} = - \gamma \left( \vec{B}_{0} + \vec{\omega}/ \gamma \right)
\end{align*}

so that the effective, time-independent field is:

\begin{align*}
\vec{B}_{r} = B \vec{i}_{r} + \left( B_{0} - \omega/ \gamma \right) \vec{k}_{r}
\end{align*}

where \(\vec{i}_{r}\) is the unit vector in the \(x\) direction in the rotating frame and \(\vec{k}_{r} = \vec{k}\) of course. In this frame, \(\vec{\mu}\) will precess around \(\vec{B}_{r}\) at a frequency

\begin{align*}
\vec{\omega}_{r} = - \gamma \vec{B}_{r},
\end{align*}

where

\begin{align*}
\left \lvert \vec{\omega}_{r} \right \rvert = \omega_{r} = \gamma \left[ B^{2} + \left( B_{0} - \omega/ \gamma \right)^{2} \right]^{1/2}.
\end{align*}

We have

\begin{align*}
\mu_{z} \left( t \right) &= \mu \cos^{2} \alpha + \mu \sin^{2} \alpha \cos \omega_{r} t \\
&= \mu_{z} \left( 0 \right) \left[ \dfrac{\left( \omega_{0} - \omega \right)^{2}}{\left( \omega_{0} - \omega \right)^{2} + \gamma^{2} B^{2}} + \dfrac{\gamma^{2} B^{2} \cos \omega_{r} t}{\left( \omega_{0} - \omega \right)^{2} + \gamma^{2} B^{2}} \right].
\end{align*}

This formula is applicable in lab frame too since \(\mu_{z}(t)\) is invariant under rotations about \(z\).

At /paramagnetic resonance/ \(\omega = \omega_{0}\), \(\vec{B}_{r} = B \vec{i}_{r}\), \(\alpha = \pi/2\), and \(\mu_{z}\) oscillates with the largest amplitude \(\mu\) at a frequency \(\gamma B\). The behavriour for \(\omega > \omega_{0}\) is obvious.

A \(90^{\circ}\) /pulse/ is when we apply the rotating field at the resonance  frequency for a time \(\tau\) such that \(\gamma B \tau = \pi/2\). It will swing the magnetic moment into the \(x-y\) plane (in either frame). Thereafter \(\vec{\mu}\) will precess around \(B_{0} \vec{k}\) at the frequency \(\omega_{0}\) in the lab frame. A \(180^{\circ}\) pulse, i.e., \(\tau = \pi/ \gamma B\), the pulse will reverse the sign of \(\vec{\mu}\) and leave it pointing down the \(z\) axis, where it will stay (in either frame).

These results for the classical moment \(\vec{\mu}\) apply to the expectation value \(\left \langle \vec{\mu}  \right \rangle\) in the quantum problem.
*** Spin and orbital degrees of freedom combined
Suppose we have a separable \(H\):

\begin{align*}
H = H_{o} + H_{s}
\end{align*}

The time evolution of the spin and orbital degrees of freedom decouple so that the energy eigenstates factorizes:

\begin{align*}
\vert \psi \rangle = \vert \psi_{0} \rangle \otimes \vert \chi_{s} \rangle.
\end{align*}

If \(H\) is /not/ separable however, say when

\begin{align*}
H = H_{\text{Coulomb}} + a \vec{L} \cdot \vec{S}
\end{align*}

the spin and orbital degrees of freedom are coupled in their time evolution. The eigenstates of \(H\) will not be simply products of orbital and spin parts, but instead superpositions of such states that diagonalize \(\vec{L} \cdot \vec{S}\).
*** Zeeman effect
The Hamiltonian of the Hydrogen atom is separable, where the Coulomb interaction is independent of spin:

\begin{align*}
H = H_{o}.
\end{align*}

Here the spin is a constant in time, and there is doubling of eigenkets:

\begin{align*}
\vert nlmm_{s} = 1/2 \rangle \xrightarrow[]{RS_{z} \text{basis}}
\psi_{nlm} \left( r, \theta, \phi \right)
\begin{bmatrix}
1 \\
0 
\end{bmatrix}
\end{align*}

\begin{align*}
\vert nlmm_{s} = -1/2 \rangle \xrightarrow[]{RS_{z} \text{basis}} \psi_{nlm} \left( r, \theta, \phi \right)
\begin{bmatrix}
0 \\
1 
\end{bmatrix}.
\end{align*}

Now suppose we turn on a weak magnetic field \(\vec{B} = B \vec{k}\). Both the proton and the electron couple to \(\vec{B}\) but as a first approximation we ignore the coupling of the proton's intrinsic and orbital magnetic moments (of order \(m/M\) and \((m/M)^{2}\) relative to the electron). The Hamiltonian now is:

\begin{align*}
H = H_{\text{Coulomb}} - \left( \dfrac{-e B}{2 m c} \right) L_{z} - \left( \dfrac{-eB}{mc} \right) S_{z}.
\end{align*}

The rotational invariance of the Hamiltonian stays intact: the eigenkets \(\vert nlmm_s \rangle\) /still/ diagnonalize new \(H\). Degeneracies are broken however via changing eigenvalues:

\begin{align*}
H \vert nlmm_{s} \rangle = \left[ \dfrac{- \text{Ry}}{n^{2}} + \dfrac{e B \hbar}{2 m c} \left( m + 2 m_{s} \right) \right] \vert nlmm_{s} \rangle.
\end{align*}

The \(2\) -fold degeneracy of the ground state is broken to yield two different energy levels:

\begin{align*}
E_{n=1} = - \text{Ry} \pm \dfrac{e \hbar B}{2 m c}.
\end{align*}

The \(8\) -fold degeneracy of the first excited state splits into five level:

\begin{align*}
E_{n=2} = - \dfrac{\text{Ry}}{4} + \dfrac{e B \hbar}{2 m c} \times
\begin{bmatrix}
2 \left( m=1, m_{s} = 1/2 \right) \\
1 \left( m = 0, m_{s} = 1/2 \right) \left( l = 0 \text{ or } 1 \right) \\
0 \left( m = 1, m_{s} = -1/2, \text{ or } m=-1, m_{s} = 1/2 \right) \\
-1 \left( m=0, m_{s} = -1/2 \right) \left( l = 0 \text{ or } 1 \right) \\
-2 \left( m = -1, m_{s} = - 1/2 \right)
\end{bmatrix}.
\end{align*}

The is called /Zeeman splitting/ or the /Zeeman effect/.
*** Stern-Gerlach (SG) experiment
** SOLVED Problem 14.3.1
CLOSED: [2022-11-10 Thu 21:02]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 20:22]--[2022-11-10 Thu 21:02] =>  0:40
:END:
*Let us verify the above corollary explicitly. Take some spinor with components* \(\alpha = \rho_{1} \exp \left \lbrace i \phi_{1}  \right \rbrace\) *and* \(\beta = \rho_{2} \exp \left \lbrace i \phi_{2}  \right \rbrace\). *From* \(\left \langle \chi \vert \chi  \right \rangle = 1\), *deduce that we can write* \(\rho_{1} = \cos \left( \theta/2 \right)\) *and* \(\rho_{2} = \sin \left( \theta/2 \right)\) *for some* \(\theta\). *Next pull out a common phase factor so that the spinor takes the form in* \(\text{Eq.} (14.3.28 \text{a})\). *This verifies the corollary and also fixes* \(\hat{n}\).

We have
\begin{align*}
\vert \chi \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\alpha \\
\beta 
\end{bmatrix} =
\begin{bmatrix}
\rho_{1} \exp \left \lbrace i \phi_{1}  \right \rbrace \\
\rho_{2}  \exp \left \lbrace i \phi_{2}  \right \rbrace
\end{bmatrix}.
\end{align*}

From

\begin{align*}
1 = \left \langle \chi \vert \chi \right \rangle &= \rho_{1}^{2} + \rho_{2}^{2},
\end{align*}

it's clear the above equality is satisfied with \(\rho_{1} = \cos \theta/2\) and \(\rho_{2} = \sin \theta/2\) for some \(\theta\). Thus

\begin{align*}
\vert \chi \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\cos \left(\theta/2\right) \exp \left \lbrace i \phi_{1}  \right \rbrace \\
\sin \left(\theta/2\right) \exp \left \lbrace i \phi_{2}  \right \rbrace
\end{bmatrix}.
\end{align*}

What's the common phase factor one must yank out? Well let it be \(\exp \left \lbrace i \varphi  \right \rbrace\). We must then have

\begin{align*}
\phi_{1} = \varphi - \phi/2 \quad \text{and} \quad \phi_{2} = \varphi + \phi/2.
\end{align*}

Clearly \(\varphi = \left(\phi_{1} + \phi_{2}\right)/2\) and \(\phi = \phi_{2} - \phi_{1}\). So yank it out and write

\begin{align*}
\vert \chi \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\cos \left(\theta/2\right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left(\theta/2\right) \exp \left \lbrace i \phi/2 \right \rbrace
\end{bmatrix}, \qquad \phi = \phi_2 - \phi_1.
\end{align*}

This fixes \(\hat{n}\) as

\begin{align*}
\hat{n}_{z} &= \cos \theta, \\
\hat{n}_{x} &= \sin \theta \cos \phi, \\
\hat{n}_{y} &= \sin \theta \sin \phi.
\end{align*}

** SOLVED Problem 14.3.2
CLOSED: [2022-11-10 Thu 22:47]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 21:02]--[2022-11-10 Thu 22:46] =>  1:44
:END:
*(1)* *Show that the eigenvectors of* \(\vec{\sigma} \cdot \hat{n}\) *are given by* \(\text{Eq.} (14.3.28)\).

The secular equation for \(\hat{n} \cdot \vec{\sigma}\) is

\begin{align*}
0 &= \left( \hbar/2 \right)^{2} \left \lbrace \left( \cos \theta - \lambda \right) \left( - \cos \theta - \lambda \right) - \left( \sin \theta \exp \left \lbrace i \phi  \right \rbrace \right)\left( \sin \theta \exp \left \lbrace - i \phi  \right \rbrace \right)  \right \rbrace \\
&= \left( \hbar/2 \right)^{2} \left \lbrace \lambda^{2} - \cos^{2} \theta - \sin^{2} \theta  \right \rbrace \\
&\Longrightarrow \lambda = \pm 1.
\end{align*}

The eigenvector \(\vert \hat{n}, + \rangle\) for \(\lambda = \pm 1\) must satisfy

\begin{align*}
\hat{n} \vec{\sigma} \vert \hat{n}, \pm \rangle = \pm \dfrac{\hbar}{2} \vert \hat{n}, + \rangle.
\end{align*}

For \(\lambda = + 1\) with

\begin{align*}
\vert \hat{n}, + \rangle =
\begin{bmatrix}
a \\
b 
\end{bmatrix}
\end{align*}

we have the system

\begin{align*}
\left( 1 - \cos \theta \right) a &= b \sin \theta \exp \left \lbrace - i \phi  \right \rbrace, \\
\left( 1 + \cos \theta \right) b &= a \sin \theta \exp \left \lbrace i \phi  \right \rbrace.
\end{align*}

Divide the first equation by the second

\begin{align*}
\dfrac{\left( 1 - \cos \theta \right)}{\left( 1 + \cos \theta \right)} \dfrac{a}{b} = \dfrac{b}{a} \exp \left \lbrace - 2 i \phi   \right \rbrace,
\end{align*}

and use some trigonometric identities to obtain

\begin{align*}
a^{2} \sin^{2} \left( \theta/2 \right) \exp \left \lbrace - i \varphi  \right \rbrace  = b^{2} \cos^{2} \left( \theta/2 \right) \exp \left \lbrace - i \left( 2 \phi + \varphi \right) \right \rbrace.
\end{align*}

\(a = \cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace\), \(b = \sin \left( \theta/2 \right) \exp \left \lbrace i \phi/2  \right \rbrace\), and \(\varphi = \phi/2\) solves the system. Thence:

\begin{align*}
\vert \hat{n}, + \rangle =
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}.
\end{align*}

For \(\lambda = - 1\) with

\begin{align*}
\vert \hat{n}, - \rangle =
\begin{bmatrix}
a \\
b 
\end{bmatrix}
\end{align*}

\begin{align*}
\left( 1 + \cos \theta \right) a &= - b \sin \theta \exp \left \lbrace - i \phi  \right \rbrace, \\
\left( 1 - \cos \theta \right) b &= a \sin \theta \exp \left \lbrace - i \phi  \right \rbrace.
\end{align*}

Divide the first equation by the second and use some trigonometric identites to obtain

\begin{align*}
a^{2} \cos^{2} \left( \theta/2 \right) \exp \left \lbrace - i \varphi  \right \rbrace = - b^{2} \cos^{2} \left( \theta / 2 \right) \exp \left \lbrace - i \left( 2 \phi + \varphi \right)  \right \rbrace.
\end{align*}

\(a = -\sin \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace\), \(b = \cos \left( \theta/2 \right) \exp \left \lbrace i \phi/2  \right \rbrace\), and \(\varphi = \phi/2\) solves the system. Thence:

\begin{align*}
\vert \hat{n}, - \rangle =
\begin{bmatrix}
-\sin \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\cos \left( \theta/2 \right) \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}.
\end{align*}

*(2)* *Verify* \(\text{Eq.} (14.3.29)\).

\begin{align*}
\left \langle \hat{n} + \left \lvert \vec{\sigma}  \right \rvert \hat{n} + \right \rangle &=
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}^{\dagger}
\begin{pmatrix}
0 & \hbar/2 \\
\hbar/2 & 0
\end{pmatrix}
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix} \vec{i} \\
&+
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}^{\dagger}
\begin{pmatrix}
0 & - i \hbar/2 \\
i \hbar/2 & 0
\end{pmatrix}
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix} \vec{j} \\
&+
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}^{\dagger}
\begin{pmatrix}
\hbar/2 & 0 \\
0 & - \hbar/2
\end{pmatrix}
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix} \vec{k} \\
&= \left( \hbar/2 \right) \left[ \sin \left( \theta/2 \right) \cos \left( \theta/2 \right) \exp \left \lbrace i \phi  \right \rbrace + \sin \left( \theta/2 \right) \cos \left( \theta/2 \right) \exp \left \lbrace - i \phi  \right \rbrace \right] \vec{i} \\
&+ \left( \hbar/2 \right) \left[- i \sin \left( \theta/2 \right) \cos \left( \theta/2 \right) \exp \left \lbrace i \phi  \right \rbrace + i \sin \left( \theta/2 \right) \cos \left( \theta/2 \right) \exp \left \lbrace - i \phi  \right \rbrace  \right] \vec{j} \\
&+ \left( \hbar/2 \right) \left[\cos^{2} \left( \theta/2 \right) - \sin^{2} \left( \theta/2 \right)] \vec{k} \\
&= \left( \hbar/2 \right) \left[ \left( 1/2 \right) \sin \theta \exp \left \lbrace i \phi  \right \rbrace + \left( 1/2 \right) \sin \theta \exp \left \lbrace - i \phi  \right \rbrace \right] \vec{i} \\
&+ \left( \hbar/2 \right) \left[ \left( 1/2 \right) \sin \theta \sin \phi + \left( 1/2 \right) \sin \theta \sin \phi \right] \vec{j} \\
&+ \left( \hbar/2 \right) \cos \theta \vec{k} \\
&= \left( \hbar/2 \right) \left[\sin \theta \cos \phi \vec{i} + \sin \theta \sin \phi \vec{j} + \cos \theta \vec{k}\right] = \left( \hbar/2 \right) \hat{n.}
\end{align*}

The resultant after matrix multiplication for \(\left \langle \hat{n} - \left \lvert \vec{\sigma}  \right \rvert \hat{n} - \right \rangle\) will be /exactly/ the same as that for \(\left \langle \hat{n} + \left \lvert \vec{\sigma}  \right \rvert \hat{n} + \right \rangle\) because the action of \(S_{x}\), \(S_{y}\) is to simply ``spin" the coordinate system so that \(x \to y\) and \(y \to x\) and then scale with \(\hbar/2\) and \(\mp i\hbar/2\) respectively. \(S_{z}\) implements \(x \to x\) and \(y \to y\) followed by a scaling with \(\pm \hbar/2\) respectively. Then the signs will conspire to cause the requisite reduction. What? You should be able to do this sort of stuff in your head.
** SOLVED Problem 14.3.3
CLOSED: [2022-11-10 Thu 23:09]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 22:57]--[2022-11-10 Thu 23:09] =>  0:12
:END:
*Using* \(\text{Eq.} (14.3.32)\) *and* \(\text{Eq.} (14.3.33)\) *show that the Pauli matrices are traceless.*

We have to use

\begin{align*}
\sigma_{i} \sigma_{j} = - \sigma_{j} \sigma_{i} \qquad \left( i \neq j \right),
\end{align*}

and

\begin{align*}
\sigma_{i} \sigma_{j} = i \sigma_{k} \quad \text{cyclic permutations of \(i\), \(j\), \(k\),}
\end{align*}

to show that \(\tr \sigma_{i} = 0, \quad i = x, y, z\).

\begin{align*}
\tr \left( \sigma_{k} \right) = \tr \left( \dfrac{\sigma_{i} \sigma_{j}}{i} \right) = \tr \left( \dfrac{- \sigma_{j} \sigma_{i}}{i} \right) = - \tr \left( \dfrac{\sigma_{j} \sigma_{i}}{i} \right), \qquad i \neq j.
\end{align*}

But \(\tr AB = \tr BA\). \(\tr AB = - \tr BA \Longrightarrow \tr AB = 0\). Therefore \(\tr \left( \sigma_{k} \right) = 0\).

** SOLVED Problem 14.3.4
CLOSED: [2022-11-11 Fri 04:03]
:LOGBOOK:
CLOCK: [2022-11-10 Thu 23:19]--[2022-11-11 Fri 04:03] =>  4:44
:END:
*Derive* \(\text{Eq.} (14.3.39)\) *in two different ways.*

Here's the ask:

\begin{align*}
\left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right) = \vec{A} \cdot \vec{B} I + i \left( \vec{A} \times \vec{B} \right) \cdot \vec{\sigma}.
\end{align*}

*(1)* *Write* \(\sigma_{i} \sigma_{j}\) *in terms of* \(\left[ \sigma_{i}, \sigma_{j} \right]_{+}\) *and* \(\left[ \sigma_{i}, \sigma_{j} \right]\).

\begin{align*}
\left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right) &= \left( A_{i} \sigma_{i} \right) \left( B_{j} \sigma_{j} \right) \\
&= A_{i} B_{j} \sigma_{i} \sigma_{j} \\
&= A_{i} B_{j} \left(\dfrac{1}{2} \left[ \sigma_{i}, \sigma_{j} \right]_{+} + \dfrac{1}{2} \left[ \sigma_{i}, \sigma_{j} \right]\right) \\
&= A_{i} B_{j} \delta_{ij} I + i \sigma_{k} \epsilon_{kij} A_{i} B_{j} \\
&= \vec{A} \cdot \vec{B} I + i \sigma_{k} \left( \vec{A} \times \vec{B} \right)_{k} \\
&= \vec{A} \cdot \vec{B} I + i \left( \vec{A} \times \vec{B} \right) \cdot \vec{\sigma}.
\end{align*}

We have: (1) represented the dot product using index notation, (2) invoked \(\left[ A_{i}, \sigma_{i} \right] = \left[ B_{j}, \sigma_{j} \right] = 0\) for all \(i\) and \(j\), (3) used \(\sigma_{i} \sigma_{j} = \dfrac{1}{2} \left[ \sigma_{i}, \sigma_{j} \right]_{+} + \dfrac{1}{2} \left[ \sigma_{i}, \sigma_{j} \right]\), (4) used the property

\begin{align*}
\left[ \sigma_{i}, \sigma_{j} \right]_{+} = 2 \delta_{ij} I \quad \text{and} \quad \left[ \sigma_{i}, \sigma_{j} \right] = \epsilon_{ijk} \sigma_{k}
\end{align*}

of the Pauli matrices, (5) fired the Kronecker and identified \(\epsilon_{kij} A_{i} B_{j} \equiv \left(\vec{A} \times \vec{B}\right)_{k}\), and (6) identified

\begin{align*}
\left( \vec{A} \times \vec{B} \right)_{k} \sigma_{k} \equiv \left( \vec{A} \times \vec{B} \right) \cdot \vec{\sigma}.
\end{align*}

*(2)* *Use* \(\text{Eq.} (14.3.42)\) *and* \(\text{Eq.} (14.3.43)\).

\begin{align*}
M &\equiv m_{\alpha} \sigma_{\alpha} \equiv \left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right)
\end{align*}

\begin{align*}
m_{0} &= \dfrac{1}{2} \tr \left[\left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right) I \right] \\
&= \dfrac{1}{2} \tr \left[\left( \vec{A} \cdot \vec{\sigma} \right) \left(\vec{\sigma} \cdot \vec{B} \right) \right] = \dfrac{1}{2} A_{\alpha k}^{i} B^{\beta k}_{j} \sigma_{\beta l}^{j} \sigma^{\alpha l}_{i} \\
&= \dfrac{1}{2} \left(A_{\alpha k}^{j} B^{\beta k}_{j}\right) \left(\sigma_{\beta l}^{i} \sigma^{\alpha l}_{i}\right) = \dfrac{1}{2} \left(A_{\alpha k}^{j} B^{\beta k}_{j}\right) \tr \left(\sigma_{\beta} \sigma_{\alpha}\right) \\
&=  \left(A_{\alpha k}^{j} B^{\beta k}_{j}\right) \delta_{\beta \alpha} = \vec{A} \cdot \vec{B}.
\end{align*}

We have: (1,3) used commutativity of \(\vec{A}\) and \(\vec{B}\) with \(\vec{\sigma}\), (2) represented matrix multiplication as a /contraction/ and used the definition of the trace, (4) identified \((\sigma_{\beta l}^{i} \sigma_{i}^{\alpha l})\) as the trace of \(\sigma_{\beta} \sigma_{\alpha}\), and (5) used the property \(\tr \left(\sigma_{\alpha} \sigma_{\beta}\right) = 2 \delta_{\alpha \beta}\) of the Pauli matrices.

\begin{align*}
m_{1} &= \dfrac{1}{2} \tr \left(\left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right) \sigma_{1} \right) \\
&= \dfrac{1}{2} \tr \left[\sigma_{1} \sigma_{\alpha} \sigma_{\beta} \right] \left( A^{\alpha} B^{\beta} \right)  \\
&= i \epsilon_{1 \alpha \beta} \left( A^{\alpha} B^{\beta} \right) = i \left( \vec{A} \times \vec{B}  \right)_{1}.
\end{align*}

Similarly

\begin{align*}
m_{2} = i \left( \vec{A} \times \vec{B} \right)_{2} \quad \text{and} \quad m_{3} = i \left( \vec{A} \times \vec{B} \right)_{3}.
\end{align*}

Now reinstate our definition and furnish

\begin{align*}
\left( \vec{A} \cdot \vec{\sigma} \right) \left( \vec{B} \cdot \vec{\sigma} \right) \equiv M \equiv m_{\alpha} \sigma_{\alpha} = \vec{A} \cdot \vec{B} I + i \left( \vec{A} \times \vec{B} \right)_{\beta} \sigma_{\beta} = \vec{A} \cdot \vec{B} I + i \left( \vec{A} \times \vec{B} \right) \cdot \vec{\sigma}.
\end{align*}

** SOLVED Problem 14.3.5
CLOSED: [2022-11-11 Fri 04:25]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 04:10]--[2022-11-11 Fri 04:25] =>  0:15
:END:
*Express the following matrix* \(M\) *in terms of the Pauli matrices:*

\begin{align*}
M =
\begin{pmatrix}
\alpha & \beta \\
\gamma & \delta \\
\end{pmatrix}.
\end{align*}

\begin{align*}
M &\xrightarrow[]{S_{z} \text{basis}} \left( \dfrac{\alpha + \delta}{2} \right) I + \left( \dfrac{\beta + \gamma}{2} \right) \sigma_{x} + i \left( \dfrac{\beta - \gamma}{2} \right) \sigma_{y} + \left( \dfrac{\alpha - \delta}{2} \right) \sigma_{z}.
\end{align*}

Baam!

** SOLVED Problem 14.3.6
CLOSED: [2022-11-11 Fri 05:22]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 04:35]--[2022-11-11 Fri 05:22] =>  0:47
:END:
*(1)* *Argue that* \(\vert \hat{n}, + \rangle = U \left[ R \left( \phi \vec{k} \right) \right] U \left[ R \left( \theta \vec{j} \right) \right] \vert s_{z} = \hbar/2 \rangle\).

Because \(\hat{n}\) points in the direction \(\left( \theta, \phi \right)\),

\begin{align*}
\hat{n}_{z} = \cos \theta, \qquad \hat{n}_{x} = \sin \theta \cos \theta, \qquad \hat{n}_{y} = \sin \theta \sin \phi.
\end{align*}

With the obvious interpretation of \(\theta\) as the colatitude and \(\phi\) as the azimuth of the unit vector \(\hat{n}\), \(\hat{n}_{x}\), \(\hat{n}_{y}\), \(\hat{n}_{z}\)  take on meaning as its \(x\), \(y\), and \(z\) components in a rectangular coordinate system. Thus, a unit vector along \(z\) (\(\vert s_{z} = \hbar/2 \rangle\)) may be allowed to fall in the \(x-z\) plane to a colatitude \(\theta\) (this is rotation about \(y\), effected by \(U \left[ R \left( \theta \vec{j} \right) \right]\)) and then swung about the \(z\) axis by azimuth \(\phi\) (this is rotation about \(z\), effected by \(U \left[ R \left( \phi \vec{k} \right) \right]\)) to coincide with \(\ket{\hat{n}, +}\). Thence:

\begin{align*}
\vert \hat{n}, + \rangle = U \left[ R \left( \phi \vec{k} \right) \right] U \left[ R \left( \theta \vec{j} \right) \right] \vert s_{z} = \hbar/2 \rangle.
\end{align*}

*(2)* *Verify by explicit calculation.*

I refuse to. Just kidding. Recall the result from =Exercise 12.5.5=

\begin{align*}
U \left[ R \right] = D^{(1/2)} (R) = \exp \left \lbrace - i \hat{\theta} \cdot \vec{J}^{(1/2)} / \hbar \right \rbrace = \cos \left( \theta /2 \right) I^{(1/2)} - \left( 2 i / \hbar \right) \sin \left( \theta/2 \right) \hat{\theta} \cdot \vec{J}^{(1/2)}.
\end{align*}

Toss \(\vec{L}^{(1/2)}\) into the can so that \(\vec{J}^{(1/2)} \to \vec{S}^{(1/2)}\), \(\hat{\theta} \to \theta \vec{j}\). We have

\begin{align*}
U \left[ R \left( \theta \vec{j} \right) \right] = \cos \left( \theta /2 \right) I - \left( 2 i / \hbar \right) \sin \left( \theta/2 \right)\sigma_{y} =
\begin{pmatrix}
\cos \theta/2 & - \sin \theta/2 \\
\sin \theta/2 & \cos \theta/2
\end{pmatrix}.
\end{align*}

Now toss \(\vec{L}^{(1/2)}\) into the can so that \(\vec{J}^{(1/2)} \to \vec{S}^{(1/2)}\) all the same, but let \(\hat{\theta} \to \phi \vec{k}\). We have

\begin{align*}
U \left[ R \left( \phi \vec{k} \right) \right] = \cos \left( \phi /2 \right) I - \left( 2 i / \hbar \right) \sin \left( \phi /2 \right)\sigma_{z} =
\begin{pmatrix}
\exp \left \lbrace - i \phi/2  \right \rbrace & 0 \\
0 & \exp \left \lbrace - i \phi/2  \right \rbrace
\end{pmatrix}.
\end{align*}

\begin{align*}
\vert \hat{n}, + \rangle &\stackrel{?}{=} U \left[ R \left( \phi \vec{k} \right) \right] U \left[ R \left( \theta \vec{j} \right) \right] \vert s_{z} = \hbar/2 \rangle \\
& \stackrel{?}{=}
\begin{pmatrix}
\exp \left \lbrace - i \phi/2  \right \rbrace & 0 \\
0 & \exp \left \lbrace - i \phi/2  \right \rbrace
\end{pmatrix}
\begin{pmatrix}
\cos \theta/2 & - \sin \theta/2 \\
\sin \theta/2 & \cos \theta/2
\end{pmatrix}
\begin{bmatrix}
1 \\
0 
\end{bmatrix} \\
& \stackrel{?}{=}
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace
\end{bmatrix}.
\end{align*}

You bet.
** SOLVED Problem 14.3.7
CLOSED: [2022-11-11 Fri 07:07]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 05:26]--[2022-11-11 Fri 07:07] =>  1:41
:END:
*Express the following as linear combinations of the Pauli matrices and* \(I\):

*(1)* \(\left( I + i \sigma_{x} \right)^{1/2}\). *(Relate it to half a certain rotation.)*

We continue to reap the benefits of having solved =Exercise 12.5.5=. Suppose that

\begin{align*}
\left(I + i \sigma_{x}\right)^{1/2} = \alpha \left[ \cos \left( \theta/2 \right) I^{(1/2)} - \left( 2i / \hbar \right) \sin \left( \theta/2 \right) S_{x} \right] \equiv R \left( \theta \vec{i} \right).
\end{align*}

Two consecutive applications of \(U \left[ R \left( \theta \vec{i} \right) \right]\) must furnish \(I + i \sigma_{x}\), i.e.,

\begin{align*}
\alpha^{2} \left[\cos \left( \theta /2 \right) I^{(1/2)} - \left( 2 i / \hbar \right) \sin \left( \theta/2 \right) S_{x} \right] \left[ \cos \left( \theta /2 \right) I^{(1/2)} - \left( 2 i / \hbar \right) \sin \left( \theta/2 \right) S_{x} \right] \equiv I + i \sigma_{x}
\end{align*}

for some \(\theta\). After multiplying and simplification we have

\begin{align*}
\alpha^{2}
\begin{pmatrix}
\cos \theta &  i \sin \theta \\
i \sin \theta & \cos \theta
\end{pmatrix} =
\begin{pmatrix}
1 & i \\
i & 1
\end{pmatrix},
\end{align*}

or better

\begin{align*}
\alpha^{2} \cos \theta I + i \alpha^{2} \sin \theta \sigma_{x} = I + i \sigma_{x}.
\end{align*}

Clearly we need \(\theta = \pi/4\) and \(\alpha^{2} = 2^{1/2}\). Therefore

\begin{align*}
\left( I + i \sigma_{x} \right)^{1/2} = 2^{1/4} \left[ \cos \left( \pi/8 \right)I - i \sin \left( \pi/8 \right) \sigma_{x} \right].
\end{align*}

*(2)* \(\left( 2 I + \sigma_{x} \right)^{-1}\).

Just need the inverse of

\begin{align*}
M \equiv 2 \begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
+
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix} =
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}.
\end{align*}

Let

\begin{align*}
M^{-1} \equiv
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}.
\end{align*}

Necessarily

\begin{align*}
2a + b = 1, \qquad a + 2b = 0, \qquad 2c + d = 0, \qquad c + 2d = 1.
\end{align*}

Solve to furnish

\begin{align*}
a = d = \dfrac{2}{3}, \qquad b = c = -\dfrac{1}{3}.
\end{align*}

Therefore

\begin{align*}
\left( 2I + \sigma_{x} \right)^{-1} = \left( 2/3 \right) I - \left( 1/3 \right) \sigma_{x}.
\end{align*}

*(3)* \(\sigma_{x}^{-1}\).

From \(\sigma_{x}^{-1} \sigma_{x} = I = \sigma_{x} \sigma_{x}\), immediately furnish \(\sigma_{x}^{-1} = \sigma_{x}\). Pauli is its own inverse.

** SOLVED Problem 14.3.8
CLOSED: [2022-11-11 Fri 13:15]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 12:51]--[2022-11-11 Fri 13:15] =>  0:24
CLOCK: [2022-11-11 Fri 08:26]--[2022-11-11 Fri 10:10] =>  1:44
:END:
*(1)* *Show that any matrix that commutes with \(\vec{\sigma}\) is a multiple of the unit matrix.*

We want to establish

\begin{align*}
\left[ M, \vec{\sigma} \right] = \vec{0} \Longrightarrow M = a I, \qquad a \thinspace \text{complex.}
\end{align*}

Say
\begin{align*}
M =
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}.
\end{align*}

Then

\begin{align*}
\sigma_{0} M \sigma_{0} = M,
\end{align*}

\begin{align*}
\sigma_{1} M \sigma_{1} &=
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}
=
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}
\begin{pmatrix}
b & a \\
d & c
\end{pmatrix}
=
\begin{pmatrix}
d & c \\
b & a
\end{pmatrix},
\end{align*}

\begin{align*}
\sigma_{2} M \sigma_{2} =
\begin{pmatrix}
0 & -i \\
i & 0
\end{pmatrix}
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\begin{pmatrix}
0 & -i \\
i & 0
\end{pmatrix}
=
\begin{pmatrix}
0 & -i \\
i & 0
\end{pmatrix}
\begin{pmatrix}
i b & -i a \\
i d & -i c
\end{pmatrix}
=
\begin{pmatrix}
d & - c \\
-b & a
\end{pmatrix},
\end{align*}

and

\begin{align*}
\sigma_{3} M \sigma_{3} =
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix} =
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}
\begin{pmatrix}
a & -b \\
c & -d
\end{pmatrix}
=
\begin{pmatrix}
a & -b \\
-c & d
\end{pmatrix}.
\end{align*}

Some trivialities immediately furnish:

\begin{align*}
\dfrac{1}{4} \sigma_{\alpha} M \sigma_{\alpha} = \dfrac{\tr M}{2} I.
\end{align*}

Note that this identity holds for /any/ positive definite matrix \(M\), whether or not it commutes with \(\vec{\sigma}\). Specialize now to the case where it does commutes:

\begin{align*}
M \sigma_{\alpha} = \sigma_{\alpha} M \qquad \alpha = 1, \thinspace 2, \thinspace 3, \thinspace 4.
\end{align*}

Dot both sides with \(\vec{\sigma}\):

\begin{align*}
\sigma_{\alpha} M \sigma_{\alpha} = 4M.
\end{align*}

Now feed

\begin{align*}
\sigma_{\alpha} M \sigma_{\alpha} &= 2
\begin{pmatrix}
a + d & 0 \\
0 & a + d
\end{pmatrix},
\end{align*}

as previously obtained into \(\sigma_{\alpha} M \sigma_{\alpha} = 4M\) to obtain

\begin{align*}
&\frac{1}{2}
\begin{pmatrix}
a + d & 0 \\
0 & a + d
\end{pmatrix} =
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix} 
\Longrightarrow c = b = 0, \quad \text{and} \quad a = d.
\end{align*}

Thus

\begin{align*}
M =
\begin{pmatrix}
a & 0 \\
0 & a
\end{pmatrix}.
\end{align*}

This establishes:

\begin{align*}
\left[ M, \vec{\sigma} \right] = \vec{0} \Longrightarrow M = a I, \qquad a \thinspace \text{complex.}
\end{align*}

*(2)* *Show that we cannot find a matrix that anticommutes with all three Pauli matrices. (If such a matrix exists, it must equal zero.)*

Suppose that we can. Let \(A\) be a matrix that anti-commutes with all the Pauli matrices. Then we have

\begin{align*}
\left[ M, \sigma_{\alpha} \right]_{+} = 0 \quad \text{for} \quad \alpha = 1, \thinspace 2, \thinspace 3, \thinspace 4.
\end{align*}

Further suppose:

\begin{align*}
M \xrightarrow[]{S_{z} \text{basis}}
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}.
\end{align*}

We can use the matrix multiplications we have already done:

\begin{align*}
M \sigma_{\alpha} = - \sigma_{\alpha} M \Longrightarrow \sigma_{\alpha} M \sigma_{\alpha} = - 4 M.
\end{align*}

\begin{align*}
\sigma_{\alpha} M \sigma_{\alpha} &= \dfrac{1}{2}
\begin{pmatrix}
a + d & 0 \\
0 & a + d
\end{pmatrix} = -
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix} \\
&\Longrightarrow c = b = 0, \quad \dfrac{1}{2} \left( a + d \right) = -a, \quad \text{and} \quad \dfrac{1}{2} \left( a + d \right) = -d.
\end{align*}

The last two consequent equations imply

\begin{align*}
a = -\left(1/3 \right) d \quad \text{and} \quad a = - 3d \quad \Longrightarrow d = a = 0.
\end{align*}

The only matrix that anticommutes with all three Pauli matrices is a matrix full of zeros, a trivial one.
** SOLVED Problem 14.4.1
CLOSED: [2022-11-11 Fri 15:18]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 14:59]--[2022-11-11 Fri 15:18] =>  0:19
CLOCK: [2022-11-11 Fri 13:23]--[2022-11-11 Fri 14:33] =>  1:10
:END:
*Show that if* \(H = - \gamma \vec{L} \cdot \vec{B}\), and \(\vec{B}\) *is position independent,*

\begin{align*}
D_{t} \left \langle \vec{L}  \right \rangle = \left \langle \mu \times \vec{B}  \right \rangle = \left \langle \mu  \right \rangle \times \vec{B}
\end{align*}

*Comparing this to* \(\text{Eq.} (14.4.8)\), *we see that* \(\left \langle \vec{\mu}  \right \rangle\) *evolves exactly like* \(\vec{\mu}\). *Notice that this conclusion is valid even if* \(\vec{B}\) *depends on time and also if we are talking about spin instead of orbital angular momentum. A more explicit verification follows in* \(\text{Exercise} \thinspace 14.4.3\).

Using /Ehrenfest's theorem/

\begin{align*}
D_{t} \left \langle L \right \rangle &= \left( -\dfrac{i}{\hbar} \right) \left \langle \psi \left \lvert \left[ L, - \gamma \vec{L} \cdot \vec{B} \right]  \right \rvert \psi \right \rangle \\
&= \left( - \dfrac{i}{\hbar} \right) \left \langle \psi \left \lvert - \gamma \vec{L} \vec{L} \cdot \vec{B} + \gamma \vec{L} \cdot \vec{B} \vec{L} \right \rvert \psi \right \rangle \\
&= \left( \dfrac{i \gamma}{\hbar} \right) \left \langle \psi \left \lvert \left[ L_{i}, L_{j} B_{j} \right] \right \rvert \psi \right \rangle \\
&= \left( \dfrac{i \gamma}{\hbar} \right) \left \langle \psi \left \lvert \left[ L_{i}, L_{j} \right] B_{j} + L_{j} \left[ L_{i}, B_{j} \right] \right \rvert \psi \right \rangle \\
&= \left( \dfrac{i \gamma}{\hbar} \right) \left \langle \psi \left \lvert i \hbar \epsilon_{ijk} L_{k} B_{j} + L_{j} \left[ L_{i}, B_{j} \right] \right \rvert \psi \right \rangle.
\end{align*}

\(\left[ L_{i}, L_{j} \right] = i \hbar \epsilon_{ijk} L_{k}\) has been invoked. The commutator \(\left[ L_{i}, B_{j} \right]\) vanishes because \(\vec{B}\) is position independent. We continue

\begin{align*}
D_{t} \left \langle \vec{L} \right \rangle &= \left( \dfrac{i \gamma}{\hbar} \right) \left \langle \psi \left \lvert i \hbar \epsilon_{ijk} L_{k} B_{j} \right \rvert \psi \right \rangle \\
&= - \left( \dfrac{e}{2 m c} \right) \gamma \left \langle \psi \left \lvert \vec{\mu} \times \vec{B} \right \rvert \psi \right \rangle \\
&= - \left( \dfrac{2 m c}{e} \right) \left( - \dfrac{e}{2 m c} \right) \left \langle \psi \left \lvert \vec{\mu} \times \vec{B} \right \rvert \psi \right \rangle \\
&= \left \langle \psi \left \lvert \vec{\mu} \times \vec{B} \right \rvert \psi \right \rangle = \left \langle \vec{\mu} \times \vec{B} \right \rangle.
\end{align*}

Since \(\vec{B}\) is position independent

\begin{align*}
D_{t} \left \langle \vec{L}  \right \rangle = \left \langle \vec{\mu}  \right \rangle \times \vec{B}.
\end{align*}

** SOLVED Problem 14.4.2
CLOSED: [2022-11-12 Sat 22:58]
:LOGBOOK:
CLOCK: [2022-11-11 Fri 15:21]--[2022-11-11 Fri 16:14] =>  0:53
:END:
*Derive* \(\text{Eq.} (14.4.31)\) *by studying* \(\text{Fig.} 14.3\).

\begin{align*}
\mu_{z} \left( t \right) &= \mu \cos^{2} \alpha + \mu \sin^{2} \alpha \cos \omega_{r} t \\
&= \mu_{z} \left( 0 \right) \left[ \dfrac{\left( \omega_{0} - \omega \right)^{2}}{\left( \omega_{0} - \omega \right)^{2} + \gamma^{2} B^{2}} + \dfrac{\gamma^{2} B^{2} \cos \omega_{r} t}{\left( \omega_{0} - \omega \right)^{2} + \gamma^{2} B^{2}} \right].
\end{align*}

Just stare at it till it's obvious.

** SOLVED Problem 14.4.3
CLOSED: [2022-11-12 Sat 17:47]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 12:59]--[2022-11-12 Sat 17:47] =>  4:48
CLOCK: [2022-11-11 Fri 17:41]--[2022-11-11 Fri 20:46] =>  3:05
:END:
*We would like to study here the evolution of a state that starts out as* \(\begin{bmatrix} 1 \\ 0 \end{bmatrix}\)  *and is subject to the* \(B\) *field given in* \(\text{Eq.} (14.4.27)\). *This state obeys*

\begin{align*}
i \hbar D_{t} \vert \psi \left( t \right) \rangle = H \vert \psi \rangle
\end{align*}

*where* \(H= - \gamma \vec{S} \cdot \vec{B}\), *and* \(\vec{B}\) *is time dependent. Since classical reasoning suggests that in a frame rotating at frequency* \(\left( - \omega \vec{k} \right)\) *the Hamiltonian should be time independent and governed by* \(\vec{B}\) [\(\text{Eq.}(14.4.29)\)], *consider the ket in the rotating frame,* \(\vert \psi_{r} \left( t \right) \rangle\), *related to* \(\ket{\psi \left( t \right)}\) *by a rotation angle* \(\omega t\):

\begin{align*}
\vert \psi_{r} \left( t \right) \rangle = \exp \left \lbrace - i \omega t S_{z}/ \hbar  \right \rbrace \vert \psi \left( t \right) \rangle.
\end{align*}

*Combine* \(\text{Eq.} (14.4.34)\) *and* \(\text{Eq.} (14.4.35)\) *to derive Schrodinger's equation for* \(\vert \psi_{r} \left( t \right) \rangle\) *in the* \(S_{z}\) *basis and verify that the classical expectation is borned out. Solve for* \(\vert \psi_{r} \left( t \right) \rangle = U_{r} \left( t \right) \vert \psi_{r} \left( 0 \right) \rangle\) *by computing* \(U_{r}(t)\), *the propagator in the rotating frame. Rotate back to the lab and show that*

\begin{align*}
\vert \psi \left( t \right) \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
\left[ \cos \left( \dfrac{\omega_{r}t}{2} \right) + i \dfrac{\omega_{0} - \omega}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) \right] \exp \left \lbrace + i \omega t/2  \right \rbrace \\
\dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) \exp \left \lbrace - i \omega t/ 2  \right \rbrace
\end{bmatrix}
\end{align*}

*Compare this to the state* \(\vert \hat{n}, + \rangle\) *and see what is happening to the spin for the case* \(\omega_{0} = \omega\). *Calculate* \(\left \langle \mu_{z} \left( t \right)  \right \rangle\) *and verify that it agrees with* \(\text{Eq.} (14.4.31)\).

Here's the field:

\begin{align*}
\vec{B} = B \cos \omega t \vec{i} - B \sin \omega t \vec{j} + B_{0} \vec{k}, \qquad \left( B \lll B_{0} \right).
\end{align*}

Here's the Schrodinger equation:

\begin{align*}
i \hbar D_{t} \vert \psi \left( t \right) \rangle = - \gamma \vec{S} \cdot \vec{B} \vert \psi \rangle
\end{align*}

\begin{align*}
\vert \psi \left( t \right) \rangle &\xrightarrow[]{\text{rotating frame}} \vert \psi_{r} \left( t \right) \rangle = \exp \left \lbrace - i \omega t S_{z}/ \hbar  \right \rbrace \vert \psi \left( t \right) \rangle \\
&\Longrightarrow \vert \psi \left( t \right) \rangle = \exp \left \lbrace i \omega t S_{z}/ \hbar \right \rbrace \vert \psi_{r} \left( t \right) \rangle.
\end{align*}

The Schrodinger equation for \(\ket{\psi_{r} \left( t \right)}\) is:

\begin{align*}
i \hbar D_{t} \vert \psi_{r} \left( t \right) \rangle = \dfrac{\hbar}{2} \exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \left[ \omega \sigma_{z} - \gamma \left( B \sigma_{x} \cos \omega t - B \sigma_{y} \sin \omega t \right) \right] \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace \vert \psi_{r} \rangle.
\end{align*}

We want to know

\begin{align*}
\exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \left[ \left( \omega - \gamma B_{0} \right) \sigma_{z} - \gamma \left( B \sigma_{x} \cos \omega t - B \sigma_{y} \sin \omega t \right) \right] \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace \stackrel{?}{\neq} f(t).
\end{align*}

We can toss out the first term inside the square bracket because \(\sigma_{z}\) acts as a \(c\) -number when sandwiched between exponentials of its scaled version: it can jump across, following which the exponentials will collide and annihilate - eviscerating all time dependence. Thereafter we can also toss out \(- \gamma B\). Thus we want to know

\begin{align*}
g(t) &\stackrel{?}{\neq} \cos \left( \omega t \right) \exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \sigma_{x} \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace \\
&- \sin \left( \omega t \right) \exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \sigma_{y} \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace
\end{align*}

Write \(\exp \left \lbrace i \omega t \sigma_{z} /2 \right \rbrace = \left[ \cos \left( \omega t/2 \right)I - i\sin \left( \omega t/2 \right) \sigma_{z} \right]\) and evaluate each term on the right by the turn:

\begin{align*}
\exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace &\sigma_{x} \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace \\
&= \left[ \cos \left( \omega t/2 \right)I - i \sin \left( \omega t/2 \right) \sigma_{z} \right] \sigma_{x} \left[ \cos \left( \omega t/2 \right)I + i \sin \left( \omega t/2 \right) \sigma_{z} \right] \\
&= \cos^{2} \left( \omega t /2  \right) \sigma_{x} \\
&+ \sin^{2} \left( \omega t /2 \right) \sigma_{z} \sigma_{x} \sigma_{z} \\
&+ i \cos \left( \omega t /2 \right) \sin \left( \omega t /2 \right) \sigma_{x} \sigma_{z} \\
&- i \cos \left( \omega t /2 \right) \sin \left( \omega t/2 \right) \sigma_{z} \sigma_{x} \\
&= \left[ \cos^{2} \left( \omega t /2 \right) - \sin^{2} \left( \omega t / 2 \right) \right] \sigma_{x} + 2 i \sin \left( \omega t /2  \right) \cos \left( \omega t /2 \right) \sigma_{x} \sigma_{z}. \\
&= \cos \left( \omega t \right) \sigma_{x} + i \sin \left( \omega t \right) \sigma_{x} \sigma_{z}.
\end{align*}

Similarly

\begin{align*}
\exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \sigma_{y} \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace = \cos \left( \omega t \right) \sigma_{y} + i \sin \left( \omega t \right) \sigma_{y} \sigma_{z}.
 \end{align*}

 Therefore
 
\begin{align*}
g(t) &\stackrel{?}{\neq} \cos^{2} \left( \omega t \right) \sigma_{x} + i \cos \left( \omega t \right) \sin \left( \omega t \right) \sigma_{x} \sigma_{z} - \sin \left( \omega t \right) \cos \left( \omega t \right) \sigma_{y} - i \sin^{2} \left( \omega t \right) \sigma_{y} \sigma_{z} \\
&= \cos^{2} \left( \omega t \right) \sigma_{x} + i \cos \left( \omega t \right) \sin \left( \omega t \right) \left( - i \sigma_{y} \right) - \sin \left( \omega t \right) \cos \left( \omega t \right) \sigma_{y} - i \sin^{2} \left( \omega t \right) \left( i \sigma_{x} \right) \\
&= \sigma_{x}.
\end{align*}

Indeed so, the classical expectations bear out. A careful backtrace, picking up the garbage, will furnish

\begin{align*}
f(t) &= \exp \left \lbrace - i \omega t \sigma_{z} / 2 \right \rbrace \left[ 2 \omega \sigma_{z} - \gamma \left( B \sigma_{x} \cos \omega t - B \sigma_{y} \sin \omega t \right) \right] \exp \left \lbrace i \omega t \sigma_{z} / 2 \right \rbrace \\
&= \left( \omega - \gamma B_{0} \right) \sigma_{z} - \gamma B \sigma_{x}.
\end{align*}

The Schrodinger equation in the rotating frame is thus

\begin{align*}
i \hbar D_{t} \vert \psi_{r} \left( t \right) \rangle = \left[ \left( \omega - \gamma B_{0} \right) S_{z} - \gamma B S_{x} \right] \vert \psi_{r} \rangle
\end{align*}

Next we need to solve for

\begin{align*}
\vert \psi_{r} \left( t \right) \rangle = U_{r} \left( t \right) \vert \psi_{r} \left( 0 \right) \rangle.
\end{align*}

Let's find the propagator first:

\begin{align*}
U_{r} \left( t \right) &= \exp \left \lbrace - i H t / \hbar  \right \rbrace \\
&= \exp \left \lbrace - i \left[ \left( \omega - \gamma B_{0} \right) S_{z} - \gamma B S_{x} \right] t / \hbar \right \rbrace \\
&= \exp \left \lbrace - i \vec{\omega}_{r} \cdot \vec{S} t / \hbar \right \rbrace, \qquad \vec{\omega}_{r} \equiv \left( - \gamma B \right) \vec{i} + \left( \omega - \omega_{0} \right) \vec{k}, \qquad \omega_{0} \equiv - \gamma B_{0} \\
&= \cos \left( \omega_{r} t /2 \right) I - i \sin \left( \omega_{r} t/2 \right) \left[ \left( \dfrac{- \gamma B}{\omega_{r}} \right)S_{x} + \left( \dfrac{\omega - \omega_{0}}{\omega_{r}} \right) S_{z} \right] \\
&=
\begin{pmatrix}
\cos \left( \dfrac{\omega_{r}}{2} \right) - i \left( \dfrac{\omega - \omega_{0}}{\omega_{r}} \right) \sin \left( \dfrac{\omega_{r} t}{2} \right) & \dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) \\
\dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) & \cos \left( \dfrac{\omega_{r}}{2} \right) + i \left( \dfrac{\omega - \omega_{0}}{\omega_{r}} \right) \sin \left( \dfrac{\omega_{r} t}{2} \right)
\end{pmatrix}.
\end{align*}


With \(\vert \psi_{r} \left( t \right) \rangle = U_{r} \left( t \right) \vert \psi_{r} \left( 0 \right) \rangle\) and $\vert \psi_{r} \left( 0 \right) \rangle = \vert \psi \left( 0 \right) \rangle = \begin{bmatrix}
                                                                                                                                                       1 \\
                                                                                                                                                       0 
                                                                                                                                                       \end{bmatrix}$,

\begin{align*}
\vert \psi_{r} \left( t \right) \rangle =
\begin{bmatrix}
\cos \left( \dfrac{\omega_{r}}{2} \right) - i \left( \dfrac{\omega - \omega_{0}}{\omega_{r}} \right) \sin \left( \dfrac{\omega_{r} t}{2} \right) \\
\dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) 
\end{bmatrix}
\end{align*}

Rotating back to the lab just requires a matrix multiplication with \(\exp \left \lbrace i \omega t S_{z}/ \hbar \right \rbrace = \left[ \cos \left( \omega t/2 \right)I - i\sin \left( \omega t/2 \right) \sigma_{z} \right]\), i.e.,

\begin{align*}
\begin{pmatrix}
\exp \left \lbrace + i \omega t/2  \right \rbrace & 0 \\
0 & \exp \left \lbrace - i \omega t/2  \right \rbrace
\end{pmatrix},
\end{align*}

we thus have:

\begin{align*}
\vert \psi \left( t \right) \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{pmatrix}
\exp \left \lbrace + i \omega t/2  \right \rbrace & 0 \\
0 & \exp \left \lbrace - i \omega t/2  \right \rbrace
\end{pmatrix}
\begin{bmatrix}
\cos \left( \dfrac{\omega_{r}}{2} \right) - i \left( \dfrac{\omega - \omega_{0}}{\omega_{r}} \right) \sin \left( \dfrac{\omega_{r} t}{2} \right) \\
\dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) 
\end{bmatrix} \\
=
\begin{bmatrix}
\left[ \cos \left( \dfrac{\omega_{r}t}{2} \right) + i \dfrac{\omega_{0} - \omega}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) \right] \exp \left \lbrace + i \omega t/2  \right \rbrace \\
\dfrac{i \gamma B}{\omega_{r}} \sin \left( \dfrac{\omega_{r} t}{2} \right) \exp \left \lbrace - i \omega t/ 2  \right \rbrace
\end{bmatrix}.
\end{align*}

** SOLVED Problem 14.4.4
CLOSED: [2022-11-12 Sat 18:25]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 17:47]--[2022-11-12 Sat 18:25] =>  0:38
:END:
*At* \(t= 0\), *an electron is in the state with* \(s_{z} = \hbar/2\). *A steady field* \(\vec{B} = B \vec{i}\), \(B = 100 \thinspace \text{G}\) *is turned on. How many seconds will it take for the spin to flip?*

What's the Hamiltonian?
\begin{align*}
H = - \vec{\mu} \cdot \vec{B} = -\gamma B S_{x} = -\dfrac{\hbar}{2}
\begin{pmatrix}
0 & \gamma B \\
\gamma B & 0
\end{pmatrix}.
\end{align*}
And the propagator?

\begin{align*}
U (t) &= \exp \left \lbrace - i H t / \hbar  \right \rbrace \\
&= \cos \left( B \gamma t /2 \right) I + i \sin \left( B \gamma t /2 \right) S_{x} \\
&=
\begin{pmatrix}
\cos \left( \gamma B t /2 \right) & i \sin \left( \gamma B t /2 \right) \\
i \sin \left( \gamma B t /2 \right) & \cos \left( \gamma B t /2 \right)
\end{pmatrix}.
\end{align*}

Where are we starting?

\begin{align*}
\vert \psi \left( 0 \right) \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
1 \\
0 
\end{bmatrix}.
\end{align*}

After time \(t\) where we at?

\begin{align*}
\vert \psi \left( t \right) \rangle =
\begin{bmatrix}
\cos \left( B \gamma t /2 \right) \\
i \sin \left( B \gamma t /2 \right)  
\end{bmatrix}.
\end{align*}

When's a spin flipped?

\begin{align*}
\begin{bmatrix}
1 \\
0 
\end{bmatrix}
\to
\begin{bmatrix}
0 \\
1 
\end{bmatrix} \exp \left \lbrace i \alpha t  \right \rbrace
\end{align*}

for some \(\alpha\).

What's the consequent demand?

\begin{align*}
\cos \left( B \gamma t/2 \right) = 0.
\end{align*}

And the solution?

\begin{align*}
t = \dfrac{\pi}{\gamma B} = \dfrac{\pi m c}{e B} \simeq 10^{-9} \text{ s}.
\end{align*}

** SOLVED Problem 14.4.5
CLOSED: [2022-11-12 Sat 21:11]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 18:37]--[2022-11-12 Sat 21:10] =>  2:33
:END:
*We would like to establish the validity of* \(\text{Eq.} (14.4.26)\) *when* \(\vec{\omega}\) *and* \(\vec{B}_{0}\) *are not parallel.*

Here's that equation:

\begin{align*}
\vec{B}_{r} = \vec{B}_{0} + \vec{\omega}/ \gamma.
\end{align*}

*(1)* *Consider a vector* \(\vec{V}\) *in the inertial (nonrotating) frame which changes by* \(\Delta \vec{V}\) *in a time* \(\Delta t\). *Argue, using the results from* =Exercise 12.4.3=, *that the change as seen in a frame rotating at an angular velocity* \(\vec{\omega}\), *is* \(\Delta \vec{V} - \vec{\omega} \times \vec{V} \Delta t\). *Obtain a relation between the time derivatives of* \(\vec{V}\) *in the two frames.*

A passive rotation by angle \(\vartheta (t)\) about \(\vec{\omega}\) transforms \(\vec{V}\) as

\begin{align*}
\vec{V}(t) \to \vec{V}(t) - \vec{\vartheta} (t) \times \vec{V}(t).
\end{align*}

After time \(\Delta t\)

\begin{align*}
\vec{V} \left( t + \Delta t \right) \to \vec{V}(t + \Delta t) - \vartheta (t + \Delta t) \times \vec{V}(t + \Delta t)
\end{align*}

Expand as a Taylor series to write

\begin{align*}
\vec{V} \left( t + \Delta t \right) \to \vec{V}(t) + \Delta t D_{t} \vec{V}(t) - \vartheta (t) \times \vec{V}(t) - \Delta t \thinspace \vec{\omega} \times \vec{V}(t) + \mathcal{O} \left( \Delta t \right)^{2}.
\end{align*}

Difference with \(\vec{V}(t) \to \vec{V}(t) - \vec{\vartheta} (t) \times \vec{V}(t)\) to obtain

\begin{align*}
\left(\Delta V\right)_{r} = \Delta V - \Delta t \thinspace \vec{\omega} \times \vec{V}.
\end{align*}

*(2)* *Apply this result to the case of* \(1\) [\(\text{Eq.} (14.4.8)\)], *and deduce the formula for the effective field in the rotating frame.*

The equation is

\begin{align*}
\vec{T} = D_{t} \vec{l} = \gamma \left( \vec{l} \times \vec{B}_{0} \right).
\end{align*}

Now we perform a passive rotation on \(\vec{l}\):

\begin{align*}
\left(D_{t} \vec{l} \right)_{r} &= D_{t} \vec{l} - \omega \times \vec{l} \\
&= \gamma \left( \vec{l} \times \vec{B}_{0} \right) + \vec{l} \times \omega \\
&= \gamma \left( \vec{l} \times \left[ \vec{B}_{0} + \vec{\omega}/ \gamma \right] \right),
\end{align*}

and identify the magnetic field in the rotating frame as

\begin{align*}
\vec{B}_{r} = \vec{B}_{0} + \vec{\omega}/ \gamma.
\end{align*}

** SOLVED Problem 14.4.6 A Density Matrix Problem
CLOSED: [2022-11-12 Sat 22:57]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 21:14]--[2022-11-12 Sat 22:56] =>  1:42
:END:
*(1)* *Show that the density matrix for an ensemble of spin* \(1/2\) *particles may be written as*

\begin{align*}
\rho = \dfrac{1}{2} \left(  I + \vec{a} \cdot \vec{\sigma} \right)
\end{align*}

*where* \(\vec{a}\) *is a* \(c\) -*number vector.*

The density matrix

\begin{align*}
\rho \equiv \sum_{i} p_{i} \vert i \rangle \langle i \vert,
\end{align*}

for an uniformly distributed ensemble over \(k\) pure states satisfies

\begin{align*}
\rho = \left( \dfrac{1}{k} \right) I.
\end{align*}

Let us consider the density matrix for spin \(1/2\) particles as a /uniformly distributed ensemble/ broken by some probability currents: implemented by a traceless (conservation of probability currents) matrix \(A/2\). Then:

\begin{align*}
\rho = \dfrac{1}{2} \left( I + A \right).
\end{align*}

Since the Pauli matrices span \(\mathbb{V}_{s}\), we may descend to representation

\begin{align*}
A = a_{i} \sigma_{i} = \vec{a} \cdot \vec{\sigma},
\end{align*}

so that

\begin{align*}
\rho = \dfrac{1}{2} \left( I + \vec{a} \cdot \vec{\sigma} \right).
\end{align*}

*(2)* *Show that* \(\vec{a}\) *is the mean polarization,* \(\left \langle \vec{\sigma} \right \rangle\).

Remember that \(\vec{a}\) is traceless. Also note that being within a trace is free pass for matrices to slide upto cyclic permutations. The ensemble average of \(\vec{\sigma}\) is

\begin{align*}
\left \langle \vec{\sigma} \right \rangle &= \tr \left( \vec{\sigma} \rho \right) = \dfrac{1}{2} \tr \left \lbrace \vec{\sigma} \left( \vec{a} \cdot \vec{\sigma} \right) \right \rbrace = \dfrac{1}{2} \tr \left \lbrace \sigma^{2} \vec{a} \right \rbrace \\
&= \dfrac{1}{2} \tr \left \lbrace I \vec{a} \right \rbrace = \dfrac{1}{2} \vec{a} \tr \left \lbrace I \right \rbrace = \vec{a}.
\end{align*}

*(3)* *An ensemble of electrons in a magnetic field* \(\vec{B}=B \vec{k}\), *is in thermal equilibrium at temperature* \(T\). *Construct the density matrix for this ensemble. Calculate* \(\left \langle \vec{\mu}  \right \rangle\).

In thermal equilibrium at temperature \(T\) the probabilities \(p_{i}\) in the density matrix

\begin{align*}
\rho \equiv \sum_{i} p_{i} \vert i \rangle \langle i \vert,
\end{align*}

are simply the ratios of the Boltzmann factor to the partition function, so we have

\begin{align*}
\rho &\equiv \dfrac{1}{Z} \sum_{i} \exp \left \lbrace - \beta H_{i}  \right \rbrace \vert i \rangle \langle i \vert, \qquad \beta = 1/k T.\\
&= \dfrac{1}{Z} \left[ \exp \left \lbrace \beta \mu_{k} B \right \rbrace \vert \uparrow \thinspace \rangle \langle \thinspace \uparrow \vert + \exp \left \lbrace - \beta \mu_{k} B \right \rbrace \vert \downarrow \thinspace \rangle \langle \thinspace \downarrow \vert \right] \\
&= \dfrac{1}{Z}
\begin{pmatrix}
\exp \left \lbrace \beta \mu_{k} B  \right \rbrace & 0 \\
0 & \exp \left \lbrace - \beta \mu_{k} B  \right \rbrace
\end{pmatrix}.
\end{align*}

Next

\begin{align*}
\left \langle \vec{\mu}  \right \rangle &= \dfrac{1}{Z} \tr \left( \mu \rho \right) = \dfrac{1}{Z} \left[\mu_{k} \exp \left \lbrace \beta \mu_{k} B \right \rbrace - \mu_{k} \exp \left \lbrace - \beta \mu_{k} B  \right \rbrace\right] \vec{k} \\
&= \mu_{k} \left( \dfrac{\exp \left \lbrace \beta \mu_{k} B \right \rbrace - \exp \left \lbrace - \beta \mu_{k} B  \right \rbrace}{\exp \left \lbrace - \beta \mu_{k} B  \right \rbrace + \exp \left \lbrace \beta \mu_{k} B \right \rbrace} \right) \vec{k} \\
&= \mu_{k} \tanh \left( \beta \mu_{k} B \right) \vec{k} \\
&= \left( e \hbar/ 2 m c \right) \tanh \left( e \hbar B/ 2 m c k T \right) \vec{k}.
\end{align*}

** SOLVED Problem 14.5.1
CLOSED: [2022-11-12 Sat 23:39]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 23:22]--[2022-11-12 Sat 23:39] =>  0:17
:END:
*(1)* *Why is the coupling of the proton's intrinsic magnetic moment to* \(\vec{B}\) *an order* \(m/M\) *correction to* \(\text{Eq.} (14.5.4)\) *?*

Because

\begin{align*}
\gamma_{p} = \dfrac{m}{M} \gamma_{e},
\end{align*}

(\(\gamma = q g / 2 m c\)).

*(2)* *Why is the coupling of its orbital magnetic moment an order* \((m/M)^{2}\) *correction? (You may reason classically in both parts.)*

Because

\begin{align*}
\vec{l}_{p} = \left( \dfrac{m}{M} \right) \vec{l}_{e} \Longrightarrow \mu_{p} \propto \left( \dfrac{m}{M} \right)^{2} \mu_{e},
\end{align*}

(\(\vec{\mu} = \left( gq/ 2 mc \right) \vec{L}\)).
** SOLVED Problem 14.5.2
CLOSED: [2022-11-13 Sun 01:13]
:LOGBOOK:
CLOCK: [2022-11-12 Sat 23:42]--[2022-11-13 Sun 01:12] =>  1:30
:END:
*(1)* *Estimate the relative size of the level splitting in the* \(n=1\) *state to the unperturbed energy of the* \(n=1\) *state, when a field* \(\vec{B} = 1000 \thinspace \text{kG}\) *is applied.*

We have

\begin{align*}
E_{n=1} = - \text{Ry} \pm \dfrac{e \hbar B}{2 m c}.
\end{align*}

With \(e \hbar/ 2 m c \simeq 0.6 \times 10^{-8} \text{eV/G}\) and \(\text{Ry} \simeq 13.6 \text{eV}\)

\begin{align*}
E_{n=1} = - 13.6 \pm 0.006 \text{ eV},
\end{align*}

so that the /relative size/ of the level splitting is \(0.006/13.6 \simeq 8 \times 10^{-4}\).

*(2)* *Recall that we have been neglecting the order* \(B^{2}\) *term in* \(H\). *Estimate its contribution in the* \(n=1\) *state relative to the linear* \(\left( - \mu \cdot \vec{B} \right)\) *term we have kept, by assuming the electron moves on a classical orbit of radius* \(a_{0}\). *Above what* \(\left \lvert \vec{B}  \right \rvert\) *does it begin to be a poor approximation?*
The dropped term is

\begin{align*}
\dfrac{e^{2} \left \lvert A  \right \rvert^{2}}{2 m c^{2}} \xrightarrow[]{\text{spherical coordinate basis}} \dfrac{e^{2} B^{2}}{8 m c^{2}} r^{2}.
\end{align*}

The relative contribution to energy is

\begin{align*}
E_{n=1, B^{2}}/E_{n=1, B} &= \left \langle \psi_{100} \left \lvert \dfrac{e^{2} B^{2}}{8 m c^{2}} r^{2}  \right \rvert \psi_{100} \right \rangle \Bigg / \left(\dfrac{e \hbar B}{2 m c}\right) \\
&\sim \dfrac{e B}{\hbar c} \left \langle r^{2}  \right \rangle_{n=1} = \dfrac{e B a_{0}^{2}}{\hbar c}.
\end{align*}

The approximation is poor when

\begin{align*}
\dfrac{E_{n=1, B^{2}}}{E_{n=1, B}} \gtrsim 1,
\end{align*}

i.e., when

\begin{align*}
B \gtrsim \dfrac{c \hbar}{e a_{0}^{2}} = \dfrac{c \hbar}{e a_{0}^{2}} \simeq \dfrac{\thinspace c \thinspace e^{4} m^{2}}{e \hbar^{3}} \simeq \left( \dfrac{e \hbar}{2 m c} \right)^{-1} \left( \dfrac{m e^{4}}{2 \hbar^{2}} \right) \sim 10^{9} G.
\end{align*}

** SOLVED Problem 14.5.3
CLOSED: [2022-11-13 Sun 03:44]
:LOGBOOK:
CLOCK: [2022-11-13 Sun 01:25]--[2022-11-13 Sun 03:44] =>  2:19
:END:
*A beam of spin* \(1/2\) *particles moving along the y axis goes through two collinear* \(\text{SG}\) *apparatuses, both with lower beams blocked. The first has its* \(\vec{B}\) *field along the* \(z\) *axis and the second has its* \(\vec{B}\) *field along the* \(x\) *axis (i.e., is obtained by rotating the first by an angle* \(\pi/2\) *about the* \(y\) *axis). What fraction of particles leaving the first will exit the second? If a third filter that transmits only spin up along the* \(z\) *axis is introduced, what fraction of particles leaving the first will exit the third? If the middle filter transmits both spins up and down (no blocking) the* \(x\) *axis, but the last one transmits only spin down the* \(z\) *axis, what fraction of particles leaving the first will leave the last?*

This relation will be useful:

\begin{align*}
\vert \hat{n}, + \rangle =
\begin{bmatrix}
\cos \left( \theta/2 \right) \exp \left \lbrace - i \phi/2  \right \rbrace \\
\sin \left( \theta/2 \right)  \exp \left \lbrace i \phi/2  \right \rbrace
\end{bmatrix}.
\end{align*}

We have

\begin{align*}
\vert x, + \rangle =
\begin{bmatrix}
2^{-1/2} \\
2^{-1/2} 
\end{bmatrix}
\end{align*}

To find the fractions, simply square the inner product of what came out with what went in.

First answer:

\begin{align*}
\left \lvert \left \langle x, + \vert z, + \right \rangle  \right \rvert^{2} = \dfrac{1}{2}.
\end{align*}

Second answer:

\begin{align*}
\left \lvert \left \langle z, + \vert x, + \right \rangle \right \rvert^{2} \left \lvert \left \langle x, + \vert z, + \right \rangle \right \rvert^{2} = \dfrac{1}{2} \times \dfrac{1}{2} = \dfrac{1}{4}.
\end{align*}

Last answer:

\begin{align*}
\left \lvert \left \langle z, - \vert x, + \right \rangle  \right \rvert^{2} \left \lvert \left \langle x, + \vert x, + \right \rangle  \right \rvert^{2} \left \lvert \left \langle x, + \vert z, + \right \rangle \right \rvert^{2} = \left \lvert \left \langle z, - \vert z, + \right \rangle  \right \rvert^{2} = 0.
\end{align*}

** SOLVED Problem 14.5.4
CLOSED: [2022-11-13 Sun 16:54]
:LOGBOOK:
CLOCK: [2022-11-13 Sun 15:22]--[2022-11-13 Sun 16:54] =>  1:32
CLOCK: [2022-11-13 Sun 03:23]--[2022-11-13 Sun 04:25] =>  1:02
:END:
*A beam of spin* \(1\) *particles, moving along the* \(y\) *axis, is incident on two collinear*  \(\text{SG}\) *apparatuses, the first with* \(\vec{B}\) *along the* \(z\) *axis and the second with* \(\vec{B}\) *along the* \(z^{\prime}\) *axis, which lies in the* \(x-z\) *plane at an angle* \(\theta\) *relative to the* \(z\) *axis. Both apparatuses transmit only the uppermost beams. What fraction leaving the first will pass the second?*

The particles are spin \(1\), so we have a three-dimensional Hilbert space \(\mathbb{V}_{s}\), a representation of the basis vectors:

\begin{align*}
\vert 1, 1 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}
\end{align*}

\begin{align*}
\vert 1, 0 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
\end{align*}

\begin{align*}
\vert 1, -1 \rangle \xrightarrow[]{S_{z} \text{basis}}
\begin{bmatrix}
0 \\
0 \\
1
\end{bmatrix},
\end{align*}

and the Pauli matrices

\begin{align*}
S_{x} = \dfrac{\hbar}{2^{1/2}}
\begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{pmatrix}
S_{y} = \dfrac{\hbar}{2^{1/2}}
\begin{pmatrix}
0 & -i & 0 \\
i & 0 & -i \\
0 & i & 0
\end{pmatrix}
S_{z} = \hbar
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0  & 0 \\
0 & 0  & -1
\end{pmatrix}.
\end{align*}

The direction we are interested in satisfies

\begin{align*}
\hat{n}_{z} = \cos \theta,
\end{align*}

\begin{align*}
\hat{n}_{x} = \sin \theta,
\end{align*}

\begin{align*}
\hat{n}_{y} = 0.
\end{align*}

The ket \(\vert \hat{n}, + \rangle\) is an eigenvector of

\begin{align*}
\hat{n} \cdot \vec{S} &= n_{x} S_{x} + n_{y} S_{y} + n_{z} S_{z} \\
&= \hbar
\begin{pmatrix}
\cos \theta & 2^{-1/2} \sin \theta & 0 \\
2^{-1/2} \sin \theta & 0 & 2^{-1/2} \sin \theta \\
0 & 2^{-1/2} \sin \theta & - \cos \theta
\end{pmatrix},
\end{align*}

let the eigenvector be

\begin{align*}
\vert \hat{n}, + \rangle =
\begin{bmatrix}
a \\
b \\
c
\end{bmatrix}.
\end{align*}

Imposing \(\hat{n} \cdot \vec{S} \vert \hat{n}, + \rangle = \hbar \vert \hat{n}, + \rangle\) and \(\left \langle \hat{n}, + \vert  \right \hat{n}, + \rangle = 1\), we get the /overcomplete/ system:

\begin{align*}
a \thinspace \cos \theta + b \thinspace \dfrac{1}{2^{1/2}} \sin \theta = a,
\end{align*}

\begin{align*}
a \thinspace \dfrac{1}{2^{1/2}} \sin \theta + c \thinspace \dfrac{1}{2^{1/2}} = b,
\end{align*}

\begin{align*}
b \thinspace \dfrac{1}{2^{1/2}} \sin \theta - c \thinspace \cos \theta = c,
\end{align*}

\begin{align*}
a^{2} + b^{2} + c^{2} = 1.
\end{align*}

One solution is

\begin{align*}
a = \dfrac{1+ \cos \theta}{2}, \qquad b = \dfrac{\sin \theta}{2^{1/2}}, \qquad c = \dfrac{1-\cos \theta}{2},
\end{align*}

so that

\begin{align*}
\vert \hat{n}, + \rangle = 2^{-1/2}
\begin{bmatrix}
2^{-1/2} \left( 1 + \cos \theta \right) \\
\sin \theta \\
2^{-1/2} \left( 1 - \cos \theta \right)
\end{bmatrix}.
\end{align*}

To find the fraction, we simply square the inner product of what came out with what went in:

\begin{align*}
\left \lvert \left \langle \hat{n}, + \vert z, + \right \rangle  \right \rvert^{2} = \left( \dfrac{1 + \cos \theta}{2} \right)^{2}.
\end{align*}
* Addition of Angular Momenta
:LOGBOOK:
CLOCK: [2022-11-13 Sun 17:04]--[2022-11-13 Sun 17:10] =>  0:06
:END:
** Notes
:LOGBOOK:
CLOCK: [2022-11-30 Wed 14:11]--[2022-11-30 Wed 17:11] =>  3:00
CLOCK: [2022-11-28 Mon 21:23]--[2022-11-29 Tue 12:04] => 14:41
:END:
*** _The general problem_
Consider two angular momenta \(\vec{J_{1}}\) and \(\vec{J_{2}}\). What are the eigenvalues and eigenkets of \(J^{2}\) and \(J_{z}\), where \(\vec{J} = \vec{J_{1}} + \vec{J_{2}}\)?

In the /product basis/ made of kets \(\vert j_1 m_1, j_2 m_2 \rangle\), \(J_{z}\) is diagonal. Its spectrum is degenerate. These product kets separate out into degenerate subspaces in which the sum of the magnetic quantum numbers \(m = m_{1} + m_{2}\) is invariant. In each degenerate eigenspace of \(J_{z}\), one has to take the available product kets and form linear combinations out of them to form a new basis in which \(J^{2}\) is diagonal.

What are the allowed values of \(j\)? Without loss of generality assume \(j_{1} > j_{2}\). \(j\) can take on values \(j_{1} + j_{2},j_{1} + j_{2} - 1, \dotso, j_{1} - j_{2}\), so that the number of total-\(j\) kets is:

\begin{align*}
\sum_{j=j_{1}-j_{2}}^{j_{1} + j_{2}} \left( 2j + 1 \right) = \sum_{j=0}^{j_{1}+j_{2}} \left( 2j + 1 \right) - \sum_{j=0}^{j_{1}-j_{2}-1} \left( 2j + 1 \right) = \left( 2j_{1} + 1 \right) \left( 2 j_{2} + 1 \right)
\end{align*}

same as the number of product kets \((2j_{1} + 1) \left( 2 j_{2} + 1 \right)\). Thus:

\begin{align*}
j_{1} \otimes j_{2} = \left( j_{1} + j_{2} \right) \oplus \left( j_{1} + j_{2} - 1 \right) \oplus \dotso \oplus \left( j_{1} - j_{2} \right).
\end{align*}

The total-\(j\) kets are:

\begin{align*}
\vert jm, j_{1} j_{2} \rangle \quad \text{with} \quad j_{1} + j_{2} \geq j \geq j_{1} - j_{2}, \qquad j \geq m \geq -j.
\end{align*}

The top state of a total-\(j\) ket with \(j = j_{1} + j_{2}\) and \(m = j_{1} + j_{2}\) can be built out of only /one/ product ket:

\begin{align*}
\vert j_{1} + j_{2}, j_{1} + j_{2} \rangle = \vert j_{1} j_{1}, j_{2} j_{2} \rangle.
\end{align*}

The action of \(J_{-}\) on \(\vert j_{1} + j_{2}, j_{1} + j_{2} \rangle\) is

\begin{align*}
J_{-} \vert j_{1} + j_{2}, j_{1} + j_{2} \rangle = \hbar \sqrt{2 \left( j_{1} + j_{2} \right)} \vert j_{1} + j_{2}, j_{1} + j_{2} - 1 \rangle.
\end{align*}

Therefore

\begin{align*}
\vert j_{1} + j_{2}, j_{1} + j_{2} - 1 \rangle &= \dfrac{1}{\hbar \sqrt{2 \left( j_{1} + j_{2} \right)}} \thinspace J_{-} \vert j_{1} + j_{2}, j_{1} + j_{2} \rangle \\
&= \dfrac{1}{\hbar \sqrt{2 \left( j_{1} + j_{2} \right)}} \left( J_{1-} + J_{2-} \right) \vert j_{1} + j_{2}, j_{1} + j_{2} \rangle \\
&= \sqrt{\dfrac{j_{1}}{j_{1} + j_{2}}} \thinspace \thinspace \vert j_{1} -1 + j_{2}, j_{1} + j_{2} \rangle \\
&+ \sqrt{\dfrac{j_{2}}{j_{1} + j_{2}}} \vert j_{1} + j_{2}, j_{1} + j_{2} - 1 \rangle \\
&= \sqrt{\dfrac{j_{1}}{j_{1} + j_{2}}} \thinspace \vert j_{1} \left( j_{1} -1 \right), j_{2} j_{2} \rangle \\
&+ \sqrt{\dfrac{j_{2}}{j_{1} + j_{2}}} \thinspace \vert j_{1} j_{1}, j_{2} \left( j_{2} - 1 \right) \rangle
\end{align*}

The top state of a total-\(j\) ket \(j = j_{1} + j_{2} - 1\) with \(m = j_{1} + j_{2} - 1\) can be built out of /two/ product ket: \(\vert j_1 j_1, j_2 \left( j_2 - 1 \right) \rangle\) and \(\vert j_{1} \left( j_{1} - 1 \right), j_{2} j_{2} \rangle\). We have two conditions:

1) A linear combination of these kets must be normalized to unity,
2) It must be orthogonal to the ket \(\vert (j_{1}+j_{2})(j_{1}+j_{2}-1) , j_1 j_2 \rangle\).

By inspection:

\begin{align*}
\vert j_{1} + j_{2} - 1, j_{1} + j_{2} - 1 \rangle &= \sqrt{\dfrac{j_{1}}{j_{1} + j_{2}}} \vert j_{1} j_{1}, j_{2} \left( j_{2} - 1 \right) \rangle \\
&- \sqrt{\dfrac{j_{2}}{j_{1} + j_{2}}} \vert j_{1} \left( j_{1} - 1 \right), j_{2} j_{2} \rangle
\end{align*}

The overall sign is fixed by the requirement that the coefficient of the product ket with \(m_{1} = j_{1}\) be positive.

The top state of a total-\(j\) ket with \(j = j_{1} + j_{2} - 2\) and \(m = j_{1} + j_{2} - 2\) can be built out of /three/ product kets: \(\vert j_1 j_1, j_2 \left( j_2 - 2 \right) \rangle\), \(\vert j_1 \left( j_{1} - 2 \right), j_2 j_2 \rangle\), and \(\vert j_1 \left( j_{1} - 1 \right), j_2 \left( j_2 - 1 \right) \rangle\). We have three conditions:

1) A linear combination of these kets must be normalized to unity,
2) It must be orthogonal to \(\vert (j_{1}+j_{2})(j_{1}+j_{2}-2) , j_1 j_2 \rangle\),
3) It must be orthogonal to \(\vert (j_{1}+j_{2}-1)(j_{1}+j_{2}-2) , j_1 j_2 \rangle\).

It is clear that there are always enough constraints to determine the top states of each \(j\), and once the top states are known, the rest can be obtained by use of \(J_{-}\).
*** _Clebsch-Gordan (CG) coefficients_
The completeness of the product kets allows us to write the total-\(j\) kets as:

\begin{align*}
\vert jm, j_{1} j_{2} \rangle = \sum_{m_{1}, m_{2}} \vert j_{1} m_{1}, j_{2} m_{2} \rangle \left \langle j_{1} m_{1}, j_{2} m_{2} \vert jm, j_{1} j_{2} \right \rangle
\end{align*}

The coefficients of the expansion:

\begin{align*}
\left \langle j_{1} m_{1}, j_{2} m_{2} \left \lvert jm, j_{1} j_{2}  \right \rvert  \right \rangle \equiv \left \langle j_{1} m_{1}, j_{2} m_{2} \vert jm \right \rangle
\end{align*}

are called /Clebsch-Gordan coefficients/ or /vector addition coefficients/. The Clebsch-Gordan coefficients have the properties:

1) \(\left \langle j_1 m_1, j_2 m_2 \vert jm \right \rangle \neq 0\) only if \(j_{1} - j_{2} \leq j \leq j_{1} + j_{2}\) (/triangle inequality/,
2) \(\left \langle j_1 m_1, j_2 m_2 \vert jm \right \rangle \neq 0\) only if \(m_{1} + m_{2} = m\),
3) they are real (convention)
4) \(\left \langle j_1 j_1, j_2 \left( j - j_1 \right) \vert jj \right \rangle\) is positive (conventional)
5) \(\left \langle j_1 m_1, j_2 m_2 \vert jm \right \rangle = \left( -1 \right)^{j_{1} + j_{2} - j} \left \langle j_{1} \left( - m_{1} \right), j_{2} \left( -m_{2} \right)  \vert j \left( -m \right) \right \rangle\)

The fifth property halves the work we have to do: we start at the top state and work our way down to \(m = 0\) (or \(1/2\) if \(j\) is half-integral). The coefficients of the negative \(m\) states are then determined by this relation.

A matrix made up of the CG-coefficients is orthogonal and unitary. This follows from the fact that it relates one orthonormal basis to another. If we invert the matrix, we can write the product kets in terms of the total-\(j\) kets. The coefficients in this expansion are also CG coefficients:

\begin{align*}
\left \langle jm \vert j_{1} m_{1}, j_{2} m_{2} \right \rangle = \left \langle j_{1} m_{1}, j_{2} m_{2} \vert jm \right \rangle^{\ast} = \left \langle j_{1} m_{1}, j_{2} m_{2} \vert jm \right \rangle.
\end{align*}
*** _Addition of \(L\) and \(S\)_
The total angular momentum \(\vec{J} = \vec{L} + \vec{S}\) can have maximum value of \(j = l + s\) and a minimum value \(j = l - s\). We wish to express the total-\(j\) states \(\vert jm, ls \rangle\) in terms of product states \(\vert l m_o, s m_{s} \rangle\), where \(m_{o}\) is the orbital magnetic quantum number and \(m_{s}\) is the spin magnetic quantum number.

We expand the total-\(j\) states as:

\begin{align*}
\vert jm, l s \rangle = \sum_{m_{1}, m_{2}} \vert l m_{o}, s m_{s} \rangle \left \langle l m_{o}, s m_{s} \vert jm, l s \right \rangle
\end{align*}

The Clebsch-Gordan coefficients are:

\begin{align*}
\left \langle l m_{o}, s m_{s} \left \lvert jm, ls \right \rangle \equiv \left \langle l m_{o}, s m_{s} \left \lvert jm \right \rangle.
\end{align*}

As an example consider an electron bound to a proton in a state of orbital angular momentum \(l\). Since the electron has spin \(1/2\), its total angular momentum \(\vec{J} = \vec{L} + \vec{S}\) can have values of \(j = l \pm 1/2\). We wish to express the total-\(j\) states in terms of product states \(\vert l m_{o}, s m_{s} \rangle\). Since \(m_{s} = \pm 1/2\), at each \(m\) there will be at the most two eligible product kets. Let

\begin{align*}
\vert j = l+1/2, m \rangle = \alpha \vert l, m-1/2; 1/2, 1/2 \rangle + \beta \vert l, m+1/2; 1/2, -1/2 \rangle
\end{align*}

\begin{align*}
\vert j = l - 1/2, m \rangle = \alpha^{\prime} \vert l, m-1/2; 1/2, 1/2 \rangle + \beta^{\prime} \vert l, m + 1/2; 1/2, -1/2 \rangle
\end{align*}

The requirement that these states be orthonormal tells us that

\begin{align*}
\alpha^{2} + \beta^{2} = 1
\end{align*}

\begin{align*}
\alpha^{\prime}^{2} + \beta^{\prime}^{2} = 1
\end{align*}

\begin{align*}
\alpha \alpha^{\prime} + \beta \beta^{\prime} = 0.
\end{align*}

We need one more constraint. We do so by demanding:

\begin{align*}
J^{2} \vert j= l+1/2, m \rangle = \hbar^{2} \left( l + 1/2 \right) \left( l + 3/2 \right) \vert j=l+1/2, m \rangle.
\end{align*}

Writing

\begin{align*}
J^{2} = L^{2} + S^{2} + 2 L_{z} S_{z} + L_{-} S_{+} + L_{+} S_{-}
\end{align*}

we can deduce that (see =Exercise 15.2.4=)

\begin{align*}
\dfrac{\beta}{\alpha} = \left( \dfrac{l + 1/2 - m}{l + 1/2 + m} \right)^{1/2}.
\end{align*}

The previous condition, this, and the convention for the overall sign fix \(\vert j = l \pm 1/2, m \rangle\). (see =Exercise 15.2.4=)

\begin{align*}
\vert j = l \pm 1/2, m \rangle &= \dfrac{1}{\sqrt{2l + 1}} \Big [ \pm \sqrt{l + 1/2 \pm m} \thinspace \vert l, m-1/2; 1/2, 1/2 \rangle \\
&+ \sqrt{l + 1/2 \mp m} \thinspace \vert l, m + 1/2; 1/2, -1/2 \rangle \Big ]
\end{align*}

If the Hamiltonian contains just the Coulomb interaction, or, in addition, an interaction with a weak constant magnetic field, the product basis is adequate. The total-\(j\) basis is useful when considering the /spin-orbit interaction/ where the operator \(\vec{L} \cdot \vec{S} = \dfrac{1}{2} \left( J^{2} - L^{2} - S^{2} \right)\) enters the Hamiltonian.
*** _Irreducible tensor operators_
A /first-rank tensor/ \(\vert T^{(1)} \rangle\) is just a vector \(\vert V \rangle\) and is an element of vector space \(\mathbb{V}^{n}(R)\), i.e., may be written as:

\begin{align*}
\vert V \rangle = \sum_{i=1}^{n} v_{i} \vert i \rangle,
\end{align*}

where the kets \(\vert i \rangle\) form a basis for \(\mathbb{V}^{n}(R)\) and \(v_{i}\) are the components along these kets.

A /tensor operator/ of rank 1 is just a vector operator:

\begin{align*}
\vec{V} = \sum_{i=1}^{n} V_{i} \vert i \rangle.
\end{align*}

The operator \(V_{i}\) defined from \(\mathbb{V}^{n}(R)\) to \(\mathbb{V}^{n}(R)\) /transform like vectors/, i.e., under \(V_{i} \to U^{\dagger} V_{i} U\) respond as do the vector component \(v_{i}\) or equivalently, under \(V_{i} \to U V_{i} U^{\dagger}\), respond as do the basis kets \(\vert i \rangle\).

A /second-rank tensor/ \(\vert T^{(2)} \rangle\) is an element of the direct product space \(\mathbb{V}^{3}(R) \otimes \mathbb{V}^{3}(R)\), i.e., may be written as:

\begin{align*}
\vert T^{(2)} \rangle = \sum_{i=1}^{3} \sum_{j=1}^{3} t_{ij} \vert i \rangle \otimes \vert j \rangle.
\end{align*}

where the nine kets \(\vert i \rangle \otimes \vert j \rangle\) for a basis for \(\mathbb{V}^{3}(R) \otimes \mathbb{V}^{3}(R)\) and \(t_{ij}\) are the components along these kets.

A /tensor operator/ of rank 2 is:

\begin{align*}
\vert T^{(2)} \rangle = \sum_{i=1}^{3} \sum_{j=1}^{3} T_{ij} \vert i \rangle \otimes \vert j \rangle.
\end{align*}

The operator \(T_{ij}\) defined from \(\mathbb{V}^{n}(R) \otimes \mathbb{V}^{n}(R)\) to \(\mathbb{V}^{n}(R) \otimes \mathbb{V}^{n}(R)\) /transform like vectors/, i.e., under \(T_{ij} \to U^{\dagger} T_{ij} U\) respond as do the vector component \(T_{ij}\) or equivalently, under \(T_{ij} \to U T_{ij} U^{\dagger}\), respond as do the basis kets \(\vert i \rangle \otimes \vert j \rangle\).

Higher ranks may similarly be defined. These are called /Cartesian tensors/.

Another class of tensors are the /spherical tensor operators/. A spherical tensor operator of rank \(k\) has \(2k + 1\) components \(T_{k}^{q}\), \(q = +k, \left( k-1 \right), \dotso, -k\), which, under \(T_{k}^{q} \to U T_{k}^{q} U^{\dagger}\) respond like the angular momentum eigenkets \(\vert j = k, m=q \rangle = \vert kq \rangle\):

\begin{align*}
U \left[ R \right] T_{k}^{q} U^{\dagger} \left[ R \right] = \sum_{q^{\prime}} D_{q^{\prime} q}^{(k)} T_{k}^{q^{\prime}}.
\end{align*}

Since the \(2k + 1\) kets \(\vert kq \rangle\) transform irreducibly, so do the operators \(T_{k}^{q}\). For this reason, they are also called /irreducible tensor operators/. We have the identities (see =Exercise 15.3.1=):

\begin{align*}
\left[ J_{\pm}, T_{k}^{q} \right] = \pm \hbar \left[ \left( k \mp q \right) \left( k \pm q + 1 \right) \right]^{1/2} T_{k}^{q \pm 1},
\end{align*}

\begin{align*}
\left[ J_{z}, T_{k}^{q} \right] = \hbar q T_{k}^{q}.
\end{align*}

Commuting a \(J\) with \(T_{k}^{q}\) is like letting \(J\) act on the ket \(\vert kq \rangle\). Let \(U \left[ R \right] T_{k}^{q}\) act on the ket \(\vert \alpha l m \rangle\):

\begin{align*}
U \left[ R \right] T_{k}^{q} \vert jm \rangle &= U \left[ R \right] T_{k}^{q} U^{\dagger} \left[ R \right] U \left[ R \right] \vert jm \rangle \\
&= \sum_{q^{\prime}} D_{q^{\prime}q}^{(k)} T_{k}^{q^{\prime}} \sum_{m^{\prime}} D_{m^{\prime}m}^{(j)} \vert jm^{\prime} \rangle \\
&= \sum_{q^{\prime}} \sum_{m^{\prime}} D_{q^{\prime}q}^{(k)} D_{m^{\prime} m}^{(j)} T_{k}^{q^{\prime}} \vert j m^{\prime} \rangle.
\end{align*}

\(T_{k}^{q} \vert jm \rangle\) responds to rotations like the product ket \(\vert kq \rangle \otimes \vert jm \rangle\). /Thus, when we act on a state with/ \(T_{k}^{q}\), /we add angular momentum/ \((k,q)\) /to the state/. In other words, an irreducible operator \(T_{k}^{q}\) imparts a definite amount of angular momentum \((k,q)\) to the state it acts on. Thus, the matrix elements of \(T_{k}^{q}\) between angular momentum eigenkets is:

\begin{align*}
\left \langle \alpha^{\prime} j^{\prime} m^{\prime} \left \lvert T_{k}^{q}  \right \rvert \alpha j m \right \rangle = 0 \quad \text{unless} \quad k + j \geq j^{\prime} \geq \left \lvert k-j \right \rvert, \quad m^{\prime} = m+q.
\end{align*}

This is because \(T_{k}^{q} \vert \alpha j m \rangle\) contains only those angular momenta that can be obtained by adding \((k,q)\) and \((j,m)\); so \(\vert \alpha^{\prime} j^{\prime} m^{\prime} \rangle\) is orthogonal to \(T_{k}^{q} \vert jm \rangle\) unless \((j^{\prime}, m^{\prime})\) is one of the possible results of adding \((k, q)\) and \((j,m)\). The equation above is an example of a /selection rule/.

In general

\begin{align*}
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert T_{k}^q  \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = \left \langle \alpha_{2} j_{2} \left \lvert T_{k}  \right \rvert \alpha_{1} j_{1} \right \rangle \cdot \left \langle j_{2} m_{2} \vert kq, j_{1} m_{1} \right \rangle.
\end{align*}

This is called the /Wigner-Eckart theorem/. It seperates the dependence of the matrix element on spatial orientation (on \(m_{2}\), \(m_{1}\), and \(q\)) from the rest. The former is expressed entirely in terms of the CG coefficients.
** SOLVED Problem 15.1.1
CLOSED: [2022-11-13 Sun 18:54]
:LOGBOOK:
CLOCK: [2022-11-13 Sun 17:10]--[2022-11-13 Sun 18:54] =>  1:44
:END:
*Derive* \(\text{Eqs.} (15.1.10)\) *and* \(\text{Eqs.}(15.1.11)\). *It might help to use*

\begin{align*}
\vec{S}_{1} \cdot \vec{S}_{2} = S_{1z} S_{2z} + \dfrac{1}{2} \left( S_{1+} S_{2-} + S_{1-} S_{2+} \right).
\end{align*}

We have

\begin{align*}
S^{2} &= \left( \vec{S}_{1} + \vec{S}_{2} \right) \cdot \left( \vec{S}_{1} + \vec{S}_{2} \right) \\
&= S_{1}^{2} + S_{2}^{2} + 2 \vec{S}_{1} \cdot \vec{S}_{2} \\
&= S_{1}^{2} + S_{2}^{2} + S_{1+} S_{2-} + S_{1-} S_{2+} + 2 S_{1z} S_{2z}.
\end{align*}

Remember that the Pauli matrices anti-commute so \(S_{1+} S_{2-} + S_{1-} S_{2+} = 0\). Thus

\begin{align*}
S^{2} \vert + + \rangle &= S_{1}^{2} \vert + + \rangle + S_{2}^{2} \vert + + \rangle + S_{1+} S_{2-} \vert + + \rangle + S_{1-} S_{2+} \vert + + \rangle + \dfrac{1}{2} S_{1z} S_{2z} \vert + + \rangle \\
&= \dfrac{3 \hbar^{2}}{4} \vert + + \rangle
+ \dfrac{3 \hbar^{2}}{4} \vert + + \rangle
+ \left( S_{1+}S_{2-} + S_{1-} S_{2+} \right) \vert + + \rangle
+ \dfrac{\hbar^{2}}{2} \vert + + \rangle \\
&= \dfrac{3 \hbar^{2}}{4} \vert + + \rangle
+ \dfrac{3 \hbar^{2}}{4} \vert + + \rangle
+ \dfrac{\hbar^{2}}{2} \vert + + \rangle \\
&= 2 \hbar^{2} \vert + + \rangle.
\end{align*}

Similarly

\begin{align*}
S^{2} \vert - - \rangle = 2 \hbar^{2} \vert - - \rangle.
\end{align*}

Now

\begin{align*}
S^{2} \left( \dfrac{\vert + - \rangle + \vert - + \rangle}{2^{1/2}} \right) = 2 \hbar^{2} \left( \dfrac{\vert + - \rangle + \vert - + \rangle}{2^{1/2}} \right),
\end{align*}

since it's a \((s=1)\) state and

\begin{align*}
S^{2} \left( \dfrac{\vert + - \rangle - \vert - + \rangle}{2^{1/2}} \right) = 0 \left( \dfrac{\vert + - \rangle - \vert - + \rangle}{2^{1/2}} \right),
\end{align*}

since it's a \((s = 0)\) state. Add the two to obtain

\begin{align*}
S^{2} \vert + - \rangle = \hbar^{2} \left( \vert + - \rangle + \vert - + \rangle \right).
\end{align*}

Subtract the second from the first to obtain

\begin{align*}
S^{2} \vert - + \rangle = \hbar^{2} \left( \vert - + \rangle + \vert + - \rangle \right).
\end{align*}

We have what we need:

\begin{align*}
S^{2} \xrightarrow[]{\text{product basis}} \hbar^{2}
\begin{pmatrix}
2 & 0 & 0 & 0  \\
0 & 1 & 1 & 0 \\
0 & 1 & 1 & 0 \\
0 & 0 & 0 & 2
\end{pmatrix}.
\end{align*}
** TOSOLVE Problem 15.1.2                                         
*In addition to the Coulomb interaction, there exists another, called the /hyperfine interaction/, between the electron and proton in the hydrogen atom. The Hamiltonian describing this interaction, which is due to the magnetic moments of the two particles is,*

*(This formula assumes the orbital state of the electron is* \(\vert 1, 0, 0 \rangle\) *.) The total Hamiltonian is thus the Coulomb Hamiltonian plus* \(H_{\text{hf}}\).

*(1)* *Show that* \(H_{\text{hf}}\) *splits the ground state into two levels:*

*and that the corresponding states are triplets and singlets respectively.*

*(2)* *Try to estimate the frequency of the emitted radiation as the atom jumps from the triplet to the singlet. To do so, you may assume that the electron and proton are two dipoles* \(\mu_{e}\) *and* \(\mu_{p}\) *separated by a distance* \(a_{0}\), *with an interaction energy of the order*

\begin{align*}
\mathcal{H} \cong \dfrac{\mu_{e} \cdot \mu_{p}}{a_{0}^{3}}.
\end{align*}

*Show that this implies that the constant in* \(\text{Eq.} (15.1.22)\) *is*

\begin{align*}
A \sim \dfrac{2e}{2mc} \dfrac{\left( 5.6 \right) e}{2 M c} \dfrac{1}{a_{0}^{3}}.
\end{align*}

*(where* \(5.6\) *is the* \(g\) *factor for the proton), and that*

\begin{align*}
\Delta E = E_{+} - E_{-} = A \hbar^{2},
\end{align*}

*is a correction of order* \((m/M) \alpha^{2}\) *relative to the ground-state energy. Estimate that the frequency of emitted radiation is a few tens of centimeters, using the mnemonics of* =Chapter 13=. *The measured value is* \(21.4 \text{ cm}\). *This radiation, called the /21-cm line/, is a way to detect hydrogen in other parts of the universe.*

*(3)* *Estimate the probability ratio* \(P \left( \text{triplet} \right)/ P \left( \text{singlet} \right)\) *of hydrogen atoms in thermal equilibrium at room temperature.*
** TOSOLVE Problem 15.2.1                                         
*(1)* *Verify that* \(\vert j_1 j_1, j_2 j_2 \rangle\) *is indeed a state of* \(j=j_{1} + j_{2}\) *by letting* \(J^{2} = J_{1}^{2} + J_{2}^{2} + 2 J_{1z} J_{2z} + J_{1-} J_{2+}\) *act on it*.
*(2)* *(optional) Verify that the right-hand side of* \(\text{Eq.}(15.2.8)\) *indeed has angular momentum* \(j = j_{1} + j_{2} - 1\).
** TOSOLVE Problem 15.2.2                                         
*Find the CG coefficients of*

*(1)* \(\frac{1}{2} \otimes 1 = \frac{3}{2} \oplus \frac{1}{2}\),

*(2)* \(1 \otimes 1 = 2 \oplus 1 \oplus 0\).

** TOSOLVE Problem 15.2.3                                         
*Argue that* \(\dfrac{1}{2} \otimes \dfrac{1}{2} \otimes \dfrac{1}{2} = \dfrac{3}{2} \oplus \dfrac{1}{2} \oplus \dfrac{1}{2}\).
** TOSOLVE Problem 15.2.4                                         
*Derive* \(\text{Eq.} (15.2.19)\) *and* \(\text{Eq.} (15.2.20)\).
** TOSOLVE Problem 15.2.5                                         
*(1)* *Show that* \(\mathbb{P}_{1} = \dfrac{3}{4} I + \left( \vec{S}_{1} \cdot \vec{S}_{2} \right)/ \hbar^{2}\) *and* \(\mathbb{P}_{0} = \dfrac{3}{4} I - \left( \vec{S}_{1} \cdot \vec{S}_{2} \right) / \hbar^{2}\) *are projection operators, i.e., obey* \(\mathbb{P}_{i} \mathbb{P}_{j} = \delta_{ij} \mathbb{P}_{j}\) *[use* \(\text{Eq.} (14.3.39)\) *].*

*(2)* *Show that these project into the spin-1 and spin-0 spaces in* \(\frac{1}{2} \otimes \frac{1}{2} = 1 \oplus 0\).
** TOSOLVE Problem 15.2.6                                         
*Construct the project operators* \(\mathbb{P}_{\pm}\) for the \(j = l \pm 1/2\) subspaces in the addition \(\vec{L} + \vec{S} = \vec{J}\).
** TOSOLVE Problem 15.2.7                                         
*Show that when we add* \(j_{1}\) *to* \(j_{1}\), *the states with* \(j = 2j_{1}\) *are symmetric.* *Show that the states with* \(j = 2 j_{1} = 1\) *are antisymmetric. (Argue for the symmetry of the top states and show that lowering does not change symmetry.) This pattern of alternating symmetry continues as* \(j\) *decreases, but is harder to prove.*
** TOSOLVE Problem 15.3.1                                         
*(1)* *Show that* \(\text{Eq.} (15.3.11)\) *follows from* \(\text{Eq.} (15.3.10)\) *when one considers infinitesimal rotations.* *(Hint:* \(D_{q^{\prime}q}^{(k)} = \left \langle k q^{\prime} \left \lvert I - \left( i \delta \vec{\theta} \cdot \vec{J} \right)  \right \rvert k q \right \rangle\) *. Pick* \(\delta \vec{\theta}\) *along, say, the* \(x\) *direction and then generalize the result to the other directions.)*
*(2)* *Verify that the spherical tensor* \(V_{1}^{q}\) *constructed out of* \(V\) *as in* \(\text{Eq.} (15.3.15)\) *obeys* \(\text{Eq.} (15.3.11)\).
** TOSOLVE Problem 15.3.2                                         
*It is claimed that* \(\sum_{q} (-1)^{q} S_{k}^{q} T_{k}^{(-q)}\) *is a scalar operator.*

*(1)* *For* \(k=1\), *verify that this is just* \(\vec{S} \cdot \vec{T}\).

*(2)* *Prove it in general by considering its response to a rotation. [Hint: \(D_{-m,-m^{\prime}}^{(j)} = \left( -1 \right)^{m-m^{\prime}} \left( D_{m, m^{\prime}}^{(j)} \right)^{\ast}\) *.]*
** TOSOLVE Problem 15.3.3                                         
*(1)* *Using* \(\left \langle jj \vert jj, 10 \right \rangle = \left[ j/ \left( j + 1 \right) \right]^{1/2}\) *show that*

\begin{align*}
\left \langle \alpha j \left \lvert J_{1}  \right \rvert \alpha^{\prime} j^{\prime} \right \rangle = \delta_{\alpha \alpha^{\prime}} \delta_{j j^{\prime}} \hbar \left[ j \left( j + 1 \right) \right]^{1/2}.
\end{align*}

*(2)* *Using* \(\vec{J} \cdot \vec{A} = J_{z} A_{z} + \frac{1}{2} \left( J_{-}A_{+} + J_{+} A_{-} \right)\) *(where* \(A_{\pm} = A_{x} \pm i A_{y}\) *argue that*

\begin{align*}
\left \langle \alpha^{\prime} j m^{\prime} \left \lvert \vec{J} \cdot \vec{A} \right \rvert \alpha j m \right \rangle = c \left \langle \alpha^{\prime} j \left \lvert A  \right \rvert \alpha j \right \rangle
\end{align*}

*where* \(c\) *is a constant independent of* \(\alpha\), \(\alpha^{\prime}\) *and* \(\vec{A}\). *Show that* \(c = \hbar \left[ j \left( j + 1 \right) \right]^{1/2} \delta_{m, m^{\prime}}\).

*(3)* *Using the above, show that*

\begin{align*}
\left \langle \alpha^{\prime} j m^{\prime} \left \lvert A^{q}  \right \rvert \alpha j m \right \rangle = \dfrac{\left \langle \alpha^{\prime} j m \left \lvert \vec{J} \cdot \vec{A}  \right \rvert \alpha j m \right \rangle}{\hbar^{2} j \left( j + 1 \right)} \left \langle j m^{\prime} \left \lvert J^{q}  \right \rvert j m \right \rangle.
\end{align*}
** TOSOLVE Problem 15.3.4                                         
*(1)* *Consider a system whose angular momentum consists of two parts* \(\vec{J}_{1}\) *and* \(\vec{J}_{2}\) *and whose magnetic moment is*

\begin{align*}
\vec{\mu} = \gamma_{1} \vec{J}_{1} + \gamma_{2} \vec{J}_{2}.
\end{align*}

*In a state* \(\vert jm, j_{1} j_{2} \rangle\) *show, using* \(\text{Eq.} (15.3.19)\) *, that*

\begin{align*}
\left \langle \mu_{x}  \right \rangle = \left \langle \mu_{y}  \right \rangle = 0,
\end{align*}

\begin{align*}
\left \langle \mu_{z}  \right \rangle = m \hbar \left[ \dfrac{\gamma_{1} + \gamma_{2}}{2} + \dfrac{\left( \gamma_{1} - \gamma_{2} \right)}{2} \dfrac{j_{1} \left( j_{1} + 1 \right) - j_{2} \left( j_{2} + 1 \right)}{j \left( j + 1 \right)} \right].
\end{align*}

*(2)* *Apply this to the problem of a proton (* \(g = 5.6\) *) in a* \({}^{2}P_{1/2}\) *state and show that* \(\left \langle \mu_{z}  \right \rangle = \pm 0.26\) *nuclear magnetons.*

*(3)* *For an electron in a* \({}^{2}P_{1/2}\) *state show that* \(\left \langle \mu_z  \right \rangle = \pm \frac{1}{3}\) *Bohr magnetons.*
** TOSOLVE Problem 15.3.5                                         
*Show that* \(\left \langle jm \left \lvert T_k^q  \right \rvert jm \right \rangle = 0 \quad \text{if} \quad  k > 2j\).
* The Variational and WKB Methods                          
* Time-Independent Perturbation Theory
:LOGBOOK:
CLOCK: [2022-11-25 Fri 01:08]--[2022-11-25 Fri 03:17] =>  2:09
CLOCK: [2022-11-24 Thu 23:27]--[2022-11-25 Fri 00:06] =>  0:39
CLOCK: [2022-11-13 Sun 22:08]--[2022-11-13 Sun 23:57] =>  1:49
:END:
** Notes
*** _Non-degenerate perturbation theory._

We want to solve:

\begin{align*}
H \vert n \rangle = E_{n} \vert n \rangle, \qquad H = H^{0} + H^{1}.
\end{align*}

\(H^{0}\) is called the /unperturbed Hamiltonian/ and \(H^{1}\) is called a /perturbation/.

To proceed we /assume/:

1) \(H\) is /non-degenerate/.
2) the eigenkets and eigenvalues of \(H\) may be expanded in a /perturbation series/:

  \begin{align*}
  \vert n \rangle = \sum_{k} \vert n^{k} \rangle = \vert n^{0} \rangle +   \vert n^{1} \rangle + \vert n^{2} \rangle + \dotso,
   \end{align*} 

   \begin{align*}
   E_{n} = \sum_{k} E_{n}^{k} = E_{n}^{0} + E_{n}^{1} + E_{n}^{2} + \dotso.
   \end{align*}  

3) the perturbation \(H^{1}\) is /small/ i.e.,

   \begin{align*}
   \vert n^{k-1} \rangle \gg \vert n^{k} \rangle \quad \text{and} \quad    E_{n}^{k-1} \gg E_{n}^{k} \quad \text{for} \quad k \geq 1.
 \end{align*}  

4) There exists solutions for

   \begin{align*}
   H^{0} \vert n^{0} \rangle = E_{n}^{0} \vert n^{0} \rangle.
 \end{align*}  

5) there exists a one-to-one map \(\vert n^{0} \rangle \mapsto \vert n \rangle\) such that

   \begin{align*}
   H^{0} \vert n^{0} \rangle = E_{n}^{0} \vert n^{0} \rangle    \Longrightarrow H \vert n \rangle = E_{n} \vert n \rangle;
 \end{align*}  

With these assumptions \(H \vert n \rangle = E_{n} \vert n \rangle\) becomes:

\begin{align*}
\left( H^{0} + H^{1} \right) \left[ \vert n^{0} \rangle + \vert n^{1} \rangle + \dotso \right] = \left( E_{n}^{0} + E_{n}^{1} + \dotso \right) \left[ \vert n^{0} \rangle + \vert n^{1} \rangle + \dotso \right].
\end{align*}

To /zeroth-order/:

\begin{align*}
H^{0} \vert n^{0} \rangle = E_{n}^{0} \vert n^{0} \rangle.
\end{align*}

\(E_{n}^{0}\) and \(\vert n^0 \rangle\) are known by assumption.

To /first-order/:

\begin{align*}
H^{0} \vert n^{1} \rangle + H^{1} \vert n^{0} \rangle = E_{n}^{0} \vert n^{1} \rangle + E_{n}^{1} \vert n^{0} \rangle,
\end{align*}

so that:

\begin{align*}
E_{n}^{1} = \left \langle n^{0} \left \lvert H^{1}  \right \rvert n^{0} \right \rangle, \quad \text{and} \quad \vert n^{1} \rangle = \sum_{m}^{\prime} \vert m^0 \rangle  \dfrac{\left \langle m^{0} \left \lvert H^1  \right \rvert n^{0} \right \rangle}{E_{n}^{0}-E_{m}^{0}}.
\end{align*}

In determining \(\vert n^1 \rangle\), we have demanded that \(\vert n \rangle\) be normalized /to first order/.

To /second-order/:

\begin{align*}
H^{0} \vert n^{2} \rangle + H^{1} \vert n^{1} \rangle = E_{n}^{0} \vert n^{2} \rangle + E_{n}^{1} \vert n^{1} \rangle + E_{n}^{2} \vert n^{0} \rangle,
\end{align*}

so that:

\begin{align*}
E_{n}^{2} = \sum_{m}^{\prime} \dfrac{\left \lvert \left \langle n^{0} \left \lvert H^{1}  \right \rvert m^{0} \right \rangle  \right \rvert^{2}}{E_{n}^{0} - E_{m}^{0}},
\end{align*}

and

\begin{align*}
\vert n^{2} \rangle = \sum_{m}^{\prime} \sum^{\prime}_{l} \vert m^{0} \rangle \dfrac{\left \langle m^{0} \left \lvert H^{1}  \right \rvert l^{0} \right \rangle \left \langle l^{0} \left \lvert H^1  \right \rvert n^{0} \right \rangle}{\left(E_{n}^{0}-E_{m}^{0}\right)\left( E_{n}^{0} - E_{l}^{0}\right)}
- \sum_{m}^{\prime} \vert m^{0} \rangle \dfrac{\left \langle m^{0} \left \lvert H^{1}  \right \rvert n^{0} \right \rangle \left \langle n^{0} \left \lvert H^1  \right \rvert n^{0} \right \rangle}{ \left( E_{n}^{0} - E_{m}^{0} \right)^{2}}.
\end{align*}

In determining \(\vert n^2 \rangle\), we have demanded that \(\vert n \rangle\) be normalized /to second order/.

Suppose there exists operator \(\Omega\) such that

\begin{align*}
H^{1} = \left[ \Omega, H^{0} \right].
\end{align*}

Then

\begin{align*}
E_{n}^{2} &= \sum_{m}^{\prime} \dfrac{\left \langle n^{0} \left \lvert H^1  \right \rvert m^{0} \right \rangle \left \langle m^{0} \left \lvert \Omega H^{0} - H^{0} \Omega \right \rvert n^{0} \right \rangle}{E_{n}^{0} - E_{m}^{0}} \\
&= \sum_{m}^{\prime} \left \langle n^{0} \left \lvert H^1  \right \rvert m^{0} \right \rangle \left \langle m^{0} \left \lvert \Omega \right \rvert n^{0} \right \rangle \\
&= \left \langle n^{0} \left \lvert H^{1} \Omega \right \rvert n^{0} \right \rangle - \left \langle n^{0} \left \lvert H^{1}  \right \rvert n^{0} \right \rangle \left \langle n^{0} \left \lvert \Omega  \right \rvert n^{0} \right \rangle
\end{align*}

Suppose there exists operator \(\Omega\) such that

\begin{align*}
H^{1} \vert n^{0} \rangle = \left[ \Omega, H^{0} \right] \vert n^{0} \rangle
\end{align*}

for a given \(\vert n^0 \rangle\). Then for /this value of/ \(n\):

\begin{align*}
E_{n}^{2} = \left \langle n^{0} \left \lvert H^{1} \Omega \right \rvert n^{0} \right \rangle - \left \langle n^{0} \left \lvert H^{1}  \right \rvert n^{0} \right \rangle \left \langle n^{0} \left \lvert \Omega  \right \rvert n^{0} \right \rangle.
\end{align*}

Demanding \(\vert n^0 \rangle \gg \vert n^1 \rangle\) is equivalent to the condition

\begin{align*}
\left \lvert \dfrac{\left \langle m^{0} \left \lvert H^1  \right \rvert n^{0} \right \rangle}{E_{n}^{0}-E_{m}^{0}}  \right \rvert \ll 1.
\end{align*}

The condition has dependence on:

1) the absolute size of \(H^{1}\);
2) the matrix elements of \(H^{1}\) between unperturbed states;
3) the energy difference between the levels.
*** _Selection rules_
:LOGBOOK:
CLOCK: [2022-11-25 Fri 04:02]--[2022-11-25 Fri 06:00] =>  1:58
:END:

\begin{align*}
\left[ \Omega, H^{1} \right] = 0 \Longrightarrow \left \langle \alpha_{2} \omega_{2} \left \lvert H^{1}  \right \rvert \alpha_{1} \omega_{1} \right \rangle = 0 \quad \text{unless} \quad \omega_{1} = \omega_{2}.
\end{align*}

#+NAME: Wigner-Eckart Theorem
#+begin_theorem latex
Given a tensor operator \(T^{(k)}\) and two states of angular momenta \(j\) and \(j^{\prime}\), there exists a constant \(\left \langle j \left \lvert \lvert T^{(k)}  \right \rvert \rvert j^{\prime} \right \rangle\) such that for all \(m\), \(m^{\prime}\), and \(q\), the following equation is satisfied:

\begin{align*}
\left \langle j m \left \lvert T_{q}^{(k)}  \right \rvert j^{\prime} m^{\prime} \right \rangle = \left \langle j^{\prime} m^{\prime} k q \left \vert j m \right \rangle \left \langle j \left \lvert \vert T^{(k)}  \vert \right \rvert j^{\prime} \right \rangle,
\end{align*}

where

1) \(T_q(k)\) is the q-th component of the spherical tensor operator \(T^{(k)}\) of rank \(k\),
2) \(\vert jm \rangle\) denotes an eigenstate of total angular momentum \(J^{2}\) and its \(z\) component \(J_{z}\),
3) \(\left \langle j^{\prime} m^{\prime} k q \left \vert j m \right \rangle\) is the /Clebsch-Gordan coefficient/ for coupling \(j^{\prime}\) with \(k\) to get \(j\),
4) \(\left \langle j \left \lvert \left \lvert T^{(k)}  \right \rvert  \right \rvert j^{\prime} \right \rangle\) denotes some value that does not depend on \(m\), \(m^{\prime}\), nor \(q\) and is referred to as the /reduced matrix element/.
#+end_theorem


If \(\left[ \Omega, H^{1} \right] = 0\), then \(\left \langle \alpha_2 \omega_2 \left \lvert H^{1} \right \rvert \alpha_1 \omega_1 \right \rangle\) unless \(\omega_{1} = \omega_{2}\).

By *Wigner-Eckart Theorem*

\begin{align*}
\left \langle \alpha_{2} j_{2} m_2 \left \lvert T_{k}^{q} \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 \quad \text{unless}
\begin{cases}
j_{1} + k \geq j_{2} \geq \left \lvert j_{1} - k  \right \rvert \\
m_{2} = m_{1} + q
\end{cases},
\end{align*}

where \(T_{k}^{q}\) is a tensor operator carrying angular momentum \((k,q)\). In words, the matrix element vanishes unless \(\vert \alpha_2 j_2 m_2 \rangle\) has the angular momentum that obtains when we add to \((j_{1} m_{1})\) the angular momentum \((kq)\)imparted by the operator. This is called the /angular momentum selection rule/.

If \(H^{1} = \lambda Z \sim T_{1}^{0}\),

\begin{align*}
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert Z \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 \quad \text{unless}
\begin{cases}
j_{2} = j_{1} + 1, \thinspace j_{1}, \thinspace j_{1} - 1 \\
m_{2} = m_{1}
\end{cases}.
\end{align*}

If \(H^{1} = \lambda X \text{ or } \lambda Y (\sim T_{1}^{\pm1})\),

\begin{align*}
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert X \text{ or } Y \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 \text{ unless }
\begin{cases}
j_{2} = j_{1} + 1, \thinspace j_{1}, j_{1} - 1 \\
m_{2} = m_{1} \pm 1.
\end{cases}
\end{align*}

The matrix element of \(\Omega\) between eigenstates of the parity operator vanishes unless they have opposite parity:

\begin{align*}
\Pi^{\dagger} \Omega \Pi = - \Omega.
\end{align*}

This is called the /parity selection rule/.

Combination of the angular momentum selection rule and parity selection rule yield the /dipole selection rule/:

\begin{align*}
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert Z \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 \quad &\text{ unless }
\begin{cases}
j_{2} = j_{1} \pm 1 \\
m_{2} = m_{1}
\end{cases}, \\
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert X \text{ or } Y \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 &\text{ unless }
\begin{cases}
j_{2} = j_{1} \pm 1 \\
m_{2} = m_{1} \pm 1.
\end{cases}.
\end{align*}

(States of orbital angular momentum \(l\) have definite parity \((-1)^{l}\)).

The response of the hydrogen atom ground state to a constant external electric field \(E = \mathcal{E} \vec{k}\) is called the *Stark Effect*.

\begin{align*}
H^{1} = e Z \mathcal{E} = - \mu_{e} \cdot E, \quad \mu_{e} = e \left( \vec{r}_{2} - \vec{r}_{1} \right) = - e \vec{r}.
\end{align*}

The first-order shift in energy:

\begin{align*}
E_{100}^{1} = \left \langle 100 \left \lvert e Z \mathcal{E} \right \rvert 100 \right \rangle = \left \langle 100 \left \lvert - \vec{\mu} \cdot \vec{E} \right \rvert 100 \right \rangle = - \left \langle 100 \left \lvert \mu  \right \rvert 100 \right \rangle \cdot E = 0.
\end{align*}

Bounds for the second order shift in energy are obtained as:

\begin{align*}
\left \lvert E_{100}^{2} \right \rvert \leq \dfrac{e^{2} \mathcal{E}^{2}}{\left \lvert E_{1}^{0} - E_{2}^{0} \right \rvert} \sum_{nlm}^{\prime} \left \lvert \left \langle nlm \left \lvert Z  \right \rvert 100 \right \rangle  \right \rvert^{2},
\end{align*}

since

\begin{align*}
E_{100}^{2} = \sum_{nlm}^{\prime} \dfrac{e^{2} \mathcal{E}^{2} \left \lvert \left \langle nlm \left \lvert Z  \right \rvert 100 \right \rangle  \right \rvert^2}{E_{100}^{0}-E_{nlm}^{0}},
\end{align*}

where

\begin{align*}
E_{100}^{0} - E_{nlm}^{0} = - \text{Ry} \left( 1 - \dfrac{1}{n^{2}} \right) = \text{Ry} \left( \dfrac{1-n^{2}}{n^{2}} \right) :
\end{align*}

and the magnitude of the energy denominator grows with \(n\). Now

\begin{align*}
&\sum_{nlm}^{\prime} \left \lvert \left \langle nlm \left \lvert Z  \right \rvert 100 \right \rangle  \right \rvert^{2} \\
&= \sum_{nlm}^{\prime} \left \langle 100 \left \lvert Z  \right \rvert nlm \right \rangle \left \langle nlm \left \lvert Z  \right \rvert 100 \right \rangle \\
&= \sum_{nlm}^{\prime} \left \langle 100 \left \lvert Z  \right \rvert nlm \right \rangle \left \langle nlm \left \lvert Z  \right \rvert 100 \right \rangle - \left \langle 100 \left \lvert Z  \right \rvert 100 \right \rangle^{2} \\
&= \left \langle 100 \left \lvert Z^{2}  \right \rvert 100 \right \rangle - \left \langle 100 \left \lvert Z  \right \rvert 100 \right \rangle^{2} \\
&= a_{0}^{2} - 0 = a_{0}^{2}.
\end{align*}

\begin{align*}
\left \lvert E_{100}^{2} \right \rvert &\leq \dfrac{e^{2} \mathcal{E}^{3}}{\left \lvert \left( e^{2}/ 2 a_{0} \right) \left( 1 - 1/4 \right) \right \rvert} a_{0}^{2} \\
&\leq \dfrac{8 a_{0}^{3} \mathcal{E}^{2}}{3}.
\end{align*}

Keeping just the first term yields a lower bound:

\begin{align*}
\left \lvert E_{100}^{2}  \right \rvert \geq \dfrac{e^{2} \mathcal{E}^{2}}{3 e^{2}/ 8 a_{0}} \left \lvert \left \langle 210 \left \lvert Z  \right \rvert 100 \right \rangle  \right \rvert^{2}
\end{align*}

With

\begin{align*}
\left \lvert \left \langle 210 \left \lvert Z  \right \rvert 100 \right \rangle  \right \rvert^{2} = \dfrac{2^{15} a_{0}^{2}}{3^{10}} \simeq 0.55 a_{0}^{2},
\end{align*}
\begin{equation*}


}
\end{equation*}

\begin{align*}
\left \lvert E_{100}^{2} \right \rvert \geq \left( 0.55 \right) \dfrac{8}{3} \mathcal{E}^{2} a_{0}^{3}.
\end{align*}

Therefore:

\begin{align*}
\left( 0.55 \right) \dfrac{8}{3} \mathcal{E}^{2} a_{0}^{3} \leq \left \lvert E_{100}^{2}  \right \rvert \leq \dfrac{8 a_{0}^{3} \mathcal{E}^{2}}{3}.
\end{align*}

Suppose that

\begin{align*}
H^{1} \vert 100 \rangle = \left[ \Omega, H^{0} \right] \vert 100 \rangle.
\end{align*}

\begin{align*}
\Omega \xrightarrow[]{\text{coordinate basis}} - \dfrac{m a_{0} e \mathcal{E}}{\hbar^{2}} \left( \dfrac{r^{2} \cos \theta}{2} + a_{0} r \cos \theta \right).
\end{align*}

The second order shift in energy is

\begin{align*}
\left \lvert E_{100}^{2} \right \rvert &= \left \lvert \left \langle 100 \left \lvert H^{1} \Omega  \right \rvert 100 \right \rangle - 0  \right \rvert \\
&= \left \lvert \left \langle 100 \left \lvert e Z \mathcal{E} \Omega  \right \rvert 100 \right \rangle  \right \rvert \\
&= \dfrac{9}{4} a_{0}^{3} \mathcal{E}^{2} = \dfrac{8}{3} a_{0}^{3} \mathcal{E}^{2} \cdot \left( \dfrac{27}{32} \right) \\
&= \left( 0.84 \right) \dfrac{8}{3} a_{0}^{3} \mathcal{E}^{2}.
\end{align*}

\(E_{100}^{2}\) represents the interaction of the induced dipole moment with the applied field. Imagine two charges \(\pm q\) separated by a distance \(x\) along \(E\). The work done on the system as \(x\) changes by \(dx\) is

\begin{align*}
dW &= - q \mathcal{E} dx \\
&= - \mathcal{E} d \mu.
\end{align*}

/Assuming/ that the induced moment is proportional to \(\vec{E}\):

\begin{align*}
\vec{\mu} = \alpha \vec{E},
\end{align*}

(where \(\alpha\) is called the /polarizability/), then

\begin{align*}
d W = - \alpha \mathcal{E} d \mathcal{E},
\end{align*}

or

\begin{align*}
W = - \dfrac{1}{2} \alpha \mathcal{E}^{2} = \left \langle 100 \left \lvert H^{1}  \right \rvert 100 \right \rangle = E_{100}^{2}.
\end{align*}

Using \(\left \lvert E_{100}^{2} \right \rvert = \left( 0.84 \right) \dfrac{8}{3} a_{0}^{3} \mathcal{E}^{2}\),

\begin{align*}
\alpha = \dfrac{18}{4} a_{0}^{3} \simeq \dfrac{18}{4} \left( 0.5 \textup{\AA} \right)^{3} \simeq 0.56 \textup{\AA}^{3}.
\end{align*}

/The second-order shift in the ground state energy is *always* negative (unless it vanishes). Since \(E_{0}^{2}\) measures the energy shift due to the first-order change in the ground -state state vector, we conclude that the system changes its configuration so as to lower its energy of interaction with the external field.
*** Degenerate perturbation theory.
Without loss of generality, assume that \(H^{0}\) has a /degenerate subspace/ and \(H^{0} + H^{1}\) is non-degenerate in this subspace. In a basis that diagonalizes \(H^{1}\) *within the degenerate subspace*

\begin{align*}
\vert n^{1} \rangle = \sum_{m}^{\prime} \vert m^0 \rangle  \dfrac{\left \langle m^{0} \left \lvert H^1  \right \rvert n^{0} \right \rangle}{E_{n}^{0}-E_{m}^{0}}
\end{align*}

has a \(0/0\) form whenever \(\vert n^0 \rangle\) and \(\vert m^0 \rangle\) belong to the degenerate subspace and a divergence is avoided.

Such a basis need not be the full Hilbert space, only a basis within the degenerate subspace that diagonalizes \(H^{1}\).

For the Stark effect (\(H^{1} = e \mathcal{E} Z\)) in the \(n=2\) level of hydrogen, the selection rules tell us that only two of the \(16\) matrix elements are non-zero:

\begin{align*}
H^{1} \to
\begin{pmatrix}
0 & \Delta & 0 & 0  \\
\Delta & 0 & 0 & 0  \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix},
\end{align*}

where the rows are ordered as \((nlm) = 200, \thinspace 210, \thinspace 211, \thinspace 21 -1\) and

\begin{align*}
\Delta = \left \langle 200 \left \lvert e \mathcal{E} Z \right \rvert 210 \right \rangle = - 3 e \mathcal{E} a_{0}.
\end{align*}

** SOLVED Problem 17.2.1
CLOSED: [2022-11-14 Mon 01:00]
:LOGBOOK:
CLOCK: [2022-11-13 Sun 23:57]--[2022-11-14 Mon 01:00] =>  1:03
:END:
*Consider* \(H^{1} = \lambda x^{4}\) *for the oscillator problem.*

*(1)* *Show that*

\begin{align*}
E_{n}^{1} = \dfrac{3 \hbar^{2} \lambda}{4 m^{2} \omega^{2}} \left[ 1 + 2n + 2n^{2} \right].
\end{align*}

Recall

\begin{align*}
x &= \sqrt{\dfrac{\hbar}{2 \omega m}} \left ( a + a^{\dagger} \right ), \\
\end{align*}

and

\begin{align*}
a \vert n^{0} \rangle = n^{1/2} \vert \left( n-1 \right)^{0} \rangle, \quad \text{and} \quad a^{\dagger} \vert n^{0} \rangle = \left( n + 1 \right)^{1/2} \vert \left( n+1 \right)^{0} \rangle.
\end{align*}

We have

\begin{align*}
E_{n}^{1} &= \left \langle n^{0} \left \lvert H^{1}  \right \rvert n^{0} \right \rangle \\
&= \lambda \left \langle n^{0} \left \lvert x^{4} \right \rvert n^{0} \right \rangle \\
&= \dfrac{\lambda \hbar^{2}}{4 \omega^{2} m^{2}} \left \langle n^{0} \left \lvert \left( a + a^{\dagger} \right)^{4}  \right \rvert n^{0} \right \rangle \\
&= \dfrac{\lambda \hbar^{2}}{4 \omega^{2} m^{2}} \left \langle n^{0} \left \lvert \left( a + a^{\dagger} \right)^{2} \left( a + a^{\dagger} \right)^{2}  \right \rvert n^{0} \right \rangle \\
&= \dfrac{\lambda \hbar^{2}}{4 \omega^{2} m^{2}} \times \\
&\left[ \langle (n-2)^{0} \vert \left \lbrace n \left( n - 1 \right)  \right \rbrace^{1/2} + \langle n^{0} \vert n + \langle n^{0} \vert \left( n + 1 \right) + \langle \left( n + 2 \right)^{0} \vert \left \lbrace \left( n+1 \right) \left( n + 2 \right)  \right \rbrace^{1/2} \right] \times \\
&\left[ \left \lbrace \left( n+1 \right) \left( n+2 \right)  \right \rbrace^{1/2} \vert \left( n+2 \right)^0 \rangle + \left( n + 1 \right) \vert n^{0} \rangle + n \vert n^{0} \rangle + \left \lbrace n \left( n - 1 \right)  \right \rbrace^{1/2} \vert \left( n-2 \right)^{0} \rangle \right] \\
&= \dfrac{\lambda \hbar^{2}}{4 \omega^{2} m^{2}} \left[\left( n + 1 \right) \left( n + 2 \right) + \left( n + 1 \right)^{2} + n^{2} + 2 n \left( n + 1 \right) + n \left( n - 1 \right)\right] \\
&= \dfrac{\lambda \hbar^{2}}{4 \omega^{2} m^{2}} \left[ 6 n^{2} + 6n + 3 \right] \\
&= \dfrac{3 \lambda \hbar^{2}}{4 \omega^{2} m^{2}} \left[ 2 n^{2} + 2n + 1 \right].
\end{align*}

*(2)* *Argue that no matter how small* \(\lambda\) *is, the perturbation expansion will break down for some large enough* \(n\). *What is the physical reason?*

The leading term in \(E_{n}^{1}\) is \(\sim \lambda n^{2}\) for large \(n\). A linear fall cannot contain a quadratic blow up. The physical reason is that states with large \(n\) foray far from the origin such that \(x \gg 1\). The perturbation Hamiltonian \(H^{1} = \lambda x^{4}\) then becomes larger than the unperturbed one, which violates one of the assumptions of the formalism of non-degenerate perturbation theory.
** SOLVED Problem 17.2.2
CLOSED: [2022-11-14 Mon 02:04]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 01:00]--[2022-11-14 Mon 02:04] =>  1:04
:END:
*Consider a spin*-\(1/2\) *particle with gyromagnetic ratio* \(\gamma\) *in a magnetic field* \(\vec{B} = B \vec{i} + B_{0} \vec{k}\). *Treating* \(\vec{B}\) *as a perturbation, calculate the first- and second-order shifts in energy and first-order shift in wave function for the ground state. Then compare the exact answers expanded to the corresponding orders.*

The unperturbed and perturbation Hamiltonian are:

\begin{align*}
H^{0} = - \gamma S_{z} B_{0} =
\begin{pmatrix}
- \gamma B_0 & 0 \\
0 & \gamma B_0
\end{pmatrix},
\end{align*}

\begin{align*}
H^{1} = - \gamma S_{x} B =
\begin{pmatrix}
0  & - \gamma B \\
- \gamma B & 0
\end{pmatrix}.
\end{align*}

The first-order shift in energy is

\begin{align*}
E_{- \gamma B_{0}}^{1} = \left \langle \left(- \gamma B_0\right)^{0}  \left \lvert - \gamma S_{x} B  \right \rvert \left(- \gamma B_{0}\right)^{0} \right \rangle = 0.
\end{align*}

\begin{align*}
E_{\gamma B_{0}}^{1} \left \langle \left(\gamma B_0\right)^{0}  \left \lvert - \gamma S_{x} B  \right \rvert \left(\gamma B_{0}\right)^{0} \right \rangle = 0.
\end{align*}

The first-order shift in wavefunction is

\begin{align*}
\vert \left( - \gamma B_{0} \right)^{1} \rangle = \dfrac{\gamma B}{2 \gamma B_{0}} \vert \left( \gamma B_{0} \right)^{0} \rangle = \dfrac{B}{2B_{0}} \vert \left( \gamma B_{0} \right)^{0} \rangle,
\end{align*}

\begin{align*}
\vert \left( \gamma B_{0} \right)^{1} \rangle = \dfrac{B}{2B_{0}} \vert \left(- \gamma B_{0} \right)^{0} \rangle.
\end{align*}

The second-order shift in energy is

\begin{align*}
E_{-\gamma B_{0}}^{2} = \dfrac{\left \lvert \left \langle \left(\gamma B_0\right)^{0}  \left \lvert - \gamma S_{x} B  \right \rvert \left(-\gamma B_{0}\right)^{0} \right \rangle  \right \rvert^{2}}{2 \gamma B_{0}} = \dfrac{\gamma^{2} B^{2}}{2 \gamma B_{0}} = \dfrac{\gamma B^{2}}{2 B_{0}}.
\end{align*}

\begin{align*}
E_{\gamma B_{0}}^{2} = \dfrac{\left \lvert \left \langle \left(- \gamma B_0\right)^{0}  \left \lvert - \gamma S_{x} B  \right \rvert \left(\gamma B_{0}\right)^{0} \right \rangle  \right \rvert^{2}}{- 2 \gamma B_{0}} = -\dfrac{\gamma^{2} B^{2}}{2 \gamma B_{0}} = -\dfrac{\gamma B^{2}}{2 B_{0}}.
\end{align*}

To obtain the exact energy and wavefunction, we need the solution of the eigenvalue problem

\begin{align*}
H \vert \psi \rangle = E \vert \psi \rangle, \qquad H =
\begin{pmatrix}
- \gamma B_0 & - \gamma B \\
- \gamma B & \gamma B_0
\end{pmatrix}.
\end{align*}

The solution is:

\begin{align*}
E_{- \gamma B_{0}} = - \gamma B_{0} \left[ 1 + \left(\dfrac{B}{B_{0}}\right)^{2} \right]^{1/2}, \quad \text{and} \quad \vert - \gamma B_{0} \rangle =
\begin{bmatrix}
B_0/B + \left( B_{0}/ B \right) \left[1 + \left( B/B_{0} \right)^{2} \right]^{1/2} \\
0 
\end{bmatrix}.
\end{align*}

\begin{align*}
E_{\gamma B_{0}} = \gamma B_{0} \left[ 1 + \left(\dfrac{B}{B_{0}}\right)^{2} \right]^{1/2}, \quad \text{and} \quad \vert \gamma B_{0} \rangle =
\begin{bmatrix}
B_0/B - \left( B_{0}/ B \right) \left[1 + \left( B/B_{0} \right)^{2} \right]^{1/2} \\
0 
\end{bmatrix}.
\end{align*}

which converges on the perturbative corrections for \(B \ll B_{0}\) upto the respective order on using:

\begin{align*}
\left( 1 + x \right)^{1/2} \simeq 1 + \dfrac{x}{2} \quad \text{for small} \thinspace \thinspace x.
\end{align*}
** SOLVED Problem 17.2.3
CLOSED: [2022-11-14 Mon 06:15]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 05:08]--[2022-11-14 Mon 06:15] =>  1:07
CLOCK: [2022-11-14 Mon 02:39]--[2022-11-14 Mon 05:01] =>  2:22
:END:
*In our study of the* \(H\) *atom, we assumed that the proton is a point charge* \(e\). *This leads to the familiar Coulomb interaction (* \(-e^{2}/r\) *) with the electron.*

*(1)* *Show that if the proton is a uniformly dense charge distribution of radius* \(R\), *the interaction is*

\begin{align*}
V(r) =
\begin{cases}
 - \dfrac{3 e^{2}}{2R} + \dfrac{e^{2} r^{2}}{2 R^{3}}, \qquad &r \leq R \\ \\
- \dfrac{e^2}{r}, \qquad &r > R
\end{cases}.
\end{align*}

The charge density is

\begin{align*}
\rho \left( \vec{r} \right) = \left(\dfrac{3e}{4 \pi R^{3}}\right) H \left( R - r \right).
\end{align*}

For \(r < R\), charge enclosed is:

\begin{align*}
Q = \iiint_{V} d V \thinspace \left(\dfrac{3e}{4 \pi R^{3}}\right) H \left( R - r \right) = \dfrac{e r^{3}}{R^{3}}.
\end{align*}

Using Gauss's law

\begin{align*}
4 \pi r^{2} E(r) = \dfrac{e r^{3}}{\epsilon_{0} R^{3}} \Longrightarrow E(r) = \dfrac{1}{4 \pi \epsilon_{0}} \dfrac{e r}{R^{3}}.
\end{align*}

Now

\begin{align*}
V \left( r \right) &= V(R) + \int_{R}^{r} e E \cdot dr \\
&= V(R) - \int_{r}^{R} e E \cdot dr \\
&= V(R) + \dfrac{1}{4 \pi \epsilon_{0}} \left(\dfrac{e^{2} r^{2}}{2 R^{3}} - \dfrac{e^{2} }{2 R} \right) + C
\xrightarrow[]{\text{Gaussian units}} \left(\dfrac{e^{2} r^{2}}{2 R^{3}} - \dfrac{e^{2} }{2 R} \right) + C^{\prime}.
\end{align*}

The same steps for \(r > R\) yield

\begin{align*}
V \left( r \right) = - \dfrac{e^{2}}{r}.
\end{align*}

Demanding continuity at \(r = R\) yields

\begin{align*}
C = - \dfrac{e^{2}}{R},
\end{align*}

so that

\begin{align*}
V(r) =
\begin{cases}
 - \dfrac{3 e^{2}}{2R} + \dfrac{e^{2} r^{2}}{2 R^{3}}, \qquad &r \leq R \\ \\
- \dfrac{e^2}{r}, \qquad &r > R
\end{cases}.
\end{align*}


*(2)* *Calculate the first-order shift in the ground-state energy of hydrogen due to this modification.* *You may assume* \(\exp \left \lbrace - R/ a_0  \right \rbrace \simeq 1\). *You should find* \(E^{1} = 2 e^{2} R^{2} / 5 a_{0}^{3}\).

We have

\begin{align*}
\psi_{100}^{0} \left( r, \theta, \phi \right) = \left( \dfrac{1}{\pi a_{0}^{3}} \right)^{1/2} \exp \left \lbrace - r/ a_{0}  \right \rbrace.
\end{align*}

The perturbation Hamiltonian is

\begin{align*}
- \dfrac{3e^{2}}{2R} + \dfrac{e^{2} r^{2}}{2 R^{3}} + \dfrac{e^{2}}{r} = \dfrac{e^2}{2 R} \left[ \left( \dfrac{r}{R} \right)^{2} - 3 + \dfrac{2 R}{r} \right].
\end{align*}

The first-order shift is

\begin{align*}
E_{0}^{1} &= \left \langle \psi_{100}^{0} \left \lvert \dfrac{e^2}{2 R} \left[ \left( \dfrac{r}{R} \right)^{2} - 3 + \dfrac{2 R}{r} \right] \right \rvert \psi_{100}^{0} \right \rangle \\
&= \dfrac{e^{2}}{2R} \left \langle \psi_{100}^{0} \left \lvert \left[ \left( \dfrac{r}{R} \right)^{2} - 3 + \dfrac{2 R}{r} \right] \right \rvert \psi_{100}^{0} \right \rangle \xrightarrow[]{\int d \Omega} \\
&= \left( \dfrac{2e^{2}}{R} \right) \left( \dfrac{1}{a_{0}^{3}} \right) \Bigg [ R^{-2} \int_{0}^{R} r^{4} \exp \left \lbrace - 2r / a_{0}  \right \rbrace dr \\
&+ 2R \int_{0}^{R} r \exp \left \lbrace - 2r / a_{0}  \right \rbrace dr - 3 \int_{0}^{R} r^{2} \exp \left \lbrace - 2r / a_{0}  \right \rbrace dr \Bigg ] \xrightarrow[]{\exp \left \lbrace -R/ a_{0}  \right \rbrace \simeq 1} \\
&\left( \dfrac{2e^{2}}{R} \right) \left( \dfrac{1}{a_{0}^{3}} \right) \Bigg [ R^{-2} \int_{0}^{R} r^{4} dr + 2R \int_{0}^{R} r dr - 3 \int_{0}^{R} r^{2} dr \Bigg ] \\
&= \left( \dfrac{2e^{2}}{R} \right) \left( \dfrac{1}{a_{0}^{3}} \right) \left( \dfrac{R^{3}}{5} \right) = \dfrac{2e^{2}R^{2}}{5 a_{0}^{3}}.
\end{align*}

Since \(R \sim 10^{-15} \text{m}\) and \(a_{0} \sim 10^{-10} \text{m}\), \(E_{0}^{1} \sim 10^{-10}\).

** SOLVED Problem 17.2.4
CLOSED: [2022-11-14 Mon 10:22]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 08:54]--[2022-11-14 Mon 10:22] =>  1:28
:END:
*(1)* *Prove the* /Thomas-Reiche-Kuhn/ *sum rule*

\begin{align*}
\sum_{n^{\prime}} \left( E_{n^{\prime}} - E_{n} \right) \left \lvert \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle  \right \rvert^{2} = \sum_{n^{\prime}} \left( E_{n^{\prime}} - E_{n} \right) \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle = \dfrac{\hbar^{2}}{2m}.
\end{align*}

*where* \(\vert n \rangle\) *and* \(\vert n^{\prime} \rangle\) *are eigenstates of* \(H = P^{2}/2m + V \left( X \right)\). *(Hint: Eliminate the* \(E_{n^{\prime}} - E_{n}\) *factor in favor of* \(H\) *).*

Because \(\vert n \rangle\) and \(\vert n^{\prime} \rangle\) are eigenkets of \(H\)

\begin{align*}
H \vert n \rangle = E_{n} \vert n \rangle, \quad \text{and} \quad H \vert n^{\prime} \rangle = E_{n^{\prime}} \vert n^{\prime} \rangle,
\end{align*}

and thus

\begin{align*}
E_{n} = \left \langle n \left \lvert H  \right \rvert n \right \rangle, \quad \text{and} \quad E_{n^{\prime}} = \left \langle n^{\prime} \left \lvert H  \right \rvert n^{\prime} \right \rangle.
\end{align*}

Subsitute in \(S = \sum_{n^{\prime}} \left( E_{n^{\prime}} - E_{n} \right) \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle\) to obtain

\begin{align*}
S &= \sum_{n^{\prime}} \left( \left \langle n^{\prime} \left \lvert H  \right \rvert n^{\prime} \right \rangle - \left \langle n \left \lvert H  \right \rvert n \right \rangle \right) \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle \\
&= \sum_{n^{\prime}} \left \langle n^{\prime} \left \lvert H  \right \rvert n^{\prime} \right \rangle \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle - \left \langle n \left \lvert H  \right \rvert n \right \rangle \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle \\
&= \sum_{n^{\prime}} \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle  \left \langle n^{\prime} \left \lvert H  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle - \left \langle n \left \lvert H  \right \rvert n \right \rangle \left \langle n \left \lvert X  \right \rvert n^{\prime} \right \rangle \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle \\
&= \left \langle n \left \lvert X H X  \right \rvert n \right \rangle - \left \langle n \left \lvert H  \right \rvert n \right \rangle \left \langle n \left \lvert X^{2}  \right \rvert n \right \rangle \\
&= \dfrac{1}{2} \left \langle n \left \lvert \left[ X, \left[ H, X \right] \right] \right \rvert n \right \rangle = \dfrac{\hbar^{2}}{2m}.
\end{align*}

In the penultimate step we have used

\begin{align*}
\dfrac{1}{2} \langle n \vert \left[ X, \left[ H,X \right] \right] \vert n \rangle &= \dfrac{1}{2} \langle n \vert \left[ X, H \right] X \vert n \rangle - \dfrac{1}{2} \langle n \vert X \left[ X, H \right] \vert n \rangle \\
&= \langle n \vert X H X \vert n \rangle - \dfrac{1}{2} \langle n \vert X^{2} H \vert n \rangle - \dfrac{1}{2} \langle n \vert H X^{2} \vert n \rangle \\
&= \langle n \vert X H X \vert n \rangle - E_{n} \left \langle n \left \lvert X^{2}  \right \rvert n \right \rangle \\
&= \langle n \vert X H X \vert n \rangle - \left \langle n \left \lvert H  \right \rvert n \right \rangle \left \langle n \left \lvert X^{2}  \right \rvert n \right \rangle.
\end{align*}

In the final step we have used

\begin{align*}
\dfrac{1}{2} \left \langle n \left \lvert \left[ X, \left[ H, X \right] \right]  \right \rvert n \right \rangle &= - \dfrac{i \hbar}{2m} \langle n \vert \left[ X, P \right] \vert n \rangle = \dfrac{\hbar^{2}}{2m}.
\end{align*}

*(2)* *Test the sum rule on the* \(n \text{th}\) *state of the oscillator.*

Recall that for the oscillator,

\begin{align*}
X = \left( \dfrac{\hbar}{2 \omega m} \right)^{1/2} \left( a + a^{\dagger} \right).
\end{align*}

Substituting in the sum immediately furnishes a direct evaluation:

\begin{align*}
S &= \sum_{n^{\prime}} \left( E_{n^{\prime}} - E_{n} \right) \left \lvert \left \langle n^{\prime} \left \lvert X  \right \rvert n \right \rangle  \right \rvert^{2} \\
&= \sum_{n^{\prime}} \left( E_{n^{\prime}} - E_{n} \right) \left \lvert \left \langle n^{\prime} \left \lvert \left( \dfrac{\hbar}{2 \omega m} \right)^{1/2} \left( a + a^{\dagger} \right) \right \rvert n \right \rangle  \right \rvert^{2} \\
&= \sum_{n^{\prime}} \hbar \omega \left(n^{\prime} - n \right) \left \lvert \left \langle n^{\prime} \left \lvert \left( \dfrac{\hbar}{2 \omega m} \right)^{1/2} \left( a + a^{\dagger} \right) \right \rvert n \right \rangle  \right \rvert^{2} \\
&= \sum_{n^{\prime}} \dfrac{\hbar^{2}}{2m} \left(n^{\prime} - n \right) \left \lvert \left \langle n^{\prime} \left \lvert \left( a + a^{\dagger} \right) \right \rvert n \right \rangle  \right \rvert^{2} \\
&= \sum_{n^{\prime}} \dfrac{\hbar^{2}}{2m} \left(n^{\prime} - n \right) \left[ \delta_{n,n^{\prime} + 1}n + \delta_{n,n^{\prime}-1} \left( n + 1 \right) \right] \\
&= \dfrac{\hbar^{2}}{2m}.
\end{align*}

** SOLVED Problem 17.2.5
CLOSED: [2022-11-14 Mon 14:39]
:LOGBOOK:
CLOCK: [2022-11-14 Mon 13:26]--[2022-11-14 Mon 14:39] =>  1:13
:END:
*(Hard) We have seen that if we neglect the repulsion* \(e^{2}/r_{12}\) *between the two electrons in the ground state of* \(\text{He}\), *the energy is* \(-8 \text{Ry} = -108.8 \text{ eV}\). *Treating* \(e^{2}/r_{12}\) *as a perturbation, show that*

\begin{align*}
\left \langle 100, 100 \left \lvert H^{1}  \right \rvert 100, 100 \right \rangle = \dfrac{5}{2} \text{Ry}.
\end{align*}

*so that* \(E_{0}^{0} + E_{0}^{1} = -5.5 \text{Ry} = - 74.8 \text{ eV}\). *Recall that the measured value is* \(-78.6 \text{ eV}\) *and the variational estimate is* \(-77.5 \text{ eV}\). *[Hint:* \(\left \langle H^{1}  \right \rangle\) *can be viewed as the interaction between two concentric, spherically symmetric exponentially falling charge distributions. Find the potential* \(\phi (r)\) *due to one distribution and calculate the interaction energy between this potential and the other charge distribution.]*

Alright, I just copied this one from [[https://quantummechanics.ucsd.edu/ph130a/130_notes/node381.html#derive:heliumgs][here]]. Don't be scared, Prof. Jim Branson is with us. What's \(\vert 100, 100 \rangle\)? It's the product of two electron wavefunctions of the hydrogen atom.

\begin{align*}
\vert 100, 100 \rangle = \left( \dfrac{Z^{3}}{\pi a_{0}^{3}} \right)^{2} \exp \left \lbrace -2 Z r_{1}/ a_{0}  \right \rbrace \exp \left \lbrace -2 Z r_{2} / a_{0}  \right \rbrace.
\end{align*}

For Helium \(Z=2\) so:

\begin{align*}
\vert 100, 100 \rangle = \left( \dfrac{8}{\pi a_{0}^{3}} \right)^{2} \exp \left \lbrace -4  r_{1}/ a_{0}  \right \rbrace \exp \left \lbrace -4 r_{2} / a_{0}  \right \rbrace.
\end{align*}

We also use the /Law of cosines/ to write:

\begin{align*}
\dfrac{e^{2}}{r_{12}} = \dfrac{e^{2}}{\left \lvert \vec{r}_{1} - \vec{r}_{2} \right \rvert} = \dfrac{e^{2}}{\left( r_{1}^{2} + r_{2}^{2} - 2 r_{1} r_{2} \cos \theta \right)^{1/2}}.
\end{align*}

Brace yourselves, now we obtain \(E_{0}^{1}\):

\begin{align*}
E_{0}^{1} &= \left \langle 100, 100 \left \lvert H^{1}  \right \rvert 100, 100 \right \rangle \\
&= \left( \dfrac{8e}{\pi a_{0}^{3}} \right)^{2} \int_{0}^{\infty} d r_{1} \thinspace r_{1}^{2} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \int_{0}^{\infty} d r_{2} \thinspace r_{2}^{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \times \\
&\int_{\Omega_{1}} d \Omega_{1} \thinspace \int_{\Omega_{2}} d \Omega_{2} \dfrac{1}{\left( r_{1}^{2} + r_{2}^{2} - 2 r_{1} r_{2} \cos \theta \right)} \\
& \xrightarrow[d \theta \sin \theta = d \cos \theta_{2}]{\cos \theta = \cos \theta_{2}, \int_{\Omega_{1}}}  4\left( \dfrac{8 \pi e}{ a_{0}^{3}} \right)^{2} \int_{0}^{\infty} d r_{1} \thinspace r_{1}^{2} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \times \\
&\int_{0}^{\infty} d r_{2} \thinspace r_{2}^{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \int_{\Omega_{2}} \dfrac{d \phi_{2} \thinspace d \cos \theta_{2}}{\left( r_{1}^{2} + r_{2}^{2} - 2 r_{1} r_{2} \cos \theta_{2} \right)} \\
&= 8\left( \dfrac{8 e}{ a_{0}^{3}} \right)^{2} \int_{0}^{\infty} d r_{1} \thinspace r_{1}^{2} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \int_{0}^{\infty} d r_{2} \thinspace r_{2}^{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \times \\
&\left[ \dfrac{-1}{r_{1} r_{2}} \left( r_{1}^{2} + r_{2}^{2} - 2 r_{1} r_{2} \cos \theta_{2} \right)^{1/2} \right]_{-1}^{1} \\
&= 8\left( \dfrac{8 e}{ a_{0}^{3}} \right)^{2} \int_{0}^{\infty} d r_{1} \thinspace r_{1}^{2} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \\ &\int_{0}^{\infty} d r_{2} \thinspace r_{2}^{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \left( \dfrac{1}{r_{1} r_{2}} \right) \left[ r_{1} + r_{2} - \left \lvert r_{1} - r_{2}  \right \rvert \right] \\
&= 8\left( \dfrac{8 e}{ a_{0}^{3}} \right)^{2} \int_{0}^{\infty} d r_{1} \thinspace r_{1} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \times \\
&\int_{0}^{\infty} d r_{2} \thinspace r_{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \left[ r_{1} + r_{2} - \left \lvert r_{1} - r_{2}  \right \rvert \right].
\end{align*}

Just catching my breath breath, (and a line break for the LaTeX compiler)

\begin{align*}
& \xrightarrow[\text{symmetric under } r_{1} \to r_{2}, r_{2} \to r_{1}]{r_{2} < r_{1}} 16\left( \dfrac{8 e}{ a_{0}^{3}} \right)^{2} \times \\ &\int_{0}^{\infty} d r_{1} \thinspace r_{1} \exp \left \lbrace - 4 r_{1}/a_{0}  \right \rbrace \int_{0}^{r_{1}} d r_{2} \thinspace r_{2} \exp \left \lbrace - 4 r_{2}/ a_{0}  \right \rbrace \left( 2 r_{2} \right) \\
& \xrightarrow[d x_{1} = - 4 d r_{1} r_{1}/ a_{0}, d x_{2} = - 4 d r_{2} r_{2} / a_{0}]{x_{1} = - 4 r_{1}/a_{0}, x_{2} = - 4 r_{2}/ a_{0}} \dfrac{2 e^{2}}{a_{0}} \\
&\int_{0}^{\infty} d x_{1} \thinspace x_{1}  \exp \left \lbrace - x_{1}  \right \rbrace \int_{0}^{x_{1}} d x_{2} \thinspace x_{2}^{2} \exp \left \lbrace - x_{2}  \right \rbrace \\
&= \dfrac{2 e^{2}}{a_{0}} \int_{0}^{\infty} d x_{1} \thinspace x_{1}  \exp \left \lbrace - x_{1}  \right \rbrace \left \lbrace - x_{1}^{2} \exp \left \lbrace - x_{1}  \right \rbrace \\
&+ \int_{0}^{x_{1}} d x_{2} 2 x_{2} \exp \left \lbrace - x_{2} \right \rbrace \right \rbrace \\
&= \dfrac{2 e^{2}}{a_{0}} \int_{0}^{\infty} d x_{1} \thinspace x_{1}  \exp \left \lbrace - x_{1}  \right \rbrace \left \lbrace - x_{1}^{2} \exp \left \lbrace - x_{1}  \right \rbrace \\
&- 2 x_{1} \exp \left \lbrace - x_{1}  \right \rbrace + 2 \int_{0}^{x_{1}} d x_{2} \exp \left \lbrace - x_{2} \right \rbrace \right \rbrace \\
&= \dfrac{2 e^{2}}{a_{0}} \int_{0}^{\infty} d x_{1} \thinspace x_{1}  \exp \left \lbrace - x_{1}  \right \rbrace \left \lbrace - x_{1}^{2} \exp \left \lbrace - x_{1}  \right \rbrace \\
&- 2 x_{1} \exp \left \lbrace - x_{1}  \right \rbrace - 2 \left( \exp \left \lbrace - x_{1}  \right \rbrace - 1 \right) \right \rbrace \\
&= \dfrac{2 e^{2}}{a_{0}} \int_{0}^{\infty} d x_{1} \thinspace \left[ \left( x_{1}^{3} + 2 x_{1}^{2} + 2 x_{1} \right) \exp \left \lbrace - 2 x_{1}  \right \rbrace \\
&- 2 x_{1} \exp \left \lbrace - x_{1}  \right \rbrace \right] - \dfrac{2 e^{2}}{a_{0}} \left[ \dfrac{3}{2} \dfrac{2}{2} \dfrac{1}{2} \dfrac{1}{2} + 2 \dfrac{2}{2} \dfrac{1}{2} \dfrac{1}{2} + 2 \dfrac{1}{2} \dfrac{1}{2} - 2 \dfrac{1}{1} \dfrac{1}{1} \right] \\
&= - \dfrac{2 e^{2}}{a_{0}} \left[ \dfrac{3}{8} + \dfrac{4}{8} + \dfrac{4}{8} - \dfrac{16}{8} \right] \\
&= + \dfrac{5}{8} \dfrac{2 e^{2}}{a_{0}} = \dfrac{5}{2} \text{Ry}.
\end{align*}

** TOSOLVE Problem 17.2.6                                         
*Verify* \(\text{Eq.} (17.2.34)\).
** TOSOLVE Problem 17.2.7                                         
*For the oscillator, consider* \(H^{1} = - q f X\). *Find an* \(\Omega\) *that satisfies* \(\text{Eq.} (17.2.28)\). *Feed it into* \(\text{Eq.}(17.2.39)\) *for* \(E_{n}^{2}\) *and compare with the earlier calculation.*
** TOSOLVE Problem 17.2.8                                         
*Fill in the steps connecting* \(\text{Eqs.} (17.2.41)\) *and* \((17.2.43)\). *Try to use symmetry arguments to reduce the labor involved in evaluating the integrals.*
** SOLVED Problem 17.3.1
CLOSED: [2022-11-25 Fri 06:32]
:LOGBOOK:
CLOCK: [2022-11-25 Fri 05:48]--[2022-11-25 Fri 06:32] =>  0:44
:END:
*Use the dipole selection rules to show that* \(H^{1}\) *has the above form and carry out the evaluation of* \(\Delta\).

The dipole selection rule is:
\begin{align*}
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert Z \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 \quad &\text{ unless }
\begin{cases}
j_{2} = j_{1} \pm 1 \\
m_{2} = m_{1}
\end{cases}, \\
\left \langle \alpha_{2} j_{2} m_{2} \left \lvert X \text{ or } Y \right \rvert \alpha_{1} j_{1} m_{1} \right \rangle = 0 &\text{ unless }
\begin{cases}
j_{2} = j_{1} \pm 1 \\
m_{2} = m_{1} \pm 1.
\end{cases}.
\end{align*}

Spin is a /spectator/ so \(j = l\). The matrix elements vanish whenever

\begin{align*}
l_{2} \neq l_{1} \pm 1 \quad \text{and} \quad m_{2} \neq m_{1}, \qquad l = 0, \thinspace 1 \quad \text{and} \quad m = -1, 0, 1 \text{ for } l = 1.
\end{align*}

\begin{align*}
H^{1} \to
\begin{pmatrix}
0 & \Delta & 0 & 0  \\
\Delta & 0 & 0 & 0  \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix},
\end{align*}

where the rows are ordered as \((nlm) = 200, \thinspace 210, \thinspace 211, \thinspace 21 -1\) and

\begin{align*}
\Delta = \left \langle 200 \left \lvert e \mathcal{E} Z \right \rvert 210 \right \rangle = e \mathcal{E} \left \langle 200 \left \lvert Z  \right \rvert 210 \right \rangle.
\end{align*}

Descending to coordinate basis:

\begin{align*}
\Delta &= e \mathcal{E} \int \left( 2 a_{0} \right)^{-3/2} 2 \left( 1 - \dfrac{r}{2 a_{0}} \right) \exp \left \lbrace -r/2a_{0}  \right \rbrace \times \\
&Y_{00} z \left( 2 a_{0} \right)^{-3/2} \dfrac{1}{\sqrt{3}} \left( \dfrac{r}{a_{0}} \right) \exp \left \lbrace -r/2a_{0}  \right \rbrace Y_{10} d^{3} r \\
&= 2 e \mathcal{E} \left( 2 a_{0} \right)^{-3} \dfrac{1}{\sqrt{3}} \int r^{3} d^{3} r \left( 1-\frac{r}{2 a_{0}} \right) \left( \dfrac{r}{a_{0}} \right) \times \\
& \exp \left \lbrace -r/a_{0}  \right \rbrace \int \dfrac{1}{\sqrt{4 \pi}} \cos \theta Y_{10} d \Omega \\
&= 2 e \mathcal{E} \left( 2 \right)^{-3} \dfrac{1}{\sqrt{3}} \dfrac{1}{\sqrt{3}} \int_{0}^{\infty} \left( \dfrac{r^{4}}{a_{0}^{4}} - \dfrac{r^{5}}{2 a_{0}^{5}} \right) \exp \left \lbrace -r / a_{0}  \right \rbrace dr \\
&= \dfrac{a_{0} e \mathcal{E}}{12} \left[ \int_{0}^{\infty} x^{4} \exp \left \lbrace -x  \right \rbrace dx - \dfrac{1}{2} \int_{0}^{\infty} x^{5} \exp \left \lbrace -x  \right \rbrace dx \right] \\
&= \dfrac{a_{0} e \mathcal{E}}{12} \left[ 4 \times 3 \times 2 \times 1 - \dfrac{5 \times 4 \times 3 \times 2 \times 1}{2} \right] \\
&= \dfrac{a_{0} e \mathcal{E}}{12} \left( -36 \right) \\
&= - 3 e \mathcal{E} a_{0}.
\end{align*}

** SOLVED Problem 17.3.2
CLOSED: [2022-11-25 Fri 07:49]
:LOGBOOK:
CLOCK: [2022-11-25 Fri 06:35]--[2022-11-25 Fri 07:34] =>  0:59
:END:
*Consider a spin-1 particle (with no orbital degrees of freedom). Let* \(H= A S_{z}^{2} + B (S_{x}^{2} - S_{y}^{2})\), *where* \(S_{i}\), *are* \(3 \times 3\) *spin matrices, and* \(A \gg B\). *Treating the* \(B\) *term as a perturbation, find the eigenstates of* \(H^{0} = AS_{z}^{2}\) *that are stable under the perturbation. Calculate the energy shifts to first order in* \(B\). *How are these related to the exact answers?*

\begin{align*}
H = A S_{z}^{2} + B \left( S_{x}^{2} - S_{y}^{2} \right)
\end{align*}

Here \(L\) is a spectator. The \(3 \times 3\) Pauli matrices are:

\begin{align*}
S_{x} = \dfrac{\hbar}{2^{1/2}}
\begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{pmatrix}
S_{y} = \dfrac{\hbar}{2^{1/2}}
\begin{pmatrix}
0 & -i & 0 \\
i & 0 & -i \\
0 & i & 0
\end{pmatrix}
S_{z} = \hbar
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0  & 0 \\
0 & 0  & -1
\end{pmatrix}.
\end{align*}

Therefore

\begin{align*}
H^{0} = A \hbar^{2}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0  & 0 \\
0 & 0  & 1
\end{pmatrix},
\end{align*}

and

\begin{align*}
H^{1} = B \hbar^{2}
\begin{pmatrix}
0 & 0 & 1 \\
0 & 0 & 0 \\
1 & 0 & 0
\end{pmatrix}.
\end{align*}

\(H^{1}\) will throw whatever is along \(x\) and \(z\) to \(z\) and \(x\) respectively and scale it with \(B \hbar^{2}\) (swivel and explode). So linear combinations of the form

\begin{align*}
\vert \pm \rangle \equiv 2^{-1/2} \left(\vert 1 \rangle \pm \vert -1 \rangle\right) 
\end{align*}

from the degenerate subspace of \(H^{0}\) are eigenkets of \(H^{1}\) with eigenvalue \(2^{-1} B \hbar^{2}\) where \(\vert \pm 1 \rangle\) are eigenkets of \(H^{0}\) with eigenvalue \(\pm 1\). In this basis within the degenerate subspace

\begin{align*}
H^{1} \xrightarrow[]{}
\begin{pmatrix}
0 & \Delta \\
\Delta & 0
\end{pmatrix},
\end{align*}

where \(\Delta = B \hbar^{2}\). We have used the dipole selection rule to assert vanishing matrix elements between \(H^{0}\) eigenkets \(\vert +1 \rangle, \vert +1 \rangle\) and \(\vert -1 \rangle, \vert -1 \rangle\).

The first-order energy shifts are \(\pm B \hbar^{2}\) for the \(\vert \pm \rangle\) eigenkets of the degenerate subspace of \(H^{0}\).

The full Hamiltonian is

\begin{align*}
H = \hbar^{2}
\begin{pmatrix}
A  & 0 & B \\
0 & 0 & 0 \\
B  & 0 & A 
\end{pmatrix}
\end{align*}

and has non-zero eigenvalues \((A \pm B) \hbar^{2}\), matching the first-order shifts obtained via perturbation.
** TOSOLVE Problem 17.3.3                                         
*Consider the case where* \(H^{0}\) *includes the Coulomb plus spin-orbit interaction and* \(H^{1}\) *is the effect of a weak magnetic field* \(\vec{B} = B \vec{k}\). *Using the appropriate basis, show that the first-order level shift is related to* \(j_{z}\) *by*
*Sketch the levels for the* \(n=2\) *level assuming that* \(E^{1} \ll E_{\text{t.s}}^{1}\).
** TOSOLVE Problem 17.3.4                                         
*We discuss here some tricks for evaluating the expectation values of certain operators in the eigenstates of hydrogen.*
*(1)* *Suppose we want* \(\left \langle 1/r  \right \rangle_{nlm}\). *Consider first* \(\left \langle \lambda/ r \right \rangle\). *We can interpret* \(\left \langle \lambda/r \right \rangle\) *as the first-order correction due to a perturbation* \(\lambda/r\). *Now this problem can be solved exactly; we just replace* \(e^{2}\) *by* \(e^{2}- \lambda\) *everywhere. (Why?) So the exact energy, from* \(\text{Eq.} (13.1.16)\) *is* \(E(\lambda)= - \left( e^{2} - \lambda \right)^{2} m / 2 n^{2} \hbar^{2}\). *The first-order correction is the term linear in* \(\lambda\), *that is,* \(E^{1} = m e^{2} \lambda / n^{2} \hbar^{2} = \left \langle \lambda/ r  \right \rangle\), *from which we get* \(\left \langle 1/r  \right \rangle = 1/ n^{2} a_{0}\), *in agreement with* \(\text{Eq.} (13.1.36)\). *For later use, let us observe that as* \(E(\lambda)= E^{0} + E^{1} + \dotso = E \left( \lambda = 0 \right) + \lambda D_{\lambda} E (0) + \dotso\), *one way to extract* \(E^{1}\) *from the exact answer is to calculate* \(\lambda D_{\lambda} E (0)\).

*(2)* *Consider now* \(\left \langle \lambda/ r^{2} \right \rangle\). *In this case, an exact solution is possible since the perturbation just modifies the centrifugal term as follows:*

\begin{align*}
\dfrac{\hbar^{2} l \left( l + 1 \right)}{2 m r^{2}} + \dfrac{\lambda}{r^{2}} = \dfrac{\hbar^{2} l^{\prime} \left( l^{\prime} + 1 \right)}{2 m r^{2}}
\end{align*}

*where* \(l^{\prime}\) *is a function of* \(A\). *Now the dependence of* \(E\) *on* \(l^{\prime} \left( \lambda \right)\) *is, from* \(\text{Eq.}(13.1.14)\),

\begin{align*}
E \left( l^{\prime} \right) = - \dfrac{m e^4}{2 \hbar^{2} \left( k + l^{\prime} + 1 \right)^{2}} = E \left( \lambda \right) = E^{0} + E^{1} + \dotso.
\end{align*}

*Show that*

\begin{align*}
\left \langle \dfrac{\lambda}{r^{2}}  \right \rangle = E^{1} \times \lambda D_{\lambda} E (0) = D_{l^{\prime}} E (l) \cdot D_{\lambda} l^{\prime} \left( l \right) \cdot \lambda = \dfrac{\lambda}{n^{3} a_{0}^{2} \left( l + 1/2 \right)}.
\end{align*}


*Canceling* \(\lambda\) *on both sides, we get* \(\text{Eq.}(17.3.11)\).

*(3)* *Consider finally* \(\left \langle l/ r^{3} \right \rangle\). *Since there is no such term in the Coulomb Hamiltonian, we resort to another trick. Consider the /radial/ momentum operator,* \(p_{r} = - i \hbar \left( \partial_{r} + \left( 1/r \right) \right)\) *in terms of which we may write the radial part of the Hamiltonian*

\begin{align*}
\left(-\dfrac{\hbar^{2}}{2m}\right) \left( r^{-2} \partial_{r} \thinspace r^{2} \thinspace \partial_{r} \right)
\end{align*}

*as* \(p_{r}^{2}/2m\). *(Verify this.) Using the fact that* \(\left \langle \left[ H, p_{r} \right]  \right \rangle = 0\) *in the energy eigenstates, and by explicitly evaluating the commutator, show that*

\begin{align*}
\left \langle \dfrac{1}{r^{3}}  \right \rangle = \dfrac{1}{a_{0} \left( l \right) \left( l + 1 \right)} \left \langle \dfrac{1}{r^{2}}  \right \rangle
\end{align*}

*combining which with the result from part* \((2)\) *we get* \(\text{Eq.} (17.3.20)\).
*(4)* *Find the mean kinetic energy using the trick from part* \((1)\), *this time resealing the mass. Regain the virial theorem.*
* Time-Dependent Perturbation Theory                       
* Scattering Theory                                        
* The Dirac Equation                                       
* Path Integrals: Part II                                  
