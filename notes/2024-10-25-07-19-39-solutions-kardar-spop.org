:PROPERTIES:
:ID:       02c3ddee-4c15-4c5a-a2b2-9d39f85194c4
:END:
#+TITLE: Solutions to Statistical Physics of Particles by Mehran Kardar
#+FILETAGS: :spop:problems:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org
#+BEGIN: clocktable :maxlevel 2 :scope nil :emphasize nil
#+CAPTION: Clock summary at [2024-10-25 Fri 08:41]
| Headline                                 |    Time |      |
|------------------------------------------+---------+------|
| *Total time*                             | *54:35* |      |
|------------------------------------------+---------+------|
| 2 Probability                            |   24:20 |      |
| \_  2.1 Characteristic functions         |         | 4:44 |
| \_  2.2 Directed random walk             |         | 0:55 |
| \_  2.3 Tchebycheff inequality           |         | 0:17 |
| \_  2.4 Optimal selection                |         | 0:26 |
| \_  2.5 Benford's law                    |         | 0:15 |
| \_  2.6 Information                      |         | 1:28 |
| \_  2.7 Dice                             |         | 0:26 |
| \_  2.8 Random matrices                  |         | 1:14 |
| \_  2.9 Random deposition                |         | 1:56 |
| \_  2.10 Diode                           |         | 1:51 |
| \_  2.11 Mutual information              |         | 0:46 |
| \_  2.12 Semi-flexible polymer in two... |         | 3:01 |
| \_  2.14 Jensen's inequality and...      |         | 1:34 |
| \_  2.15 The book of records             |         | 1:23 |
| \_  2.16 Jarzynski equality              |         | 1:08 |
| \_  2.17 Approach to equilibrium         |         | 2:56 |
| 3 Kinetic theory of gases                |   30:15 |      |
| \_  3.1 One-dimensional gas              |         | 5:46 |
| \_  3.2 Evolution of entropy             |         | 1:44 |
| \_  3.3 The Vlasov equation              |         | 6:48 |
| \_  3.4 Two-component plasma             |         | 5:02 |
| \_  3.12 Moments of momentum             |         | 2:22 |
| \_  3.13 Generalized ideal gas           |         | 3:06 |
| \_  3.14 Effusion                        |         | 3:39 |
| \_  3.15 Adsorbed particles              |         | 1:05 |
| \_  3.16 Electron emission               |         | 0:43 |
#+END
* 1 Thermodynamics
* 2 Probability
** 2.1 Characteristic functions
:PROPERTIES:
:ID:       1e9755ad-40ab-4293-8ee5-7d12b6d7e5a2
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 11:15]--[2024-04-12 Fri 15:59] =>  4:44
:END:
*Calculate the characteristic function, the mean, and the variance of the following probability density functions.*

The characteristic function is the Fourier transform of the PDF [cite:@kardar2007spop]

\begin{align*}
\tilde{p}(k)=\left\langle\mathrm{e}^{-\mathrm{i} k x}\right\rangle=\int \mathrm{d} x p(x) \mathrm{e}^{-\mathrm{i} k x} .
\end{align*}

Once we have the characteristic function, the moments of the distribution can be read off from the expansion of \(\tilde{p}(k)\) in powers of \(k\) [cite:@kardar2007spop]

\begin{align*}
\tilde{p}(k)=\left\langle\sum_{n=0}^{\infty} \frac{(-\mathrm{i} k)^n}{n !} x^n\right\rangle=\sum_{n=0}^{\infty} \frac{(-\mathrm{i} k)^n}{n !}\left\langle x^n\right\rangle.
\end{align*}

*** 2.1.1 Uniform
\[ p(x) = \frac{1}{2a} \quad \text{for} \quad -a < x < a, \quad \text{and} \quad p(x) = 0 \quad \text{otherwise}. \]

The characteristic function is

\begin{align*}
\tilde{p}(k) & \equiv \int p(x) \exp [-i k x] \mathrm{~d} x =\int_{-a}^a \frac{1}{2 a} \exp [-i k x]  \mathrm{~d} x \\
&\qquad =\frac{1}{2 i k a}[\exp (i k a)-\exp (-i k a)] \\
&\qquad =\frac{\sin (a k)}{a k} = \sum_{n=0}^{\infty} \frac{(- i k)^{2n}}{(2n) !} \bigg( \frac{a^{2n}}{2n + 1} \bigg).
\end{align*}

We thus have \(m_1=\langle x\rangle=0\) and  \(\qquad m_2= \langle x^2 \rangle=a^{2} / 3\).
*** 2.1.2 Laplace
\[ p(x) = \frac{1}{2a} \exp \left( -\frac{|x|}{a} \right), \qquad - \infty < x < \infty \]

The characteristic function is

\begin{align*}
& \tilde{p} (k)=\frac{1}{2 a}\left[\int_{-\infty}^0 \exp \left(-i k x+\frac{x}{a}\right) d x+\int_0^{\infty} \exp \left(-i k x - \frac{x}{a}\right) d x\right] \\
&\quad =\frac{1}{2 a}\left[\frac{1}{-i k+1 / a}+\frac{1}{i k+1 / a}\right]=\frac{1}{1+(a k)^2} \\
&\qquad = \sum_{n=0}^{\infty} \frac{(- i k)^{2n}}{(2n)!} \big[ a^{2n} (2n)! \big]\\
\end{align*}

Hence, \(m_{1} = \langle x \rangle = 0\), and \(m_{2} = \langle x^{2} \rangle = 2 a^{2} \).
*** 2.1.3 Cauchy
\[ p(x) = \frac{a}{\pi(x^2 + a^2)} \]

The characteristic function is

\begin{align*}
\tilde{p} (k) & = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \exp (-i k x)\left[\frac{1}{- i x + a} + \frac{1}{i x + a}\right] d x
\end{align*}

We know that the PDF can be recovered from the characteristic function through the inverse Fourier transform

\begin{align*}
p(x)=\frac{1}{2 \pi} \int \mathrm{d} k \exp (i k x) \tilde{p}(k) .
\end{align*}

so on applying the transformation \(x \to - y\) to the expression for \(\tilde{p} (k)\) for the Cauchy PDF

\begin{align*}
\tilde{p} (k) & = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \exp (i k y)\left[\frac{1}{- i y + a} + \frac{1}{i y + a}\right] d y,
\end{align*}

it is now clear that \(\tilde{p} (k)\) is the inverse Fourier transform of characteristic function of the (unnormalized) Laplace PDF we encountered in (2.1.2). We can thus immediately write \(\tilde{p} (k)=\exp (-|k a|)\). \(\tilde{p} (k)\) cannot be expanded in a Taylor series about \(k=0\) because it is not an [[id:432be539-cd8c-4bc5-ad10-45091801426b][Analytic function]]. We thus resort to using the definition of [[id:0aa35d43-6356-4910-a842-4ed740377570][Moments]]

\begin{align*}
m_1 = \langle x\rangle = \int_{-\infty}^{\infty} \frac{a x}{x^2+a^2} d x = 0,
\end{align*}

\begin{align*}
m_2= \langle x^2 \rangle=\int_{-\infty}^{\infty} \frac{a}{\pi} \frac{x^2}{\left(x^2+a^2\right)} d x.
\end{align*}

For the first moment we have used the fact that the integrand in an odd function of \(x\). The second moment is undefined because the integrand is not Lebesgue integrable.
*** 2.1.4 Rayleigh
\[ p(x) = \frac{x}{a^2} \exp \left( -\frac{x^2}{2a^2} \right), \qquad x \geq 0 \]

The characteristic function is

\begin{align*}
\tilde{p}(k)=\int_0^{\infty}[\cos (k x)-i \sin (k x)] \thinspace \frac{x}{a^2} \exp \left(-\frac{x^2}{2 a^2}\right) d x
\end{align*}

Let us define

\begin{align*}
& A(k) \equiv \int_0^{\infty} \cos (k x) \frac{x^2}{a^2} \exp \left(\frac{-x^2}{2 a^2}\right) d x, \\
& B(k) \equiv-i \int_0^{\infty} \sin (k x) \frac{x}{\lambda^2} \exp \left(\frac{-x^2}{2 \lambda^2}\right) d x. \\
\end{align*}

First we evaluate \(A(k)\)

\begin{align*}
A(k) &= \int_0^{\infty} \frac{x}{a^2} \cos (k x) \exp \left(\frac{-x^2}{2 a^2}\right) d x \\
& = - \cos (k x) \exp \left(\frac{-x^2}{2 a^2}\right) \bigg \rvert_0 ^{\infty} - \int_0^{\infty} \sin (k x) \cdot k \cdot \exp \left(\frac{-x^2}{2 a^2}\right) d x\\
& =1 - k \int_0^{\infty} \sin (k x) \exp \left(\frac{-x^2}{2 a^2}\right) d x.
\end{align*}

To proceed, we transform \(x\) as \(x \to at / 2^{1/2}\) and \(k \to 2^{1/2} k / a\) to obtain

\begin{align*}
A(k) & =1 - k \int_0^{\infty} \sin \big(k t \big) \exp \big(-t^2 / 4\big) d t.
\end{align*}

Now we identify the second term as the Dawson function so that \(A(k) & =1 - 2 k \thinspace D (k)\). The Dawson function is related to the error function \(D_{+}(k) = \frac{\pi^{1/2}}{2} \exp (-k^2) \operatorname{erfi} (k)\), thus we have

\begin{align*}
A(k) = 1 - a k \sqrt{\frac{\pi}{2}} \exp \big[-(a k)^{2} / 2 \big] \operatorname{erfi} \bigg(\frac{a k}{2^{1/2}}\bigg).
\end{align*}

Moving on to evaluating \(B(k)\),

\begin{align*}
B(k) &=\int_0^{\infty} \sin (k x) \frac{x}{a^2} \exp \left(\frac{-x^2}{2 a^2}\right) d x \\
&= - \left.\sin (k x) \exp \left(\frac{-x^2}{2 a^2}\right)\right|_0 ^{\infty} + k \int_0^{\infty} \cos (k x) \exp \left(\frac{-x^2}{2 a^2}\right) d x \\
&= \frac{k}{2} \int_{-\infty}^{\infty} \cos (k x) \exp \left(\frac{-x^2}{2 a^2}\right) d x.
\end{align*}

Let \(C(k)=\int_{-\infty}^{\infty} \cos (k x) \exp \left(\frac{-x^2}{2 a^2}\right) d x\). Using the [[id:d993201b-c7d1-4402-b55d-c2a76a3f2530][Leibniz integral rule]], we have

\begin{align*}
C^{\prime}(k) & =\frac{2 a^2}{2} \sin (k x) \exp \bigg(\frac{-x^2}{2 a^2}\bigg) \bigg \rvert_{0}^{\infty} - a^2 k \int_{-\infty}^{\infty} \exp \left(\frac{-x^2}{2 a^2}\right) \cos (k x) d x \\
& =-a^2 k C(k).
\end{align*}

Therefore \(C(k) & =C(0) \exp \big(-a^{2} k^{2}/2\big)\) where \(C(0) = 2 a \sqrt{\frac{\pi}{2}}\). Substituting in the expression for \(B(k)\) we have \(B(k) = a k \thinspace \sqrt{\frac{\pi}{2}} \exp \big[-(a k)^{2}/2\big]\). Finally, since \(\tilde{p}(k) = A(k) - i B(k)\), we arrive at the characteristic function of the Rayleigh PDF

\begin{align*}
\tilde{p}(k) = 1 - a k \thinspace  \exp \bigg(- \frac{a^{2} k^{2}}{2} \bigg) \sqrt{\frac{\pi}{2}} \bigg[ \operatorname{erfi} \bigg(\frac{a k}{\sqrt{2}}\bigg) + i \bigg].
\end{align*}

We resort to using the definition of [[id:0aa35d43-6356-4910-a842-4ed740377570][Moments]] to evaluate \(m_{1}\) and \(m_{2}\):

\begin{align*}
m_1 = \langle x \rangle = \int_0^{\infty} \frac{x^2}{a^2} \exp \left( \frac{-x^2}{2a^2} \right) dx = \frac{1}{2} \int_{-\infty}^{\infty} \frac{x^2}{a^2} \exp \left( \frac{-x^2}{2a^2} \right) dx = a \sqrt{\frac{\pi}{2}},
\end{align*}

\begin{align*}
m_2 &= \langle x^2 \rangle = \int_0^{\infty} \frac{x^3}{a^2} \exp \left( \frac{-x^2}{2a^2} \right) dx  \qquad \bigg(\frac{x^2}{2a^2} \to u \bigg) \\
&= 2a^2 \left[ \int_0^{\infty} u^2 \exp(-u) du \right] = 2a^2 \left[ \int_0^{\infty} u \exp(cu) du \right] \bigg \rvert_{c = -1} \\
&= 2a^2 \thinspace \partial_{c} \bigg[\frac{\exp (cu)}{c} \bigg] \bigg \rvert_{0}^{\infty} \bigg \rvert_{c = -1} = 2a^2 \left[ \frac{u \exp(cu)}{c}  - \frac{\exp(cu)}{c^2} \right] \bigg \rvert_{c = -1} \bigg \rvert_{0}^{\infty}\\
&= 2a^2 \big[- u \exp (-u) - \exp (-u) \big] \rvert_{0}^{\infty} = 2a^{2} \big[0 - (-1) \big] = 2a^2.
\end{align*}

*** 2.1.5 Maxwell

\[ p(x) = \sqrt{\frac{2}{\pi a^3}} x^2 \exp \left( -\frac{x^2}{2a^2} \right), \qquad \geq 0 \]

Consider the case where \(a=1\). It's called the standard Maxwell distribution. Instead of the characteristic function, let's first calculate the moment generating function

\begin{align*}
& m(t) \equiv \int_0^{\infty} \sqrt{\frac{2}{\pi}} x^2 \exp \bigg(\frac{-x^2}{2}\bigg) \exp (t x) d x \\
& =\int_0^{\infty} \sqrt{\frac{2}{\pi}} \exp \bigg(t^2 / 2\bigg) x^2 \exp \bigg(\frac{-(x-t)^2}{2}\bigg) d x \\
& =\sqrt{\frac{2}{\pi}} \exp \bigg(\frac{t^2}{2}\bigg) \int_{-t}^{\infty}(z+t)^2 \exp \big(-z^2 / 2\big) d z \\
& =\sqrt{\frac{2}{\pi}} \exp \bigg(\frac{t^2}{2}\bigg) \int_{-t}^{\infty}\bigg(z^2+2 t z+t^2\bigg) \exp \bigg(\frac{-z^2}{2}\bigg) d z \\
& =\sqrt{\frac{2}{\pi}} \exp \bigg(\frac{t^2}{2}\bigg)\bigg[\int_{-t}^{\infty} z^2 \exp \bigg(\frac{-z^2}{2}\bigg) d z+\int_{-t}^{\infty} 2 t z \exp \bigg(\frac{-z^2}{2}\bigg) d z + t^2 \int_{-t}^{\infty} \exp \big(-z^2 / 2\big) d z\bigg] \\
& =\sqrt{\frac{2}{\pi}} \exp \bigg(\frac{t^2}{2}\bigg)\bigg[-t \exp \bigg(\frac{-t^2}{2}\bigg)+\sqrt{2 \pi} \Phi(t)+2 t \exp \bigg(\frac{-t^2}{2}\bigg) + t^2 \sqrt{2 \pi} \Phi(t)\bigg] \\
& =\sqrt{\frac{2}{\pi}} t+2\bigg(1+t^2\bigg) \exp \bigg(\frac{t^2}{2}\bigg) \Phi(t),
\end{align*}

where \(\Phi(t)\) is the PDF of the standard normal distribution. We can now retrieve the characteristic function

\begin{align*}
\tilde{p}(k) = m(- i a k) = - i \sqrt{\frac{2}{\pi}} a k+2\left(1-a^2 k^2\right) \exp \left(\frac{-a^2 k^2}{2}\right) \Phi(- i a k).
\end{align*}

We resort to using the definition of [[id:0aa35d43-6356-4910-a842-4ed740377570][moments]] to evaluate \(m_{1}\) and \(m_{2}\):

\begin{align*}
m_1=\langle x\rangle & =\sqrt{\frac{2}{\pi}} \int_0^{\infty} \frac{x^3}{a^3} \exp \left(\frac{-x^2}{2 a^2}\right) d x=2 a \sqrt{\frac{2}{\pi}} \int_0^{\infty} \frac{x^2}{2 a^2} \exp \left(\frac{-x^2}{2 a^2}\right) \mathrm{~d} \bigg(\frac{x^{2}}{2a^2} \bigg) \\
& =2 \sqrt{\frac{2}{\pi}} a \int_0^{\infty} y \exp (-y) d y = 2 \sqrt{\frac{2}{\pi}} a,
\end{align*}

\begin{align*}
m_2= \langle x^2 \rangle & =\sqrt{\frac{2}{\pi}} \int_0^{\infty} \frac{x^4}{a^3} \exp \left(-\frac{x^2}{2 a^2}\right) d x=\sqrt{\frac{2}{\pi}} \partial_{a}\left[\int_0^{\infty} x^2 \exp \left(\frac{-x^2}{2 a^2}\right) \mathrm{~d}x \right] \\
& =\sqrt{\frac{2}{\pi}} \thinspace \partial_{a} \left(a^3 \sqrt{\frac{\pi}{2}}\right) = 3 a^2.
\end{align*}
** 2.2 Directed random walk
:PROPERTIES:
:ID:       70bdc644-aa9c-4b05-88f7-9c4e5cbe9f3e
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 17:22]--[2024-04-12 Fri 18:17] =>  0:55
:END:
*The motion of a particle in three dimensions is a series of independent steps of length* \(l\). *Each step makes an angle* \( \theta \) *with the* \(z\) *axis, with a probability density* \( p(\theta) = 2 \cos^2(\theta/2) / \pi; \) *while the angle* \( \phi \) *is uniformly distributed between* \(0\) *and* \( 2\pi \). *(Note that the solid angle factor of* \( \sin \theta \) *is already included in the definition of* \( p(\theta) \), *which is correctly normalized to unity.) The particle (walker) starts at the origin and makes a large number of steps* \( N \).

*** 2.2.1 
*Calculate the expectation values* \(\langle z \rangle\), \(\langle x \rangle\), \(\langle y \rangle\), \(\langle z^2 \rangle\), \(\langle x^2 \rangle\), *and* \(\langle y^2 \rangle\), *and the covariances* \(\langle xy \rangle\), \(\langle xz \rangle\), *and* \(\langle yz \rangle\).

\begin{aligned}
\langle z\rangle & =\sum_{i=1}^N\left\langle z_i\right\rangle=N\left\langle z_i\right\rangle=N \ell\left\langle\cos \theta_i\right\rangle \\
& =N l \int_0^\pi \cos \theta\left(2 \cos ^2(\theta / 2) / \pi\right) d \theta=\frac{N l}{\pi} \int_0^\pi \cos \theta[\cos \theta+1] d t \\
& =\frac{N l}{\pi} \int_0^\pi\left(\cos ^2 \theta+\cos \theta\right) d \theta=\frac{N l}{\pi} \int_0^\pi \frac{\cos (2 \theta)+1}{2} d \theta \\
& =\frac{N l}{\pi}\left[\frac{1}{2} \pi+0\right]=\frac{N \ell}{2}
\end{aligned}


Unlike \(z\), \(\langle x\rangle=\langle y\rangle=0\), since there's no directional bias. Moving on to the variances, we have


\begin{align*}
\langle x^2 \rangle & =\sum_{i, j} \langle x_i x_j \rangle=\sum_i \sum_{i \neq j} \langle x_i \rangle \langle x_j \rangle+\sum_{i=j} \langle x_i^2 \rangle = N \langle x_i^2 \rangle,
\end{align*}

\begin{align*}
\langle y^2 \rangle & =\sum_{i, j} \langle y_i y_j \rangle=\sum_i \sum_{i \neq j} \langle y_i \rangle \langle y_j \rangle+\sum_{i=j} \langle y_i^2 \rangle = N \langle y_i^2 \rangle,
\end{align*}

and

\begin{aligned}
\langle z^2\rangle & =\sum \langle z_i z_j \rangle=\sum_{i, j} \langle z_i z_j \rangle=\sum_i \sum_{i \neq j} \langle z_i z_j \rangle \\
& =\sum_{i=j} \sum_{i \neq j} \langle z_i \rangle \langle z_j \rangle+\sum_i \langle z_i^2 \rangle \\
& =N(N-1)\left(\frac{l}{2}\right)^2+N \langle z_i^2 \rangle.
\end{aligned}

Since

\begin{aligned}
\langle x_i^2\rangle &= l^2\langle\sin ^2 \theta \cos ^2 \phi\rangle=\frac{l^2}{2} \int_0^\pi \frac{\sin ^2 \theta(\cos \theta+1)}{\pi} d \theta \thinspace \int_0^{2 \pi} \frac{\cos (2 \phi)+1}{2 \pi} d \phi \\
&=l^2 / 4,
\end{aligned}

\begin{align*}
\langle y_i^2\rangle = \langle x_i^2\rangle = l^2 / 4,
\end{align*}

and

\begin{align*}
\langle z_i^2 \rangle & =l^2 \langle\cos ^2 \theta_i \rangle=l^2 \int_0^\pi \cos ^2 \theta\left[2 \cos ^2\left(\frac{\theta}{2}\right) / \pi\right] d \theta \\
& =l^2 \int_0^\pi \frac{\cos ^2 \theta(\cos \theta+1) d \theta}{\pi} \\
& =\frac{l^2}{2} \int_0^\pi \frac{(\cos (2 \theta)+1)}{\pi} d \theta=l^2 / 2,
\end{align*}

we have \(\langle x^{2} \rangle = N l^{2} / 4\), \(\langle y^{2} \rangle = N l^{2} / 4\), and  \(\langle z^2\rangle = N(N+1) (l/2)^2\). As for the covariances, they all vanish: even though there is a directional bias along \(z\), it appears with other variables in covariances, which are equally probable to be positive or negative; we therefore have \(\langle x y \rangle\), \(\langle y z \rangle\), and \(\langle z x \rangle\).
*** 2.2.2 
*Use the central limit theorem to estimate the probability density* \(p(x, y, z)\) *for the particle to end up at the point* \((x, y, z)\).

By appeal to [[id:345593a9-547f-4a22-869d-7963ab81054a][Central limit theorem]], \(p(x, y, z)\) is a multivariate Gaussian, i.e., all cumulants \(>2\) vanish as \(N \rightarrow \infty\). The matrix of covariances \(C\) is:

\begin{align*}
\left[\begin{array}{ccc}
\left\langle x^2\right\rangle_c & 0 & 0 \\
0 & \left\langle y^2\right\rangle_c & 0 \\
0 & 0 & \left\langle z^2\right\rangle_c
\end{array}\right]
\end{align*}

The cumulants are easily obtained from the moments: \(\langle x^2\rangle_c & =\langle y^2\rangle_c=\langle x^2\rangle=\langle y^2\rangle= N (l/2)^{2}\), and \(\langle z^2\rangle_c =\langle z^2\rangle-\langle z\rangle^2 = N (l / 2)^{2}\). The probability density \(p(x, y, z)\) is thus

\begin{align*}
p(x,\, y,\, z) = \left(\frac{2}{\pi N l^2}\right)^{3 / 2} \exp \left[-\frac{x^2+y^2+(z-N l / 2)^2}{N l^{2} / 2}\right] = p(x\,\vert\, y,\, z) p(y,\, z) = p(x\,\vert\, y,\, z) p(y\,\vert\, z) p(z) = p(x) p(y) p(z).
\end{align*}

In the final step, we have used the fact that steps along a given direction is independent of the steps along a different direction. This is not true in general, it merely happens to be the case because of the structure of the covariance matrix \(C\). The probability densities along each of the directions are easily isolated:

\begin{align*}
p(x) = \left(\frac{2}{\pi N l^2}\right)^{1 / 2} \exp \bigg(-\frac{x^2}{N l^{2} / 2}\bigg),
\end{align*}

\begin{align*}
p(y) = \left(\frac{2}{\pi N l^2}\right)^{1 / 2} \exp \bigg(-\frac{y^2}{N l^{2} / 2}\bigg),
\end{align*}

\begin{align*}
p(z) = \left(\frac{2}{\pi N l^2}\right)^{1 / 2} \exp \bigg(-\frac{(z-N l / 2)^2}{N l^{2} / 2}\bigg).
\end{align*}

** 2.3 Tchebycheff inequality
:PROPERTIES:
:ID:       f58465bf-212c-469b-aab3-4a54eafee50c
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 18:22]--[2024-04-12 Fri 18:39] =>  0:17
:END:
*Consider any probability density* \( p(x) \) *for* \( (-\infty < x < \infty) \), *with mean* \( \lambda \), *and variance* \( \sigma^2 \). *Show that the total probability of outcomes that are more than* \( n\sigma \) *away from* \( \lambda \) *is less than* \( 1/n^2 \), *that is,*

\[ \int_{|x-\lambda|\geq n\sigma} dx\, p(x) \leq \frac{1}{n^2}. \]

*Hint: Start with the integral defining* \( \sigma^2 \), *and break it up into parts corresponding to* \( |x - \lambda| > n\sigma \) *and* \( |x - \lambda| < n\sigma \).

\begin{align*}
\int_{-\infty}^{\infty}(x-\lambda)^2 & p(x) \,dx = \sigma^2 \\
&\Rightarrow \int_{n \sigma \leqslant|x-\lambda|}(x-\lambda)^2 \, p(x) \,dx \leqslant \sigma^2 \\
&\Rightarrow \int_{n \sigma \leqslant|x-\lambda|}(n \sigma)^2 \,p(x) \,dx \leqslant \sigma^2 \\
&\Rightarrow \int_{n \sigma \leqslant|x-\lambda|} \,p(x) \,dx \leqslant \frac{1}{n^2} \qquad n \neq 0.
\end{align*}

Note that \(n \leqslant 1\) is trivially true. Tchebycheff's inequality dictates bounds for an integral beyond the distance \(n\sigma\) from the mean for /any/ arbitrary PDF. In fact, /any/ even cumulant will do, you need not stick to the variance

\begin{aligned}
\int_{\lvert x-\lambda \rvert \geqslant l} \, p(x) \,dx \leqslant \frac{\left\langle x^m\right\rangle_c}{l^m}, \quad m=2 n, \qquad n=1,\,2,\,3, \ldots.
\end{aligned}

** 2.4 Optimal selection
:PROPERTIES:
:ID:       965c9ac7-0ec9-42ba-9f4b-431d977535d4
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 18:45]--[2024-04-12 Fri 19:11] =>  0:26
:END:
*In many specialized populations, there is little variability among the members. Is this a natural consequence of optimal selection?*

*** 2.4.1
*Let* \( \{r_a\} \) *be* \( n \) *random numbers, each independently chosen from a probability density* \( p(r) \), *with* \( r \) *in* \([0, 1]\). *Calculate the probability density* \( P_n \,(x) \) *for the largest value of* \(r\) *in the set* \(\{r_1, \ldots, r_n\}\).

Without lass of generality let \(x=r_n=\max \left\{r_\alpha\right\}\) where \(\alpha=1,\,2,\,\ldots,\,n\). Because no index is any more likely to be the maximum than any other index, we have

\begin{aligned}
p_n(x)=\left[\prod_{i=1}^{n-1} p\left(r_i \leqslant x\right)\right] p\left(r_n=x\right) \cdot n.
\end{aligned}

*** 2.4.2
*If each* \(r_a\) *is uniformly distributed between* \(0\) *and* \(1\), *calculate the mean and variance of* \(x\) *as a function of* \(n\), *and comment on their behavior at large* \(n\).

Given
\begin{align*}
p(r)= 
\begin{cases}
1 & 0 \leqslant r \leqslant 1 \\
0 & \text {otherwise}
\end{cases},
\end{align*}

we can write down a functional form for \(p_{n} (x)\)

\begin{aligned}
p_n(x)=\left[\int_0^x d r\right]^{n-1} \cdot x \cdot n=n x^{n-1}=\frac{d}{d x}\left(x^n\right).
\end{aligned}

The first and second moments are

\begin{aligned}
\langle x\rangle=n \int_0^1 x^n d x=n /(n+1), \qquad \langle x^2 \rangle = n \int_0^1 x^{n+1}\,dx = n / (n + 2).
\end{aligned}

In general we have \(\langle x^m\rangle=n /(n+m)\). The cumulants are easily obtained from the moments

\begin{align*}
\langle x \rangle_{c} = \langle x \rangle = n / (n+1), \qquad \langle x^{2} \rangle_{c} = \langle x^{2} \rangle - \langle x \rangle^{2} = n / \big[ (n + 2) (n + 1)^{2} \big].
\end{align*}

For large \(n\), we get \(\lim_{n \to \infty} \langle x \rangle_{c} = 1\), and \(\lim_{n \to \infty} \langle x^{2} \rangle_{c} = 1/n^{2}\). We see that the variance of \(x\) vanishes and the mean approaches the higher extreme of \(r_{\alpha}\)'s support.

** 2.5 Benford's law
:PROPERTIES:
:ID:       0d2fdffa-e91f-467b-8384-d7febc40590e
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 19:16]--[2024-04-12 Fri 19:31] =>  0:15
:END:
 *Benford's law describes the observed probabilities of the first digit in a great variety of data sets, such as stock prices. Rather counter-intuitively, the digits* \(1\) *through* \(9\) *occur with probabilities* \(0.301,\,0.176,\,0.125,\,0.097,\,0.079,\,0.067,\,0.058,\,0.051,\,0.046\) *respectively. The key observation is that this distribution is invariant under a change of scale, for example, if the stock prices were converted from dollars to Persian rials! Find a formula that fits the above probabilities on the basis of this observation.*

We have \(p(i)=\sum_n \int_{b^n i}^{b^n(i+1)} p (x)\,dx\), where \(\sum_n\) is a sum over all orders of magnitude. The key observation is that \(p(i)\) is scale invariant. This is equivalent to asserting that the integral inside the summation has no \(n\) dependence. Let's change scale to \(\log_b\). A simple application of the [[id:50471612-d516-4025-8add-a0f7a659edba][Mean value theorem]] yields

\begin{align*}
p(i) = \sum_n \int_{n+\ln (i)}^{n+\ln (i+1)} p(y)\,dy = \sum_n \int_{\ln (i)}^{\ln (i+1)} p(y)\,dy = \sum_n c_i \, [\ln (i+1) - \ln (i)].
\end{align*}

Scale invariance implies \(c_i=1 / n \quad \forall i\). Thus we are left with

\begin{align*}
p(i)=\log _b(i+1)-\log _b(i).
\end{align*}

This is Benford's law. Using \(\sum_i p(i)=1\), one can easily retrieve the probabilities \(0.301,\,0.176,\,0.125,\,0.097,\,0.079,\,0.067,\,0.058,\,0.051,\,0.046\). What's happening essentially is that the logarithm of \(x\) has a uniform distribution. Repeated sampling will thus yield variable that is distributed according to the log-normal distribution. Newcomb gave the above expression for \(p(i)\) long before Benford (see [[id:575f8aa2-6fa2-492f-9d05-746c93e98776][Stigler's law of eponymy]]). His observation was that in the log tables that he and his fellow astronomers used had the pages for \(1\) were much more worn out than other digits!

** 2.6 Information
:PROPERTIES:
:ID:       f5772738-f405-482b-9a1b-bb4c6a5f6ae0
:END:
:LOGBOOK:
CLOCK: [2024-04-12 Fri 22:30]--[2024-04-12 Fri 23:58] =>  1:28
:END:
*Consider the velocity of a gas particle in one dimension* \( (-\infty < v < \infty) \).

*** 2.6.1
*Find the unbiased probability density* \( P_1(v) \), *subject only to the constraint that the average speed is* \( c \), *that is,* \( \langle |v| \rangle = c\).

We will maximize the entropy subject to the constraint of normalization and average speed, the constraints imposed using Lagrange multipliers. By definition

\begin{align*}
S \equiv -\langle\ln p\rangle=-\int_{-\infty}^{\infty} p_1(v) \ln p_1(v) d v +\underbrace{\lambda_1\left(1-\int_{-\infty}^{\infty} p_1(v) d v\right)}_{\text{PDF is normalized}} +\underbrace{\lambda_{2} \left(c-\int_{-\infty}^{\infty} p_1(v)|v| d v\right)}_{\text{average speed}}.
\end{align*}

\begin{align*}
\partial_{p_{1}} S &= -\ln p_1(v)-1-\lambda_1-\lambda_2|(v)|=0 \Rightarrow p_1(v)=\exp \left(-1-\lambda_1-\lambda_2|v|\right).
\end{align*}

To find \(\lambda_{1}\) and \(\lambda_{2}\), we use the constraints

\begin{align*}
\int_{-\infty}^{\infty} p_1(v) d v=1 &\Rightarrow \int_{-\infty}^{\infty} \exp \left(-1-\lambda_1-\lambda_2|v|\right) d v=1 \\
& \Rightarrow 2 \exp \left(-1-\lambda_1\right) \int_0^{\infty} \exp \left(-\lambda_2 v\right) d v=1 \text {. } \\
& \Rightarrow \exp \left(-1-\lambda_1\right) / \lambda_2=1 / 2. \\
\end{align*}

\begin{align*}
\int_{-\infty}^{\infty} p_1(v)|v| d v= c &= 2 \exp \big(-1-\lambda_1\big) \int_0^{\infty} v p_1(v) d v \\
& = 2 \exp \big(-1-\lambda_1\big) \int_0^{\infty} v \exp \big(-\lambda_2 \, v\big) d v \\
& =2 \exp \big(-1-\lambda_1\big)\bigg[\exp \big(-\lambda_2 \, v\big)\bigg(\frac{-\lambda_2 \, v-1}{\lambda_2^2}\bigg)\bigg]_0^{\infty} \\
& = 2 \exp \big(-1-\lambda_1\big)\big(-1/\lambda_2^2\big) \\
& \Rightarrow c = 1 / \lambda_{2}.
\end{align*}

Substituting in the expression for \(p_{1} (v)\), we recover the PDF

\begin{align*}
p_1(v)=\frac{1}{2 c} \exp \bigg(\frac{-|v|}{c}\bigg).
\end{align*}

*** 2.6.2
*Now find the probability density* \( P_2(v) \), *given only the constraint of average kinetic energy,* \( \langle mv^2/2 \rangle = mc^2/2\).*

Once again, we will maximize the entropy subject to the constraint of normalization and average kinetic energy

\begin{align*}
S=-\langle\ln p\rangle=-\int_{-\infty}^{\infty} p_2(v) \ln p_2(v) d v +\underbrace{\lambda_1\bigg(1-\int_{-\infty}^{\infty} p_2(v) d v\bigg)}_{\text{PDF is normalized}} +\underbrace{\lambda_{2} \bigg(\frac{m c^2}{2} - \int_{-\infty}^{\infty} p_2(v) \bigg(\frac{m v^{2}}{2} \bigg) d v\bigg)}_{\text{average kinetic energy}}.
\end{align*}
\[
\partial_{p_{2}} S = - \ln p_2(v) - 1 - \lambda_1 - \lambda_2 \frac{m v^2}{2} = 0 \Rightarrow p_2(v) = \exp \left(-1 - \lambda_1 - \lambda_2 \frac{m v^2}{2}\right).
\]

As before, we use the constraints for normalization and average kinetic energy to find \( \lambda_1 \) and \( \lambda_2 \).

\[
\int_{-\infty}^{\infty} \exp \left(-1 - \lambda_1 - \lambda_2 \frac{m v^2}{2}\right) dv = 1 = \sqrt{\frac{2 \pi}{\lambda_2 m}} \exp(-1 - \lambda_1).
\]

\begin{align*}
\exp \left(-1 - \lambda_1 \right) \int_{-\infty}^{\infty} & v^2 \exp \left(- \lambda_2 \frac{m v^2}{2}\right) dv \\
= c^2 &= \exp(-1 - \lambda_1) \sqrt{\frac{2 \pi}{\lambda_2^3 m^3}} = \frac{1}{m \lambda_{2}}\\
\end{align*}

Substituting in the expression for \(p_{2} (v)\), we recover the PDF

\begin{align*}
p_{2}(v)=\frac{1}{\sqrt{2 \pi c^2}} \exp \left(-\frac{v^2}{2 c^2}\right) .
\end{align*}
*** 2.6.3
*Which of the above statements provides more information on the velocity? Quantify the difference in information in terms of* \( I_2 - I_1 \equiv (\langle \ln p_2 \rangle - \langle \ln p_1 \rangle)/\ln 2\).

For two PDFs on the same support

\begin{align*}
I_1+S_1 / \ln 2=I_2+S_2 / \ln 2 \Rightarrow & I_1-I_2=\frac{1}{\ln 2}\left(S_2-S_1\right),
\end{align*}

i.e., the difference in information is proportional to the difference in entropy. Let us calculate the entropy of each of the above distributions

\begin{align*}
S_1 &=-\left\langle\ln p_1\right\rangle=-\int_{-\infty}^{\infty} p_1(v) \ln [p(v)] d v \\
& =-\int_{-\infty}^{\infty} \frac{1}{2 c} \exp \left(-\frac{|v|}{c}\right)\left[-\ln (2 c)-\frac{|v|}{c}\right] d v \\
& =\int_{-\infty}^{\infty} \frac{\ln (2 c)}{2 c} \exp \left(\frac{-|v|}{c}\right) d v+\int_{-\infty}^{\infty} \frac{1}{2 c} \frac{|v|}{c} \exp \left(\frac{-|v|}{c}\right) d v \\
& =\frac{\ln (2 c)}{c} \int_0^{\infty} \exp \left(\frac{-|v|}{c}\right) d v+\frac{1}{c} \int_0^{\infty} \frac{|v|}{c} \exp \left(-\frac{|v|}{c}\right) d v \\
& =\frac{\ln (2 c)}{c} \times c + \frac{1}{c^2}\left[\exp \left(\frac{-v}{c}\right)\left(\frac{(-1 / c) v-1}{(-1 / c)^2}\right)\right]_0^{\infty} \\
& =\ln (2 c)+1=\ln 2+\ln c+1,
\end{align*}

\begin{align*}
S_2 &=-\left\langle\ln p_2\right\rangle=-\int_{-\infty}^{\infty} p_2(v) \ln \left[p_2(v)\right] d v \\
& =-\int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi}} \cdot \frac{1}{c} \cdot \exp \left(\frac{-v^2}{2 c^2}\right) \ln \left(\frac{1}{\sqrt{2 \pi c^2}} \cdot \exp \bigg[\frac{-v^2}{2 c^2}\bigg]\right) d v \\
& =-\int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi c^2}} \exp \left(\frac{-v^2}{2 c^2}\right)\left[-\ln \left(\sqrt{2 \pi c^2}\right)-\frac{v^2}{2 c^2}\right] d v \\
& =\frac{\ln \big(\sqrt{2 \pi c^2}\big)}{\sqrt{2 \pi c^2}} \int_{-\infty}^{\infty} \exp \left(\frac{-v^2}{2 c^2}\right) d v+\int_{-\infty}^{\infty}\left(\frac{v^2}{2 c^2}\right)\left(\frac{1}{\sqrt{2 c^2}}\right) \exp \left(\frac{-v^2}{2 c^2}\right) d v \\
& =\frac{\ln \big(\sqrt{2 \pi c^2}\big)}{\sqrt{2 \pi c^2}} \sqrt{\frac{2 \pi}{1 / c^2}}+\frac{1}{2 c^3 \sqrt{2 \pi}} \sqrt{\frac{\pi}{\left(1 / 2 c^2\right)^3}} \cdot \frac{1}{2} \\
& =\frac{1}{2}+\frac{1}{2} \ln (2 \pi)+\ln (c).
\end{align*}

Now, the difference in information of \(p_{1} (v)\) and \(p_{2} (v)\) is

\begin{align*}
I_1-I_2 = \frac{1}{\ln 2}\left(S_2-S_1\right)= \frac{1}{2 \ln (2)}[\ln (\pi)-\ln (2)-1] \approx -0.3956.
\end{align*}

Thus, the constraint of constant energy provider \(0.3956\) more bits of information. Why is this? Because revealing the average value of \(v^2\) is the same as revealing the first two moments of the distributions, while revealing the average speed \(|v|\) is the same as only revealing the first moment. This reflects in the distributions we ultimately construct, starting from the uniform distribution. The constraint of average speed yields a Laplace PDF while the constraint of average kinetic energy yields a Gaussian PDF. The entropy \(S\) is a measure of the PDF's /dispersion/. The Gaussian PDF has less entropy than the Laplace PDF because it falls faster as we move away from the origin. The Laplace PDF's slower fall means that it is more /disperse/, i.e., it has more entropy. All probability distributions satisfy a conservation law: sum of its information and entropy is a constant. Because the Gaussian PDF has less entropy than the Laplace PDF, it has more information compared to the Laplace PDF; approximately 0.3956 bits more information.

** 2.7 Dice
:PROPERTIES:
:ID:       91e39ba2-fe8b-485c-8386-e7912c415064
:END:
:LOGBOOK:
CLOCK: [2024-04-13 Sat 02:22]--[2024-04-13 Sat 02:48] =>  0:26
:END:
*A dice is loaded such that* \(6\) *occurs twice as often as* \(1\).

*** 2.7.1
*Calculate the unbiased probabilities for the six faces of the dice.*

\begin{align*}
S (p_1) &= -p_1 \ln p_1 \\
&= -4 \bigg(\frac{1-3 p_1}{4}\bigg) \ln \bigg(\frac{1-3 p_1}{4}\bigg) -2 p_1 \ln \big(2 p_1\big)\\
&= -3 p_1 \ln p_1 - \big(1-3 p_1\big) \ln \big(1-3 p_1\big) - 8 p_1 \ln (2)
\end{align*}

\begin{align*}
D_{p_{1}} S &= 3 \ln \left(1-3 p_1\right)-3 \ln p_1-3+3-8 p_1 \ln (2) / p_1 \\
&=  3\left[\ln \left(1-3 p_1\right)-\ln p_1-(8 / 3) \ln (2)\right] = 3 \ln \left(\frac{1-3 p_1}{2^{8 / 3} p_1}\right)
\end{align*}

For the logarithm to vanish, its argument must equal unity

\begin{align*}
\frac{1-3 p_1}{2^{8 / 3} p_1}=1 \Rightarrow p_1=\frac{1}{3+2^{8 / 3}}.
\end{align*}

We thus recover the unbiased probabilities for the six faces of the dice

\begin{align*}
p_1=\frac{1}{3+2^{8 / 3}}, p_2=p_3=p_4=p_5=\frac{2^{8 / 3}}{12+2^{14 / 3}}, p_6=\frac{2}{3+2^{8 / 3}}.
\end{align*}

*** 2.7.2
*What is the information content (in bits) of the above statement regarding the dice?*

The information content is

\begin{align*}
I\left(\left\{p_i\right\}\right) & =\log_2 6+\sum_{i=1}^6 p_i \log_2 p_i=\log_2 6+\log_2 \bigg(\frac{2^{2 / 3}}{3+2^{8 / 3}}\bigg) \\
& =\frac{5}{3}+\log_2 \frac{3}{3+2^{8 / 3}} \approx 0.03 \, \text {bits}.
\end{align*}

** 2.8 Random matrices
:PROPERTIES:
:ID:       17d12082-ff2e-4076-a54c-9f40ad7964b3
:END:
:LOGBOOK:
CLOCK: [2024-04-17 Wed 20:48]--[2024-04-17 Wed 21:08] =>  0:20
CLOCK: [2024-04-17 Wed 19:52]--[2024-04-17 Wed 20:46] =>  0:54
:END:
*As a model for energy levels of complex nuclei, Wigner considered \(N \times N\) symmetric matrices whose elements are random. Let us assume that each element \(M_{ij}\) (for \(i \geq j\)) is an independent random variable taken from the probability density function*

\[ p(M_{ij}) = \frac{1}{2a} \quad \text{for} \quad -a < M_{ij} < a, \quad \text{and} \quad p(M_{ij}) = 0 \quad \text{otherwise}. \]

*** 2.8.1
*Calculate the characteristic function for each element \( M_{ij} \).*

Each entry is random and equiprobable. The [[id:f5d85255-1e37-41cb-b961-7c1a6992fc97][Characteristic function]] is thus that of a uniform

\begin{align*}
\tilde{p} (k)= \frac{\sin (a k)}{a k}.
\end{align*}

*** 2.8.2
*Calculate the characteristic function for the trace of the matrix, \( T = tr M = \sum_{i} M_{ii} \).*

\begin{align*}
\tilde{p}_T(k) & \equiv\langle\exp (-i k T)\rangle \\
& =\bigg\langle\prod_{i=1}^N \exp \left(-i k M_{i i}\right)\bigg\rangle \\
& =\prod_{i=1}^N\langle\exp \left(-i k M_{i i}\right)\rangle=\bigg(\frac{\sin (a k)}{a k}\bigg)^N
\end{align*}

We have used the fact that the matrix entries are independent and identically distributed.

*** 2.8.3
*What does the central limit theorem imply about the probability density function of the trace at large \( N \)?*

Because the matrix entries are independent and identically distributed, we have \( \langle T \rangle_{c} = 0 \) and \( \langle T^{2} \rangle_{c} = N \langle M_{ii}^{2} \rangle = N a^2 /3 \). Appeal the central limit theorem allows us to assert that the random variables \( t = T / \sqrt{N} \) is normally distributed with the probability density function

\[p(t)=\sqrt{\frac{3}{2 \pi a^2}} \exp \left(\frac{-3 t^2}{2 a^2}\right).\]

*** 2.8.4
*For large \( N \), each eigenvalue \( \lambda_\alpha \) ( \( \alpha = 1, 2, \ldots, N \) ) of the matrix \( M \) is distributed according to a probability density function*

\[ p(\lambda) = \frac{2}{\pi \lambda_0^2} \sqrt{1 - \frac{\lambda^2}{\lambda_0^2}} \quad \text{for} \quad -\lambda_0 < \lambda < \lambda_0, \quad \text{and} \quad p(\lambda) = 0 \quad \text{otherwise}. \]

*(known as the Wigner semicircle rule). Find the variance of \( \lambda \). (Hint: Changing variables to \( \lambda = \lambda_0 \sin \theta \) simplifies the integrals.)*

Notice that the mass about \(p(\lambda)\) is equal and immediately assert \( \langle \lambda \rangle = \langle \lambda  \rangle_c = 0 \), so that \( \langle \lambda^{2} \rangle_{c} = \langle \lambda^{2} \rangle \). Using the substitution \(\lambda = \lambda_{0} \sin \theta \), the integral for \( \langle \lambda^{2} \rangle \) simplifies

\[
\langle\lambda^2\rangle_c &= 2 \int_{-\lambda_0}^{\lambda_0} \frac{d \lambda \cdot \lambda^2}{\pi \lambda_0} \sqrt{1-\frac{\lambda^2}{\lambda_0^2}} = \frac{2 \lambda_0^2}{\pi} \int_{-\pi / 2}^{\pi / 2} d \theta \cos ^2 \theta \sin ^2 \theta = \frac{2 \lambda_0^2}{\pi} \cdot \frac{\pi}{8}=\lambda_0^2 / 4.
\]

*** 2.8.5
*If, in the previous result, we have \( \lambda_0^2 = 4Na^2/3 \), can the eigenvalues be independent of each other?*

First, we recall that the trace is the sum of eigenvalues \(T=\sum_{i=1}^N \lambda_i\). We therefore have

\[\langle T^2\rangle_c=\bigg \langle \bigg(\sum_{i=1}^N \lambda_i \bigg) \bigg(\sum_{j=1}^N \lambda_j \bigg) \bigg \rangle=\bigg \langle\sum_{ij}^N \lambda_i \lambda_j \bigg \rangle =\sum_{ij}^N\langle\lambda_i \lambda_j\rangle=\sum_{i=j}^N\langle\lambda_i^2\rangle+\sum_{i \neq j}^N\langle\lambda_i \lambda_j\rangle\]

 If the eigenvalues were independent, we would have identically vanishing \( \langle \lambda_{i} \lambda_{j} \rangle \) for \(i \neq j\). As such \(\sum_{i \neq j}^N\langle\lambda_i \lambda_j\rangle\) must also vanish. But \(\sum_{i \neq j}^N\langle\lambda_i \lambda_j\rangle=\langle T^2\rangle_c-\sum_{i=j}^N\langle\lambda_i^2\rangle=\frac{N a^2}{3}-\frac{N^2 a^2}{3} \neq 0\) is non-vanishing. As a consequence, the eigenvalues cannot be independent of each other.

** 2.9 Random deposition
:PROPERTIES:
:ID:       99217c52-b39a-4d41-bbfc-5ae812d51764
:END:
:LOGBOOK:
CLOCK: [2024-04-17 Wed 21:30]--[2024-04-17 Wed 23:26] =>  1:56
:END:
*A mirror is plated by evaporating a gold electrode in vacuum by passing an electric current. The gold atoms fly off in all directions, and a portion of them sticks to the glass (or to other gold atoms already on the glass plate). Assume that each column of deposited atoms is independent of neighboring columns, and that the average deposition rate is \( d \) layers per second.*

*** 2.9.1
*What is the probability of \( m \) atoms deposited at a site after a time \( t \)? What fraction of the glass is not covered by any gold atoms?*

The random deposition described above is a Poisson process. Let us work out how the [[id:45bd3e37-0464-4358-99a3-79707a816cd5][Poisson distribution]] emerges naturally when modelling an arrival process using first principles. In a given time interval \(\Delta t\), the probability of an arrival is \(\Delta p\). The probability of \(n\) arrivals in time \(t\) is

\begin{align*}
p(n)= \binom{t / \Delta t}{n} (\Delta p)^n(1-\Delta p)^{t / \Delta t-n} = \frac{(t \Delta p / \Delta t) \cdots(t \Delta p / \Delta t-(n-1) \Delta p)}{n!}(1-\Delta p)^{t / \Delta t-n}.
\end{align*}

The average number of arrivals in time \(t\) is

\begin{align*}
\sum_{k=0}^{t / \Delta t} k \binom{t / \Delta t}{n} (\Delta p)^k(1-\Delta p)^{t / \Delta t -k} =\frac{\Delta p}{\Delta t} t \equiv \lambda t,
\end{align*}

where we have introduced a proportionality constant \(\lambda\) to define the relation \(\Delta p \equiv \lambda \Delta t\). In encodes the simple fact that the probability of an arrival is directly proportional to the time interval over which it is awaited. Substituting \(\Delta t=\Delta p / \lambda\) in the expression for \(p(n)\), the \(\Delta t \to 0\) limit can be evaluated and yields the Poisson PDF

\begin{align*}
p(n)= \lim_{1/\Delta p \rightarrow \infty} \frac{(\lambda  t)^n}{n!}\bigg(1+ \frac{(-\lambda t)}{1/\Delta p}\bigg)^{1 / \Delta p} =\frac{(\lambda t)^n e^{- \lambda t}}{n!}.
\end{align*}

It describes an arrival process: given time \(t\) has elapsed, the probability of \(n\) arrivals having occured during this period is given by \(p(n)\). The proportionality constant \(\lambda\) is the /average rate of arrival/, it has dimensions of \(t^{-1}\). Across a large number of observations of \(n\) keeping \(t\) fixed, we will observe that \( \langle n \rangle_{c} = \lambda t \). Thus, the probability \( p(m) \) of \( m \) atoms having deposited at a site after a time \( t \), given an average deposition rate of \(d\) layers per second is \( p(m)=(dt)^m \exp (-d t) / m ! \).

*** 2.9.2
*What is the variance in the thickness?*

We can appeal to the fact that all the cumulants of the [[id:45bd3e37-0464-4358-99a3-79707a816cd5][Poisson distribution]] are equal to \( \langle m \rangle \), thus so is \( \langle m^{2} \rangle_{c} \), the variance. In this case, since \( \langle m \rangle = dt \), \( \langle m^{2} \rangle_{c} = dt\). However, let us work it out explicitly for the sake of completeness. First, we will explicitly show that \( \langle m \rangle = dt \). By definition

\begin{align*}
\langle m \rangle = \sum_{m=0}^{\infty} \frac{m (dt)^m \exp (-dt)}{m!} = \exp (-dt) \, dt \sum_{m=1}^{\infty} \frac{(dt)^{m-1}}{(m-1)!} = \exp (-dt) \, dt \, \exp (dt) = dt.
\end{align*}

Now, let us calculate the second moment \( \langle m^2 \rangle \). By definition

\begin{align*}
\langle m^2 \rangle &= \sum_{m=0}^{\infty} \frac{m(m - 1 + 1)}{m !}(d t)^m \exp (-dt) \\ &=\sum_{m=2}^{\infty} \frac{m(m-1)}{m !}(d t)^m \exp (-dt)+\sum_{m=1}^{\infty} \frac{m}{m !}(d t)^m \exp (-dt)\\
&= \exp (-dt) \, (dt)^2 \sum_{m=2}^{\infty} \frac{(dt)^{m-2}}{(m-2)!} + \exp (-dt) \, dt \sum_{m=1}^{\infty} \frac{(d t)^{m-1}}{(m-1)!} \\
&= \exp (-dt) \, (dt)^2 \, \exp (dt) + \exp (-dt) \, dt \, \exp (dt) = (d t)^2 + d t.
\end{align*}

The variance is \(\langle m \rangle_{c} \equiv \langle m^{2} \rangle - \langle m \rangle^{2} = dt\).

** 2.10 Diode
:PROPERTIES:
:ID:       606f5026-eb51-4aa7-8783-1ae9756bd686
:END:
:LOGBOOK:
CLOCK: [2024-04-17 Wed 23:32]--[2024-04-18 Thu 01:23] =>  1:51
:END:
*The current \( I \) across a diode is related to the applied voltage \( V \) via \( I = I_0[\exp(eV/kT) - 1] \). The diode is subject to a random potential \( V \) of zero mean and variance \( \sigma^2 \), which is Gaussian distributed. Find the probability density \( p(I) \) for the current \( I \) flowing through the diode. Find the most probable value for \( I \), the mean value of \( I \), and indicate them on a sketch of \( p(I) \).*

Given \( I=I_0[\exp (e V / k T)-1]\) and \(V \sim N\left(0, \sigma^2\right) \), we have \( p(I) d I=\sum_i p\left(V_i\right) \, d V_i \). Since \(V= (K T/ e) \ln (1+I/I_0)\) and we can write \(p(I) &= p(V)\left|\frac{d V}{d I}\right|\).

\begin{align*}
p(I) &= p(V)\left|\frac{d V}{d I}\right| \\
&= \exp \bigg\{-\frac{1}{2}\left(\frac{K T}{\sigma e}\right)^2 \ln (1+I/I_0) \ln (1+I/I_0)\bigg\} \times \frac{K T}{e} (1+I/I_0)^{-1} I_{0}^{-1} (2 \pi \sigma^2)^{-1/2} \\
&= \exp \bigg\{- \ln (1+I/I_0) \bigg[\frac{1}{2}\left(\frac{K T}{\sigma e}\right)^2 \ln (1+I/I_0) + 1\bigg] \bigg\} \times \frac{1}{I_{0}} \frac{K T}{e} (2 \pi \sigma^2)^{-1/2} \\
&= \frac{1}{(I_0+I) (\sigma e / KT)} \cdot \frac{1}{\sqrt{2 \pi}} \exp \bigg\{-\frac{1}{2}\bigg(\frac{\ln (I_0+I)-\ln I_0}{\sigma e / K T}\bigg)^2\bigg\} \\
&= \frac{1}{I (\sigma e / KT)} \cdot \frac{1}{\sqrt{2 \pi}} \exp \bigg\{-\frac{1}{2}\bigg(\frac{\ln I - \ln I_0}{\sigma e / K T}\bigg)^2\bigg\}.
\end{align*}

In the final step we have scaled \(I \to I - I_{0}\); the Jacobian associated with this transformation is unity. It is clear that the current readings are samples from a [[id:52439cfd-3214-4edf-8492-6eaa6159143d][Log-normal distribution]]. The mean is \(I_0 \exp \big\{ (\sigma e / K T)^{2}/2  \big\} > I_{0}\) and the most-probable value is \(I_0 \exp \big\{-(e \sigma/K T)^2\big \} < I_{0}\).

#+begin_src latex :file ~/pictures/.images/spop-sol-2.10.png :results file graphics
  \begin{tikzpicture}[scale=0.8] % Adjust scale for overall size
  \begin{axis}[
      axis lines=left,
      xlabel={$I$},
      ylabel={$p(I)$},
      ymax=0.2,
      ymin=0, % Adjust to avoid extra space below
      xmax=10,
      xmin=0, % Adjust to avoid extra space to the left
      clip=false,
      domain=0.1:10,
      samples=100,
      smooth,
      xtick=\empty,
      ytick=\empty,
      x axis line style={-},
      y axis line style={-},
      xlabel style={at={(axis description cs:1,0)}, anchor=north},
      ylabel style={at={(axis description cs:0,1)}, rotate=-90, anchor=south}
  ]
  % Define the parameters
    \def\Io{4} % I_0
  \def\sigma{1} % sigma

  % Probability density function
  \addplot[black] {1/(x*\sigma) * 1/sqrt(2*pi) * exp(-0.5*((ln(x/\Io)/\sigma)^2))};

  % Define the most probable and mean values
  \pgfmathsetmacro{\Imp}{\Io * exp(-(\sigma^2))}
  \pgfmathsetmacro{\Imean}{\Io * exp((\sigma^2)/2)}

  % Coordinate for I_0 on the curve
  \pgfmathsetmacro{\pIo}{1/(\Io*\sigma) * 1/sqrt(2*pi) * exp(-0.5*((ln(\Io/\Io)/\sigma)^2))}
  \coordinate (I0) at (axis cs:\Io,\pIo);

  % Coordinate for most probable I on the curve
  \pgfmathsetmacro{\pImp}{1/(\Imp*\sigma) * 1/sqrt(2*pi) * exp(-0.5*((ln(\Imp/\Io)/\sigma)^2))}
  \coordinate (Imp) at (axis cs:\Imp,\pImp);

  % Coordinate for mean I on the curve
  \pgfmathsetmacro{\pImean}{1/(\Imean*\sigma) * 1/sqrt(2*pi) * exp(-0.5*((ln(\Imean/\Io)/\sigma)^2))}
  \coordinate (Imean) at (axis cs:\Imean,\pImean);

  % Vertical lines for I_0, most probable I, and mean I
  \draw[dashed, thick] (I0) -- (axis cs:\Io,0) node[below] {$I_0$};
  \draw[dashed, thick] (Imp) -- (axis cs:{\Io*exp(-\sigma^2)},0) node[below] {$I_{\text{mp}}$};
  \draw[dashed, thick] (Imean) -- (axis cs:{\Io*exp(0.5*\sigma^2)},0) node[below] {$\langle I \rangle$};
  \end{axis}
  \end{tikzpicture}
#+end_src

** 2.11 Mutual information
:PROPERTIES:
:ID:       0254a8eb-08e7-464b-b34f-467e4289f2f0
:END:
:LOGBOOK:
CLOCK: [2024-04-18 Thu 01:55]--[2024-04-18 Thu 02:34] =>  0:39
CLOCK: [2024-04-18 Thu 01:28]--[2024-04-18 Thu 01:35] =>  0:07
:END:
*Consider random variables* \(x\) *and* \(y\), *distributed according to a joint probability* \(p(x,\, y)\). *The mutual information between the two variables is defined by*

\[M(x, \, y) = \sum_{xy} p(x, \, y) \ln \bigg( \frac{p(x, \, y)}{p_x(x) \, p_y(y)} \bigg),\]

*where* \(p_x\) *and* \(p_y\) *denote the unconditional probabilities for* \(x\) *and* \(y\).

*** 2.11.1
*Relate* \(M(x,\,y)\) *to the entropies* \(S(x,\,y)\), \(S(x)\), *and* \(S(y)\) *obtained from the corresponding probabilities.*

\begin{align*}
M(x, \, y) &\equiv \sum_{xy} p(x, \, y) \ln \left(\frac{p(x, \, y)}{p_x(x) \, p_y(y)}\right) \\
&= \sum_{xy} p(x, \, y) \ln p(x, \, y)-\sum_{x} \ln p_x(x) \sum_{y}p(x,\,y) - \sum_{y} \ln p_y(y) \sum_{x} p(x,\,y) \\
&\equiv \sum_{xy} p(x,\,y) \ln p(x,\,y)- \sum_x p_x(x) \ln p_x(x) - \sum_y p(y) \ln p_y(y) \\
&\equiv S(x) + S(y) - S(x,\,y).
\end{align*}

*** 2.11.2
*Calculate the mutual information for the joint Gaussian form*

\[ p(x, y) \propto \exp \left( -\frac{a x^2}{2} - \frac{b y^2}{2} - cxy \right). \]

Some combination of the normalization constants of \(p(x,\,y)\), \(p(x)\), and \(p(y)\) will appear in the evaluation of \(M(x,\,y)\) so there's no getting around calculating them.

\begin{align*}
\iint_{-\infty}^{\infty} dy\,dx\,\exp &\left(-\frac{a}{2} x^2-\frac{b}{2} y^2-c x y\right) \\
&=\int_{-\infty}^{\infty} dy\,\exp \left(-\frac{b}{2} y^2\right) \int_{-\infty}^{\infty} dx\, \exp \left(-\frac{a}{2} x^2-c x y\right) \\
&=\int_{-\infty}^{\infty} dy\,\exp \left(-\frac{b}{2} y^2\right) \sqrt{\frac{2 \pi}{a}} \exp \left(\frac{c^2 y^2}{2 a}\right) \\
&=\sqrt{\frac{2 \pi}{a}} \int_{-\infty}^{\infty} d y \exp \left[-\frac{1}{2}\left(\frac{a b-c^2}{2}\right) y^2\right] \\
&=\sqrt{\frac{2 \pi}{a}} \sqrt{\frac{2 \pi a}{a b-c^2}}=2 \pi / \sqrt{a b-c^2}
\end{align*}

The properly normalized joint PDF is therefore

\[
p(x, y) = \frac{\sqrt{a b-c^2}}{2 \pi} \exp \left(-\frac{a x^2}{2}-\frac{b y^2}{2}-c x y\right).
\]

Similarly, the properly normalized marginals are

\begin{align*}
p(x) &= \frac{\sqrt{a b-c^2}}{\sqrt{2 \pi b}} \exp \bigg\{-\frac{1}{2} \bigg(\frac{x}{[a-(c^2/ b)]^{-1/2}}\bigg)^2 \bigg\},
\end{align*}

\begin{align*}
p(y) &= \frac{\sqrt{a b-c^2}}{\sqrt{2 \pi a}} \exp \bigg\{-\frac{1}{2} \bigg(\frac{y}{[b-(c^2/ a)]^{-1/2}}\bigg)^2 \bigg\},
\end{align*}

The mutual information is

\begin{align*}
M(x, y) &= \sum_{x, y} p(x, y)\left[\ln ([1- (c^2/a b)]^{-1 / 2})-c x y - (c^2/2 b)\,x^2 - (c^2/2 a)\,y^2\right] \\
& =\ln ([1-(c^2/ a b)]^{-1 / 2})- (c^2/2 b)\,\int_{-\infty}^{\infty} x^2\,p_x(x)\,d x \\
& - (c^2/2 a)\,\int_{-\infty}^{\infty} y^2\,p_y(y)\,dy -c \int_{-\infty}^{\infty} dx\, x\, \int_{-\infty}^{\infty} dy\, y \, p(x, y).
\end{align*}

The three integrals add up to zero so that the first term is the only survivor. The mutual information \(M (x,\,y)\) is thus \(M (x,\,y) = \ln ([1-(c^2/a b)]^{-1/2})\).
** 2.12 Semi-flexible polymer in two dimensions
:PROPERTIES:
:ID:       cf7e86d2-be63-4d92-924b-3dda1ccdac66
:END:
:LOGBOOK:
CLOCK: [2024-04-18 Thu 16:35]--[2024-04-18 Thu 19:36] =>  3:01
:END:
*Configurations of a model polymer can be described by either a set of vectors* \( \{\boldsymbol{t}_i\} \) *of length \( a \) in two dimensions (for \( i = 1, \ldots, N \)), or alternatively by the angles* \( \{\phi_i\} \) *between successive vectors, as indicated in the figure below.*

#+begin_src latex :file ~/pictures/.images/spop-sol-2.12.png :results file graphics
  \begin{tikzpicture}[vector/.style={-Stealth, thick}, dashed line/.style={dashed, thick}, angle line/.style={dashed, thick}]

    \coordinate (origin) at (0.0, 0.0);
    \coordinate (t1_end) at (1.0, 1.0);
    \coordinate (t2_end) at (1.6666666666666667, 2.6666666666666665);
    \coordinate (t3_end) at (3.3333333333333335, 2.0);
    \coordinate (tN-1_end) at (5.333333333333333, 2.0);
    \coordinate (tN_end) at (6.0, 1.0);
    \coordinate (R_end) at (4.666666666666667, 0.3333333333333333);

    \draw[vector] (origin) -- (t1_end) node[midway, above left] {$\boldsymbol{t}_{1}$};
    \draw[vector] (t1_end) -- (t2_end) node[midway, above left] {$\boldsymbol{t}_{2}$};
    \draw[vector] (t2_end) -- (t3_end) node[midway, above] {$\boldsymbol{t}_{3}$};
    \draw[dashed line] (t3_end) -- (tN-1_end); % Dashed line implies vectors in between
    \draw[vector] (tN-1_end) -- (tN_end) node[midway, above right] {$\boldsymbol{t}_{N-1}$};
    \draw[vector] (tN_end) -- (R_end) node[midway, above] {$\boldsymbol{t}_{N}$};
    \draw[vector] (origin) -- (R_end) node[midway, below] {$\boldsymbol{R}$};

    \draw[angle line] (t1_end) -- ($ (t1_end) + (1.025,1.025) $) node[above, left] {$\phi_{1}$};
    \draw[angle line] (tN_end) -- ($ (tN_end) + (0.67,-1.0) $) node[midway, below, left] {$\phi_{N-1}$};

  \end{tikzpicture}
#+end_src

*The polymer is at a temperature* \( T \), *and subject to an energy*

\[ H = -\kappa \sum_{i=1}^{N-1} \boldsymbol{t}_i \cdot \boldsymbol{t}_{i+1} = - \kappa a^2 \sum_{i=1}^{N-1} \cos \phi_i, \]

*where \( \kappa \) is related to the bending rigidity, such that the probability of any configuration is proportional to* \(\exp(-H/k_{B}T)\).

*** 2.12.1
*Show that* \( \langle \boldsymbol{t}_{m} \cdot \boldsymbol{t}_{n} \rangle \propto \exp(-|n - m|/\xi)\), *and obtain an expression for the persistence length* \( l_p = a \xi \). *(You can leave the answer as the ratio of simple integrals.)*

#+begin_src latex :file ~/pictures/.images/spop-sol-2.12.1.png :results file graphics
  \begin{tikzpicture}[
    vector/.style={-Stealth, thick},
    angle style/.style={angle eccentricity=1.2, draw, angle radius=0.7cm},
    dashed circle/.style={dashed},
    arc style/.style={dotted, bend right, decoration={markings, mark=at position 0.5 with {\node[transform shape] {$\dots$};}}, postaction={decorate}}
  ]

    \coordinate (center) at (0,0);
    \def\radius{2cm}

    \draw[dashed circle] (center) circle[radius=\radius];

    \draw[vector] (center) -- node[at end, below right] {$\boldsymbol{t}_{N}$} ++(0:\radius);
    \draw[vector] (center) -- node[at end, above right] {$\boldsymbol{t}_{1}$} ++(25:\radius);
    \draw[vector] (center) -- node[at end, above left] {$\boldsymbol{t}_{2}$} ++(105:\radius);
    \draw[vector] (center) -- node[at end, below right] {$\boldsymbol{t}_{3}$} ++(185:\radius);
    \draw[vector] (center) -- node[at end, below right] {$\boldsymbol{t}_{N-1}$} ++(285:\radius);

    \draw[vector, angle style] (25:\radius/4) arc (25:105:\radius/4) node[midway, above] {$\phi_{1}$};
    \draw[vector, angle style] (105:\radius/3) arc (105:185:\radius/3) node[midway, above] {$\phi_{2}$};
    \draw[vector, angle style] (285:\radius/4) arc (285:360:\radius/4) node[midway, right] {$\phi_{N-1}$};

    \draw[arc style] (185:\radius/1.5) arc (185:285:\radius/1.55);
  
  \end{tikzpicture}
#+end_src

Without loss of generality, let \(n  - 1 \geq m\). From the schematic above, it is clear that

\begin{align*}
\langle \boldsymbol{t}_{m} \cdot \boldsymbol{t}_n \rangle &= a^2 \bigg \langle \cos \bigg( \sum_{k=m}^{n-1} \phi_k \bigg) \bigg \rangle = \frac{a^2}{2^{n-m}} \bigg( \prod_{k=m}^{n-1} \big \langle \big[ \exp (i \phi_{k}) + \exp (- i \phi_{k}) \big] \big \rangle \bigg) \\
&= \frac{a^2}{2^{n-m}} \bigg( \prod_{k=m}^{n-1} \big \langle \big[ \exp (i \phi_{k}) + \exp (- i \phi_{k}) \big] \big \rangle \bigg) = a^{2} \prod_{k=m}^{n-1} \big \langle \cos \phi_{k} \big \rangle \\
&= a^{2} \big \langle \cos \phi \big \rangle^{n - m} = a^{2} \Bigg( \frac{\int_{0}^{2 \pi} d\phi\, \cos \phi \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}}{\int_{0}^{2\pi} d\phi\, \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}} \Bigg)^{n-m} \\
&\propto \exp \Bigg \{ - \lvert n - m \rvert \ln \Bigg( \frac{\int_{0}^{2\pi} d\phi\, \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}}{\int_{0}^{2 \pi} d\phi\, \cos \phi \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}} \Bigg) \Bigg \}.
\end{align*}

Comparing the expression above with \(\langle \boldsymbol{t}_{m} \cdot \boldsymbol{t}_{n} \rangle \propto \exp(-|n - m|/\xi)\), it is clear that

\[
\xi = \Bigg[ \ln \Bigg( \frac{\int_{0}^{2\pi} d\phi\, \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}}{\int_{0}^{2 \pi} d\phi\, \cos \phi \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}} \Bigg) \Bigg]^{-1},
\]

and using the relation \(l_{p} = a\,\xi\)

\[
l_{p} = a\, \xi = a \Bigg[ \ln \Bigg( \frac{\int_{0}^{2\pi} d\phi\, \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}}{\int_{0}^{2 \pi} d\phi\, \cos \phi \exp \{ (\kappa a^{2} / K_{B} T) \, \phi \}} \Bigg) \Bigg]^{-1}.
\]
*** 2.12.2
*Consider the end-to-end distance* \( \boldsymbol{R} \) *as illustrated in the figure. Obtain an expression for* \( \langle R^2 \rangle \) *in the limit of* \( N \gg 1 \).

Given that \(\boldsymbol{R}=\sum_{n=1}^{N-1} \boldsymbol{t}_n\), we have  \(R^{2} = \boldsymbol{R} \cdot \boldsymbol{R} = \sum_{mn}^{N-1} \boldsymbol{t}_{m} \cdot \boldsymbol{t}_{n} \), and thus

\[
\langle R^2 \rangle = \sum_{mn}^{N-1} \langle \boldsymbol{t}_m \cdot \boldsymbol{t}_n \rangle = \sum_{mn}^{N-1} a^2 \exp \left(-|n-m|/\xi\right).
\]

#+begin_src latex :file ~/pictures/.images/spop-sol-2.12.2.png :results file graphics
  \begin{tikzpicture}[
    dot/.style={circle, fill, minimum size=#1, inner sep=0pt, outer sep=0pt},
    scale=0.75, every node/.style={scale=0.75},
    label font/.style={font=\normalsize}
  ]

    \def\gridWidth{5}
    \def\gridHeight{5}

    \def\xlabels{{"$1$","$2$","$3$","$\ldots$","$N-1$"}}
    \def\ylabels{{"$1$","$2$","$3$","$\vdots$","$N-1$"}}

    \def\maxSize{12pt}
    \def\minSize{3pt}

    \draw[step=1, gray, very thin] (0,0) grid (\gridWidth,\gridHeight);

    \foreach \x in {1,...,\gridWidth} {
      \foreach \y in {1,...,\gridHeight} {
        \pgfmathsetmacro\nodeSize{\maxSize - abs(\x-\y)*(\maxSize-\minSize)/(\gridWidth-1)}
        \node[dot=\nodeSize] at (\x-0.5,\gridHeight-\y+0.5) {};
      }
    }

    \foreach \x [count=\xi] in {1,...,\gridWidth} {
      \node[label font] at (\xi-0.5, \gridHeight+0.5) {\pgfmathparse{\xlabels[\x-1]}\pgfmathresult};
    }

    \foreach \y [count=\yi] in {1,...,\gridHeight} {
      \node[label font] at (-0.5, \gridHeight-\yi+0.5) {\pgfmathparse{\ylabels[\y-1]}\pgfmathresult};
    }

    \node[anchor=west font] at (\gridWidth + 1.0, \gridHeight/2) {$n$};
    \node[anchor=north font] at (\gridWidth/2, -0.5) {$m$};

  \end{tikzpicture}
#+end_src

Consider the schematic. The terms fall off exponentially about \( \lvert n - m \rvert = 0 \). To zeroth order, we could keep the largest blobs and assert \( \langle R^{2} \rangle \approx a^2 N \). We can do better by observing that for a given \(n\) and \( m < n \), we have a geometric series with coefficient and common ratio both equal to \( \exp (- 1/ \xi) \). Therefore, for \( N \gg 1 \), we can assert

\[
\langle R^2 \rangle \approx a^2 N \big[1 + 2 \exp (- 1/\xi) / (1 - \exp (- 1 / \xi))  \big].
\]

*** 2.12.3
*Find the probability* \( p(\boldsymbol{R} ) \) *in the limit of* \( N \gg 1 \).

Given that \(\boldsymbol{R}=\sum_{n=1}^{N-1} \boldsymbol{t}_n\), we can appeal to the central limit theorem and assert that the density \( p (\boldsymbol{R}) \) assumes a Gaussian form in two dimensions. We already have \( \langle R^2 \rangle \), so we need only calculate \( \langle R \rangle \) to write down the actual form. To that end, notice that under the transformation \(\phi_i \rightarrow-\phi_i\), the mirror image of the polymer about the \(y\)-axis is obtained. Since \(\phi_{i}\) enters the Boltzmann weight via the cosine (an even function of its argument), it is invariant under the transformation \( \phi_{i} \to - \phi_{i} \). This means that \( \boldsymbol{R}  \) and \( - \boldsymbol{R}  \) occur with the same probability. It immediately follows that \( \langle \boldsymbol{R}  \rangle = 0 \). Now, the covariance matrix is

\begin{align*}
\begin{bmatrix}
\langle R_{x}^2 \rangle & 0 \\
0 & \langle R_{y}^2 \rangle
\end{bmatrix} =
\begin{bmatrix}
\langle R^2 \rangle / 2 & 0 \\
0 & \langle R^2 \rangle / 2
\end{bmatrix}
\end{align*}

where we have used the fact that \( \phi_{i} \) is independent and identically distributed to assert \( \langle R_{x} R_{y} \rangle = \langle R_{y} R_{x} \rangle = 0 \), and the rotational invariance of the Hamiltonian to assert \( \langle R_{x} \rangle = \langle R_{y} \rangle = \langle R \rangle/2 \). The determinant of the covariance matrix is \( \langle R^2 \rangle^{2} / 4 \), thus the normalization for the two dimension Gaussian is \( 1 / \sqrt{4 \pi^{2} \langle R^2 \rangle^{2}/4} = 1 / \pi \langle R^2 \rangle \). Thus, \( p (\boldsymbol{R} ) \) assumes the form \( p (\boldsymbol{R}) = \pi^{-1} \langle R^{2} \rangle^{-1} \exp (\boldsymbol{R} \cdot \boldsymbol{R} / \langle R^{2} \rangle) \).

*** 2.12.4
*If the ends of the polymer are pulled apart by a force* \( \boldsymbol{F}  \), *the probabilities for polymer configurations are modified by the Boltzmann weight* \( \exp \left(\frac{\boldsymbol{F} \cdot \boldsymbol{R} }{k_BT}\right) \). *By expanding this weight, or otherwise, show that*

\[ \langle \boldsymbol{R}  \rangle = K^{-1} \boldsymbol{F}  + \mathcal{O} (F^3), \]

*and give an expression for the Hookian constant* \( K \) *in terms of quantities calculated before.*

When the ends of the polymer are pulled apart by a force \( \boldsymbol{F}  \), the symmetry under the transformation \( \phi_{i} \to -\phi_{i} \) is broken, and \( \langle \boldsymbol{R}  \rangle \) becomes non-vanishing. We have

\begin{align*}
\langle \boldsymbol{R}  \rangle=\frac{\langle \boldsymbol{R}  \exp (\beta \boldsymbol{F}  \cdot \boldsymbol{R})\rangle}{\langle\exp (\beta \boldsymbol{F}  \cdot \boldsymbol{R} )\rangle}
\end{align*}

However, for sufficiently small forces, we can expand \( \exp (\beta \boldsymbol{F}  \cdot \boldsymbol{R}) \) in powers of \( \boldsymbol{F}  \) about \( \boldsymbol{F} = \boldsymbol{0} \). we have

\[
\langle R_{n}  \rangle \propto \langle R_{n} \exp (\beta F_{m} R_{m})  \rangle = \langle R_{n}  \rangle + \beta F_{m} \langle R_{m} R_{n} \rangle  + \frac{\beta^{2} F_{m}^{2} \langle R_{m}^{2} R_{n} \rangle}{2} + \mathcal{O} (F^{3}).
\]

Since the expansion is about \( \boldsymbol{F} = \boldsymbol{0} \), odd powers of \(\boldsymbol{R} \) vanish due to the symmetry discussed in 2.12.3. Furthermore, \( \langle R_{m} R_{n} \rangle = \langle R^{2} \rangle / 2 \), because rotational invariance is restored. Finally, if we assume \( \langle \exp (\beta \boldsymbol{F} \cdot \boldsymbol{R}  ) \rangle = 1 \) for \( \boldsymbol{F} \approx \boldsymbol{0} \), we are left with \( \langle \boldsymbol{R}  \rangle =  \beta \boldsymbol{F} \langle R^{2} \rangle/2 + \mathcal{O} (F^{3})\) which is of the form \( \langle \boldsymbol{R}  \rangle = K^{-1} \boldsymbol{F}  + \mathcal{O} (F^3) \) if \( K = 2 K_{B} T / \langle R^{2} \rangle \).
** 2.14 Jensen's inequality and Kullback-Liebler divergence
:PROPERTIES:
:ID:       34b7a24f-52de-4df5-bb04-be2c86a23e48
:END:
:LOGBOOK:
CLOCK: [2024-04-19 Fri 05:15]--[2024-04-19 Fri 05:35] =>  0:20
CLOCK: [2024-04-19 Fri 03:56]--[2024-04-19 Fri 05:10] =>  1:14
:END:
*A convex function* \(f(x)\) *always lies above the tangent at any point, i.e.* \(f(x) \geq f(y)+f^{\prime}(y)(x-y)\) *for all* \(y\).

*** 2.14.1 
*Show that for a convex function* \(\langle f(x)\rangle \geq f(\langle x\rangle)\).

Consider \( x_1, x_2, \ldots, x_n \) as points within the domain of \( f \) and corresponding probability masses \( p_1,\,p_2,\,\ldots,\,p_n \), such that \( \sum_{i=1}^n p_i = 1 \). By definition

\[
\langle x \rangle = \sum_{i=1}^n p_i\,x_i \qquad \qquad \langle f(x) \rangle = \sum_{i=1}^n p_i f(x_i)
\]

Now substitute \( y = \langle x \rangle \) in the convexity property \(f(x) \geq f(y) + f'(y)(x-y)\) to obtain for any \( x_i \) in the domain of \( f \)

\[
f(x_i) \geq f(\langle x \rangle) + f'(\langle x \rangle)(x_i - \langle x \rangle)
\]

Using the probability masses \( p_1,\,p_2,\,\ldots,\,p_n \), we form the expectations

\[
\sum_{i=1}^n p_i f(x_i) \geq \sum_{i=1}^n p_i \left(f(\langle x \rangle) + f'(\langle x \rangle)(x_i - \langle x \rangle)\right)
\]

The sum of the terms involving \( f'(\langle x \rangle)(x_i - \langle x \rangle) \) equals zero due to the definition of the expectation

\[
\sum_{i=1}^n p_i (x_i - \langle x \rangle) = 0.
\]

This simplifies to [[id:56afc0f9-990f-4e3c-ab03-44b5571eb321][Jensen's inequality]]

\[
\langle f(x) \rangle \geq f(\langle x \rangle).
\]

*** 2.14.2
*The Kullback-Liebler divergence of two probability distributions* \(p(x)\) *and* \(q(x)\) *is defined as* \(D(p \mid q) \equiv \int d x p(x) \ln [p(x) / q(x)]\). *Use Jensen's inequality to prove that* \(D(p \mid q) \geq 0\).

We use Jensen's inequality \( \langle f(x) \rangle \geq f(\langle x \rangle) \) with \( f(x) = - \ln x \) to get \( \langle - \ln x \rangle \geq - \ln \langle x \rangle \). It follows that

\[\int dx\,p(x)\big[-\ln (q(x)/p(x)) \big] \geq - \ln &\bigg(\int dx\,p(x)\,\big[q(x)/p(x)\big]\bigg)\]

Now we rewrite the left hand side as \( \int dx\,p(x)\big[\ln (p(x)/q(x)) \big] \) and simplify the right hand side to \( -\ln \big(\int dx\,q(x)\big) = - \ln (1) = 0 \). The resulting relation is the non-negativity of the [[id:a72ac711-488c-4ab4-b483-9d3b5cc233fc][Kullback-Liebler divergence]]

\[
\int dx\,p(x)\,\big[\ln (q(x)/p(x))\big] \equiv D(p \mid q) \geq 0.
\]
** 2.15 The book of records
:PROPERTIES:
:ID:       386bac1f-f9d0-4175-b9c4-f8cadae238fc
:END:
:LOGBOOK:
CLOCK: [2024-04-19 Fri 05:40]--[2024-04-19 Fri 07:03] =>  1:23
:END:
*Consider a sequence of random numbers* \(\left\{x_{1}, x_{2}, \cdots, x_{n}, \cdots\right\}\); *the entry* \(x_{n}\) *is a record if it is larger than all numbers before it, i.e. if* \(x_{n}>\left\{x_{1}, x_{2}, \cdots, x_{n-1}\right\}\). *We can then define an associated sequence of indicators* \(\left\{R_{1}, R_{2}, \cdots, R_{n}, \cdots\right\}\) *in which* \(R_{n}=1\) *if* \(x_{n}\) *is a record, and* \(R_{n}=0\) *if it is not (clearly* \(R_{1}=1\) *)*.

*** 2.15.1
*Assume that each entry* \(x_{n}\) *is taken independently from the same probability distribution* \(p(x)\). *In other words,* \(\left\{x_{n}\right\}\) *are IIDs (independent identically distributed). Show that, irrespective of the form of* \(p(x)\), *there is a very simple expression for the probability* \(P_{n}\) *that the entry* \(x_{n}\) *is a record.*

Given that \(\left\{x_n\right\}\) are IIDS, \(p\left(x_n \mid x_m\right)=p\left(x_n\right)\). With just this fact, the maximally disperse PDF is the uniform. For the \(n^{\text {th }}\) entry \(P_n= n^{-1}\).

*** 2.15.2
*The records are entered in the Guinness Book of Records. What is the average number* \(\left\langle S_{N}\right\rangle\) *of records after* \(N\) *attempts, and how does it grow for* \(N \gg 1\) *? If the number of trials, e.g., the number of participants in a sporting event, doubles every year, how does the number of entries asymptotically grow with time.*

\begin{align*}
\langle S_N \rangle =\sum_{n=1}^N P_n = \sum_{n=1}^N n^{-1} \approx \ln N+\gamma, \qquad N \gg 1.
\end{align*}

where

\[\gamma \equiv \lim _{n \rightarrow \infty} \bigg(-\ln (n)+\sum_{k=1}^n 1 / k\bigg),\]

the Euler-Mascheroni contant. Participant doubling on a yearly basis mean the number of participants in the \( t^{\text{th}} \) year is \(\propto 2^t\), so that \(\langle S_N\rangle \approx t \ln (2) + \gamma\) for \(N \gg 1\).

*** 2.15.3
*Prove that* \(\left\langle R_{n} R_{m}\right\rangle_{c}=0\) *for* \(m \neq n\). *(The record indicators* \(\left\{R_{n}\right\}\) *are in fact independent random variables, though not identical, which is a stronger statement than the vanishing of the covariance.)*

The cumulant \( \langle R_n R_m \rangle_c \) can be calculated from the moments as \( \langle R_n R_m \rangle_c = \langle R_n R_m \rangle - \langle R_n \rangle \langle R_m \rangle \) where \(\langle R_n \rangle = P(R_n = 1) = n^{-1} \), \(\langle R_m \rangle = P(R_m = 1) = m^{-1}\), and \(\langle R_n R_m \rangle = P(R_{n}=1 \wedge R_{m} = 1)\). Without loss of generality, let \(m < n\). For the event \(R_m = 1 \wedge R_n = 1\) to occur 1) \(x_m\) must be the largest among \(x_1, ..., x_m\), 2) \(x_n\) must be the largest overall, independent of \(x_m\)’s status. Thus \( \langle R_n R_m \rangle = 1 \cdot P(R_n = 1 \wedge R_m=1) = (nm)^{-1} \). It is then clear that \( \langle R_n R_m \rangle_c = (nm)^{-1} - n^{-1}\,m^{-1} = 0 \).

*** 2.15.4
*Compute all moments, and the first three cumulants of the total number of records* \(S_{N}\) *after* \(N\) *entries. Does the central limit theorem apply to* \(S_{N}\) *?*

Let \( S_N = \sum_{n=1}^N R_n \), where \( R_n \) is the indicator random variable for records, i.e., \( R_n = 1\) if \(x_n\) is a record, otherwise \( R_n = 0 \). By virtue of being an indicator random variable, \( R_n \) satisfies the property \( \langle R_n^m \rangle = n^{-1} \) for any positive integer  \( m \). Hence, the cumulants are easily obtained using the moments

\begin{align*}
\langle S_N \rangle_c &= \sum_{n=1}^N \langle R_n \rangle_c = \sum_{n=1}^N n^{-1}, \\
\langle S_N^2 \rangle_c &= \sum_{n=1}^N \langle R_n^2 \rangle_c = \sum_{n=1}^N (n^{-1} - n^{-2}), \\
\langle S_N^3 \rangle_c &= \sum_{n=1}^N \langle R_n^3 \rangle_c = \sum_{n=1}^N (n^{-1} - 3 n^{-2} + 2 n^{-3}).
\end{align*}

The characteristic function for \( S_N \), in terms of the characteristic function of \( S_{N-1} \) is

\begin{align*}
\langle \exp(-i k S_N) \rangle &= N^{-1} \big[ \exp(-i k) \langle \exp(-i k S_{N-1}) \rangle + (N-1) \langle \exp(-i k S_{N-1}) \rangle \big] \\
&= N^{-1} (\exp(-i k) + N-1) \langle \exp(-i k S_{N-1}) \rangle.
\end{align*}

Utilizing the base case \( S_1 = 1 \), or \( \langle \exp(-i k S_1) \rangle = \exp(-i k) \), we can use this recursive relation to find the characteristic function for any \( N \)

\[
\langle \exp(-i k S_N) \rangle = (N!)^{-1} \prod_{n=1}^N (\exp(-i k) + n - 1).
\]

Approximately, this expands as:

\[
\langle \exp(-i k S_N) \rangle = (N!)^{-1} \sum_{n=0}^N \mathrm{S}_1 (N, n) \exp(-i k n),
\]

where \( \mathrm{S}_1 (N, n) \) is the /unsigned Stirling number of the first kind/. On expanding \( \exp(-i k n) \) in a Taylor series in \( k \) about \( k = 0 \)

\begin{align*}
\cdot\left\langle\exp \left[-i k S_N\right]\right\rangle & = (N!)^{-1} \sum_{n=0}^N \mathrm{S}_1 (N, n) \sum_{m=0}^{\infty} \frac{n^m(-i k)^m}{m !} \\
& =\sum_{m=0}^{\infty} \frac{(-i k)^m}{m !}\left[(N!)^{-1} \sum_{n=0}^N \mathrm{S}_1(N, n) n^m\right],
\end{align*}

we can read off the moments of \( S_{N} \)

\begin{align*}
\langle S_N^m\rangle= (N!)^{-1} \sum_{n=0}^N \mathrm{S}_1(N, n) n^m.
\end{align*}

*** 2.15.5
*The first record, of course, occurs for* \(n_{1}=1\). *If the third record occurs at trial number* \(n_{3}=9\), *what is the mean value* \(\left\langle n_{2}\right\rangle\) *for the position of the second record? What is the mean value* \(\left\langle n_{4}\right\rangle\) *for the position of the fourth record?*

\(n_2\) can take values from 2 to 8 . Let \(n_2=n, 2 \leqslant n \leqslant 8\). We have \( P(R_n=1)= n^{-1} \) and \( P(R_n=0)=1- n^{-1} \). Therefore

\[
p\left(n_2=n\right)=\frac{1}{1} \cdot \frac{(n-3)}{(n-2)} \cdot \frac{(n-2)}{(n-1)} \cdots \frac{1}{n} \cdot \frac{n}{(n+1)} \cdot \frac{(n+1)}{(n+2)} \cdots \frac{1}{8} \cdot \frac{1}{9} = \frac{1}{72(n-1)}.
\]

\[
\langle n_2 \rangle = \bigg(\sum_{n_2=2}^8 n_2 \cdot \frac{1}{72(n_2-1)} \bigg) \bigg(\sum_{n_2=2}^8 \frac{1}{72(n_2-1)} \bigg)^{-1} = 1343/363 \approx 3.7.
\]

** 2.16 Jarzynski equality
:PROPERTIES:
:ID:       71074a92-d485-49e0-b3e7-4adb0098106f
:END:
:LOGBOOK:
CLOCK: [2024-04-20 Sat 07:30]--[2024-04-20 Sat 08:38] =>  1:08
:END:
*In equilibrium at a temperature* \(T\), *the probability that a macroscopic system is in a microstate* \(\mu\) *is* \(p(\mu)=\exp [-\beta \mathcal{H}(\mu)] / Z\), *where* \(\mathcal{H}(\mu)\) *is the energy of the microstate,* \(\beta=1 /\left(k_{B} T\right)\), *and the normalization factor is related to the free energy by* \(-\beta F=\ln Z\). *We now change the macroscopic state of the system by performing external work* \(W\), *such that the new state is also in equilibrium at temperature* \(T\). *For example, imagine that the volume of a gas in changed by moving a piston as* \(L(t)=L_{1}+\left(L_{2}-L_{1}\right) t / \tau\). *Depending on the protocol (e.g., the speed* \(u=\left(L_{2}-L_{1}\right) / \tau\)), *the process may be close to or far from reversible. Nonetheless, the Jarzynski equality relates the probability distribution for the work* \(W\) *to the equilibrium change in free energy!*

*** 2.16.1
*Assume that the process by which work is performed is fully deterministic, in the sense that for a given protocol, any initial microstate* \(\mu\) *will evolve to a specific final microstate* \(\mu^{\prime}\). *The amount of work performed* \(W(\mu)\) *will vary with the initial microstate, and there is thus a probability distribution* \(p_{f}(W)\) *which can be related to the equilibrium* \(p(\mu)\). *The energy of the final microstate, however, is precisely* \(\mathcal{H}^{\prime}\left(\mu^{\prime}\right)=\mathcal{H}(\mu)+W(\mu)\). *Time reversal symmetry implies that if we now instantaneously reverse all the momenta, and proceed according to the reversed protocol, the time-reversed microstate* \(\overline{\mu^{\prime}}\) *will deterministically evolve back to microstate* \(\mu\), *and the work* \(-W(\mu)\) *is recovered. However, rather than doing so, we first allow the system to equilibrate into its new macrostate at temperature* \(T\), *before reversing the protocol to recover the work. The recovered work* \(-W\) *will now be a function of the selected microstate, and distributed according to a different probability* \(p_{b}(-W)\), *related to* \(p^{\prime}\left(\mu^{\prime}\right)=\exp \left[-\beta \mathcal{H}^{\prime}\left(\mu^{\prime}\right)\right] / Z^{\prime}\). *It is in general not possible to find* \(p_{f}(W)\) *or* \(p_{b}(-W)\). *However, by noting that the probabilities of a pair of time-reversed microstates are exactly equal, show that their ratio is given by*

\begin{align*}
\frac{p_{f}(W)}{p_{b}(-W)}=\exp \left[\beta\left(W+F-F^{\prime}\right)\right]
\end{align*}

*While you were guided to prove the above result with specific assumptions, it is in fact more generally valid, and known as the work-fluctuation theorem.*

\begin{align*}
p_f(W)\,dW= \sum_{W (\mu)= W} p(\mu)\,d\mu \qquad p_b(-W)\,dW = \sum_{W^{\prime} (\mu^{\prime})=-W} p^{\prime} (\mu^{\prime})\,d\mu^{\prime}
\end{align*}

Equilibrium is restored at the same temperature. Therefore, \(d \mu=d \mu^{\prime}\). Given the one-to-one mapping between \(\mu\) and \(\mu^{\prime}\), we have

\[
p_b(-W)\,dW = \sum_{W^{\prime} (\mu^{\prime})=-W} p^{\prime} (\mu^{\prime})\,d\mu^{\prime} = \sum_{W(\mu)=W} p^{\prime} (\mu^{\prime}(\mu))\, d \mu
\]

\[
p_f(W) \sum_{W(\mu)=W} p^{\prime} (\mu^{\prime}(\mu))\,d\mu = p_b(-W) \sum_{W(\mu)=W} p(\mu)\,d\mu \tag{2.16.1.1}
\]

Regardless of the intermediate steps, detailed balance must be satisfied. Thus

\[\frac{p(\mu)\,d\mu}{p^{\prime}(\mu^{\prime}(\mu))\,d\mu} &= (Z^{\prime}/Z) \exp (-\beta [H (\mu)- H^{\prime}(\mu^{\prime})]) =\exp \left[\beta\left(W+F-F^{\prime}\right)\right] \tag{2.16.1.2}
\]

From (2.16.1.1) and (2.16.1.2), we get

\[
\frac{p_f(W)}{p_b(-W)}=\exp \left(\beta\left[W+F-F^{\prime}\right]\right). \tag{2.16.1.3}
\]

*** 2.16.2
*Prove the Jarzynski equality*

\[
F^{\prime}-F \equiv \Delta F = -k_{B} T \ln \langle \exp (- \beta W) \rangle \equiv- k_{B} T \ln \bigg[\int d W p_{f}(W) \exp (-\beta W) \bigg]
\]

*This result can in principle be used to compute equilibrium free energy differences from an ensemble of non-equilibrium measurements of the work. For example, in Liphardt, et. al., Science 296, 1832 (2002), the work needed to stretch a single RNA molecule was calculated and related to the free energy change. However, the number of trials must be large enough to ensure that the averaged exponential, which is dominated by rare events, is accurately obtained.*

Using (2.16.1.3), \(\quad p_f(W) \exp (-\beta W)= p_b(-W) \exp (-\beta \Delta F)\). Thus

\begin{align*}
\int &d W p_b(-W) \exp (-\beta \Delta F)=\int d W p_f(W) \exp (-\beta W) \\
&\Rightarrow \quad \exp (-\beta \Delta F)= \langle\exp (-\beta W)\rangle \\
&\Rightarrow \Delta F \equiv F^{\prime}-F=- \beta^{-1} \ln \langle \exp (-\beta W) \rangle \equiv - K_B T \ln \bigg[\int d W p_f(W) \exp(-\beta W)\bigg].
\end{align*}

This is the [[id:c38f4ce5-97be-450c-b588-c8c082338f27][Jarzynski equality]].
*** 2.16.3
*Use the Jarzynski equality to prove the familiar thermodynamic inequality*

\[\langle W\rangle \geq \Delta F\]

The Jarzynski equality states that

\[
F^{\prime}-F \equiv \Delta F = -k_{B} T \ln \langle \exp (- \beta W) \rangle
\]

Using Jensen's inequality, we have \( \langle \exp (- \beta W) \rangle \geq \exp (- \beta \langle W \rangle) \), so that

\begin{align*}
\Delta F & =-K_B T\langle\exp (-\beta W)\rangle \leqslant-K_B T \ln [\exp (-\beta\langle W\rangle)] =\langle W \rangle.
\end{align*}

*** 2.16.4
*Consider a cycle in which a work* \(W-\omega\) *is performed in the first stage, and work* \(-W\) *is returned in the reversed process. According to the second law of thermodynamics, the net gain* \(\omega\) *must be positive. However, within statistical physics, it is always possible that this condition is violated. Use the above results to conclude that the probability of violating the second law decays with the degree of violation according to*

\begin{align*}
P_{\text {violating second law }}(\omega>0) \leq \mathrm{e}^{-\omega} \text {. }
\end{align*}

*Two relevant articles: (i) On the Jarzynski relation, G.E. Crooks and C. Jarzynski, Phys. Rev. E 75, 021116 (2007); (ii) Regarding records, J. Krug, J. Stat. Mech. (2007) P07001.*

Let \(p(\omega)\) be the PDF that gives the probability density of violation of the second law by a degree \(\omega>0\), \( p(\omega)=\int p_f(W-\omega) p_b(-W)\,dW \). Using (2.16.1.3),

\[
\frac{p_f(W-\omega) p_b(-w)}{p_b(-W+\omega) p_f(w)} = \frac{\exp \big(\beta (W-\omega+F-F^{\prime})\big)}{\exp \big(\beta (W+F-F^{\prime}) \big)}.
\]

It follows that \( p_f(W-\omega) p_b(-W) & =p_b(-W+\omega) p_f(W) \exp (-\beta \omega) \). We then arrive at the PDF

\[
p (\omega) =\int dW\,p_b(-W+\omega) p_f(W) \exp (-\beta \omega) = p(-\omega) \exp (-\beta \omega). \tag{2.16.4.1}
\]

The CDF, say \( P(\omega) \), is 

\[
P(\omega) \equiv \int_\omega^{\infty} \omega^{\prime} p (\omega^{\prime}) & =\int_\omega^{\infty} \omega^{\prime} p (-\omega^{\prime}) \exp (-\beta \omega^{\prime}) <\exp (-\beta \omega) \int_\omega^{\infty} \omega^{\prime} p (-\omega^{\prime} ) < \exp (-\beta \omega).
\]

We have used (2.16.4.1) followed by replacing \(\omega^{\prime}\) by \(\omega\). The inequality follows because \(\exp \left(-\beta \omega^{\prime}\right)<\exp (-\beta \omega)\).

** 2.17 Approach to equilibrium
:PROPERTIES:
:ID:       d0e163af-e5e9-4a00-bbde-6856b144032b
:END:
:LOGBOOK:
CLOCK: [2024-04-20 Sat 08:44]--[2024-04-20 Sat 11:40] =>  2:56
:END:
*For a dynamical system described by parameters* \(\mathbf{x}=\left\{x_{i}\right\}\), *we can define time dependent correlation functions* \(C_{i j}(t)=\langle x_{i}(t) x_{j}(0)\rangle\).

*** 2.17.1
*Show that time translational invariance* \((C(t)=C(t+\tau))\), *combined with time reversal symmetry* \((C(t)=C(-t))\) - *both characteristics of equilibrium* - *implies* \(C_{i j}(t)=C_{j i}(t)\).

Setting \( \tau = t \) in \(C_{ij}(-t) = C_{ij} (-t + \tau)\) yields \(C_{ij}(-t) = C_{ji} (t)\). But \(C_{ij}(-t) = C_{i j}(t)\). Therefore \( C_{ij}(t) = C_{ji}(t) \).

*** 2.17.2
*If the equilibrium weight for small fluctuations is Gaussian distributed, with density function*

\begin{align*}
c=\sqrt{\frac{\operatorname{det}[K]}{(2 \pi)^{n}}} \exp \left[-\frac{1}{2} \sum_{i j} K_{i j} x_{i} x_{j}\right]
\end{align*}

*relate* \(C_{i j}(0)\) *to the (positive definite) matrix* \([K]\).

At equilibrium, \(\mathbf{x}=\left\{x_{i}\right\}\) are the fluctuations in the equilibrium value of the parameters in the dynamical system. If \( S (\mathbf{x}) \) denotes the entropy of the system, then the probability density \( p (\mathbf{x}) \) for a fluctuation \( \mathbf{x} \) is \( p(\mathbf{x}) \propto \exp (S(\mathbf{x})/K_B) \). For sufficiently small fluctuations, we can expand \( S (\mathbf{x}) \) in a [[id:1d3383f5-5945-4d7f-b7b6-e8971afe319d][Taylor series]]

\[
S (\mathbf{x}_{\text{eq}} + \mathbf{x}) \approx S (\mathbf{x}_{\text{eq}}) + 2^{-1} \sum_{ij} (\partial_{x_i}\,\partial_{x_j} S(\mathbf{x}_{\text{eq}}))\, x_{i} x_{j}.
\]

With \(  \)\( K_{ij} \equiv - (\partial_{x_i}\,\partial_{x_j} S(\mathbf{x}_{\text{eq}})) / K_{B} \), we have \( p(\mathbf{x}) \propto \exp \big(- 2^{-1} \sum_{ij} K_{ij} x_{i} x_{j}\big)\). When properly normalized, we are left with a multivariate Gaussian distribution of the form

\[p (\mathbf{x}) = (2 \pi)^{-n/2} (\det \mathbf{K})^{1/2} \exp \bigg(- 2^{-1} \sum_{i j} K_{i j} x_{i} x_{j} \bigg).\]
where \(\boldsymbol{K} \equiv \Sigma^{-1}\) is the inverse of the covariance matrix - called the precision matrix. Given \( \langle x_i x_j \rangle_c = \Sigma_{ij} \), we have \(C_{ij} (0) = \langle x_i(0) \,x_j(0) \rangle_c = \langle x_i\,x_j \rangle_c = K^{-1}_{ij} \).

*** 2.17.3
*Conjugate variables (forces) are defined by* \(J=-\partial_{x} \ln p(\mathbf{x})\). *Show that* \(\langle J x\rangle=\delta\).

The conjugate force for the generalized displacement \( x_i \) is

\[
J_i = - \partial_{x_i} \ln p(\mathbf{x}) = 2^{-1} \,\partial_{x_i} \bigg(\sum_{i j} K_{i j} x_i x_j\bigg)= \sum_j K_{i j} x_j.
\]
We then have

\[
\langle J_i x_k \rangle= \bigg \langle\bigg(\sum_j K_{i j} x_j\bigg) x_k \bigg \rangle =\sum_j K_{i j}\left\langle x_j x_k\right\rangle=\sum_j K_{i j} \, [K^{-1}]_{j k} = [K K^{-1}]_{ik} = \delta_{i k}.
\]

*** 2.17.4
*In a generalized form of gradient descent, relaxation to equilibrium follows* \(\dot{x}_{i}=\) \(-\mu_{i} J=-\mu_{i} K \quad x\), *where* \(\left\{\mu_{a b}\right\}\) *are kinetic coefficients. By considering* \(D_{t} C_{i j} (0)\) *show that the matrix* \(\mu\) *must be symmetric. (This is an example of an Onsager relation).*

Since \(C_{ij} (t) = C_{ji} (t)\), we have \(\langle (\mathrm{D}_t x_i (t)) x_j (0) \rangle = \langle (\mathrm{D}_t x_j (t)) x_i (0)  \rangle\), or \(\mu_{ik} \langle J_{k} (t) \, x_{j} (0) \rangle = \mu_{jk} \langle J_{k} (t) \, x_{i} (0) \rangle\). At \( t = 0 \), we have \(\mu_{ik} \langle J_{k} x_{j} \rangle = \mu_{jk} \langle J_{k} x_{i} \rangle\). Using \( \langle J_i x_k \rangle = \delta_{ik} \) from (2.17.3) we get \(\mu_{ik} \delta_{kj} = \mu_{jk} \delta_{ki} \) and thus \( \mu_{ij} = \mu_{ji} \).

* 3 Kinetic theory of gases
** 3.1 One-dimensional gas
:PROPERTIES:
:ID:       54029e29-f615-4482-919f-022e50022ae2
:END:
:LOGBOOK:
CLOCK: [2024-04-20 Sat 12:39]--[2024-04-20 Sat 18:25] =>  5:46
:END:
*A thermalized gas particle is suddenly confined to a one-dimensional trap. The corresponding mixed state is described by an initial density* \( \rho(q,\,p,\,t = 0) = \delta(q)\,f(p) \), *where* \( f(p) = (2\pi\, m K_B T)^{-1/2} \exp(-p^2/2m K_B T)\).

*** 3.1.1
*Starting from Liouville's equation, derive* \( \rho(q,\,p,\,t) \) *and sketch it in the \((q,\,p)\) plane.*

- \(f(q, p, t=0)=\delta(q) f(p), f(p)=\frac{\exp \left(-p^2 / 2 m K_B T\right)}{\sqrt{2 \pi m K_B T}}\)

The [[id:a2da6b4b-5ecc-4ad5-9268-33aeab1643f6][Liouville's equation]] is \(\partial_t \rho = - \{\rho, H \}\). The [[id:d8d2e4a1-0da2-4031-9a83-c9b93e16676c][Poisson bracket]] \(\{\rho, H \}\), with \(H=p^2 / 2 m\) evaluates to

\[
\big[ (\partial_q \rho) \, (\partial_p H) - (\partial_p \rho) \,
(\partial_q H) \big] = (p/m) \, (\partial_q \rho)
\]

so we must have \(\partial_t \rho = - (p / m)\,\partial_q \rho \). We use the [[id:b1fbfbc6-fcd6-4519-bc82-adbccded6709][Method of characteristics]]. The [[id:6addcb36-479e-4b1e-83c2-0e530632a35f][Lagrange-Charpit equations]] are

\[\mathrm{D}_t \rho = 0,\qquad \mathrm{D}_t q = \partial_p H = p/m\]

the later of which has solution \( q(t) = (p/m) \, t \). This is the characteristic curve for the PDE \(\partial_t \rho = - (p / m)\,\partial_q \rho \). Thus, the solution, subject to the given initial condition is

\[
\rho (q,\,p,\,t) = \rho (q - (p/m)\,t,\,p,\,0) = \delta (q - (p/m)\,t) \, f(p).
\]

#+begin_src latex :file ~/pictures/.images/spop-sol-3.1.1.png :results file graphics
  \begin{tikzpicture}
    \begin{axis}[
        axis lines=center,
        width=6cm, height=6cm,
        axis equal image,
        xlabel={$q$},
        ylabel={$p$},
        xtick=\empty,
        ytick=\empty,
        xlabel style={at=(current axis.right of origin), anchor=north},
        ylabel style={at=(current axis.above origin), anchor=east},
        xmin=-3, xmax=3,
        ymin=-3, ymax=3,
        clip=false
      ]
      % Plot line
      \addplot+[no marks, black, -stealth] expression[domain=-3:3,samples=100]{x} 
      node[pos=0.95, xshift=2.5pt, right] {$\delta(q-(p/m)\,t) f (p)$};
    
      % Label tan inverse equation in the 4th quadrant
      \node at (axis cs: 2, -2) {$\tan^{-1}(\theta) = m/t$};
    \end{axis}
  \end{tikzpicture}
#+end_src

*** 3.1.2
*Derive the expressions for the averages* \( \langle q^2 \rangle \) *and* \( \langle p^2 \rangle \) *at* \( t > 0 \).

\[
\langle p^2 \rangle = \int p^2 \delta(q-(p / m) t) f(p)\,dp\,dq =\int p^2 f(p)\,dp = (2\pi\, m K_B T)^{-1/2} \int p^2 \exp(-p^2/2m K_B T)\,dp = m K_B T,
\]

\[
\langle q^2 \rangle = \int q^2 \delta(q-(p / m) t) f(p)\,dp\,dq =\int [t\,(p/m)]^2 f(p)\,dp =(t / m)^2 \langle p^2 \rangle = (m^{-1} K_B T)\,t^2.
\]
*** 3.1.3
*Suppose that hard walls are placed at* \( q = \pm Q \). *Describe* \( \rho(q,\,p,\,t > \tau) \), *where* \( \tau \) *is an appropriately large relaxation time.*

#+begin_src latex :file ~/pictures/.images/spop-sol-3.1.3.png :results file graphics
  \begin{tikzpicture}

    \def\Q{2} % The Q value
    \def\spacing{2.0}
    \def\midT{3} % Midpoint on the t-axis
    \def\lineCount{4} % Number of lines on each side of the center line

    % Define the slope values for each panel
    \def\slopeOne{0.8}
    \def\slopeTwo{0.4}
    \def\slopeThree{0.2}

    \def\slopeOneQ{0.7}
    \def\slopeTwoQ{0.35}
    \def\slopeThreeQ{0.15}

    \newcommand\drawLinesOne[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-\yinterceptRange,\spacing,...,\yinterceptRange} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4};
      }
    }

    \newcommand\drawLinesTwo[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-\yinterceptRange,\spacing,...,\yinterceptRange} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4*2};
      }
    }

    \newcommand\drawLinesThree[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-\yinterceptRange,\spacing,...,\yinterceptRange} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4*3};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y - #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y + #1*4*3};
      }
    }

    % Define function to draw multiple lines
    \newcommand\drawLinesFour[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-3,\spacing,...,3} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4};
      }
    }

    % Define function to draw multiple lines
    \newcommand\drawLinesFive[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-3,\spacing,...,3} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4*2};
      }
    }

    % Define function to draw multiple lines
    \newcommand\drawLinesSix[2]{
      \pgfmathsetmacro\yinterceptRange{\lineCount * \spacing}
      \foreach \y in {-3,\spacing,...,3} {
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4*3};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y- #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4*2};
        \addplot+[mark=none, black, domain=-2:2, samples=2] {#1*\x + \y+ #1*4*3};
      }
    }

    % Panel 1
    \begin{axis}[
        at={(0,0)}, % Position of this plot
        width=5cm, height=6cm, % Size of the plot
        axis lines=center,
        xlabel={$q$},
        ylabel={$p$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_q p(q) = m/t_1$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesOne{\slopeOne}{0}
    \end{axis}

    % Panel 2
    \begin{axis}[
        at={(6cm,0)},
        width=5cm, height=6cm,
        axis lines=center,
        xlabel={$q$},
        ylabel={$p$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_q p(q) = m/t_2$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesTwo{\slopeTwo}{0}
    \end{axis}

    % Panel 3
    \begin{axis}[
        at={(12cm,0)}, % Position of this plot
        width=5cm, height=6cm, % Size of the plot
        axis lines=center,
        xlabel={$q$},
        ylabel={$p$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_q p(q) = m/t_3$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesThree{\slopeThree}{0}
    \end{axis}

    % Panel 4
    \begin{axis}[
        at={(0,-7cm)}, % Position of this plot
        width=5cm, height=6cm, % Size of the plot
        axis lines=center,
        xlabel={$q$},
        ylabel={$t$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_t q(t) = p_1/m$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesFour{\slopeOneQ}{0}
      \drawProportionalBrace{\slopeOneQ}{4}{\tauRelOne}
    \end{axis}

    % Panel 5
    \begin{axis}[
        at={(6cm,-7cm)},
        width=5cm, height=6cm,
        axis lines=center,
        xlabel={$q$},
        ylabel={$t$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_t q(t) = p_2/m$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesFive{\slopeTwoQ}{0}
      \drawProportionalBrace{\slopeTwoQ}{5}{\tauRelTwo}
    \end{axis}

    % Panel 6
    \begin{axis}[
        at={(12cm,-7cm)}, % Position of this plot
        width=5cm, height=6cm, % Size of the plot
        axis lines=center,
        xlabel={$q$},
        ylabel={$t$},
        xmin=-3, xmax=3,
        ymin=-5, ymax=5,
        xtick={-2,2},
        xticklabels={\(-Q\),\(Q\)},
        ytick=\empty,
        clip=false,
        title={$\mathrm{D}_t q(t) = p_3/m$},
      ]
      \draw[dashed] (axis cs:-2,-5) -- (axis cs:-2,5);
      \draw[dashed] (axis cs:2,-5) -- (axis cs:2,5);
      \drawLinesSix{\slopeThreeQ}{0}
      \drawProportionalBrace{\slopeThreeQ}{6}{\tauRelThree}
    \end{axis}
  \end{tikzpicture}
#+end_src

For the illustration above, \( t_3 > t_2 > t_1\) and \( p_3 > p_2 > p_1 \). 

On the \((p,\,q)\)-plane, because of the hard wall, a single particle is trapped a /pair/ of parallel lines whose midpoints are at the same distance from the origin, along the \( q \)-axis. When it exits from one of the lines in the pair, it enters the other. The lines, via their slopes, are functions of time, starting out parallel to the \(p\)-axis and asymptotically approach alignment with the \(q\)-axis. The separation between the lines vanishes like \(2 mQ / t\) . \(f(q,\,p,\,t)\) becomes a set of closely spaced lines after sufficiently long.

On the \((q,\,t)\)-plane, slopes are proportional to the momentum of the particle and /not/ functions of time. Particles far out along the \(p\)-axis relax rapidly while particles with small values of \( p \), have a longer relaxation time. The relaxation time is the time taken by a particle (on average, since \(\tau_{\text {rel}} \propto 1 / p\)) to travel the entire distance along \( q \), i.e., from \(-Q\) to \(Q\)

\[
\tau_{\text{rel}} \sim 2Q/ \lvert \mathrm{D}_t q \rvert = 2 Q m / \langle p^2 \rangle^{1/2} = 2 Q (m^{-1} K_B T)^{-1/2}.
\]

For \(t \gg \tau_{\text{rel}}\), most accessible states have been visited and \(f(q, p, t)\) has relaxed to it's stationary configuration of being parallel to the \(q\)-axis as \(t \rightarrow \infty\).

*** 3.1.4
*A "coarse-grained" density* \( \tilde{\rho} \) *is obtained by ignoring variations of* \( \rho \) *below some small resolution in the \((q,\,p)\) *plane; for example, by averaging* \( \rho \) *over cells of the resolution area. Find* \( \tilde{\rho}(q, p) \) *for the situation in part 3.1.3, and show that it is stationary.*

#+begin_src latex :file ~/pictures/.images/spop-sol-3.1.4.png :results file graphics
\begin{tikzpicture}
    \def\xmin{2}
    \def\xmax{3}
    \def\ymin{2}
    \def\ymax{3}

    \begin{axis}[
        at={(0cm,0cm)},
        width=5cm, height=5cm,
        axis lines=center,
        xlabel={$q$},
        ylabel={$p$},
        xmin=-1, xmax=5,
        ymin=-1, ymax=5,
        xtick=\empty,
        ytick=\empty,
        clip=false,
      ]
      \draw[dashed] (axis cs:0,0) -- (axis cs:0,5);
      \draw[dashed] (axis cs:1,0) -- (axis cs:1,5);
      \draw[dashed] (axis cs:2,0) -- (axis cs:2,5);
      \draw[dashed] (axis cs:3,0) -- (axis cs:3,5);
      \draw[dashed] (axis cs:4,0) -- (axis cs:4,2);
      \draw[dashed] (axis cs:4,3) -- (axis cs:4,5);

      \draw[dashed] (axis cs:0,0) -- (axis cs:5,0);
      \draw[dashed] (axis cs:0,1) -- (axis cs:5,1);
      \draw[dashed] (axis cs:0,2) -- (axis cs:5,2);
      \draw[dashed] (axis cs:0,3) -- (axis cs:5,3);
      \draw[dashed] (axis cs:0,4) -- (axis cs:5,4);

      \draw[pattern=north east lines, pattern color=black] (\xmin,\ymin) rectangle (\xmax,\ymax);
      \draw [decorate,decoration={brace,amplitude=2.0pt,mirror},xshift=1.75pt,yshift=-0.9pt]
      (\xmax,\ymin) -- (\xmax,\ymax) node [black,middle,xshift=15pt, yshift=-6pt] 
            { $\epsilon^{1/2}$ };
    \end{axis}
  \end{tikzpicture}
#+end_src

Choose any small area \( \epsilon  \) in the \( (p,\,q) \)-plane. If \( \delta p, \, \delta q \ll \epsilon \), there are variations in \( \rho \) over the chosen area \( \epsilon \), but we ignore them by /coarse-graining/ at the chosen scale \( \epsilon^{1/2} \). To average \( \rho \) over cells of area \( \epsilon \), simply count the number of lines that pass through \( \epsilon  \) and divide by \( \epsilon  \). For \( t \gg \tau_{\text{rel}} \), this procedure yields a /coarse-grained/ density \( \tilde{\rho} (q,\,p,\,t \gg \tau_{\text{rel}}) =  (2Q)^{-1} f (p)\). The \( (2Q)^{-1} \) prefactor appears because the particles lack acceleration so are as probable to be anywhere over a line segment of length \( 2Q \) as anywhere else. Clearly \( (2Q)^{-1} f (p) \) has no time-dependence and therefore \( \partial_{t} \tilde{\rho} = - (p/m)\,(\partial_q \tilde{\rho}) = 0 \), i.e., \( \tilde{\rho}\) is stationary.
** 3.2 Evolution of entropy
:PROPERTIES:
:ID:       6e7146da-2e33-40f4-9824-e2e014d54829
:END:
:LOGBOOK:
CLOCK: [2024-04-20 Sat 18:39]--[2024-04-20 Sat 20:23] =>  1:44
:END:
*The normalized ensemble density is a probability in the phase space* \( \Gamma \). *This probability has an associated entropy* \( S(t) = - \int d\Gamma\,\rho(\Gamma,\,t) \ln \rho(\Gamma,\,t) \).

*** 3.2.1
*Show that if* \( \rho(\Gamma,\,t) \) *satisfies Liouville's equation for a Hamiltonian* \(H\), \(\mathrm{D}_t S = 0 \).

By definition

\[S(t) \equiv -\langle\ln \rho(\Gamma,\,t)\rangle=-\int d\Gamma\,\rho(\Gamma,\,t) \ln \rho(\Gamma,\,t).\]

Therefore \( \mathrm{D}_t S=-\int d\Gamma\,\big[(\partial_{t} \, \rho) \ln \rho + \partial_t \rho \big]=-\int d\Gamma\,(\partial_{t} \, \rho) (\ln \rho + 1)\). Substituting [[id:a2da6b4b-5ecc-4ad5-9268-33aeab1643f6][Liouville's equation]] \(\partial_t \rho = - \{\rho, H \}\), we arrive at

\[
\mathrm{D}_t S = \int d\Gamma\,\sum_{i=1}^{3N} \big[ (\partial_q \rho) \, (\partial_p H) - (\partial_p \rho) \,
(\partial_q H) \big] (\ln \rho + 1).
\]

We will integrating by parts, i.e., \( \int_a^b F\,dG = FG \vert_a^b - \int_a^b G\,dF \).

\begin{align*}
\mathrm{D}_t S &= \int d \Gamma\, \sum_{i=1}^{3N} \bigg[\rho \partial_{p_i} \big[\partial_{q_i} H (\ln \rho + 1)\big] -  \rho \partial_{q_i} \big[ \partial_{p_i} H (\ln \rho + 1)\big] \bigg] \\
&= \int d \Gamma\, \sum_{i=1}^{3N} \bigg[\rho (\partial_{p_i q_i} H)\,(\ln \rho + 1) + (\partial_{q_i} H)\,(\partial_{p_i} \rho) - \rho (\partial_{q_i p_i} H)\,(\ln \rho + 1) - (\partial_{p_i} H)\,( \partial_{q_i} \rho) \bigg] \\
&= \int d \Gamma\, \sum_{i=1}^{3N} \bigg[(\partial_{q_i} H)\,(\partial_{p_i} \rho) - (\partial_{p_i} H)\,( \partial_{q_i} \rho) \bigg].
\end{align*}

Integrating by parts again

\begin{align*}
\mathrm{D}_t S &= \int d\Gamma\, \sum_{i=1}^{3N} \bigg[(\partial_{q_i} H)\,(\partial_{p_i} \rho) - (\partial_{p_i} H)\,( \partial_{q_i} \rho) \bigg] \\
&= \int d\Gamma\, \sum_{i=1}^{3N} \bigg[\rho\,(\partial_{p_iq_i} H) - \rho\,(\partial_{q_i p_i} H) \bigg] = 0.
\end{align*}

Thus \( \mathrm{D}_t S = 0 \).

*** 3.2.2
*Using the method of Lagrange multipliers, find the function* \( \rho_{max}(\Gamma) \) *that maximizes the functional* \( S[\rho] \), *subject to the constraint of fixed average energy,* \( \langle H \rangle = \int d\Gamma\,\rho\,H  = E\).

With [[id:425bdc45-56d7-483e-8767-95232a6542f9][Lagrange multipliers]] \(\alpha\), and \(\beta\)

\begin{align*}
S[\rho] & =-\int d\Gamma\,\rho(\Gamma) \ln \rho(\Gamma) - \alpha \bigg(\int d\Gamma\, \rho(\Gamma)-1 \bigg) - \beta \bigg(\int d\Gamma\,\rho(\Gamma)H - E \bigg).
\end{align*}

so that

\[\partial_{\rho} S (\rho_{\text{max}}) = -\ln \rho_{\text{max}}(\Gamma)- \alpha -\beta H-1=0.\]

Solving for \(\rho_{\text{max}} (\Gamma)\) we get

\[\rho_{\text{max}} (\Gamma) = \overbrace{\exp (-\alpha-1)}^{C} \exp (-\beta H) =C \exp (-\beta H).\]

*** 3.2.3
*Show that the solution to part (b) is stationary, that is,* \(\mathrm{D}_t\,\rho_{\text{max}} = 0 \).

\begin{align*}
\partial_t\,\rho_{\text{max}} &= - \big\{\rho_{\text{max}},\,H\big\} = - \{C \exp (-\beta H), H\} \\
&= C \beta (\partial_q H) (\partial_p H) \exp (-\beta H) - C \beta (\partial_p H) (\partial_q H) \exp (-\beta H) \\
&= 0.
\end{align*}

*** 3.2.4
*How can one reconcile the result in (a) with the observed increase in entropy as the system approaches the equilibrium density in (b)? (Hint: Think of the situation encountered in the previous problem.)*

In a strict sense, one cannot reconcile the results in (3.2.1) and (3.2.2). However, if ones view of the system is a coarse-grained, then while the \( \ln_2 M \) term in

\begin{equation*}
I = \ln_2 (M) + \sum_i p_i \, \ln p_i.
\end{equation*}

is unaffected, the \( \sum_i p_i \, \ln p_i \) term decreases as a result of such a procedure. Coarse-graning reduces information at the scale \(\epsilon_{\text{cg}}\) by turning all probability distributions over outcomes contained in \( \epsilon_{\text{cg}} \) into a uniform distribution. In such a scenario the results can be reconciled because the information loss via coarse-graining results in an increase in the distribution's entropy, since \( \mathrm{D}_t I = - \mathrm{D}_t S\). Note that there is no many-to-one reduction in outcomes, which would decrease entropy. The support is unaffected, it is the probability density function that is systematically redefined so that it is more and more disperse, having greater entropy.
** 3.3 The Vlasov equation
:PROPERTIES:
:ID:       7e249727-e935-4729-87a9-d575fc34052e
:END:
:LOGBOOK:
CLOCK: [2024-04-25 Thu 03:11]--[2024-04-25 Thu 09:59] =>  6:48
:END:
*The Vlasov equation is obtained in the limit of high particle density* \( n = N/V \), *or large interparticle interaction range* \( \lambda \), *such that* \( n\lambda^3 \gg 1 \). *In this limit, the collision terms are dropped from the left-hand side of the equations in the BBGKY hierarchy.*

*The BBGKY hierarchy*

\begin{align*}
\bigg[ \partial_{t} + \sum_{i=1}^{s} (\vec{p}_i/m) \cdot \partial_{\vec{q}_i} - \sum_{i=1}^{s} \bigg( \partial_{\vec{q}_i} U + \sum_{i^\prime=1}^{l} \partial_{\vec{q}_i} \, \partial_{\vec{q}_{i^\prime}}  &V (\vec{q}_i - \vec{q}_{i^\prime}) \bigg) \cdot \partial_{\vec{p}_i} \bigg] f_s \\
&= \bigg[ \sum_{i=1}^{s} \int \mathrm{d}\mathbf{V}_{s+1}\, \partial_{\vec{q}_i} V(\vec{q}_i - \vec{q}_{s+1}) \,\partial_{\vec{p}_i} \bigg] f_{s+1} \tag{1}
\end{align*}

*has the characteristic time scales*

\[
\tau_U^{-1} \sim \partial_{\vec{q}} U \cdot \partial_{\vec{p}} \approx (v/L), \qquad \tau_c^{-1} \sim \partial_{\vec{q}} \mathcal{V} \cdot \partial_{\vec{p}} \approx (v/\lambda), \qquad \tau_\times^{-1} \sim \int \mathrm{d}V\, \partial_{\vec{q}} \mathcal{V} \, \partial_{\vec{p}} \, (f_{s+1}/f_s) \approx \tau_c^{-1} \cdot n \lambda^3
\]

*where* \( n\lambda^3 \) *is the number of particles within the interaction range* \( \lambda \), *and* \( v \) *is a typical velocity. The Boltzmann equation is obtained in the dilute limit,* \( n\lambda^3 \ll 1 \), *by disregarding terms of order* \( \tau_x^{-1} \ll \tau_c^{-1} \). *The Vlasov equation is obtained in the dense limit of* \( n\lambda^3 \gg 1 \) *by ignoring terms of order* \( \tau_c^{-1} \ll \tau_x^{-1} \).

*** 3.3.1
*Assume that the N-body density is a product of one-particle densities, that is,* \( \rho = \prod_{i=1}^N \rho_i(x_i,\,t) \), *where* \(x_i = (\vec{p}_i,\,\vec{q}_i)\). *Calculate the densities* \( f_s \), *and their normalizations.*

The [[id:261ca926-8250-4eaa-9974-ad0839ed3680][s-particle density]] is given by

\begin{align*}
f_s(\vec{p}, \vec{q}, t) = \frac{N!}{(N-s)!} \int \prod_{i=s+1}^N \mathrm{~d} V_i\,\rho (\mathbf{p},\,\mathbf{q},\,t)
\end{align*}

where \(\mathrm{d} V_i=\mathrm{d}^3 \vec{p}_i \mathrm{~d}^3 \vec{q}_i = \mathrm{d} x_i\) is the contribution of particle \(i\) to phase space volume. Substituting the assumed decomposition of the [[id:21d62749-69ab-4e25-b366-eb6ff17a2f09][phase space density]] \( \rho (\mathbf{p},\,\mathbf{q},\,t) = \prod_{i=1}^N \rho_1 (x_i,\,t) \) where \( x_i \equiv (\vec{p}_i,\,\vec{q}_i)\) we have

\begin{align*}
f_s & = \frac{N!}{(N-s)!} \int \prod_{i=s+1}^N \mathrm{d} x_i \, \prod_{j=1}^N \rho_1 (x_j,\,t) \\
& = \frac{N!}{(N-s)!} \prod_{i=1}^s \rho_1 (x_i,\,t) \bigg[ \prod_{j=s+1}^{N} \underbrace{\int \mathrm{d} x_j \, \rho_1 (x_j,\,t)}_{\equiv 1} \bigg] =\frac{N!}{(N-s)!} \prod_{i=1}^s \rho_1 (x_i,\,t).
\end{align*}

*** 3.3.2
*Show that once the collision terms are eliminated, all the equations in the BBGKY hierarchy are equivalent to the single equation*

\[
\bigg[ \partial_{t} + (\vec{p}/m) \cdot \partial_{\vec{q}} - \partial_{\vec{q}} U_{\mathrm{eff}} \cdot \partial_{\vec{p}} \bigg]\,f_{1} (\vec{p},\,\vec{q},\,t) = 0
\]

*where*

\[
U_{\mathrm{eff}}(\vec{q},\,t) = U(\vec{q}) + \int \mathrm{d} \mathbf{x}^{\prime} \mathcal{V}(\vec{q} - \vec{q}^{\thinspace \prime}) f_{1}(\mathbf{x}^{\prime},\,t)
\]

The Vlasov equation is obtained in the dense limit of \( n\lambda^3 \gg 1 \), in contrast with the [[id:1d6a703e-1e34-4c07-8d66-c80b6b4bb1ef][the Boltzmann equation]], by ignoring terms of order \(\tau_c^{-1} \ll  \tau_x^{-1}\) from the left hand side of the BBGKY hierarchy. Doing so in (1) yields

\begin{align*}
\bigg[ \partial_{t} + \sum_{i=1}^{s} \bigg( (\vec{p}_i/m) \cdot \partial_{\vec{q}_i} - \partial_{\vec{q}_i} U \cdot \partial_{\vec{p}_i} \bigg) \bigg] f_s = \bigg[ \sum_{i=1}^{s} \int \mathrm{d}V_{s+1}\, \partial_{\vec{q}_i} \mathcal{V} (\vec{q}_i - \vec{q}_{s+1}) \,\partial_{\vec{p}_i} \bigg] f_{s+1}. \tag{2}
\end{align*}

In (3.3.1), we found \(f_s = \frac{N!}{(N-s)!} \prod_{i=1}^s \rho_1 (x_i,\,t)\). For \( N \gg s \), \(\frac{N!}{(N-s)!} \approx N^s\). Therefore \( f_s \approx N^s \prod_{i=1}^s \rho_1 (x_i, \, t) \) and \( f_{s+1} = N^{s+1} \prod_{i=1}^{s+1} \rho_1 (x_i, \, t) \). Using of the method of [[id:dbb10b5f-3ff6-4dc3-ab61-adcdb4ba5ddb][separation of variables]], we substitute \( f_s \) and \( f_{s+1} \) in [[id:0f74dbc6-6e75-44b9-8c93-eebb92805033][the BBGKY hierarchy]] (2) and rearrange to obtain

\begin{align*}
\bigg[ \partial_{t} + \sum_{i=1}^{s}  \bigg((\vec{p}_i/m) \cdot \partial_{\vec{q}_i} &- \partial_{\vec{q}_i} \underbrace{\bigg[U (\vec{q}_i) + \int \mathrm{d}V_{s+1}\,\mathcal{V} (\vec{q}_i - \vec{q}_{s+1})\,f_{1} (\vec{q}_{s+1},\,\vec{p}_{s+1},\,t)\bigg]}_{U_{\text{eff}} (\vec{q}_i,\,t)} \,\partial_{\vec{p}_i} \bigg) \bigg] \prod_{j=1}^s \rho_{1} (x_j,\,t) = 0,
\end{align*}

where we have introduced \(U_{\mathrm{eff}}(\vec{q}_i,\,t) \equiv U (\vec{q}_i) + \int \mathrm{d}V_{s+1}\,\mathcal{V}(\vec{q}_i - \vec{q}_{s+1})\,f_{1} (\vec{q}_{s+1},\,\vec{p}_{s+1},\,t)\). Note how \( U_{\text{eff}} \) is time-dependent while \(U\) is not. Under the action of the operator on the left hand side of the above equation on \( \prod_{j=1}^s \rho_{1} (x_j,\,t) \)

\begin{align*}
\sum_{i=1}^s \prod_{k \neq i}^{s} \rho_1 (x_k,\,t) \, \bigg[\partial_{t} + (\vec{p}_i/m) \cdot \partial_{\vec{q}_i} &- \partial_{\vec{q}_i} U_{\text{eff}} (\vec{q}_i,\, t) \cdot \partial_{\vec{p}_i} \bigg] \rho_{1} (x_i,\,t) = 0,
\end{align*}

which when divided by \( \prod_{j=1}^s \rho_1 (x_j,\,t) \) on both sides yields

\begin{align*}
\sum_{i=1}^s (\rho_1 (x_i,\,t))^{-1} \, \bigg[\partial_{t} + (\vec{p}_i/m) \cdot \partial_{\vec{q}_i} &- \partial_{\vec{q}_i} U_{\text{eff}} (\vec{q}_i,\, t) \cdot \partial_{\vec{p}_i} \bigg] \rho_{1} (x_i,\,t) = 0. \tag{3}
\end{align*}

The \( i^{\text{th}} \) term in the \( \sum \) on the left hand side of (3) is a function only of \( (\vec{q}_i,\,\vec{p}_i) \) so each term must equal some constant value, say \( c \), so that \( s \cdot c = 0 \). Since \( s > 0 \), we must have \( c = 0 \), i.e., each term in the \( \sum \) on the left hand side of (3) must vanish identically. Using the trivial proportionality \( f_1 = N \rho_1 \) relating the [[id:261ca926-8250-4eaa-9974-ad0839ed3680][s-particle density]] and the marginals of the [[id:21d62749-69ab-4e25-b366-eb6ff17a2f09][phase space density]] yields the Vlasov equation

\[
\big[\partial_{t} + (\vec{p}/m) \cdot \partial_{\vec{q}} &- \partial_{\vec{q}} U_{\text{eff}} (\vec{q},\, t) \cdot \partial_{\vec{p}} \big]\,f_{1} (\vec{p},\,\vec{q},\,t) = 0, \tag{4}
\]

where

\[
U_{\mathrm{eff}}(\vec{q},\,t) \equiv U(\vec{q}) + \int \mathrm{d} \mathbf{x}^{\prime}\, \mathcal{V} (\vec{q} - \vec{q}^{\thinspace \prime}) \, f_{1} (\mathbf{x}^{\prime},\,t). \tag{5}
\]

We have dropped the index \( i \) to emphasize that the above equation governs the evolution of the one-particle density for /any/ arbitrary particle with coordinate and momentum \( (\vec{q},\,\vec{p}) \). /This follows from the factorization of the phase space density as the product of one-particle densities./

*** 3.3.3
*Now consider* \( N \) *particles confined to a box of volume* \( V \), *with no additional potential. Show that* \( f_{1}(\vec{q}, \vec{p}) = g(\vec{p}) / V \) *is a stationary solution to the Vlasov equation for any* \( g(\vec{p}) \). *Why is there no relaxation toward equilibrium for* \( g(\vec{p}) \)?

First let us evalute \( U_{\text{eff}} \) (see 3.3.2).

\begin{align*}
U_{\mathrm{eff}} &\equiv U(\vec{q}) + \int \mathrm{d}^3\vec{q}^{\thinspace \prime}\, \mathrm{d}^3\vec{p}^{\thinspace \prime}\,\mathcal{V} (\vec{q} - \vec{q}^{\thinspace \prime}) \, f_{1} (\vec{q}^{\thinspace \prime},\,\vec{p}^{\thinspace \prime},\,t)
\xrightarrow[f_1 = g]{U(\vec{q}) \equiv 0} \\
&= (N/V) \int \mathrm{d}^3\vec{q}^{\thinspace \prime}\, \mathrm{d}^3\vec{p}^{\thinspace \prime}\,\mathcal{V} (\vec{q}-\vec{q}^{\thinspace \prime})\,g(\vec{p}^{\thinspace \prime}) 
\xrightarrow{\int \mathrm{d}x\,\mathrm{d}y\, f(x)\,g(y) = \big(\int \mathrm{d}x\,f(x)\big) \big(\int \mathrm{d}y\,g(y) \big)} \\
&= (N/V) \bigg( \int \mathrm{d}^3\vec{q}^{\thinspace \prime}\,\mathcal{V} (\vec{q}-\vec{q}^{\thinspace \prime})\bigg) \bigg(\int \mathrm{d}^3\vec{p}^{\thinspace \prime}\,g(\vec{p}^{\prime}) \bigg) \xrightarrow[\mathcal{V}(\vec{q}) \equiv \mathcal{V}(-\vec{q})]{-\vec{q}^{\thinspace \prime \prime} = \, \vec{q}-\vec{q}^{\thinspace \prime}} \\
&= (N/V) 
\underbrace{
\bigg(\int \mathrm{d}^3\vec{q}^{\thinspace \prime \prime}\,
\mathcal{V}(\vec{q}^{\thinspace \prime \prime})\bigg)
}_{\text{constant}} 
\underbrace{
\bigg(\int \mathrm{d}^3\vec{p}^{\thinspace \prime}\,g(\vec{p}^{\prime})\bigg)
}_{\text{constant}}.
\end{align*}

Plugging \( U_{\text{eff}} \) and  \(f_1(\vec{q}, \vec{p})=g(\vec{p}) / V\) into the Vlasov equation it is evident that \(f_1(\vec{p}, \vec{q})=g(\vec{p}) / V\) is a solution for any \( g (\vec{p}) \):

\begin{align*}
0 &= \big[\partial_{t} + (\vec{p}/m) \cdot \partial_{\vec{q}} - \partial_{\vec{q}} U_{\text{eff}} (\vec{q},\, t) \cdot \partial_{\vec{p}} \big]\,f_{1} (\vec{p},\,\vec{q},\,t)
\xrightarrow[U_{\text{eff}} (\vec{q},\,t) = U_{\text{eff}}]{f_{1} (\vec{p},\,\vec{q},\,t) = g(\vec{p})/V}\\
&= V^{-1} \big[\partial_{t} g (\vec{p}) + (\vec{p}/m) \cdot \partial_{\vec{q}} g (\vec{p}) - \partial_{\vec{q}} U_{\text{eff}} \cdot \partial_{\vec{p}} \, g (\vec{p}) \big]
\xrightarrow[\partial_{\vec{q}} U_{\text{eff}} = 0]{\partial_t g(\vec{p})=0,\,\partial_{\vec{q}} g(\vec{p}) = 0} = 0.
\end{align*}

\(g(\vec{p}) / V\) is a /solution/ of the Vlasov equation. It is a /stationary/ density because \( \partial_t g(\vec{p}) = \partial_{\vec{q}} U_{\text{eff}} \cdot \partial_{\vec{p}} \, g(\vec{p}) = 0 \) (\( \partial_{\vec{q}} U_{\text{eff}}\) vanishes). \(g(\vec{p}) / V\) is therefore a /stationary solution/.

This system is equivalent to a system of free particle that pass right through each other. With /no/ collisions, time-dependent variations \((\delta \vec{p}(t),\,\delta \vec{q}(t))\) vanish identically. Therefore, \( g (\vec{p}) \) does not relax.

#+BEGIN_COMMENT
We have already encountered a similar situation in the problem on the [[id:54029e29-f615-4482-919f-022e50022ae2][one-dimensional gas]], where the Hamiltonian was a function of the particle momenta only and /not/ a function of their coordinates, rendering half of the canonical equations trivial.

Note, that while an ensemble of [[id:2b3acff9-a43f-4fc5-92d8-a1296fb3f0f7][microstates]] corresponding to an equilibrium [[id:d351a06e-42c5-4a72-98c9-bbfe8f40afe7][macrostate]] implies a stationary [[id:21d62749-69ab-4e25-b366-eb6ff17a2f09][phase space density]], i.e., \( \partial_t \, \rho_{\text{eq}} = 0 \), a stationary phase space density need not necessarily imply that the system is in equilibrium. Macroscopic equilibrium is associated with /stable stationary phase space densities/.
#+END_COMMENT
** 3.4 Two-component plasma
:PROPERTIES:
:ID:       84d548b9-50e8-497e-b0d1-3d54c035d023
:END:
:LOGBOOK:
CLOCK: [2024-04-25 Thu 11:26]--[2024-04-25 Thu 16:28] =>  5:02
:END:
*** 3.4.1

*Show that the Vlasov equations for this two-component system are*

\begin{equation*}
\bigg[\partial_t + \frac{\vec{p}}{m_{+}} \cdot \partial_{\vec{q}} + e \partial_{\vec{q}} \Phi_{\mathrm{eff}} \cdot \partial_{\vec{p}}\bigg] f_{+}(\vec{p},\,\vec{q},\,t) = 0  
\end{equation*}

\begin{equation*}
\bigg[\partial_t + \frac{\vec{p}}{m_{-}} \cdot \partial_{\vec{q}} - e \partial_{\vec{q}} \Phi_{\mathrm{eff}} \cdot \partial_{\vec{p}}\bigg] f_{-}(\vec{p},\,\vec{q},\,t) = 0  
\end{equation*}

*where the effective Coulomb potential is given by*

\[
\Phi_{\mathrm{eff}}(\vec{q},\,t) = \Phi_{\mathrm{ext}}(\vec{q}) + e \int \mathrm{d} \mathbf{x}^{\prime}\,C(\vec{q} - \vec{q}^{\prime})\,\big[f_{+}(\mathbf{x}^{\prime},\,t) - f_{-}(\mathbf{x}^{\prime},\,t)\big]
\]

*Here,* \( \Phi_{\text{ext}} \) *is the potential set up by the external charges, and the Coulomb potential* \( C(\vec{q}) \) *satisfies the differential equation* \( \nabla^2 C = 4 \pi \delta^3(\vec{q}) \).

The Hamiltonian is

\begin{equation*}
H = \underbrace{\bigg[ \sum_{i=1}^{N} \frac{p_i^2}{2m_{+}} + e \, \Phi_{\text{eff}} (\vec{q}_i,\,t) \bigg]}_{\equiv H_{\text{ions}}} + \underbrace{\bigg[ \sum_{j=1}^{N} \frac{p_j^2}{2 m_{-}} - e\,\Phi_{\text{eff}} (\vec{q}_j,\,t) \bigg]}_{\equiv H_{\text{electrons}}}  \tag{1}  
\end{equation*}

By analogy with [[id:7e249727-e935-4729-87a9-d575fc34052e][the Vlasov equation]], we obtain

\[
\big[\partial_t + (\vec{p} / m_{+}) \cdot \partial_{\vec{q}} + e\,\partial_{\vec{q}} \,\Phi_{\text{eff}} (\vec{q},\,t) \cdot \partial_{\vec{p}} \big]\,f_{+}(\vec{p},\,\vec{q},\,t) = 0
\]

\[
\big[\partial_t + (\vec{p} / m_{-}) \cdot \partial_{\vec{q}} - e\,\partial_{\vec{q}}\,\Phi_{\text{eff}} (\vec{q},\,t) \cdot \partial_{\vec{p}} \big]\,f_{-}(\vec{p},\,\vec{q},\,t) = 0
\]

*** 3.4.2 
*Assume that the one-particle densities have the stationary forms* \(f_{\pm} = g_{\pm}(\vec{p})\,n_{\pm}(\vec{q})\). *Show that the effective potential satisfies the equation*

\[
\nabla^2\,\Phi_{\mathrm{eff}} = 4 \pi \, \rho_{\mathrm{ext}} + 4 \pi e \, \big[n_{+}(\vec{q}) - n_{-}(\vec{q})\big]
\]

*where* \(\rho_{\text{ext}}\) *is the external charge density.*

By definition

\[
\Phi_{\mathrm{eff}}(\vec{q},\,t) = \Phi_{\mathrm{ext}}(\vec{q}) + e \int \mathrm{d} \mathbf{x}^{\prime}\, C(\vec{q} - \vec{q}^{\prime})\,\big[f_{+}(\mathbf{x}^{\prime},\,t) - f_{-}(\mathbf{x}^{\prime},\,t)\big].
\]

Substituting  \(f_{\pm} = g_{\pm}(\vec{p})\,n_{\pm}(\vec{q})\) and integrating over \( g_{\pm} (\vec{p}) \) we get

\begin{align*}
\Phi_{\mathrm{eff}}(\vec{q},\,t) &= \Phi_{\mathrm{ext}}(\vec{q}) + e \int \mathrm{d}^3 \vec{q}^{\thinspace \prime} \, \mathrm{d}^3 \vec{p}^{\thinspace \prime} \,C(\vec{q} - \vec{q}^{\thinspace \prime})\,\big[g_{+}(\vec{p}^{\thinspace \prime})\,n_{+}(\vec{q}^{\thinspace \prime}) - g_{-}(\vec{p}^{\thinspace \prime})\,n_{-}(\vec{q}^{\thinspace \prime})\big] \\
&= \Phi_{\mathrm{ext}}(\vec{q}) + e \int \mathrm{d}^3 \vec{q}^{\thinspace \prime} \, C(\vec{q} - \vec{q}^{\thinspace \prime})\,\bigg[n_{+}(\vec{q}^{\thinspace \prime}) \underbrace{\bigg(\int \mathrm{d}^3 \vec{p}^{\thinspace \prime} \, g_{+}(\vec{p}^{\thinspace \prime}) \bigg)}_{\equiv 1} - n_{-}(\vec{q}^{\thinspace \prime}) \underbrace{\bigg(\int \mathrm{d}^3 \vec{p}^{\thinspace \prime} \, g_{-}(\vec{p}^{\thinspace \prime}) \bigg)}_{\equiv 1} \bigg] \\
&= \Phi_{\mathrm{ext}}(\vec{q}) + e \int \mathrm{d}^3 \vec{q}^{\thinspace \prime}\, C(\vec{q} - \vec{q}^{\thinspace \prime})\,\big[n_{+}(\vec{q}^{\thinspace \prime}) - n_{-}(\vec{q}^{\thinspace \prime}) \big].
\end{align*}

Under the action of the [[id:347b7b19-6382-4038-9941-dfcae1888856][Laplacian operator]] \( \nabla^2 \), the equation transform as (see [[id:66b521f2-0abe-45ee-9b0b-b56ce82900b2][divergence of electric field]] if manipulations are not obvious)

\begin{align*}
\nabla^2 \, \Phi_{\mathrm{eff}} &= \overbrace{\nabla^2 \, \Phi_{\mathrm{ext}}(\vec{q})}^{\equiv 4 \pi \rho_{\text{ext}}} + e \int \mathrm{d}^3 \vec{q}^{\thinspace \prime}\, \overbrace{\nabla^2 \,C(\vec{q} - \vec{q}^{\thinspace \prime})}^{\equiv 4 \pi \delta^3 (\vec{q} - \vec{q}^{\thinspace \prime})}\,\big[n_{+}(\vec{q}^{\thinspace \prime}) - n_{-}(\vec{q}^{\thinspace \prime}) \big] \\
&= 4 \pi \rho_{\text{ext}} + 4 \pi e \int \mathrm{d}^3 \vec{q}^{\thinspace \prime}\,\delta^3 (\vec{q} - \vec{q}^{\thinspace \prime})\,\big[n_{+}(\vec{q}^{\thinspace \prime}) - n_{-}(\vec{q}^{\thinspace \prime}) \big] \\
&= 4 \pi \big[ \rho_{\text{ext}} + e \,\big[n_{+}(\vec{q}) - n_{-}(\vec{q}) \big].
\end{align*}

*** 3.4.3 
*Further assuming that the densities relax to the equilibrium Boltzmann weights* \( n_{\pm}(\vec{q}) = n_0 \exp(\pm \beta\,e\,\Phi_{\text{eff}}(\vec{q})) \) *leads to the self-consistency condition*

\[
\nabla^2 \Phi_{\mathrm{eff}} = 4 \pi \, \big[\rho_{\mathrm{ext}} +  e \big( n_0 \big[\exp (\beta\,e\,\Phi_{\mathrm{eff}}) - \exp (-\beta\,e\,\Phi_{\mathrm{eff}}) \big] \big) \big]
\]

*known as the Poisson-Boltzmann equation. Due to its non-linear form, it is generally not possible to solve the Poisson-Boltzmann equation. By linearizing the exponentials, one obtains the simpler Debye equation*

\[
\nabla^2 \Phi_{\mathrm{eff}} = 4 \pi \rho_{\mathrm{ext}} + \lambda^{-2} \Phi_{\mathrm{eff}}
\]

*Give the expression for the Debye screening length* \( \lambda \).

Using \( \exp (x) \approx 1 + x \) for sufficiently small \( x \), the *Poisson-Boltzmann equation* transforms as

\[
\nabla^2 \Phi_{\mathrm{eff}} = 4 \pi \, \big[\rho_{\mathrm{ext}} +  e \big( n_0 \big[ 2\beta e\,\Phi_{\text{eff}} \big] \big) \big].
\]

This is the *Debye equation*. Matching coefficients with the form

\[
\nabla^2 \Phi_{\mathrm{eff}} = 4 \pi \rho_{\mathrm{ext}} + \lambda^{-2} \Phi_{\mathrm{eff}}
\]

we read off the *Debye screening length* \(\lambda \equiv (8 \pi\,\beta\,n_0\,e^2)^{-1/2}\).
*** 3.4.4 
*Show that the Debye equation has the general solution*

\[
\Phi_{\mathrm{eff}} (\vec{q}) = \int \mathrm{d}^3 \vec{q}^{\prime}\,G (\vec{q} - \vec{q}^{\thinspace \prime}) \, \rho_{\mathrm{ext}}(\vec{q}^{\thinspace \prime}) 
\]

*where* \(G(\vec{q}) =  \lvert \vec{q} \rvert^{-1} \, \exp(- \lvert \vec{q} \rvert / \lambda)\) *is the screened Coulomb potential.*

A rewrite of the Debye equation \( \big(\nabla^2 - \lambda^{-2} \big)\,\Phi_{\mathrm{eff}} = 4 \pi \, \rho_{\mathrm{ext}}\) is called the *screened Poisson equation*. Removing the inhomogeneity yields the *Helmholtz equation* i.e., \((\nabla^2 - \lambda^{-2})\, \Phi_{\text{eff}} (\vec{q}) = 0 \). Here \( \nabla^2 \) is the [[id:347b7b19-6382-4038-9941-dfcae1888856][Laplacian operator]].

The proposed general solution is reminiscent of the convolution \( G(\vec{q} - \vec{q}^{\thinspace \prime}) \ast \rho_{\text{ext}} (\vec{q}^{\thinspace \prime})\), which suggests the \( G(\vec{q}) =  \lvert \vec{q} \rvert^{-1} \, \exp(- \lvert \vec{q} \rvert / \lambda) \) is the [[id:f62d1df2-edc2-49a3-a4aa-c56fb4a5189a][Green's function]] for the /linear/ [[id:08acb081-f7cf-41ce-8c6d-e1a3a1887b5f][differential operator]] \(\mathrm{L} \equiv \big(\nabla^2 - \lambda^{-2} \big)\). The Green's function \( G(\vec{q}) \) for \( \mathrm{L} \) is a solution of the Helmholtz equation, i.e., \( \mathrm{L} G(\vec{q}) = \delta (\vec{q}) \), where \( \delta (\vec{q}) \) is the [[id:129a3159-a355-485b-b23a-a308063b98fc][Dirac delta function]]. If \( G(\vec{q}) \) is in fact \((\nabla^2 - \lambda^{-2})\)'s Green's function, then \((\nabla^2 - \lambda^{-2}) G(\vec{q}) = \delta (\vec{q}) \) must hold. This is easily verified by evaluating \( \nabla^2 G (\vec{q}) \stackrel{?}{=} \lambda^{-2} G(\vec{q}) \). 

Because \( G(\vec{q}) \)'s dependendence on \( \vec{q} \) is via \( \lvert \vec{q} \rvert \) and  \( \lvert \vec{q} \rvert \) only, the problem has spherical symmetry. [[id:9b149a74-f823-4dc5-8aa3-cba9d7879fa0][Changing coordinates]] to spherical polar, we have \(G(\vec{q}) \to G(r) = r^{-1}\,\exp(- r/\lambda)\) and \( \nabla^{2} \equiv r^{-2} \, \partial_r (r^2 \, \partial_r) \). We will now evaluate evaluating \( \nabla^2 G (r) \stackrel{?}{=} \lambda^{-2} G(r) \).

\begin{align*}
\lambda^{-2} \,G(r) &\stackrel{?}{=} r^{-2} \, \partial_r [r^2 \, \partial_r \, G(r)] \\
&\stackrel{?}{=} r^{-2} \, \partial_r \bigg(- r \lambda^{-1} \exp (- r / \lambda) - \exp (- r / \lambda) \bigg) \\
&\stackrel{?}{=} r^{-2} \, \bigg(r \lambda^{-2} \exp (- r / \lambda) - \lambda^{-1} \exp (- r / \lambda) + \lambda^{-1} \exp (- r / \lambda) \bigg) \\
&\stackrel{?}{=} \lambda^{-2} r^{-1} \exp (- r / \lambda ) = \lambda^{-2} G(r).
\end{align*}

\( G(\vec{q}) \) is indeed the Green's function for \((\nabla^2 - \lambda^{-2})\), so the general solution \(\Phi_{\text{eff}} (\vec{q})\) of \( \big(\nabla^2 - \lambda^{-2} \big)\,\Phi_{\mathrm{eff}} = 4 \pi \, \rho_{\mathrm{ext}}\) is obtained as

\[
\Phi_{\mathrm{eff}} (\vec{q}) = \int \mathrm{d}^3 \vec{q}^{\thinspace \prime}\,G (\vec{q} - \vec{q}^{\thinspace \prime}) \, \rho_{\mathrm{ext}}(\vec{q}^{\thinspace \prime}).
\]

*** 3.4.5 
*Give the condition for the self-consistency of the Vlasov approximation, and interpret it in terms of the interparticle spacing.*

The Vlasov equation is applicable when \( 1 \ll n_0\, \lambda^3\), where \( n_0 = N / V\) is the particle density and \(\lambda\) is the Debye screening length. In (3.4.3), we found  \(\lambda \equiv (8 \pi\,\beta\,n_0\,e^2)^{-1/2}\). Substituting in \(1 \ll n_o \lambda^3 \) and simplifying

\[
1 \ll n_0 (8 \pi\,\beta\,n_0\,e^2)^{-3/2} \approx n_0^{-1/2} (k_B\,T)^{3/2} e^{-3} \approx n_0^{-1/3} (k_B\,T) e^{-2} \Longrightarrow (e^2 / k_B T) \ll n_0^{-1/3} \sim l \Longrightarrow (e^2/l) \ll k_B T.
\]

Here \( l \) is the interparticle spacing. The physical interpretation of the condition \( (e^2/l) \ll k_B T \) is that the typical kinetic energy must be much larger than the typical interaction energy.

*** 3.4.6 
*Show that the characteristic relaxation time* \( (\tau \approx \lambda / v) \) *is temperature-independent. What property of the plasma is it related to?*

\( E \approx m\,v^2 \) and \( E \approx k_B T \), hence \( c \sim (k_B\,T/m)^{1/2} \). Using \(\lambda \sim (k_B T)^{1/2} n_0^{-1/2} e^{-1}\), \(\tau \approx \lambda / v \sim e^{-1}\,m^{1/2}\,n_0^{-1/2} \sim \omega_p^{-1}\). Clearly, \( \tau \) is temperature-independent. Here \( \omega_p \) is the *plasma frequency*. This frequency is related to the oscillations in the number density \( n_0 \) of electrons in the plasma (called *plasma oscillations* or *Langmuir waves*).
*** Answers
This is the classical version of the "Landau Levels" problems we recently solved in \(Q M I\) class!
(a) \(H=\sum_i\left[\frac{\left(\overrightarrow{p_i}+e \vec{A}\right)^2}{2 m} \pm \mu_B|\vec{B}|\right], \vec{A}=\vec{B} \times \vec{q} / 2\)
- Expand, substitute, simplify...
\begin{align*}
H=\frac{p^2}{2 m}+\frac{e}{2 m} \vec{p} \times \vec{B} \cdot \vec{q}+\frac{e^2}{8 m}\left(B^2 q^2-(\vec{B} \cdot \vec{q})^2\right) \pm \mu_B|\vec{B}|
\end{align*}
- The canonical equations are
\begin{align*}
\begin{aligned}
& -\frac{e}{2 m} \vec{p} \times \vec{B}-\frac{e^2}{4 m} B^2 \vec{q}+\frac{e^2}{4 m}(\vec{B} \cdot \vec{q}) \vec{B} \\
&
\end{aligned}
\end{align*}
- To recast in Newton's second I sw form, solve the first equation for p, differedtitle w.r.t time and substitute in the second equation.
\begin{align*}
\begin{aligned}
& m \ddot{\vec{q}}-\frac{e}{2} \vec{B} \times \dot{\vec{q}}=-\frac{e}{2 m} \vec{p} \times \vec{B}-\frac{e^2}{4 m} B^2 \vec{q}+\frac{e^2}{4 m}(\vec{B} \cdot \vec{q}) \vec{B} \\
& =\frac{-e}{2 m}\left[m \dot{\vec{q}}-\frac{e}{2} \vec{B} \times \vec{q}\right] \times \vec{B} \\
& -\frac{e^2}{4 m}\left(B^2 \vec{q}-(\vec{B} \cdot \vec{q}) \vec{B}\right) \\
& =\frac{e}{2} \vec{B} \times \dot{\vec{q}} \quad(\vec{a} \times(\vec{b} \times \vec{c})=\vec{b}(\vec{c} \cdot \vec{a})-\vec{c}(\vec{a} \cdot \vec{b}) \\
& m \ddot{\vec{q}}=e \vec{B} \times \dot{\vec{q}} \\
& (\vec{a} \times \vec{b}) \times \vec{c}=\vec{b}(\vec{c} \cdot \vec{a})-\vec{a} \cdot(\vec{b} \cdot \vec{b}) \\
&
\end{aligned}
\end{align*}
- Finally,
(vector triple brevet)

\begin{align*}
m \ddot{\vec{q}}=e \vec{B} \times \dot{\vec{q}} \leftarrow
\end{align*}

Lorentz force, with no electric
or \(\quad \ddot{\vec{q}}=\overrightarrow{\omega_c} \times \dot{\vec{q}}\)
\begin{align*}
\begin{aligned}
q & =\vec{w}_c \times \vec{q} \\
\left|\overrightarrow{\omega_c}\right| & =e \mid \overrightarrow{B V} / m
\end{aligned}
\end{align*}
cyclotron frequency field.
(b) - To write the Boltzmann equations for \(f_{\uparrow}(\vec{p}, \vec{q}, t)\) and \(f \downarrow(\vec{p}, \vec{q}, t)\), we need to include two terns in the collisions \(F\) integral os a given spin can collide, in a spin conserving manner, in the two following ways:
\begin{align*}
\begin{aligned}
& \left.\left.\begin{array}{l}
\uparrow \not \uparrow \rightarrow \uparrow \uparrow \\
\downarrow \succ \downarrow \rightarrow \downarrow \downarrow
\end{array}\right\}_{\uparrow}, \quad \begin{array}{l}
\sigma_{>} \downarrow \rightarrow \uparrow \downarrow \\
\downarrow \chi \uparrow \rightarrow \downarrow \uparrow
\end{array}\right\} \sigma_x \\
& \text { cross-section } \\
& \text { of the collision } \\
& \text { cross-section } \\
& \text { of the collision } \\
&
\end{aligned}
\end{align*}
- The streaming terms for exch spin type are like - (1)
\begin{align*}
\frac{\partial f_{\downarrow}}{\partial t}-\left\{H_{\downarrow}, f_{\downarrow}\right\}=\int d^2 p d \Omega\left|\frac{\overrightarrow{p_1}-\overrightarrow{p_2}}{m}\right| \times\{
\end{align*}
\begin{align*}
\begin{aligned}
& {\left[\frac{d \sigma}{d \Omega}\left[f_{\downarrow}\left(\vec{p}_1^{\prime}\right) f_{\downarrow}\left(\overrightarrow{p_2^{\prime}}\right)-f_{\downarrow}\left(\vec{p}_1\right) f_{\downarrow}\left(\vec{p}_2\right)\right]\right]+} \\
& {\left[\frac{d \sigma_x}{d \Omega}\left[f_{\downarrow}\left(\vec{p}_1^{\prime}\right) f_{\uparrow}\left(\vec{p}_2^{\prime}\right)-f_{\downarrow}\left(\overrightarrow{p_1}\right) f_{\uparrow}\left(\overrightarrow{p_2}\right)\right]\right]}
\end{aligned}
\end{align*}
(c) \(H \equiv H_{\uparrow}+H_{\downarrow} \equiv\left(H_{\uparrow \uparrow}+H_{\uparrow \downarrow}\right)+\left(H_{\downarrow \downarrow}+H_{\downarrow \uparrow}\right)\)
- Linearity of the derivative and the integrals allows us to proceed with each of the above terms separately, in the standard manner that the H-theorem is proved. (They are in one to on ell correspondence with the collision integrals).
- The consequence is:
\begin{align*}
\begin{aligned}
& \frac{d H_{\uparrow \uparrow}}{d t} \leqslant 0, \quad \frac{d H_{\uparrow \downarrow}}{d t} \leqslant 0, \frac{d H_{\downarrow \downarrow}}{d t} \leqslant 0, \frac{d H_{\downarrow}}{d t} \leqslant 0 \\
\Rightarrow \quad & \frac{d}{d t}\left(H_{\uparrow \uparrow}+H_{\uparrow \downarrow}\right) \leqslant 0, \frac{d}{d t}\left(H_{\downarrow \downarrow}+H_{\downarrow \uparrow}\right) \leqslant 0
\end{aligned}
\end{align*}
or \(\frac{d}{d t}\left(H_{\uparrow}\right) \leqslant 0, \frac{d}{d t}\left(H_{\downarrow}\right) \leqslant 0\)
or \(\frac{d}{d t}\left(H_{\uparrow}+H_{\downarrow}\right)=\frac{d}{d t}(H) \leqslant 0\).
d) - Looks like well have to write oof \(\mathrm{dH} / \mathrm{dt}\) anyloaty. Fine, let's do it.
\begin{align*}
\begin{aligned}
\frac{d H_{\uparrow}}{d t}=\frac{1}{4} \int & d^2 \vec{q} d^2 \vec{p}_1 d^2 \vec{p}_2 d \Omega\left|v_1-v_2\right| \frac{d \sigma}{d \Omega}\left[\ln \left(f_{\uparrow}\left(\vec{p}_1\right) f_{\uparrow}\left(\vec{p}_2\right)\right)\right. \\
& -\ln \left(f_{\uparrow}\left(\vec{p}_1^{\prime}\right) f_{\uparrow}\left(\vec{p}_2^{\prime}\right)\right] \times\left[f_{\uparrow}\left(\overrightarrow{p_1}\right) f_1\left(\overrightarrow{p_2}\right)-f_{\uparrow}\left(\vec{p}_1\right) f_1\left(\mu^2\right)\right.
\end{aligned}
\end{align*}

- \(\frac{d H}{d t} \uparrow\) is similarly written as:
\begin{align*}
\begin{aligned}
& \frac{d H_{\uparrow}}{d t}=-\frac{1}{2} \int d^2 q d^2 p_1 d^2 p_2 d \Omega\left|v_1-\nu_2\right| \frac{d \sigma_x}{d \Omega}\left[\ln f_{\uparrow}\left(\overrightarrow{p_1}\right)-\ln f_{\uparrow}\left(\overrightarrow{p_1}\right)\right] \\
& x\left[f_{\uparrow}\left(\vec{p}_1\right) f_{\downarrow}\left(\overrightarrow{p_2}\right)-f_{\uparrow}\left(\vec{p}_1^{\prime}\right) f_{\downarrow}\left(\vec{p}_2\right)\right] \\
&
\end{aligned}
\end{align*}
- \(d H_{\Delta \downarrow} / d t\) and \(d H_{\downarrow \uparrow} / d t\) are written in a similar manner \(\rightarrow\) just replace \(\uparrow\) with \(\downarrow\) and \(\downarrow\) with \(\uparrow\) in each cAse, along with \(\overrightarrow{p_1} \rightarrow \overrightarrow{p_2}\), and \(\vec{p}_1^{\prime} \rightarrow \vec{p}_2^{\prime}\)
- For \(d H_{\uparrow \uparrow} / d t\) to vanish, we must have (at exch point \(\vec{q}\) ):
\begin{align*}
\ln f_{\uparrow}\left(\vec{p}_1\right)+\ln f_{\uparrow}\left(\vec{p}_2\right)=\ln f_{\uparrow}\left(\vec{p}_1^{\prime}\right)+\ln f_{\uparrow}\left(\vec{p}_2^{\prime}\right)
\end{align*}
- This is equivalent to saying
\begin{align*}
\overrightarrow{p_1}+\overrightarrow{p_2}={\overrightarrow{p_1}}^{\prime}+{\overrightarrow{p_2}}^{\prime}
\end{align*}
- This is in general true for an in elastic collision. Thus \(d H \pi r / d t=0\)
- In fact this will be true of any \(\operatorname{lnf}\) which is, at each location, a linear combination of quantities conserved in the collision.
- For \(d H_{\uparrow \downarrow} / d t\) (or \(d H_{\downarrow \uparrow} / d t\) ) to vanish, we must have (at exch point \(\vec{q}\) ):
\begin{align*}
\ln f_{\downarrow}\left(\overrightarrow{p_2}\right)+\ln f_{\uparrow}\left(\overrightarrow{p_1}\right)=\ln f_{\downarrow}\left(\vec{p}_2^{\prime}\right)+\ln f_{\uparrow}\left(\vec{p}_1^{\prime}\right)
\end{align*}
- Notice the difference between (1) and (2). (1) involves \(\uparrow\) only but (2) involves and \(\uparrow\) and \(\downarrow\). This constrains the scalar that multiplies the conserved quantities (all \(n\) b of the number density of op and down spins) - they cannot be functions of the spins of the colliding particles. So long as this constraint is obeyed, \(d H / d t=0\) for thy \(\ln f\) that at each ans is a linear combination of consented the quantities. 

(e) The ask is to show,
- Let \(\left\{c_i\right\}\) be the conserved quantities under the onebody Jtanithion \(\mathcal{H}_{\uparrow}\) and \(\mathcal{H}_{\downarrow}\) If \(f_{\uparrow}\), and \(f \downarrow\) are functions only of these quantities ie:
\begin{align*}
f_{\uparrow} \equiv f_{\uparrow}\left(\left\{c_i\right\}\right) \text { and } f_{\downarrow} \equiv f_{\downarrow}\left(\left\{c_i\right\}\right)
\end{align*}
then.
\begin{align*}
\begin{aligned}
& \text { then. } \\
& \left\{f_{\uparrow}, H_{\uparrow}\right\}=\sum_i \frac{\partial f_{\uparrow}}{\partial C_i}\left\{C_i, H_{\uparrow}^0\right\}=0 \\
& \left\{f_{\downarrow}, H_{\downarrow}\right\}=\sum_i \frac{\partial f_{\downarrow}}{\partial C_i}\left\{C_i, J_{\downarrow}\right\}=0
\end{aligned}
\end{align*}
- The ait has been answered.
f)
During Collisions
\begin{align*}
\begin{aligned}
& \vec{p}_1+\vec{p}_2=\vec{p}_1^{\prime}+\vec{p}_2^{\prime} \\
& \vec{q} \times\left(\vec{p}_1+\vec{p}_2\right)=\vec{q} \times\left(\vec{p}_1^{\prime}+\vec{p}_2^{\prime}\right) \\
& \overrightarrow{L_1}+\overrightarrow{L_2}=\overrightarrow{L_1}+\overrightarrow{L_2^{\prime}} \\
&
\end{aligned}
\end{align*}

Away from Collisions
\begin{align*}
\{\vec{L}, H\}
\end{align*}
\begin{align*}
\begin{aligned}
= & -\left\{\vec{p}^2, \vec{L}\right\} / 2 m \text { (ii) } \\
& -\frac{\{\vec{p} \times \vec{B} \cdot \vec{q}, \vec{L}\} e}{2 m} \\
= & \left\{\vec{q}^2, \vec{L}\right\} \frac{e^2 B^2}{8 m} \\
+ & \left\{(\vec{B} \cdot \vec{q})^2, \vec{L}\right\} e^2 / \delta m
\end{aligned}
\end{align*}
(iv)

- For (i), (iii), and (iv), expand the cross-broduct using a bevi-civita pseudotensor and you'll see it. For (ii), first move stuff around using the property of A scalar triple product and then use the properties of the poisson bracket (poisson bracket of a function with a multiple of itself vanishes) and you'll see it.
- Therefore,
\begin{align*}
\begin{aligned}
& \left.\overrightarrow{L_1}+\overrightarrow{L_2}={\overrightarrow{L_1}}^{\prime}+{\overrightarrow{L_2}}^{\prime} \quad \text { (collision) }\right\} \text { at } \\
& \{\vec{L}, H\}=0 \quad \text { (away from collision) }\} \vec{q} \\
&
\end{aligned}
\end{align*}
- The angular momentum \(\vec{L}=\vec{q} \times \vec{p}\) is conserved during and away from collisions.
(9) The most general local equilibrium distribution is written is
\begin{align*}
\begin{aligned}
\ln f_{\uparrow} & =a_{\uparrow}(\vec{q})-\vec{\alpha}(\vec{q}) \cdot \vec{p}-\beta(\vec{q})(\underbrace{\left(\frac{\vec{p}}{2 m}+u_{\uparrow}(\vec{q})\right)} \\
\Rightarrow f_{\uparrow} & =\mathcal{N}(\vec{q}) \exp [-\vec{\alpha}(\vec{q}) \cdot \vec{p}-\beta(\vec{q}) H-\gamma(\vec{q})] H_{\uparrow}(\vec{p}, \vec{q}) .
\end{aligned}
\end{align*}
- The local equilibrium distribution preserves its form during collisions but evolves aw at from collisions
- For the global equilibrium distribution, we must further impose the condition of vanishing steaming terms, ie \(\left\{f_{\uparrow}, \mathcal{H} \uparrow\right\}=0\).
- In that case, weill need to fodrop \(-\vec{\alpha}(\vec{q}) \cdot \vec{p}\) from the argument of the exponent, (2) and demand that \(\mathcal{N}\) and \(\beta\) NOT be functions of \(\vec{q}\).
- (1) shouldn't surprise you. Linear momentum is conserved during a collision but NOT -(ii) we have already justified.
- Therefore, the most general form for the equilibrium distribution functions for particles confined to a circularly symmetric potential is:
\begin{align*}
\begin{aligned}
& f_{\uparrow}=\mathcal{N}_{\uparrow} \exp \left[-\beta H_{\uparrow}-\gamma L_z\right] \\
& f_{\downarrow}=\mathcal{N}_{\downarrow} \exp \left[-\beta H_{\downarrow}-\gamma L_z\right]
\end{aligned}
\end{align*}
(h) Scattering from magnetic impurities
- \(\vec{P} \& \vec{L}\) is no longer conserved during collisions,
\(-\gamma L_z\) term will be dropped.
- Collisions are no longer spin-conserving. Equilibrium will be characterized by equal numbers of of and down spin electron. \(\left(_{\uparrow}=\mathcal{N}_{\downarrow}=\mathcal{N}_{\mathcal{N}}\right)\)
\begin{align*}
f_{\uparrow}=\mathcal{N} \exp \left(-\beta H_{\uparrow}\right), f_{\downarrow}=\mathcal{N} \exp \left(-\beta H_{\downarrow}\right)
\end{align*}

Scattering from non-magnetic impurities
- \(-\gamma L_z\) term is doffed. (Collisions don't conserve \(\vec{p}\) no more).
- Collisions the spin-conserving still.
\begin{align*}
f_{\uparrow}=N_{\uparrow} \exp \left(-\beta H_{\uparrow}\right), \quad f_{\downarrow}=\mathcal{N}_{\downarrow} \exp \left[-\beta \mathcal{H}_{\downarrow}\right]
\end{align*}
(i) Conservation of angular momentum does not read to new hydrodynamic equations.
(if you like, it leads to 2 an equation for the angular velocity, tile such an equation is trivially ob tailed from the hydrodynamic equation for the velocity field).
- Conservation of spin does lead to a new non trivia hydrodynamic equation for the quantity ker-kerticle magnetisation. \(m\). \(m a\) for \(x_{\uparrow}+x_{\uparrow}\)
\begin{align*}
m \propto n_{\uparrow}-n_{\downarrow}
\end{align*}

** 3.7 Thermal conductivity
:PROPERTIES:
:ID:       11cf1e85-06e4-410b-b109-3e25465bcde1
:END:
*** 3.7.1
*What is the necessary relation between* \( n(y) \) *and* \( T(y) \) *to ensure that the gas velocity* \( \vec{u} \) *remains zero? (Use this relation between* \( n(y) \) *and* \( T(y) \) *in the remainder of this problem.)*

*** 3.7.2
*Using Wick's theorem, or otherwise, show that*

\[
\left\langle p^{2}\right\rangle^{0} \equiv\left\langle p_{\alpha} p_{\alpha}\right\rangle^{0}=3\left(m k_{B} T\right), \quad \text { and } \quad\left\langle p^{4}\right\rangle^{0} \equiv\left\langle p_{\alpha} p_{\alpha} p_{\beta} p_{\beta}\right\rangle^{0}=15\left(m k_{B} T\right)^{2},
\]

*where* \( \langle\mathcal{O}\rangle^{0} \) *indicates local averages with the Gaussian weight* \( f_{1}^{0} \). *Use the result* \( \left\langle p^{6}\right\rangle^{0}=105\left(m k_{B} T\right)^{3} \) *in conjunction with symmetry arguments to conclude*

\[
\left\langle p_{y}^{2} p^{4}\right\rangle^{0}=35\left(m k_{B} T\right)^{3}
\]

*** 3.7.3
*The zeroth-order approximation does not lead to relaxation of temperature/density variations related as in part* (a). *Find a better (time-independent) approximation* \( f_{1}^{1}(\vec{p}, y) \), *by linearizing the Boltzmann equation in the single collision time approximation to*

\[
\mathcal{L}\left[f_{1}^{1}\right] \approx\left[\frac{\partial}{\partial t}+\frac{p_{y}}{m} \frac{\partial}{\partial y}\right] f_{1}^{0} \approx-\frac{f_{1}^{1}-f_{1}^{0}}{\tau_{K}}
\]

*where* \( \tau_{K} \) *is of the order of the mean time between collisions.*

*** 3.7.4
*Use* \( f_{1}^{1} \), *along with the averages obtained in part* (b), *to calculate* \( h_{y} \), *the* \( y \) *component of the heat transfer vector, and hence find* \( K \), *the coefficient of thermal conductivity.*

*** 3.7.5
*What is the temperature profile,* \( T(y) \), *of the gas in steady state?*
** 3.12 Moments of momentum
:PROPERTIES:
:ID:       6197ff71-afed-49c5-9796-8995cf7b66a7
:END:
:LOGBOOK:
CLOCK: [2024-04-26 Fri 21:03]--[2024-04-26 Fri 23:25] =>  2:22
:END:

*Consider a gas of* \(N\) *classical particles of mass* \(m\) *in thermal equilibrium at a temperature* \(T\), *in a box of volume* \(V\).

*** 3.12.1
*Write down the equilibrium one-particle density* \(f_{\text {eq. }}(\vec{p},\,\vec{q})\), *for coordinate* \(\vec{q}\), *and momentum* \(\vec{p}\).

The equilibrium [[id:261ca926-8250-4eaa-9974-ad0839ed3680][1-particle density]] \(f_{\text {eq.}} (\vec{p},\,\vec{q})\), for coordinate \(\vec{q}\), and momentum \(\vec{p}\) for a gas of* \(N\) classical particles of mass \(m\) in thermal equilibrium at a temperature \(T\), in a box of volume \(V\) is (see [[id:88fb08c6-3bc3-4d68-b620-8019b544946c][Particles in a box (classical)]])

\begin{align*}
f_{\text{eq.}} (\vec{p},\,\vec{q}) = n \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(-\frac{\beta(\vec{p}-\vec{p}_0)^2}{2 m}\bigg),
\end{align*}

*** 3.12.2
*Calculate the joint characteristic function,* \(\langle\exp (-\mathrm{i} \vec{k} \cdot \vec{p})\rangle\), *for momentum.*

Marginalizing over \( \vec{q} \), we are left with (see also the problem [[id:df72e834-3e97-490b-93b6-bcbc6d85e4c0][Effusion]])

\begin{align*}
f_{\text{eq.}} (\vec{p}) = N \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(-\frac{\beta(\vec{p}-\vec{p}_0)^2}{2 m}\bigg).
\end{align*}

We then use \( f_{1} = N \rho_1 \) (see [[id:261ca926-8250-4eaa-9974-ad0839ed3680][s-particle density]]) to obtain the marginal of the [[id:21d62749-69ab-4e25-b366-eb6ff17a2f09][phase space density]]

\begin{align*}
\rho_{\text{eq.}} (\vec{p}) = \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(-\frac{\beta(\vec{p}-\vec{p}_0)^2}{2 m}\bigg).
\end{align*}

Its joint characteristic function, by definition is

\begin{align*}
\tilde{\rho}_{\text{eq.}}(\vec{k}) &\equiv \langle \exp (-i \vec{k} \cdot \vec{p}) \rangle = \int \mathrm{d}^3 \vec{p}\, \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(- \frac{\beta (\vec{p} - \vec{p}_0)^2}{2 m} - i \, \vec{k} \cdot \vec{p} \bigg) \\
\end{align*}

The transformation \( \vec{p} - \vec{p}_0 \to \vec{p}^{\thinspace \prime}\) (with unit [[id:dad8b579-a898-43e8-a65c-78b8848b00fa][Jacobian]]) yields

\begin{align*}
\tilde{\rho}_{\text{eq.}}(\vec{k}) &= \int \mathrm{d}^3 \vec{p}^{\thinspace \prime}\, \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(- \beta \frac{\vec{p}^{\thinspace \prime} \cdot \vec{p}^{\thinspace \prime}}{2 m} - i \, \vec{k} \cdot \big[\vec{p}^{\thinspace \prime} + \vec{p}_0\big] \bigg) \\
&= \exp \big(- i \, \vec{k} \, \vec{p}_0 \big) \int \mathrm{d}^3 \vec{p}^{\thinspace \prime}\, \bigg(\frac{\beta}{2 \pi m}\bigg)^{3 / 2} \exp \bigg(- \beta \frac{\vec{p}^{\thinspace \prime} \cdot \vec{p}^{\thinspace \prime}}{2 m} - i \, \vec{k} \cdot \vec{p}^{\thinspace \prime} \bigg) \\
\end{align*}

Using standard [[id:708e32d3-4489-46b7-b35d-ce8cc91c0d82][Gaussian integral]] results

\begin{equation*}
\tilde{\rho}_{\text{eq.}}(\vec{k})  & =\exp \bigg( - i \, \vec{k} \cdot \vec{p}_0 -\frac{m \vec{k} \cdot \vec{k}}{2 \beta} \bigg)
\end{equation*}

*** 3.12.3
*Find all the joint cumulants* \(\left\langle p_{x}^{\ell} p_{y}^{m} p_{z}^{n}\right\rangle_{c}\).

The joint cumulants \(\langle p_x^l p_y^m p_z^n\rangle_c\) are generated by the cumulant generating function which, by definition, is the logarithm of the characteristic function. So we have

\begin{align*}
\langle p_x^l \, p_y^m \, p_z^n\rangle_c &= \big[\partial_{-i k_x}^{\thinspace l} \, \partial_{-i k_y}^{\thinspace m} \, \partial_{-i k_z}^{\thinspace n} \big] \ln \tilde{\rho}_{\text{eq.}} \, (\vec{k}) \vert_{\vec{k}=0} \\
&= \big[\partial_{-i k_x}^{\thinspace l} \, \partial_{-i k_y}^{\thinspace m} \, \partial_{-i k_z}^{\thinspace n} \big] \bigg(- i\, \big[k_x \cdot p_{0,\,x} + k_y \cdot p_{0,\,y} + k_z \cdot p_{0,\,z} \big] - (m/2 \beta) \big[k_x^2 + k_y^2 + k_z^2 \big] \bigg) \bigg \vert_{\vec{k} = 0} \\
&= p_{0,\,x} \, \delta_{l1}\, \delta_{m0}\,\delta_{n0} + p_{0,\,y} \, \delta_{l0}\, \delta_{m1}\,\delta_{n0} + p_{0,\,z} \, \delta_{l0}\, \delta_{m0}\,\delta_{n1} + (m / \beta) \big[\delta_{l2}\,\delta_{m0},\delta_{n0} + \delta_{l0}\,\delta_{m2},\delta_{n0} + \delta_{l0}\,\delta_{m0},\delta_{n2} \big]
\end{align*}

*** 3.12.4
*Calculate the joint moment* \(\langle p_{\alpha} \, p_{\beta} \, (\vec{p} \cdot \vec{p})\rangle\).

Using [[id:0b9d22e8-6701-4afd-bc64-5c41e491822e][Wick's theorem]] we have

\begin{align*}
\langle p_\alpha p_\beta \, (\vec{p} \cdot \vec{p}) \rangle &= \langle p_\alpha \, p_\beta \, p_\gamma \, p_\gamma \rangle \\
&= \langle p_\alpha \, p_\beta \rangle \langle p_\gamma \, p_\gamma \rangle + 2 \langle p_\alpha \, p_\gamma \rangle \langle p_\beta \, p_\gamma \rangle \\
&= (m k_B T)^2 \delta_{\alpha \beta} \, \delta_{\gamma \gamma} + 2 (m k_B T)^2 \delta_{\alpha \gamma} \, \delta_{\beta \gamma} \\
& =5(m k_B T)^2 \delta_{\alpha \beta} .
\end{align*}

** 3.13 Generalized ideal gas
:PROPERTIES:
:ID:       323e99f4-7b93-4150-a804-ee4741a65acd
:END:
:LOGBOOK:
CLOCK: [2024-04-26 Fri 17:52]--[2024-04-26 Fri 20:58] =>  3:06
:END:

*Consider a gas of* \(N\) *particles confined to a box of volume* \(V\) *in* \(d\) *dimensions.* *The energy,* \(\epsilon\), *and momentum,* \(p\), *of each particle are related by* \(\epsilon=p^{s}\), *where* \(p=|\mathbf{p}|\). (*For classical particles* \(s=2\), *while for highly relativistic ones* \(s=1\).* *Let* \(f(v) \mathrm{d} v\) *denote the probability of finding particles with speeds between* \(v\) *and* \(v+\mathrm{d} v\), *and* \(n=N / V\).

*** 3.13.1
*Calculate the number of impacts of gas molecules per unit area of the wall of the box, and per unit time as follows:*

(i) *Show that the number of particles hitting area* \(A\) *in a time* \(\mathrm{d} t\) *arriving from a specific direction* \(\vec{\Omega}\), *with a speed* \(v\), *is proportional to* \(A \cdot v \mathrm{~d} t \cos \theta \cdot n f(v) \mathrm{d} v\), *where* \(\theta\) *is the angle between the direction* \(\vec{\Omega}\) *and the normal to the wall*.

(ii) *Summing over all directions* \(\vec{\Omega}\) *with the same polar angle* \(\theta\), *demonstrate that*

\[
\mathrm{d} N(\theta, v)=A \cdot v \mathrm{~d} t \cos \theta \cdot n f(v) \mathrm{d} v \cdot \frac{S_{d-1} \sin ^{d-2} \theta \mathrm{d} \theta}{S_{d}},
\]

*where* \(S_{d}=2 \pi^{d / 2} /(d / 2-1)!\) *is the total solid angle in* \(d\) *dimensions*. 

(iii) *By averaging over* \(v\) *and* \(\theta\) *show that*

\[
\frac{N}{A \mathrm{~d} t}=\frac{S_{d-1}}{(d-1) S_{d}} \cdot n \bar{v}, \quad \text { where } \quad \bar{v}=\int v f(v) \mathrm{d} v \quad \text { is the average speed. }
\]

#+begin_src latex :file ~/pictures/.images/spop-sol-3.13.1.png :results file graphics
\begin{tikzpicture}[scale=1, every node/.style={scale=1}]

  % Define radius
  \def\radius{sqrt(5)}

  % Draw the base line
  \draw[-] (0,0) -- (6,0) node[midway, below] {$A$};

  % Draw the vertical vector
  \draw[-Triangle] (3,0) -- (3,1.5) node[above] {$\vec{A}$};

  % Draw the angular velocity vector
  \draw[-Triangle] (3,0) -- (4,2) node[above right] {$\vec{\Omega}$};

  % Draw the arc for angle theta
  \draw (3,0.3) arc (90:63.435:0.3) node[above] {$\theta$};

  % Label v dt midway to the vector Omega
  \path (3,0) -- (4,2) node[midway, right] {$v \mathrm{d}t$};

  % Draw a dashed half-circle centered at (3,0) with radius sqrt(5)
  \draw[dashed] (5.24,0) arc (0:180:\radius);

\end{tikzpicture}
#+end_src

For a generalized ideal gas, the differential number of molecules \(\mathrm{d}N(\theta,\,v,\,\vec{\Omega})\) is

\[\mathrm{d}N(\theta,\,v,\,\vec{\Omega}) = A \cdot v \mathrm{d}t \cos\theta \cdot n f(v) \mathrm{d}v\]

where \(A\) is the area of the wall, \(v \mathrm{d}t \cos \theta\) represents velocities that can realize a collision in the time interval \(\mathrm{d}t\), and \(n f(v) \mathrm{d}v\) is the proportion of particles with velocity \(v\). Integrating over the [[id:80667201-22b0-49a8-a434-df7e89d8155b][Solid angle]] gives us the number of collisions

\begin{align*}
\mathrm{d}N(\theta,\,v) &= \int \mathrm{d}^{d} \vec{\Omega}\, A \cdot v \mathrm{d}t \cos\theta \cdot n f(v) \mathrm{d}v  \\
&= A \cdot v \mathrm{d}t \cos\theta \cdot n f(v) \mathrm{d}v \cdot \frac{S_{d-1}\,\sin^{d-2} \theta\,\mathrm{d}\theta}{S_d}.
\end{align*}

Here \(S_{d}\) is the total solid angle in \(d\) dimensions, and \(S_{d-1}\,\sin^{d-2}\theta\,\mathrm{d}\theta\) is the fraction of \(S_{d}\) that corresponds to the polar angle \(\theta\). The normalized number of molecules per unit area and time is

\begin{equation*}
\frac{1}{A\mathrm{d}t} \underbrace{\int \mathrm{d}\theta \,\mathrm{d}v\, \mathrm{d}N(\theta,\,v)}_{= N} = n \, \frac{S_{d-1}}{S_{d}}\, \underbrace{\int_{0}^{\pi} \mathrm{d}\theta\, \sin^{d-2} \theta \cos\theta}_{= 1/ (d-1)} \underbrace{\int \mathrm{d}v\, v f(v)}_{\equiv \bar{v}},
\end{equation*}

so that

\begin{equation*}
\frac{N}{A\mathrm{d}t} = \frac{S_{d-1}}{S_d} \cdot \frac{1}{(d-1)} \cdot n \cdot \bar{v},\qquad \bar{v} = \int \mathrm{d}v\, v f(v), \qquad S_{d}= 
\begin{cases}
2 \pi^{d/2} / (d/2 - 1)! & d \text { even} \\
2^d \pi^{(d-1)/2} (d/2-1/2)! /(d-1)! & d \text { odd}
\end{cases}.
\end{equation*}

Here \(\bar{v}\) is the average speed.

*** 3.13.2
*Each (elastic) collision transfers a momentum* \(2 p \cos \theta\) *to the wall. By examining the net force on an element of area prove that the pressure* \(P\) *equals* \(\frac{s}{d} \cdot \frac{E}{V}\), *where* \(E\) *is the average (kinetic) energy.* (*Note that the velocity* \(\mathbf{v}\) *is not* \(\mathbf{p} / m\) *but* \(\partial \boldsymbol{\epsilon} / \partial \mathbf{p}\).* (*Hint. Clearly, upon averaging over all directions* \(\left\langle\cos ^{2} \theta\right\rangle=1 / d\).*)

We have \( \mathrm{d}P = 2 p \, \cos \theta \) and \( \mathrm{d}t = \frac{2V}{A\,v\,\cos \theta} \) so that the force applied by a single particle is \( F_1 = \mathrm{D}_t P = p \, A\, v \cos^2 \theta / V \). The total force is \( F = \langle N \, \mathrm{D}_t P \rangle = N\,p\,A\,v \langle \cos^2 \theta \rangle/V \). Using \( \langle \cos^2 \theta \rangle = d^{-1} \), we get \( F/A = (s/d)\,(N/V)\,p^s = (s/d) (E/V) \) which implies that \( P = (s/d) \cdot (E/V) \).

*** 3.13.3
*Using thermodynamics and the result in 3.13.2, show that along an adiabatic curve* \(P V^{\gamma}\) *is constant, and calculate* \(\gamma\).

The [[id:17498b42-c75b-4044-84a5-4befa819cd0d][fundamental identity of thermodynamics]] for an ideal gas is \(\mathrm{d}E = T \mathrm{d}S - P \mathrm{d}V\). For an adiabatic process, \( T \mathrm{d}S = 0 \), so \(\mathrm{d}E = P \mathrm{d}V\). From (3.13.2) we have

\[
\frac{d}{s} \big(V\,\mathrm{d}P + P\,\mathrm{d}V \big) = - P\,\mathrm{d} V \Longrightarrow \bigg(\frac{d}{d+s}\bigg) \frac{\mathrm{d} P}{P} + \frac{\mathrm{d}V}{V} = 0
\]

Let \( \gamma \equiv (d+s)/d \). Then \(\mathrm{d}P/P = - \gamma \, \mathrm{d}V / V\). Integration of both sides yields \(PV^{\gamma} = \text{constant} \).
*** 3.13.4
*According to the equipartition theorem, each degree of freedom that appears quadratically in the energy has an energy* \(k_{B} T / 2\). *Calculate the value of* \(\gamma\) *if each gas particle has* \(\ell\) *such quadratic degrees of freedom in addition to its translational motion.* *What values of* \(\gamma\) *are expected for helium and hydrogen at room temperature?*

\(P=\frac{s}{d} \cdot \frac{E}{V}\) combined with \(P V = N K_B T\) gives \( \frac{s}{d} \cdot E=N K_B T \) or \( E=\frac{d}{s} N K_B T \). In addition to the translational degrees of freedom, each gas particle now has \(l\) quadratic degrees of freedom

\[E & =\frac{d}{s} N K_B T+\frac{l}{2} N K_B T =\left(\frac{d}{s}+\frac{l}{2}\right) N K_B T.\]

We have \(C_V \equiv \partial_T E \vert_{V} = (d/s + l/2) N k_B\) and \( C_P = C_V + N k_B = (d/s + l/2 + 1) N k_B \). Furthermore \( \gamma \equiv C_P/C_V = (2d + ls + 2s)/ (2d + ls)\). Because the gas is at room-temperature, the energy spectrum is assumed to be quadratic (\(s=2\)). Rooms are usually three-dimensional so (\(d=3\)). For diatomic Hydrogen \(l = 2\) because it has rotational and vibration degrees of freedom. For monoatomic Helium \( l = 0 \) because it only has translational degrees of freedom. Substituting these values in the expression of \( \gamma \) we get

\[
\gamma_{\text{H}} &= (2 \times 3+2 \times 2+2 \times 2) /(2 \times 3+2 \times 2) =7 / 5,
\]

\[
\gamma_{\text{He}} &= (2 \times 3+0 \times 2+2 \times 2) /(2 \times 3+0 \times 2) = 5 / 3.
\]

*** 3.13.5
*Consider the following experiment to test whether the motion of ants is random. 250 ants are placed inside a* \(10 \mathrm{~cm} \times 10 \mathrm{~cm}\) *box. They cannot climb the wall, but can escape through an opening of size* \(5 \mathrm{~mm}\) *in the wall. If the motion of ants is indeed random, and they move with an average speed of* \(2 \mathrm{~mm} \mathrm{~s}^{-1}\), *how many are expected to escape the box in the first 30 seconds?*

From (3.13.1) we found the formula

\begin{equation*}
\frac{N}{A\mathrm{d}t} = \frac{S_{d-1}}{S_d} \cdot \frac{1}{(d-1)} \cdot n \cdot \bar{v},\qquad \bar{v} = \int \mathrm{d}v\, v f(v), \qquad S_{d}= 
\begin{cases}
2 \pi^{d/2} / (d/2 - 1)! & d \text { even} \\
2^d \pi^{(d-1)/2} (d/2-1/2)! /(d-1)! & d \text { odd}
\end{cases}.
\end{equation*}

For the experiment under consideration, \( d = 2 \). Since \( S_1 = 2 \) and \( S_2 = 2 \pi \), the formula reduces to \(N =  \frac{A \mathrm{d}t}{\pi} \cdot n \cdot \bar{v}\). Now \( n = N_i / L^2 \) where \( N_i = 250 \) and \( L = 10 \mathrm{~cm} = 100 \mathrm{~mm}\), \( \mathrm{d}t = 30 \mathrm{~s}\) and \(\bar{v} = 2 \mathrm{~mm} \mathrm{~s}^{-1}\). Note that since the box is assumed to be two dimensional, the opening through which the ants escape cannot be considered an orifice; it is more of a slit, that is \( A = 5\mathrm{~mm} \). The expected number of ants \( N_e \) that escape the box in the first \( 30 \) seconds is

\begin{equation*}
N_e = \frac{5 \, \mathrm{~mm} \times 30 \, \mathrm{~s}}{3.14159} \cdot \frac{250}{10^4 \, \mathrm{~mm}^{2}} \cdot 2 \, \mathrm{~mm} \, \mathrm{~s}^{-1} \approx 2.387.
\end{equation*}
** 3.14 Effusion
:PROPERTIES:
:ID:       df72e834-3e97-490b-93b6-bcbc6d85e4c0
:END:
:LOGBOOK:
CLOCK: [2024-04-26 Fri 14:00]--[2024-04-26 Fri 17:39] =>  3:39
:END:

*A box contains a perfect gas at temperature* \(T\) *and density* \(n\).

*** 3.14.1
*What is the one-particle density,* \(\rho_{1}(\vec{v})\), *for particles with velocity* \(\vec{v}\) ?

The one-particle density for a homogenous gas at temperature \( T \) and with number density \( n \) is (see [[id:88fb08c6-3bc3-4d68-b620-8019b544946c][particles in a box (classical)]] and [[id:c3729898-9aa3-4966-a16c-24216deb2c8d][equilibrium properties]]) is

\begin{align*}
f_1(\vec{p},\,\vec{q}) = \big(2 \pi m k_B T\big)^{-3 / 2} \, n\, \exp \bigg(- \frac{\vec{p} \cdot \vec{p}}{2 m k_B T}\bigg).
\end{align*}

Because relation between \(\rho_1 (\vec{p},\,\vec{q}) \) and \( f_1(\vec{p}, \vec{q}) \) is described by (see [[id:261ca926-8250-4eaa-9974-ad0839ed3680][s-particle density]])

\begin{align*}
f_1(\vec{p},\,\vec{q}) & =\bigg\langle\sum_{i=1}^N \delta^3(\vec{p}-\vec{p}_i) \delta^3(\vec{q}-\vec{q}_i)\bigg\rangle \\
& =N \int \prod_{i=2}^N \mathrm{~d}^3 \vec{p}_i \mathrm{~d}^3 \vec{q}_i \rho\big(\vec{p}_1=\vec{p}, \vec{q}_1=\vec{q}, \vec{p}_2, \vec{q}_2, \cdots, \vec{p}_N, \vec{q}_N\big),
\end{align*}

we have

\begin{align*}
\rho_1(\vec{p},\,\vec{q}) = \big(2 \pi m k_B T\big)^{-3 / 2} \, V^{-1} \, \exp \bigg(- \frac{\vec{p} \cdot \vec{p}}{2 m k_B T}\bigg).
\end{align*}

Marginalizing over \( \vec{q} \), we are left with

\begin{align*}
\rho_1 (\vec{p}) &\equiv \int \mathrm{d}^3 \vec{q}\, \rho_1 (\vec{p},\,\vec{q}) = \rho_1 (\vec{p},\,\vec{q}) \int \mathrm{d}^3 \vec{q}\, = \rho_{1} (\vec{p},\,\vec{q}) \, V \\
&= \big(2 \pi m k_B T\big)^{-3 / 2} \exp \bigg(- \frac{\vec{p} \cdot \vec{p}}{2 m k_B T}\bigg).
\end{align*}

Using \( \rho_1 (\vec{v}) = \rho_1 (\vec{p}) \lvert D_{\vec{v}} \vec{p} \rvert \) and \( \vec{p} = m \vec{v} \), we have

\begin{equation*}
\rho (\vec{v})= \bigg(\frac{m}{2 \pi \,k_B T}\bigg)^{3 / 2} \exp \bigg(- \frac{m}{2} \frac{\, \vec{v} \cdot \vec{v}}{k_B T} \bigg).  
\end{equation*}

Note that \( \lvert \mathrm{D}_{\vec{v}} \vec{p} \rvert = m^3 \).

*** 3.14.2
*A small hole is opened in the wall of the box for a short time to allow some particles to escape into a previously empty container. During the time that the hole is open what is the flux (number of particles per unit time and per unit area) of particles into the container?* *(Ignore the possibility of any particles returning to the box.)*

#+begin_src latex :file ~/pictures/.images/spop-sol-3.14.2.png :results file graphics
\begin{tikzpicture}[scale=1, every node/.style={scale=1}]

% Define a command to create random dots
\def\randomdots#1#2#3#4#5{
  \foreach \x in {1,...,#5}{
    \pgfmathrandominteger{\a}{#1}{#2}
    \pgfmathrandominteger{\b}{#3}{#4}
    \fill (\a*0.1 - rnd,-\b*0.1 + rnd) circle (0.5pt);
  }
}

% Draw the hatched plate in the middle of the left cylinder
\draw[pattern=north east lines] (0,-2.1) ellipse [x radius=1.75cm, y radius=0.5cm];
\filldraw[fill=gray] (0,-1.9) ellipse [x radius=1.75cm, y radius=0.5cm];

% Random dots in the upper part of the left cylinder
\begin{scope}
\clip (-1.75,0) rectangle (1.75,-2);
\randomdots{-17}{17}{0}{20}{500}
\end{scope}

% Draw the left cylinder body
\filldraw[fill=gray] (0,0) ellipse [x radius=1.75cm, y radius=0.5cm];
\draw (-1.75,0) -- (-1.75,-4);
\draw (1.75,0) -- (1.75,-4);
\draw[pattern=north east lines] (0,-4) ellipse [x radius=1.75cm, y radius=0.5cm];

% Draw the slit in the hatched plate of the left cylinder
\filldraw[fill=white] (0,-1.9) ellipse [x radius=0.2cm, y radius=0.125cm];
\draw[pattern=north east lines] (0,-1.9) ellipse [x radius=0.2cm, y radius=0.125cm];
\filldraw[fill=white] (0,-1.95) ellipse [x radius=0.2cm, y radius=0.1cm];

% Draw the hatched plate in the middle of the right cylinder
\draw[pattern=north east lines] (7,-2.1) ellipse [x radius=1.75cm, y radius=0.5cm];
\filldraw[fill=gray] (7,-1.9) ellipse [x radius=1.75cm, y radius=0.5cm];

% Random dots in the whole right cylinder
\begin{scope}
\clip (5.25,0) rectangle (8.75,-2.25);
\randomdots{53}{87}{0}{25}{250}
\end{scope}

% Draw the right cylinder shifted to the right to accommodate the longer arrow
\filldraw[fill=gray] (7,0) ellipse [x radius=1.75cm, y radius=0.5cm];
\draw (5.25,0) -- (5.25,-4);
\draw (8.75,0) -- (8.75,-4);
\draw[pattern=north east lines] (7,-4) ellipse [x radius=1.75cm, y radius=0.5cm];

% Draw the slit in the hatched plate of the right cylinder
\filldraw[fill=white] (7,-1.9) ellipse [x radius=0.2cm, y radius=0.125cm];
\draw[pattern=north east lines] (7,-1.9) ellipse [x radius=0.2cm, y radius=0.125cm];
\filldraw[fill=white] (7,-1.95) ellipse [x radius=0.2cm, y radius=0.1cm];

% Random dots in the whole right cylinder
\begin{scope}
\clip (5.25,-2.5) rectangle (8.75,-4.25);
\randomdots{53}{87}{30}{45}{250}
\end{scope}

% Draw the horizontal arrow between the two cylinders
\draw[-Triangle] (2.5, -2) -- (4.5, -2);
% Add "passage of" and "time" above and below the arrow
\node[above] at (3.5, -1.8) {passage of};
\node[below] at (3.5, -2.2) {time};

\draw[-Triangle] (3,-3) -- (3,-4) node[below right] {$z$};
\draw[-Triangle] (3,-3) -- (4,-3) node[right] {$x$};
\draw[-Triangle] (3,-3) -- (3.5,-3.5) node[below right] {$y$};

\end{tikzpicture}
#+end_src

Starting from \(f(\vec{v})\) obtained in 3.14.1, a [[id:9b149a74-f823-4dc5-8aa3-cba9d7879fa0][change of coordinates]] to a spherical coordinate system, followed by an integration over all solid angles will yield the [[id:dacc4eb0-8672-4b99-9990-5dd61329e426][Maxwell-Boltzmann distribution of speeds]]

\[f (v)= \bigg(\frac{m}{2 \pi \,k_B T}\bigg)^{3 / 2} \,(4 \pi \, v^2)\, \exp \bigg(- \frac{m \, v^2}{2 k_B T} \bigg).\]

In the problem on [[id:f5d85255-1e37-41cb-b961-7c1a6992fc97][characteristic functions]], we obtained the first and second moments of the Maxwell probability density function

\[ p(x) = \sqrt{\frac{2}{\pi a^3}} x^2 \exp \left( -\frac{x^2}{2a^2} \right), \qquad \geq 0, \]

\[m_1 =  2 \sqrt{\frac{2}{\pi}} a, \qquad m_2 =  3 a^2.\]

Comparing \( p(x) \) with \( f(v) \), we get \( a = (k_B T / m)^{1/2} \), so the first and second moments of \( f(v) \) are

\[ \langle v \rangle = \bigg(\frac{8 k_B T}{\pi m}\bigg)^{1/2}, \qquad \langle v^2 \rangle = \frac{3 k_B T}{m}.\]

As obtained in the previous problem [[id:323e99f4-7b93-4150-a804-ee4741a65acd][Generalized ideal gas]] the flux \( J \) is

\[
J \equiv \frac{N}{A \mathrm{~d} t}=\frac{S_{d-1}}{(d-1) S_{d}} \cdot n \bar{v}
\]

where \(\bar{v}=\int v f(v) \mathrm{d} v\) is the average speed and \( S_d = \frac{2 \pi^{d/2}}{(d/2 - 1)!} \). Substituting \( S_d = \frac{2 \pi^{d/2}}{(d/2 - 1)!} \) we get \(J = 4^{-1} n \bar{v}\). Substituting \(\bar{v} = \langle v \rangle = \sqrt{\frac{8 k_B T}{\pi m}}\), we get \(J = n \sqrt{\frac{k_B T}{2 \pi m}}\).

*** 3.14.3
*Show that the average kinetic energy of escaping particles is* \(2 k_{B} T\). *(Hint. Calculate contributions to kinetic energy of velocity components parallel and perpendicular to the wall separately.)*

The *root mean squared speed*, by definition, is \( v_{\text{rms}} \equiv \langle v^2 \rangle^{1/2} \). To find the \( v_{\text{rms}} \) before the beginning of effusion, we can substitute \( \langle v^2 \rangle = 3 k_B T/m \) in its definition to obtain \(v_{\text{rms}} = \sqrt{3 k_B T/m}\) so that the average kinetic energy is

\[\bigg \langle \frac{1}{2} m v^2 \bigg \rangle = \frac{3}{2} k_B T;\]

\( k_B T \) for each degree of freedom. For an escaping particle \(\vec{v}_z\) is given by a normal distribution (3.14.1), but imposing \(v_z \geqslant 0\) changes the probability density function into a /folded normal distribution/ given by

\begin{align*}
p(v_z)=\bigg(\frac{m}{2 \pi K_B T}\bigg)^{1 / 2} \exp \bigg(-\frac{m v_z^2}{2 K_B T}\bigg) + \bigg(\frac{m}{2 \pi K_B T}\bigg)^{1 / 2} \exp \bigg(-\frac{m v_z^2}{2 K_B T}\bigg),
\end{align*}

which, as the above form suggests, is like having an additional quadratic degree of freedom that is a copy of \( v_z \). Hence, for escaping particles, \( \langle m v_z v_z / 2 \rangle = k_B T \), not \( k_B T / 2 \), so that the average kinetic energy of escaping particles is

\begin{align*}
\bigg \langle \frac{1}{2} m v^2 \bigg \rangle &= \bigg \langle \frac{1}{2} m (v_x^2+v_y^2+v_z^2) \bigg \rangle = \frac{1}{2} k_B T + \frac{1}{2} k_B T + k_B T = 2 k_B T.
\end{align*}

*** 3.14.4
*The hole is closed and the container (now thermally insulated) is allowed to reach equilibrium. What is the final temperature of the gas in the container?*

We have

\begin{align*}
P &= n K_B T \Rightarrow \mathrm{d}P = k_B (T\,\mathrm{d}n + n\,\mathrm{d}T) \Rightarrow \frac{\mathrm{d}P}{k_B} - T \frac{\mathrm{d}n}{n} = \mathrm{d}T \Rightarrow \frac{\mathrm{d}P}{P} - \frac{\mathrm{d}n}{n} = \frac{\mathrm{d}T}{T}.
\end{align*}

Therefore

\begin{align*}
P_f= \frac{2}{3} \frac{E}{V} = \frac{2}{3} \cdot \frac{1}{V} \bigg[\frac{3}{2} N k_B T - \frac{2 k_B T N A \mathrm{d}t}{V} \bigg(\frac{k_B T}{2 \pi m}\bigg)^{1/2}\bigg],
\end{align*}

\begin{align*}
n_f=n\bigg(1-\frac{A \mathrm{d}t}{V} \sqrt{\frac{k_B T}{2 \pi m}}\bigg),
\end{align*}

and

\begin{align*}
T_{f} = P_f / n_f k_B = T\bigg(1-\bigg[\bigg(\frac{1}{3} \frac{A \mathrm{d}t}{V} \sqrt{\frac{K_B T}{2 \pi m}}\bigg) \bigg / \bigg(1-\frac{A \mathrm{d}t}{V} \sqrt{\frac{K_B T}{2 \pi m}}\bigg)\bigg] \bigg).
\end{align*}

*** 3.14.5
*A vessel partially filled with mercury (atomic weight 201), and closed except for a hole of area* \(0.1 \mathrm{~mm}^{2}\) *above the liquid level, is kept at* \(0^{\circ} \mathrm{C}\) *in a continuously evacuated enclosure. After 30 days it is found that* \(24 \mathrm{mg}\) *of mercury has been lost. What is the vapor pressure of mercury at* \(0^{\circ} \mathrm{C}\) *?*

\[
\frac{N}{\mathrm{d}t} &= P A / \sqrt{2 \pi m K_B T} \Longrightarrow P=\frac{N}{A \mathrm{d}t} \sqrt{2 \pi m K_B T} = \frac{M}{A \mathrm{d}t} \sqrt{\frac{2 \pi K_B T}{m}}
\]

On substituting \(M=2.4 \times 10^{-5} \mathrm{~kg}\), \(A=10^{-7} \mathrm{~m}^2\), \(\mathrm{d}t = 2.592 \times 10^6 \mathrm{~s}\), \(m=3.33 \times 10^{-25} \mathrm{~kg}\), and \(T=273.15 \mathrm{~K}\), we get \(P=0.025 \mathrm{~Pa}\).

** 3.15 Adsorbed particles
:PROPERTIES:
:ID:       d133f2ba-605b-4279-a173-4edb65e80cd0
:END:
:LOGBOOK:
CLOCK: [2024-04-25 Thu 18:54]--[2024-04-25 Thu 19:59] =>  1:05
:END:

*Consider a gas of classical particles of mass* \(m\) *in thermal equilibrium at a temperature* \(T\), *and with a density* \(n\). *A clean metal surface is introduced into the gas. Particles hitting this surface with normal velocity less than* \(v_{t}\) *are reflected back into the gas, while particles with normal velocity greater than* \(v_{t}\) *are absorbed by it.*

*** 3.15.1
*Find the average number of particles hitting one side of the surface per unit area and per unit time.*

As obtained in [[id:323e99f4-7b93-4150-a804-ee4741a65acd][Generalized ideal gas]]

\[J \equiv \frac{N}{\mathrm{d}t A}= 4^{-1}\,n\, \langle v \rangle = 4^{-1}\,n\,\bigg(\frac{8 K_B T}{\pi m}\bigg)^{1/2}.\]

See [[id:dacc4eb0-8672-4b99-9990-5dd61329e426][Maxwell-Boltzmann distribution of velocities]] and the problem [[id:f5d85255-1e37-41cb-b961-7c1a6992fc97][Characteristic functions]] for an explicit calculation of \(\langle v \rangle\).

*** 3.15.2
*Find the average number of particles absorbed by one side of the surface per unit area and per unit time.*

The average number of particles absorbed by one side of the surface per unit area and per unit time is given by \(\frac{N}{\mathrm{d}t\,A} = n \bar{v}/4\) where \(\bar{v} = \int_{v_t}^{\infty} v f(v) \mathrm{d}v\). Let us evaluate the integral for \( \bar{v} \).

\begin{align*}
\bar{v} &= \int_{v_t}^{\infty} \mathrm{d}v\, v\bigg(\frac{m}{2 \pi k_B T}\bigg)^{3 / 2} 4 \pi v^2 \exp \bigg(-\frac{m v^2}{2 k_B T}\bigg) \\
&=4 \pi\bigg(\frac{m}{2 \pi K_B T}\bigg)^{3 / 2} \int_{v_t}^{\infty} \mathrm{d}v\, v^3 \exp \bigg(-\frac{m v^2}{2 k_B T}\bigg) \xrightarrow{(\beta m/2) \to b} \\
& =4 \pi\bigg(\frac{b}{\pi}\bigg)^{3 / 2} \int_{v_t}^{\infty}  \mathrm{d}v\, v^3 \exp \big(-b v^2\big) \\
& =4 \pi\bigg(\frac{b}{\pi}\bigg)^{3 / 2} \cdot \frac{\bigg(b v_t^2+1\bigg)}{2 b^2} \exp \big(-b v_t^2\big) \\
&= \sqrt{\frac{4}{\pi b}} \cdot\bigg(b v_t^2+1\bigg) \exp \big(-b v_t^2\big) \xrightarrow{b \to (\beta m/2)} \\
& =\sqrt{\frac{8 k_B T}{\pi m}} \cdot\bigg[\bigg(m v_t^2 / 2 k_B T\bigg)+1\bigg] \exp \bigg(-\frac{m v_t^2}{2 k_B T}\bigg).
\end{align*}
** 3.16 Electron emission
:PROPERTIES:
:ID:       601854a4-237e-49a7-a0b7-e15e7bf08726
:END:
:LOGBOOK:
CLOCK: [2024-04-25 Thu 17:49]--[2024-04-25 Thu 18:32] =>  0:43
:END:
*When a metal is heated in vacuum, electrons are emitted from its surface. The metal is modeled as a classical gas of non-interacting electrons held in the solid by an abrupt potential well of depth* \(\phi\) *(the work-function) relative to the vacuum.*

Next: [[id:2eea2039-7175-4635-8256-224892e7134e][Classical harmonic oscillators]]

*** 3.16.1
*What is the relationship between the initial and final velocities of an escaping electron?*

\[2^{-1} m_e (v_f^2 - v_i^2) = \phi \Rightarrow v_f= \big[v_i{ }^2+ (2 \phi/m_e)\big]^{1/2}.\]

*** 3.16.2
*In thermal equilibrium at temperature* \(T\), *what is the probability density function for the velocity of electrons?*

As obtained in the problem [[id:df72e834-3e97-490b-93b6-bcbc6d85e4c0][Effusion]] (3.14.1) (also see [[id:c3729898-9aa3-4966-a16c-24216deb2c8d][equilibrium properties]]),

\[f (\vec{v}_e)= \bigg(\frac{m_e}{2 \pi \,k_B T}\bigg)^{3 / 2} \exp \bigg(- \frac{m_e \, v^2}{2 k_B T} \bigg).\]

*** 3.16.3
*If the number density of electrons is* \(n\), *calculate the current density of thermally emitted electrons.*

As obtained in the problem [[id:df72e834-3e97-490b-93b6-bcbc6d85e4c0][Effusion]] the [[id:ad948e53-1a7b-4c30-81cc-708f6ab74d58][current density]] \( J \) is given by

\begin{equation*}
J = 4^{-1} \, n \, \bar{v}_e, \qquad \bar{v}_e = \int_{(2 \phi / m_e)^{1/2}}^\infty v_e \, f(\vec{v}_e) \, \mathrm{d} v_e.
\end{equation*}

Apart from a change in the lower limit from \(v_t\) to \((2 \phi / m_e)^{1/2}\), the integral for \( \bar{v}_e \) is the same as the one we encountered in the previous problem [[id:d133f2ba-605b-4279-a173-4edb65e80cd0][Adsorbed particles]]. So we immediately write

\begin{align*}
\bar{v}_e = 2^{3/2} \big( \pi\, \beta \, m_e \big)^{-1/2} \big(\beta \, \phi + 1\big) \exp \big(- \beta \, \phi \big), \qquad J= 2^{-1/2} \big(\pi \, \beta \, m_e \big)^{-1/2} \big(\beta \, \phi + 1\big) \exp \big(- \beta \, \phi \big).
\end{align*}

In our expression for \(J\), the leading term in \(T\) goes like \(J \propto T^{\thinspace 1 / 2} \exp \big(-\beta \, \phi \big) + \mathcal{O} (T^{\thinspace-1/2})\), which of course differs from [[id:c01f3f40-a5b9-432a-b480-dd9582385833][Richardson's law for thermionic emission]] in which the current density shows behaviour \(J \propto T^{\thinspace 2} \, \exp (- \beta \, \phi)\).  For that, we'll have to take into account [[id:3d61b366-690a-4b0a-9200-2604eb725676][Fermi statistics]] and modify \(n_e\) suitably (taken to be a constant here).

* 4 Classical statistical mechanics
** 4.1 Classical harmonic oscillators
:PROPERTIES:
:ID:       2eea2039-7175-4635-8256-224892e7134e
:END:
*Consider* \(N\) *harmonic oscillators with coordinates and momenta* \(\left\{q_i, p_i\right\}\), *and subject to a Hamiltonian*

    \[
    H \left(\left\{q_i, p_i\right\}\right)=\sum_{i=1}^N\left[\frac{p_i^2}{2 m}+\frac{m \omega^2 q_i^2}{2}\right]
   \]

*** 4.1.1
*Calculate the entropy* \(S\), *as a function of the total energy* \(E\).

    #+begin_hint latex
    By appropriate change of scale, the surface of constant energy can be deformed into a sphere. You may then ignore the difference between the surface area and volume for \(N \gg 1\). A more elegant method is to implement this deformation through a canonical transformation.
    #+end_hint

    Transform the variables \(p_i \rightarrow \sqrt{m\omega} p_i, \quad q_i \rightarrow q_i/ \sqrt{m\omega}\). This constitutes a canonical transformation, leading to a revised Hamiltonian \(H(\{q_i, p_i\}) = 2^{-1} \sum_{i} \omega \big( p_i^2 + q_i^2 \big)\). For a system with energy \(E\), the accessible phase space is defined by an ellipsoid for the original Hamiltonian and a sphere in \(2N\) dimensions for the transformed Hamiltonian. The volume \(V_d\) of a hypersphere in \(2N\) dimensions can be approximated by its surface area, given as \(V_{d} = S_{d} R^{d} / d\), \(S_{d} = 2 \pi^{d / 2} / \Gamma (d / 2)\), \(R = 2E / \omega h\). \(h\) is introduced in \(R\) due to the phase space measure \(\prod_{i} \mathrm{d} q_i \mathrm{d} p_i / h\). The surface area \(\Omega(E)\) and thus entropy \(S(E)\) for fixed \(E\), using  \(N ! \approx N^{N} \exp (-N)\), is

    \begin{align*}
    \Omega(E) = &\frac{2 \pi^{N}}{(N-1) !} \cdot \frac{1}{2 N} \cdot\bigg(\frac{2 E}{h \omega}\bigg)^{N} \approx\bigg(\frac{2 \pi E}{h \omega}\bigg)^{N} \cdot \frac{1}{N !}, \qquad S \approx N k_B \ln \bigg[ \frac{2 \pi e E}{N h \omega} \bigg]. \tag{4.1.1}
    \end{align*}

*** 4.1.2
*Calculate the energy* \(E\), *and heat capacity* \(C\), *as functions of temperature* \(T\), *and* \(N\).

  From the relationship \(T^{-1} = (\partial_{E} S)_{N}\) and \(C = (D_{T} E)_{N}\) we get

   \begin{align*}
   E = N k_B T, \qquad \qquad C=N k_B. \tag{4.1.2}
   \end{align*}

*** 4.1.3
*Find the joint probability density* \(P(p, q)\) *for a single oscillator. Hence calculate the mean kinetic energy, and mean potential energy for each oscillator.*

    \begin{align*}
    P(p, q) & = h^{-1} \frac{\Omega\left(N-1, E_{N-1}\right)}{\Omega(N, E)} \approx \frac{\omega}{2 \pi} \cdot \frac{N}{E} \cdot \frac{1}{e} \cdot\left(\frac{E_{N-1}}{E_{N}}\right)^{N} \\
    & =\frac{1}{2 \pi K_{B} T} \cdot \frac{\omega}{e} \cdot\bigg(\frac{N K_{B} T-p^{2} / 2 m-m \omega^{2} q^{2} / 2}{N K_{B} T}\bigg)^{N} \\
    & =\frac{1}{2 \pi K_{B} T} \cdot \frac{\omega}{e}\bigg(1-\frac{1}{N}\bigg[\frac{p^{2}}{2 m K_{B} T}+\frac{m \omega^{2} q^{2} }{2 K_{B} T}\bigg]\bigg)^{N} \\
    & \approx \frac{\omega}{2 \pi} \cdot \frac{1}{k_{B} T} \cdot \exp \bigg\{-\frac{1}{K_{B} T}\left(\frac{p^{2}}{2 m}+\frac{m \omega^{2} q^{2} }{2}\right)\bigg\}. \tag{4.1.3}
    \end{align*}

    The approximations are of the form \(N-1 \approx N \text { for } N \gg 1\) and as \(N \to \infty\), \(\big(1 +  x / N \big)^{N} \to \exp \thinspace (x)\). The mean kinetic energy and mean potential energy is given by \(\langle p^2 / 2m \rangle = \langle m\omega^2 q^2 / 2 \rangle = \langle E \rangle /2 = k_B T / 2\).

** 4.2 Quantum harmonic oscillators
:PROPERTIES:
:ID:       85a2f79a-6fa0-48f3-86a1-e35cf0c89386
:END:
*Consider* \(N\) *independent quantum oscillators subject to a Hamiltonian*

\begin{gathered}
H\left(\left\{n_{i}\right\}\right)=\hbar \omega \sum_{i=1}^{N}\left(n_{i}+\frac{1}{2}\right)
\end{gathered}

\(n_{i}=0,1,2, \ldots\) are the quantum occupation numbers for the \(i\) th oscillator.

*** 4.2.1
*Calculate the entropy* \(S\), *as a function of the total energy* \(E\).

    An alternate way of writing the Hamiltonian is \(H(\{n_{i}\})= \hbar \omega \big(\frac{N}{2} + \sum_{i} n_i \big) \equiv \hbar \omega \big(\frac{N}{2} + M \big)\), with \(M (E) \equiv \sum_i n_i\). The number of microstates for a given energy \(E\) is the number of all possible sets of quantum occupation numbers \(\{n_i\}\) that add up to \(M\). Equivalently, we can ask /How many different ways are there to place/ \(M\) /plain balls into/ \(N\) /marked boxes, with no other rules on placement?/" 

#+begin_src latex :file ~/pictures/.images/spop-sol-4.2.1.png :results file graphics
    \begin{tikzpicture}[scale=0.7, transform shape]

      % Function to draw a single diagram
      \newcommand{\drawdiagram}[2]{
        % Grid
        \draw[step=1cm,gray,very thin] (#1,0) grid (#1+5,5);

        % Axes
        % Axes with labels aligned with the axes
        \draw[thick,-Latex] (#1,0) -- (#1+6,0) node[anchor=north west] {\(i\)};
        \draw[thick,-Latex] (#1,0) -- (#1,6) node[anchor=south east] {\(n_i\)};

        \foreach \x in {1,2,3,4,5}
        \draw[thick] (#1+\x,0.1) -- (#1+\x,-0.1) node[anchor=north] {\x};

        % Energy Levels with breaks
        \foreach \y in {1,2,3,4,5}
                 {
                   \draw[thick] (#1+0.75,\y) -- (#1+1.25,\y);
                   \draw[thick] (#1+1.75,\y) -- (#1+2.25,\y);
                   \draw[thick] (#1+2.75,\y) -- (#1+3.25,\y);
                   \draw[thick] (#1+3.75,\y) -- (#1+4.25,\y);
                   \draw[thick] (#1+4.75,\y) -- (#1+5.25,\y);
                 }

                 % Dots for continuity on the right side of the grid
                 \foreach \y in {1,2,3,4,5}
                 \node at (#1+5.5,\y) {$\ldots$};

                 % Dots for continuity on the top of the grid
                 \foreach \x in {1,2,3,4,5}
                 \node at (#1+\x,5.5) {$\vdots$};

                 % Particles with numbers to the side
                 \foreach \x/\y in {#2}
                          {
                            \filldraw (#1+\x,\y) circle (2pt);
                            \node at (#1+\x+0.5,\y) {\y};
                          }


      }

      % Draw first diagram
      \drawdiagram{0}{1/2, 2/3, 3/4, 4/1, 5/3};

      % Draw second diagram, shifted to the right by 10 units with different arrangement
      \drawdiagram{10}{1/5, 2/1, 3/2, 4/4, 5/1};
      % Global label for M, larger
      \node[anchor=north east] at (current bounding box.north east) {\Large $M = \sum_{i} n_i = 13$};

  \end{tikzpicture}
#+end_src

To answer the question, imagine forming sequential arrangements of all the balls and all but one of the boxes with the understanding that each box is filled with all the balls to its left and whenever there's a sequence of one or more balls with no box to its right, it goes into the box we left out. To answer the posed question is to find out how many /unique/ ways, say \(R\), exist of arranging these \(M + N - 1\) entities, keeping in mind that the boxes are distinguishable while the balls are not.

\[
\Omega = \binom{M+N-1}{M} = \frac{(M+N-1)(M+N-2) \cdots (N+1) N}{M(M-1) \cdots 2 \cdot 1} = \frac{(M+N-1) !}{M !(N-1) !}. \tag{4.2.1}
\]

#+begin_src latex :file ~/pictures/.images/spop-sol-4.2.2.png :results file graphics
\begin{tikzpicture}[scale=0.8]
    % Identifiers for the first set of boxes
    \foreach \x/\l in {0.5/a, 2/b, 3.5/c, 5/d, 6.5/e} {
        \node[above] at (\x,2) {\l};
    }
    
    % First set of boxes
    % Box 1
    \draw (0,0) rectangle ++(1,2);
    \foreach \x in {0.25, 0.75} {
        \filldraw (\x,0.225) circle (0.2);
    }

    % Box 2
    \draw (1.5,0) rectangle ++(1,2);
    \foreach \x/\y in {1.74/0.2, 2.25/0.2, 2.0/0.55} {
        \filldraw (\x,\y) circle (0.2);
    }

    % Box 3
    \draw (3,0) rectangle ++(1,2);
    \foreach \x/\y in {3.25/0.2, 3.725/0.2, 3.25/0.625, 3.725/0.625} {
        \filldraw (\x,\y) circle (0.2);
    }

    % Box 4
    \draw (4.5,0) rectangle ++(1,2);
    \filldraw (5,0.225) circle (0.2);

    % Box 5
    \draw (6,0) rectangle ++(1,2);
    \foreach \x in {6.25, 6.75} {
        \filldraw (\x,0.225) circle (0.2);
    }

    % Space between the two sets of boxes
    \newcommand{\spaceX}{10}

    % Identifiers for the second set of boxes
    \foreach \x/\l in {\spaceX+0.5/a, \spaceX+2/b, \spaceX+3.5/c, \spaceX+5/d, \spaceX+6.5/e} {
        \node[above] at (\x,2) {\l};
    }
    
    % Second set of boxes
    % Box 1 with 5 balls
    \draw (\spaceX,0) rectangle ++(1,2);
    \foreach \x/\y in {\spaceX+0.275/0.2, \spaceX+0.275/0.65, \spaceX+0.725/0.2, \spaceX+0.725/0.65, \spaceX+0.5/1.05} {
        \filldraw (\x,\y) circle (0.2);
    }

    % Box 2 with 1 ball
    \draw (\spaceX+1.5,0) rectangle ++(1,2);
    \filldraw (\spaceX+2,0.2) circle (0.2);

    % Box 3 with 2 balls
    \draw (\spaceX+3,0) rectangle ++(1,2);
    \foreach \x in {\spaceX+3.25, \spaceX+3.75} {
        \filldraw (\x,0.2) circle (0.2);
    }

    % Box 4 with 4 balls
    \draw (\spaceX+4.5,0) rectangle ++(1,2);
    \foreach \x/\y in {\spaceX+4.775/0.2, \spaceX+5.25/0.2, \spaceX+4.775/0.625, \spaceX+5.25/0.625} {
        \filldraw (\x,\y) circle (0.2);
    }

    % Box 5 with 1 ball
    \draw (\spaceX+6,0) rectangle ++(1,2);
    \filldraw (\spaceX+6.5,0.2) circle (0.2);
\end{tikzpicture}
#+end_src

The quantity \(\Omega\) - the number of ways to distribute \(M\) quanta of energy over N oscillators - was called /complexions/ by Plank. For a fixed energy \(E\), we have \(M = E/\hbar \omega - N/2\). The entropy as a function of energy is then given by

\begin{align*}
S(M(E)) &\equiv K_{B} \ln \bigg( \frac{(M+N-1)^{M+N-1} \exp(-[M+N-1])}{M^{M} \exp(-M) (N-1)^{N-1} \exp(1-N)} \bigg) \\
&= K_{B} \ln \bigg( \frac{(M+N-1)^{M+N-1}}{M^{M} (N-1)^{N-1}} \bigg) \\
&= K_{B} \big[ (M+N-1) \ln(M+N-1) - M \ln M - (N-1) \ln(N-1) \big] 
\tag{4.2.2}
\end{align*}

#+begin_src latex :file ~/pictures/.images/spop-sol-4.2.3.png :results file graphics
  \begin{tikzpicture}
  \begin{axis}[
      xlabel={$M$},
      ylabel={$S$},
      axis lines=left,
      enlargelimits=true,
      xtick=\empty, % No x-axis ticks
      ytick=\empty, % No y-axis ticks
      width=6cm,
      height=5cm,
      clip=false,
      domain=1:10, % Adjust domain according to your M range
      samples=100,
      xmin=0,
      smooth,
      thick,
  ]

  % First curve, N=10
  \def\N1{10} % example value for N
  \def\KB{1} % Simplified for visualization
  \addplot+[white, no marks] {(\KB)*ln((x+\N1-1)^(x+\N1-1) / (x^x * (\N1-1)^(\N1-1)))};
  \node at (axis cs:6, {(\KB)*ln((9+\N1-1)^(9+\N1-1) / (9^9 * (\N1-1)^(\N1-1)))}) [anchor=south] {$N=10$};

  % Third curve, N=1000
  \def\N3{1000} % example value for N
  \addplot+[white, no marks] {(\KB)*ln((x+\N3-1)^(x+\N3-1) / (x^x * (\N3-1)^(\N3-1)))};
  \node at (axis cs:3,{(\KB)*ln((9+\N3-1)^(9+\N3-1) / (9^9 * (\N3-1)^(\N3-1)))}) [anchor=west] {$N=1000$};

  \end{axis}
  \end{tikzpicture}
#+end_src

*** 4.2.2
*Calculate the energy* \(E\), *and heat capacity* \(C\), *as functions of temperature* \(T\), *and* \(N\).

From the relationship \(T^{-1} \equiv (\partial_{E} S)_{N}\) follows \(T^{-1} = K_{B} (D_{E} M) (\partial_{M} S)_{N}\) so that

\begin{align*}
\frac{\hbar \omega}{K_{B} T} = \ln(E/ \hbar \omega + N/2 - 1) - \ln(E/ \hbar \omega - N/2) \approx \ln \bigg(\frac{E/ \hbar \omega + N/2}{E/ \hbar \omega - N/2} \bigg) \tag{4.2.3}
\end{align*}

where we have used \(N/2-1 \approx N/2\) for \(N \gg 1\). Solving for \(E\) and using  \(C = \left(D_{T} E\right)_{N}\) we get

\begin{align*}
\frac{E}{\hbar \omega}=\frac{N}{2} \left[\frac{\exp \left(\hbar \omega / k_{B} T\right)+1}{\exp \left(\hbar \omega / k_{B} T\right)-1}\right], \qquad C=N K_{B}\left(\frac{\hbar \omega}{K_{B} T}\right)^{2} \frac{\exp \left(\hbar \omega / K_{B} T\right)}{\left[\exp \left(\hbar \omega / K_{B} T\right)-1\right]^{2}}. \tag{4.2.4}
\end{align*}

#+begin_src latex :file ~/pictures/.images/spop-sol-4.2.4.png :results file graphics
    \begin{tikzpicture}
      % Define constants for easier modification
      \def\N{500} % Adjust N according to your scenario
      \def\kB{1} % Boltzmann constant
      \def\hbr{1} % Reduced Planck constant
      \def\omg{1} % Frequency of oscillators

      % E(T) vs T plot
      \begin{axis}[
          xlabel={$T$},
          ylabel={$E$},
          axis lines=left,
          xtick=\empty, % No x-axis ticks
          ytick=\empty, % No y-axis ticks
          width=5cm,
          height=4cm,
          domain=0:2, % T from 0.1 to 5 for visualization
          samples=100,
          smooth,
          thick,
          xmin=0, xmax=2,
          ymin=0,
          at={(0,0)} % Position of this plot
        ]
        \addplot+[no marks, white] {(\N/2)*((exp(\omg / (\kB * x)) + 1) / (exp(\omg / (\kB * x)) - 1))};
      \end{axis}

      % C(T) vs T plot
      \begin{axis}[
          xlabel={$T$},
          ylabel={$C$},
          xtick=\empty, % No x-axis ticks
          ytick=\empty, % No y-axis ticks
          axis lines=left,
          width=5cm,
          height=4cm,
          domain=0:2, % T from 0.1 to 5 for visualization
          samples=100,
          smooth,
          thick,
          xmin=0, xmax=2,
          ymin=0,
          at={(7cm,0)} % Position to the right of the first plot
        ]
        \addplot+[no marks, white] {(\N * (\omg / (\kB * x))^2) * (exp(\omg / (\kB * x)) / (exp(\omg / (\kB * x)) - 1)^2)};
      \end{axis}
    \end{tikzpicture}
#+end_src

*** 4.2.3
*Find the probability* \(p(n)\) *that a particular oscillator is in its* \(n^{\mathrm{th}}\) *quantum level.*

\begin{aligned}
p(n) & =\frac{\Omega(N-1, M-n)}{\Omega(N, M)}=\frac{[(M-n)+(N-1)-1] !}{(M-n) !(N-2) !} \cdot \frac{M !(N-1) !}{(M+N-1) !} \\
& =\frac{M(M-1) \cdots(M-n+1) \cdot(N-1)}{(M+N-1)(M+N-2) \cdots(M+N-n-1)} \\
&  \approx \frac{M^{n} N}{(M+N)^{n+1}} = N\bigg(\frac{E}{\hbar \omega}-\frac{N}{2}\bigg)^{n} \Big/ \bigg(\frac{E}{\hbar \omega}-\frac{N}{2}+N\bigg)^{n+1} \\
&= \frac{N}{(E / \hbar \omega+N / 2)} \cdot\left(\frac{E / \hbar \omega- N / 2}{E / \hbar \omega + N / 2}\right)^{n}=\exp \left(-\frac{n \hbar \omega}{k_{B} T}\right)\left[1-\exp \left(\frac{-\hbar \omega}{k_{B} T}\right)\right]
\end{aligned}

We have assumed \(M \gg n\) and used the approximation \(N - k \approx N\) for \(N \gg k \). In the final step, we have used (4.2.3) to eliminate \(E\).

*** 4.2.4
*Comment on the difference between heat capacities for classical and quantum oscillators.*

#+begin_src latex :file ~/pictures/.images/spop-sol-4.2.5.png :results file graphics
  \begin{tikzpicture}
  \begin{axis}[
      axis lines = left,
      xlabel = {$\hbar \omega / K_{B} T$},
      ylabel = {$C_{\text{q}} / C_{\text{c}}$},
      domain=0.01:10,
      samples=100,
            axis lines=left,
            xtick=\empty, % No x-axis ticks
            ytick=\empty, % No y-axis ticks
            width=5cm,
            height=4cm,
      ymin=0,
      ymax=1.25,
      enlargelimits=false,
      clip=false,
      no marks]
  \addplot+[thick, white] {(x^2 * exp(x))/(exp(x)-1)^2};
  \end{axis}
  \end{tikzpicture}
#+end_src

From (4.1.2) and (4.2.4) we find \(C_{\text{q}} / C_{\text{c}} = [\exp \lambda -1]^{-2}} \lambda^{2} \exp \lambda \) where \(\lambda \equiv \hbar \omega / K_{B} T\). Thus \(\lim_{T \to \infty} C_{\text{q}} / C_{\text{c}} \to 1\) and \(\lim_{T \to 0} C_{\text{q}} / C_{\text{c}} \to 0\). The heat capacity of a group of classical oscillators is temperature invariant. For sufficiently large temperatures, the group of quantum oscillators has comparable heat capacity to the group of classical oscillators. For sufficiently small temperatures, the heat capacity of the quantum oscillator vanishes.
** 4.3 Relativistic particles
:PROPERTIES:
:ID:       c989f71c-ffd9-4078-a5fd-c1e026345610
:END:
\(N\) *indistinguishable relativistic particles move in one dimension subject to a Hamiltonian*

\[
\mathcal{H}\left(\left\{p_i, q_i\right\}\right)=\sum_{i=1}^N\left[c\left|p_i\right|+U\left(q_i\right)\right],
\]

*with* \(U\left(q_i\right)=0\) for \(0 \leq q_i \leq L\), *and* \(U\left(q_i\right)=\infty\) *otherwise. Consider a microcanonical ensemble of total energy* \(E\).
*** 4.3.1
*Compute the contribution of the coordinates* \(q_i\) *to the available volume in phase space* \(\Omega(E, L, N)\).

#+begin_src latex :file ~/pictures/.images/spop-sol-4.3.1.png :results file graphics
  \begin{tikzpicture}[scale=1, >=Stealth]
      % Define the length of the lines
      \def\lineLength{5}
      \def\lineHeight{0.5}
      \def\lineSpacing{0.5} % spacing between lines

      % First line q1, p1
      \draw (0,0) -- (\lineLength,0);
      \draw[->] (2,0) -- (2.5,0) node[midway, above] {$\vec{p_1}$};
      \filldraw (2,0) circle (2pt);
      \node[left] at (0,0) {$q_1$};
      \node[right] at (\lineLength,0) {$L$};

      % Second line q2, p2
      \draw (0,\lineHeight) -- (\lineLength,\lineHeight);
      \draw[->] (\lineLength-1.0,\lineHeight) -- (\lineLength-1.5,\lineHeight) node[midway, above] {$\vec{p_2}$};
      \filldraw (\lineLength - 1.0,\lineHeight) circle (2pt);
      \node[left] at (0,\lineHeight) {$q_2$};

      % Third line q3, p3
      \draw (0,2*\lineHeight) -- (\lineLength,2*\lineHeight);
      \draw[->] (1.0,2*\lineHeight) -- (1.5,2*\lineHeight) node[midway, above] {$\vec{p_3}$};
      \filldraw (1.0,2*\lineHeight) circle (2pt);
      \node[left] at (0,2*\lineHeight) {$q_3$};

      % Vertical ellipsis
      \node at (\lineLength/2,3*\lineHeight) {$\vdots$};

      % Second to last line q(N-1), p(N-1)
      \draw (0,3.5*\lineHeight) -- (\lineLength,3.5*\lineHeight);
      \draw[->] (\lineLength,3.5*\lineHeight) -- (\lineLength-0.5,3.5*\lineHeight) node[midway, above] {$\vec{p_{N-1}}$};
      \filldraw (\lineLength,3.5*\lineHeight) circle (2pt);
      \node[left] at (0,3.5*\lineHeight) {$q_{N-1}$};

      % Last line qN, pN
      \draw (0,4.5*\lineHeight) -- (\lineLength,4.5*\lineHeight);
      \draw[->] (0.5,4.5*\lineHeight) -- (1.0,4.5*\lineHeight) node[midway, above] {$\vec{p_N}$};
      \filldraw (0.5,4.5*\lineHeight) circle (2pt);
      \node[left] at (0,4.5*\lineHeight) {$q_N$};
  \end{tikzpicture}
#+end_src

From the figure, it is clear that \(\Omega_{q} (E, L, N) = L^{N}/N!\). The \(N!\) accounts for particle indistinguishability (also called correct Boltzmann counting).

*** 4.3.2
*Compute the contribution of the momenta* \(p_i\) *to* \(\Omega(E, L, N)\).

#+begin_hint
The volume of the hyperpyramid defined by \(\sum_{i=1}^d x_i \leq R\), and \(x_i \geq 0\), in \(d\) dimensions is \(R^d / d!\).
#+end_hint

#+begin_src latex :file ~/pictures/.images/spop-sol-4.3.2.png :results file graphics
\begin{tikzpicture}
    % 2D representation for N=2
    \begin{scope}
        \draw[thin,->] (-2,0) -- (2,0) node[anchor=north] {$p_1$};
        \draw[thin,->] (0,-2) -- (0,2) node[anchor=east] {$p_2$};
        \draw[thick] (1,0) -- (0,1) -- (-1,0) -- (0,-1) -- cycle;
        \node at (2.0,1.4) {$E = c \thinspace |p_1| + c \thinspace |p_2|$};
    \end{scope}
    
    % Shift to the right for side-by-side placement
    \begin{scope}[shift={(5cm,0cm)}] % Adjust the shift values as needed
        \tdplotsetmaincoords{70}{120} % to set the 3D view
        \begin{scope}[tdplot_main_coords]
            \draw[thin,->] (-2,0,0) -- (2,0,0) node[anchor=south] {$p_1$};
            \draw[thin,->] (0,-2,0) -- (0,2,0) node[anchor=west] {$p_2$};
            \draw[thin,->] (0,0,-2) -- (0,0,2) node[anchor=south] {$p_3$};

            % Draw the positive part of the pyramid
            \draw[thick] (1,0,0) -- (0,1,0) -- (0,0,1) -- cycle; 
            % Draw the negative part of the pyramid
            \draw[thick] (-1,0,0) -- (0,-1,0) -- (0,0,-1) -- cycle;
            % Connect positive and negative parts
            \draw[thick] (1,0,0) -- (0,0,-1);
            \draw[thick] (0,1,0) -- (-1,0,0);
            \draw[thick] (0,0,1) -- (0,-1,0);

            \draw[thick] (-1,0,0) -- (0,0,1);
            \draw[thick] (0,-1,0) -- (1,0,0);
            \draw[thick] (0,0,-1) -- (0,1,0);
            
            \node at (-1.0,2.0,1.5) {$E = c \thinspace |p_1| + c \thinspace |p_2| + c \thinspace |p_3|$};
        \end{scope}
    \end{scope}
\end{tikzpicture}
#+end_src

In \(d\) dimensions, there are \(2^d\) quadrants. The momenta of the \(N\) particles are anywhere to be found on the surface of \(2^N\) hyperpyramids.  An equivalent interpretation for the \(2^{N}\) factor is that it accounts for the two possible signs for each \(p_{i}\). The volume and surface area of a hyper-pyramid defined by \(\sum_{i=1}^d x_i \leqslant r\), \(x_i \geqslant 0\), in \(d\) dimensions is \(r^d / d!\) and \(\sqrt{d} \thinspace r^{d-1} / (d-1)!\) respectively. The difference \(r^{d} \big(1 - d^{3/2} / r\big) / d!\) vanishes as \(d \to \infty\), so we may use either of the formulae for sufficiently large \(d\). Using the volume formula we get \(\Omega_{\vec{p}} \thinspace (E, L, N) = 2^{N} (E / c)^{N} / N!\).

*** 4.3.3
*Compute the entropy* \(S(E, L, N)\).

\begin{align*}
\Omega (E, L, N) = \frac{1}{N! (N-1)!} \left(\frac{2LE}{hc}\right)^N &\approx \frac{1}{N^{2N}} \left(\frac{2e^2 L E}{hc}\right)^N \\
&\Rightarrow S(E, L, N) = N K_B \ln \left(\frac{2 e^2 L E}{h c}\right). \tag{4.3.1}
\end{align*}

Apart from the definition of entropy \(S (E, L, N) \equiv K_B \Omega \thinspace (E, L, N)\), we have used \(\Omega (E, L, N) = h^{-N} \Omega_{q} (E, L, N) \cdot \Omega_{\vec{p}} \thinspace (E, L, N)\) and \(N! \approx N^N \exp (-N) \).
*** 4.3.4
*Calculate the one-dimensional pressure* \(P\). 
Using the relation \(P = T (\partial_{V} S)_{E, N}\), we get \(P = N K_{B} T / L\).
*** 4.3.5
*Obtain the heat capacities* \(C_L\) *and* \(C_P\).

   Using the relations  \(T^{-1} = (\partial_{E} S)_{N}\), \(C_{L} = (D_{T} E)_{N,L}\), and \(C_{P} = (D_{T} (E + PV))_{N,P}\) we get \(E = N K_{B} T\), \(C_{L} = N K_{B}\) and \(C_{P} = 2 N K_{B} \).
*** 4.3.6
*What is the probability* \( p\left(p_1\right) \) *of finding a particle with momentum* \( p_1 \)?

\begin{align*}
p\left(p_1\right) & =\Omega_p\left(E-c\left|p_1\right|, \thinspace N-1\right) / \thinspace \Omega_p(E, N) \\
& =\bigg[\frac{2^{N-1}}{(N-1) !} \cdot\bigg(\frac{E-c\left|p_1\right|}{c}\bigg)^{N-1}\bigg] \cdot\bigg[\frac{N !}{2^N} \cdot\bigg(\frac{c}{E}\bigg)^N\bigg] \\
& \approx \frac{c N}{2 E} \cdot\left(1-\frac{c\left|p_1\right|}{E}\right)^N \approx \frac{c N}{2 E} \cdot \exp \left(\frac{-c N\left|p_1\right|}{E}\right) \\
& =\frac{c}{2 K_B T} \exp \left(\frac{-c\left|p_1\right|}{K_B T}\right)
\end{align*}
The approximations are of the form \(N-1 \approx N \text { for } N \gg 1\) and as \(N \to \infty\), \(\big(1 +  x / N \big)^{N} \to \exp \thinspace (x)\).

* 5 Interacting particles
* 6 Quantum statistical mechanics
* 7 Ideal quantum gases
