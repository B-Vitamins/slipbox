:PROPERTIES:
:ID:       f075c4f0-69aa-4f72-8879-42180ea7a063
:END:
#+TITLE: Markov network
#+FILETAGS: :literature:prml:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org

*Markov networks*, also known as a [[id:a6b72a88-bab0-4c02-a8b2-1fd285a29de5][Markov random fields]] or [[id:5559c3da-2d3b-43e6-8b53-996c265ad38d][undirected graphical models]] are a type of [[id:4588e307-d9cd-4a69-9648-a6c8db14ed1a][probabilistic graphical models]] in which a [[id:f39a8683-abf8-4620-957d-b20795422d2d][probability distribution]] is represented by a [[id:e1fc9380-a936-4cf0-bc64-78119a1081da][graph]]. A Markov network has a set of [[id:a0fe774b-6d44-4807-ab68-023a7e867ed4][nodes]] and a set of [[id:ca49181e-4b87-4ec7-aab7-50aacceda405][edges]] each of which connects a pair of nodes. Unlike [[id:5665a889-6a84-4065-be33-f5186d348ea6][Bayesian networks]], the edges are /undirected/, that is they do not carry arrows.

* Conditional independence properties
See [[id:c6de868e-1284-4ce9-a2e7-31f71c25a270][conditional independence]] and [[id:971e6cb8-1177-4d9a-90d7-43d22c22fb61][D-separation]]. 
* Factorization properties
We now seek a factorization rule for undirected graphs that will correspond to the above conditional independence test. Again, this will involve expressing the joint distribution \(p(\mathbf{x})\) as a product of functions defined over sets of variables that are local to the graph. We therefore need to decide what is the appropriate notion of locality in this case. 

If we consider two nodes \(x_{i}\) and \(x_{j}\) that are not connected by a link, then these variables must be conditionally independent given all other nodes in the graph. This follows from the fact that there is no direct path between the two nodes, and all other paths pass through nodes that are observed, and hence those paths are blocked. This conditional independence property can be expressed as

\[
p(x_{i}, x_{j} \mid \mathbf{x}_{\backslash\{i, j\}})=p(x_{i} \mid \mathbf{x}_{\backslash\{i, j\}}) p(x_{j} \mid \mathbf{x}_{\backslash\{i, j\}})
\]

where \(\mathbf{x} \backslash\{i, j\}\) denotes the set \(\mathbf{x}\) of all variables with \(x_{i}\) and \(x_{j}\) removed. The factorization of the joint distribution must therefore be such that \(x_{i}\) and \(x_{j}\) do not appear in the same factor in order for the conditional independence property to hold for all possible distributions belonging to the graph.

Let us denote a [[id:5b83c54c-ad39-4f70-a41b-4e4334513d7f][clique]] by \(C\) and the set of variables in that clique by \(\mathbf{x}_{C}\). Then the joint distribution is written as a product of potential functions \(\psi_{C}\left(\mathbf{x}_{C}\right)\) over the [[id:66774f9d-b5bf-429c-9062-1abc9be7399d][maximal cliques]] of the graph

\[
p(\mathbf{x})=\frac{1}{Z} \prod_{C} \psi_{C}\left(\mathbf{x}_{C}\right) .
\]

Here the quantity \(Z\), sometimes called the partition function, is a normalization constant and is given by

\[
Z=\sum_{\mathbf{x}} \prod_{C} \psi_{C}\left(\mathbf{x}_{C}\right)
\]

which ensures that the distribution \(p(\mathbf{x})\) given by (8.39) is correctly normalized. By considering only potential functions which satisfy \(\psi_{C}\left(\mathbf{x}_{C}\right) \geqslant 0\) we ensure that \(p(\mathbf{x}) \geqslant 0\). In (8.40) we have assumed that \(\mathbf{x}\) comprises discrete variables, but the framework is equally applicable to continuous variables, or a combination of the two, in which the summation is replaced by the appropriate combination of summation and integration.

Note that we do not restrict the choice of potential functions to those that have a specific probabilistic interpretation as marginal or conditional distributions. This is in contrast to directed graphs in which each factor represents the conditional distribution of the corresponding variable, conditioned on the state of its parents. However, in special cases, for instance where the undirected graph is constructed by starting with a directed graph, the potential functions may indeed have such an interpretation, as we shall see shortly.

One consequence of the generality of the potential functions \(\psi_{C}\left(\mathbf{x}_{C}\right)\) is that their product will in general not be correctly normalized. We therefore have to introduce an explicit normalization factor given by (8.40). Recall that for directed graphs, the joint distribution was automatically normalized as a consequence of the normalization of each of the conditional distributions in the factorization.

*The presence of this normalization constant is one of the major limitations of undirected graphs.* If we have a model with \(M\) discrete nodes each having \(K\) states, then the evaluation of the normalization term involves summing over \(K^{M}\) states and so (in the worst case) is exponential in the size of the model. The partition function is needed for parameter learning because it will be a function of any parameters that govern the potential functions \(\psi_{C}\left(\mathbf{x}_{C}\right)\). However, for evaluation of local conditional distributions, the partition function is not needed because a conditional is the ratio of two marginals, and the partition function cancels between numerator and denominator when evaluating this ratio. Similarly, for evaluating local marginal probabilities we can work with the unnormalized joint distribution and then normalize the marginals explicitly at the end. Provided the marginals only involves a small number of variables, the evaluation of their normalization coefficient will be feasible.

So far, we have discussed the notion of conditional independence based on simple graph separation and we have proposed a factorization of the joint distribution that is intended to correspond to this conditional independence structure. However, we have not made any formal connection between conditional independence and factorization for undirected graphs. To do so we need to restrict attention to potential functions \(\psi_{C}\left(\mathbf{x}_{C}\right)\) that are strictly positive (i.e., never zero or negative for any choice of \(\mathbf{x}_{C}\) ). Given this restriction, we can make a precise relationship between factorization and conditional independence.

To do this we again return to the concept of a graphical model as a filter, corresponding to Figure 8.25. Consider the set of all possible distributions defined over a fixed set of variables corresponding to the nodes of a particular undirected graph. We can define \(\mathcal{U} \mathcal{I}\) to be the set of such distributions that are consistent with the set of conditional independence statements that can be read from the graph using graph separation. Similarly, we can define \(\mathcal{U F}\) to be the set of such distributions that can be expressed as a factorization of the form (8.39) with respect to the maximal cliques of the graph. The [[id:743df8cc-80d1-4dea-9fa6-37ff9eb45506][Hammersley-Clifford theorem]] states that the sets \(\mathcal{U} \mathcal{I}\) and \(\mathcal{U F}\) are identical.

Because we are restricted to potential functions which are strictly positive it is convenient to express them as exponential, so that

\[
\psi_{C}\left(\mathbf{x}_{C}\right)=\exp \left\{-E\left(\mathbf{x}_{C}\right)\right\}
\]

where \(E\left(\mathbf{x}_{C}\right)\) is called an energy function, and the exponential representation is called the Boltzmann distribution. The joint distribution is defined as the product of potentials, and so the total energy is obtained by adding the energies of each of the maximal cliques.

In contrast to the factors in the joint distribution for a directed graph, the potentials in an undirected graph do not have a specific probabilistic interpretation. Although this gives greater flexibility in choosing the potential functions, because there is no normalization constraint, it does raise the question of how to motivate a choice of potential function for a particular application. This can be done by viewing the potential function as expressing which configurations of the local variables are preferred to others. Global configurations that have a relatively high probability are those that find a good balance in satisfying the (possibly conflicting) influences of the clique potentials. We turn now to a specific example to illustrate the use of undirected graphs.
