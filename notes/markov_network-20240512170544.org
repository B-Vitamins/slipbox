:PROPERTIES:
:ID:       f075c4f0-69aa-4f72-8879-42180ea7a063
:END:
#+TITLE: Markov network
#+FILETAGS: :literature:prml:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org

*Markov networks*, also known as a [[id:a6b72a88-bab0-4c02-a8b2-1fd285a29de5][Markov random fields]] or [[id:5559c3da-2d3b-43e6-8b53-996c265ad38d][undirected graphical models]] are a type of [[id:4588e307-d9cd-4a69-9648-a6c8db14ed1a][probabilistic graphical models]] in which a [[id:f39a8683-abf8-4620-957d-b20795422d2d][probability distribution]] is represented by a [[id:e1fc9380-a936-4cf0-bc64-78119a1081da][graph]]. A Markov network has a set of [[id:a0fe774b-6d44-4807-ab68-023a7e867ed4][nodes]] and a set of [[id:ca49181e-4b87-4ec7-aab7-50aacceda405][edges]] each of which connects a pair of nodes. Unlike [[id:5665a889-6a84-4065-be33-f5186d348ea6][Bayesian networks]], the edges are /undirected/, that is they do not carry arrows.

* Conditional independence properties
See [[id:c6de868e-1284-4ce9-a2e7-31f71c25a270][conditional independence]] and [[id:971e6cb8-1177-4d9a-90d7-43d22c22fb61][D-separation]]. 
* Factorization properties
Let us denote a [[id:5b83c54c-ad39-4f70-a41b-4e4334513d7f][clique]] by \(C\) and the set of variables in that clique by \(\mathbf{x}_{C}\). Then the joint distribution is written as a product of [[id:90eb8a52-db71-475e-940b-2f133b926715][potential functions]] \(\psi_{C}\left(\mathbf{x}_{C}\right)\) over the cliques of the graph

\[
p(\mathbf{x})= Z^{-1} \prod_{C} \psi_{C}\left(\mathbf{x}_{C}\right), \qquad Z=\sum_{\mathbf{x}} \prod_{C} \psi_{C}\left(\mathbf{x}_{C}\right).
\]

Here the quantity \(Z\), sometimes called the [[id:ca1d61e0-c60f-42c3-8de7-8dd8557aa6f3][partition function]], is a normalization constant ensures \( \sum_{\mathbf{x}} p(\mathbf{x}) = 1 \). We must also ensure \(p(\mathbf{x}) \geqslant 0\): this is easily done by demanding \(\psi_{C}\left(\mathbf{x}_{C}\right) \geqslant 0\). When \( \mathbf{x} \) is continuous, the \( \sum \) is replaced with an \( \int \).

#+BEGIN_COMMENT
While the potential functions may lend themselves to interpretation as [[id:98cfed25-404f-4443-9096-e604ca5faccd][marginal]] or [[id:391465bc-1399-40f0-b049-738c1a64d6fb][conditional]] distributions (for instance when the undirected graph is constructed by starting with a directed graph), it need not be so in general. The only inviolable constraint on the potential functions is that they must respect the conditional independence properties of the Markov network which they do by construction (see [[id:90eb8a52-db71-475e-940b-2f133b926715][potential functions]]).

One consequence of this generality of the potential functions is that their product will in general not be correctly normalized: hence the partition function. Recall that for Bayesian networks, the joint distribution was automatically normalized as a consequence of the normalization of each of the conditional distributions in the factorization (see [[id:c8691cca-9591-4bd1-bdd1-4793e92f4365][normalization of Bayesian networks]]).
#+END_COMMENT

1) *The presence of this normalization constant is one of the major limitations of undirected graphs*: see [[id:b39465f1-fc0b-4207-8934-956b87d9139d][confronting the partition function]].

2) *The flexibility of potential functions in Markov networks comes with a challenge*: see [[id:e99d6be8-a617-48b5-accf-e1c9b32febd4][choice of potential functions (probabilistic graphical models)]].



In contrast to the factors in the joint distribution for a directed graph, the potentials in an undirected graph do not have a specific probabilistic interpretation. 
