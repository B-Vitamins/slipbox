:PROPERTIES:
:ID:       c233fe81-d1e4-4326-b280-b2253a0e3aa3
:END:
#+TITLE: Bayesian model comparison
#+FILETAGS: :literature:prml:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org

Suppose we wish to compare a set of \(L\) models \(\left\{\mathcal{M}_{i}\right\}\) where \(i=1, \ldots, L\). Here a model refers to a probability distribution over the observed data \(\mathcal{D}\). We shall suppose that the data is generated from one of these models but we are uncertain which one. Our uncertainty is expressed through a prior probability distribution \(p\left(\mathcal{M}_{i}\right)\). Given a training set \(\mathcal{D}\), we then wish to evaluate the posterior distribution

\begin{align*}
p\left(\mathcal{M}_{i} \mid \mathcal{D}\right) \propto p\left(\mathcal{M}_{i}\right) p\left(\mathcal{D} \mid \mathcal{M}_{i}\right) \tag{1}
\end{align*}

The prior allows us to express a preference for different models. Let us simply assume that all models are given equal prior probability. Once we know the posterior distribution over models, the predictive distribution is given, from the [[id:e9446808-4593-483e-b66e-adb9cb3db93a][rules of probability]] as

\begin{align*}
p(t \mid \mathbf{x}, \mathcal{D})=\sum_{i=1}^{L} p\left(t \mid \mathbf{x}, \mathcal{M}_{i}, \mathcal{D}\right) p\left(\mathcal{M}_{i} \mid \mathcal{D}\right) \tag{2}
\end{align*}

This is an example of a *mixture distribution* in which the overall predictive distribution is obtained by averaging the predictive distributions \(p\left(t \mid \mathbf{x}, \mathcal{M}_{i}, \mathcal{D}\right)\) of individual models, weighted by the posterior probabilities \(p\left(\mathcal{M}_{i} \mid \mathcal{D}\right)\) of those models. For instance, if we have two models that are a-posteriori equally likely and one predicts a narrow distribution around \(t=a\) while the other predicts a narrow distribution around \(t=b\), the overall predictive distribution will be a bimodal distribution with modes at \(t=a\) and \(t=b\), not a single mode at \(t=(a+b) / 2\).

A simple approximation to model averaging is to use the single most probable model alone to make predictions. This is known as [[id:fc08c0b0-19ee-4ee2-9e1e-b1066a5e6f1e][Model selection]].

The interesting term in (1) is the [[id:7a527c55-77eb-4287-b09e-5af08d301b39][model evidence]] \(p\left(\mathcal{D} \mid \mathcal{M}_{i}\right)\) which expresses the preference shown by the data for different models, and we shall examine this term in more detail shortly. The ratio of model evidences \(p\left(\mathcal{D} \mid \mathcal{M}_{i}\right) / p\left(\mathcal{D} \mid \mathcal{M}_{j}\right)\) for two models is known as a [[id:df9ebb0f-bedb-406d-8b2a-f2c2ac3bc0c0][Bayes factor]]. For a model governed by parameters \(\mathbf{w}\), the model evidence, derived from the sum and product rules of probability, is:

\[
p\left(\mathcal{D} \mid \mathcal{M}_{i}\right) = \int p\left(\mathcal{D} \mid \mathbf{w}, \mathcal{M}_{i}\right) p\left(\mathbf{w} \mid \mathcal{M}_{i}\right) \mathrm{d} \mathbf{w}
\]

From a sampling perspective, the marginal likelihood represents the probability of generating the dataset \(\mathcal{D}\) from a model with parameters sampled from the prior. The evidence is the normalizing term in [[id:731eff69-04dd-45f2-b2a7-968e9c44dc3e][Bayes's theorem]] for evaluating the posterior distribution over parameters:

\[
p\left(\mathbf{w} \mid \mathcal{D}, \mathcal{M}_{i}\right) = \frac{p\left(\mathcal{D} \mid \mathbf{w}, \mathcal{M}_{i}\right) p\left(\mathbf{w} \mid \mathcal{M}_{i}\right)}{p\left(\mathcal{D} \mid \mathcal{M}_{i}\right)}
\]

To approximate the integral for a model with a single parameter \(w\), consider a sharply peaked posterior distribution around \(w_{\text{MAP}}\) with width \(\Delta w_{\text{posterior}}\). Assuming a flat prior with width \(\Delta w_{\text{prior}}\), the prior is \(p(w) = 1 / \Delta w_{\text{prior}}\). The model evidence is approximated as:

\[
p(\mathcal{D}) \approx p\left(\mathcal{D} \mid w_{\text{MAP}}\right) \frac{\Delta w_{\text{posterior}}}{\Delta w_{\text{prior}}}
\]

#+ATTR_HTML: :width 400px
[[file:~/.local/images/prml-3-12.png]]
#+CAPTION: We can obtain a rough approximation to the model evidence if we assume that the posterior distribution over parameters is sharply peaked around its mode \(w_{\text {MAP }}\).

Taking the logarithm:

\[
\ln p(\mathcal{D}) \approx \ln p\left(\mathcal{D} \mid w_{\text{MAP}}\right) + \ln \left(\frac{\Delta w_{\text{posterior}}}{\Delta w_{\text{prior}}}\right)
\]

For a model with \(M\) parameters, assuming equal ratios for all parameters:

\[
\ln p(\mathcal{D}) \approx \ln p\left(\mathcal{D} \mid \mathbf{w}_{\text{MAP}}\right) + M \ln \left(\frac{\Delta w_{\text{posterior}}}{\Delta w_{\text{prior}}}\right)
\]

Here, the complexity penalty increases linearly with \(M\). Optimal model complexity balances the fit to the data and the complexity penalty. A refined Gaussian approximation to the posterior will be developed later.

Bayesian model comparison considers model evidence to favor models of intermediate complexity. Consider three models \(\mathcal{M}_{1}\), \(\mathcal{M}_{2}\), and \(\mathcal{M}_{3}\) of increasing complexity. The evidence for a particular dataset \(\mathcal{D}_0\) may be highest for the intermediate complexity model due to better balance between data fit and model simplicity.

#+ATTR_HTML: :width 400px
[[file:~/.local/images/prml-3-13.png]]
#+CAPTION: Schematic illustration of the distribution of data sets for three models of different complexity, in which \(\mathcal{M}_{1}\) is the simplest and \(\mathcal{M}_{3}\) is the most complex. Note that the distributions are normalized. In this example, for the particular observed data set \(\mathcal{D}_{0}\), the model \(\mathcal{M}_{2}\) with intermediate complexity has the largest evidence.

Bayesian model comparison, assuming the true distribution is within the model set, will on average favor the correct model. For two models \(\mathcal{M}_{1}\) and \(\mathcal{M}_{2}\) with the true model \(\mathcal{M}_{1}\), the expected Bayes factor is:

\[
\int p\left(\mathcal{D} \mid \mathcal{M}_{1}\right) \ln \frac{p\left(\mathcal{D} \mid \mathcal{M}_{1}\right)}{p\left(\mathcal{D} \mid \mathcal{M}_{2}\right)} \mathrm{d} \mathcal{D}
\]

This [[id:a72ac711-488c-4ab4-b483-9d3b5cc233fc][Kullback-Liebler divergence]] is positive unless the two distributions are equal, favoring the correct model on average.

The Bayesian framework avoids over-fitting but depends on assumptions about the model form. Model evidence is sensitive to prior aspects, especially tail behavior. Evidence is undefined for improper priors. However, the evidence ratio may yield a meaningful answer when taking limits of proper priors. In practice, an independent test set is recommended to evaluate overall performance.
