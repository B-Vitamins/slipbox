:PROPERTIES:
:ID:       93b460a0-85fc-447a-8063-cbe6a1604b2e
:END:
#+TITLE: Probability
#+FILETAGS: :literature:spop:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org

The laws of thermodynamics are based on observations of macroscopic bodies, and encapsulate their thermal properties. On the other hand, matter is composed of atoms and molecules whose motions are governed by more fundamental laws (classical or quantum mechanics). It should be possible, in principle, to derive the behavior of a macroscopic body from the knowledge of its components. This is the problem addressed by kinetic theory in the following chapter. Actually, describing the full dynamics of the enormous number of particles involved is quite a daunting task. As we shall demonstrate, for discussing equilibrium properties of a macroscopic system, full knowledge of the behavior of its constituent particles is not necessary. All that is required is the likelihood that the particles are in a particular microscopic state. Statistical mechanics is thus an inherently probabilistic description of the system, and familiarity with manipulations of probabilities is an important prerequisite. The purpose of this chapter is to review some important results in the theory of probability, and to introduce the notations that will be used in the following chapters.

The entity under investigation is a random variable \(x\), which has a set of possible outcomes \(\mathcal{S} \equiv\left\{x_{1}, x_{2}, \cdots\right\}\). The outcomes may be discrete as in the case of a coin toss, \(S_{\text {coin }}=\{\) head, tail \(\}\), or a dice throw, \(\mathcal{S}_{\text {dice }}=\{1,2,3,4,5,6\}\), or continuous as for the velocity of a particle in a gas, \(\mathcal{S}_{\vec{v}}=\left\{-\infty<v_{x}, v_{y}, v_{z}<\infty\right\}\), or the energy of an electron in a metal at zero temperature, \(\mathcal{S}_{\epsilon}=\left\{0 \leq \epsilon \leq \epsilon_{F}\right\}\). An event is any subset of outcomes \(E \subset \mathcal{S}\), and is assigned a probability \(p(E)\), for example, \(p_{\text {dice }}(\{1\})=1 / 6\), or \(p_{\text {dice }}(\{1,3\})=1 / 3\). From an axiomatic point of view, the probabilities must satisfy the following conditions:

1) Positivity. \(p(E) \geq 0\), that is, all probabilities must be real and non-negative.

2) Additivity. \(p(A\) or \(B)=p(A)+p(B)\), if \(A\) and \(B\) are disconnected events.

3) Normalization. \(p(\mathcal{S})=1\), that is, the random variable must have some outcome in \(\mathcal{S}\). From a practical point of view, we would like to know how to assign probability values to various outcomes. There are two possible approaches:

1. Objective probabilities are obtained experimentally from the relative frequency of the occurrence of an outcome in many tests of the random variable. If the random process is repeated \(N\) times, and the event \(A\) occurs \(N_{A}\) times, then

\[
p(A)=\lim _{N \rightarrow \infty} \frac{N_{A}}{N}
\]

For example, a series of \(N=100,200,300\) throws of a dice may result in \(N_{1}=19,30,48\) occurrences of 1 . The ratios \(0.19,0.15,0.16\) provide an increasingly more reliable estimate of the probability \(p_{\text {dice }}(\{1\})\).

2. Subjective probabilities provide a theoretical estimate based on the uncertainties related to lack of precise knowledge of outcomes. For example, the assessment \(p_{\text {dice }}(\{1\})=1 / 6\) is based on the knowledge that there are six possible outcomes to a dice throw, and that in the absence of any prior reason to believe that the dice is biased, all six are equally likely. All assignments of probability in statistical mechanics are subjectively based. The consequences of such subjective assignments of probability have to be checked against measurements, and they may need to be modified as more information about the outcomes becomes available.
