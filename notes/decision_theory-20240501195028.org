:PROPERTIES:
:ID:       869cf352-d95e-471d-a21a-c618a35c51dd
:END:
#+TITLE: Decision theory
#+FILETAGS: :literature:prml:
#+SETUPFILE: ~/.config/emacs/setup/setupfile.org

Suppose we have an input vector \(\mathbf{x}\) together with a corresponding vector \(\mathbf{t}\) of target variables, and our goal is to predict \(\mathbf{t}\) given a new value for \(\mathbf{x}\). For [[id:31f8fc5c-fdc7-4c1c-8288-3d4f1c8c0110][regression problems]], \(\mathbf{t}\) will comprise *continuous variables*, whereas for [[id:28d575a5-08f9-4f78-bb0b-b7fedcbb24d3][Classification problems]] \(\mathbf{t}\) will represent *class labels*.

The joint probability distribution \(p(\mathbf{x}, \mathbf{t})\) provides a complete summary of the uncertainty associated with these variables. Determination of \(p(\mathbf{x}, \mathbf{t})\) from a set of training data is the problem of [[id:ccd9c665-97bf-4274-b2b1-5a0ebc5409e2][density estimation]] an example of [[id:01b2eedd-71b0-428f-bc4b-146b7068af36][Statistical inference]]. In a practical application, however, we must often make a [[id:9fccdf3c-554a-45d9-b0b5-cb65c6db031b][point estimation]] for the value of \(\mathbf{t}\).

*Decision theory* is concerned with situations where the understanding of the likely values \(\mathbf{t}\) informs specific action. These actions aim at achieving a certain goal. The solution of this *decision problem* is a *decision rule* that assigns each value of \(\mathbf{x}\) to one of the available classes and in doing so achieves the stated goal. Such a rule will divide the input space into regions \(\mathcal{R}_{k}\) called [[id:a9eca4bd-9e7f-4cfa-8037-75c65972706b][decision regions]], one for each class, such that all points in \(\mathcal{R}_{k}\) are assigned to class \(\mathcal{C}_{k}\). The boundaries between decision regions are called [[id:61799020-5bb6-41c0-943b-7476700d1d15][decision boundaries/surfaces]].

One decision-making strategy is the [[id:a468994a-d366-48dc-9396-fdd9418dc60b][minimum misclassification rate decision rule]]. This is equivalent to selecting the class with the highest [[id:e166b400-40c8-410b-bb5b-0e0decca5f4c][posterior probability]] \( p(\mathbf{t} \mid \mathbf{x}) \). For an example, see [[id:19101ea0-b59c-47e7-8002-3bb75be3e6f7][decision problem of diagnosing cancer]].

Another decision-making strategy is the [[id:192b5010-9a9b-4c31-bbbd-546e969d9196][minimum expected loss decision rule]] where one selects a class label \( j \) of all the available, say \( K \), such that

\begin{align*}
\sum_{k} L_{k j} p\left(\mathcal{C}_{k} \mid \mathbf{x}\right)
\end{align*}

is minimized.