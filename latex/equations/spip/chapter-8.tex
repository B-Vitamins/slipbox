\documentclass{article}

% Document Layout and Fonts
\usepackage[margin=0.9in]{geometry}    % Page margins
\usepackage{fontspec}                  % For custom fonts (LuaLaTeX feature)
\usepackage{tgpagella}
\usepackage{mathpazo}
\setmainfont{EB Garamond}              % Main font (EB Garamond)
\usepackage{microtype}                 % Improves text appearance
\usepackage{titlesec}                  % Customize section title fonts

% Right-align section headings
\titleformat{\section}
  {\normalfont\large\scshape\raggedright}  % Right-align and small caps
  {}{0em}{}[]

% Right-align subsection headings and add a line below
\titleformat{\subsection}
  {\normalfont\normalsize\raggedleft}     % Right-align subsections
  {}{0em}{\titlerule[0.5pt]}              % Horizontal line below

% Right-align and italicize subsubsections
\titleformat{\subsubsection}
  {\normalfont\normalsize\itshape\raggedleft} % Right-align and italicize subsubsections
  {}{0em}{}[]

% Math and Science Packages
\usepackage{amsmath, amsfonts, amssymb, mathtools, amsthm, dsfont}

% Math commands and operators
\newcommand{\minus}{\scalebox{0.8}{\(-\)}}
\newcommand{\plus}{\scalebox{0.6}{\(+\)}}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\tr}{Tr}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}    % Differential d

% Custom headers for the document
\title{\LARGE\scshape\MakeUppercase{Chapter 8: Learning in perceptron}}
\author{\textit{Hidetoshi Nishimori}}
\date{}  % No date

% Start of the document
\begin{document}

\maketitle

\section{Learning and generalization error}

\subsection{Learning in perceptron}

No equations.

\subsection{Generalization error}

\begin{align*}
u &= \sum_{j=1}^{N} J_{j} \xi_{j}, \quad v = \sum_{j=1}^{N} B_{j} \xi_{j}
\tag{8.1}
\end{align*}

\begin{align*}
R &= \frac{1}{N} \sum_{j=1}^{N} B_{j} J_{j} \tag{8.2}
\end{align*}

\begin{align*}
P(u, v) &= \frac{1}{2 \pi \sqrt{1 - R^2}} \exp \left(-\frac{u^2 + v^2 - 2 R u v}{2 (1 - R^2)}\right) \tag{8.3}
\end{align*}

\begin{align*}
E &= \sum_{\mu=1}^{p} V(\boldsymbol{J}, \sigma_{\mu}, \boldsymbol{\xi}_{\mu}) \tag{8.4}
\end{align*}

\begin{align*}
E &= \sum_{\mu=1}^{p} \Theta\left(-\sigma_{\mu} u_{\mu}\right) = \sum_{\mu=1}^{p} \Theta\left(-u_{\mu} v_{\mu}\right) \tag{8.5}
\end{align*}

\begin{align*}
E(R) &\equiv \int \mathrm{d}u \, \mathrm{d}v \, P(u, v) \, \Theta(-uv) = \frac{1}{\pi} \cos^{-1} R \tag{8.6}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}}(\alpha) &= E(R(\alpha)) \tag{8.7}
\end{align*}

\clearpage

\section{Batch learning}

\subsection{Bayesian formulation}

\begin{align*}
P\left(\boldsymbol{J} \mid \sigma_{1}, \ldots, \sigma_{p}\right) &= \frac{P\left(\sigma_{1}, \ldots, \sigma_{p} \mid \boldsymbol{J}\right) P(\boldsymbol{J})}{Z} \tag{8.8}
\end{align*}

\begin{align*}
\sigma = \begin{cases}
\operatorname{sgn}(v) & \text{prob.} \left(1 + e^{-\beta}\right)^{-1} \\
-\operatorname{sgn}(v) & \text{prob.} \left(1 + e^{\beta}\right)^{-1}
\end{cases} \tag{8.9}
\end{align*}

\begin{align*}
P\left(\sigma_{\mu} \mid \boldsymbol{B}\right)=\frac{\Theta\left(\sigma_{\mu} v_{\mu}\right)}{1+\mathrm{e}^{-\beta}}+\frac{\Theta\left(-\sigma_{\mu} v_{\mu}\right)}{1+\mathrm{e}^{\beta}}=\frac{\exp \left\{-\beta \Theta\left(-\sigma_{\mu} v_{\mu}\right)\right\}}{1+\mathrm{e}^{-\beta}}
\tag{8.10}
\end{align*}

\begin{align*}
P\left(\sigma_{1}, \ldots, \sigma_{p} \mid \boldsymbol{B}\right)=\prod_{\mu=1}^{p} P\left(\sigma_{\mu} \mid \boldsymbol{B}\right)=\left(1+\mathrm{e}^{-\beta}\right)^{-p} \exp \left\{-\beta \sum_{\mu=1}^{p} \Theta\left(-\sigma_{\mu} v_{\mu}\right)\right\}
\tag{8.11}
\end{align*}

\begin{align*}
P\left(\boldsymbol{J} \mid \sigma_{1}, \ldots, \sigma_{p}\right) &= \frac{\exp \left\{-\beta \sum_{\mu=1}^{p} \Theta\left(-\sigma_{\mu} u_{\mu}\right)\right\} P(\boldsymbol{J})}{Z} \tag{8.12}
\end{align*}

\begin{align*}
E &= \sum_{\mu=1}^{p} \Theta\left(-\sigma_{\mu} u_{\mu}\right) \tag{8.13}
\end{align*}

\subsection{Learning algorithms}

\begin{align*}
\sigma &= \operatorname{sgn}\left(V^{+} - V^{-}\right) \tag{8.14}
\end{align*}

\begin{align*}
V^{\pm} &= \int \mathrm{d} \boldsymbol{J} \, \Theta\left( \pm \boldsymbol{J} \cdot \boldsymbol{\xi}\right) P\left(\boldsymbol{J} \mid \sigma_{1}, \ldots, \sigma_{p}\right) \tag{8.15}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{0.44}{\alpha} \tag{8.16}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{0.625}{\alpha} \tag{8.17}
\end{align*}

\begin{align*}
E &= \sum_{\mu=1}^{p} V\left(\sigma_{\mu} u_{\mu}\right) \tag{8.18}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{0.40}{\sqrt{\alpha}} \tag{8.19}
\end{align*}

\begin{align*}
V(x) &= \begin{cases}
\infty & x < \kappa \\
0 & x \geq \kappa
\end{cases} \tag{8.20}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{0.50}{\alpha} \tag{8.21}
\end{align*}

\begin{align*}
Z &= \int \mathrm{d} \boldsymbol{J} P(\boldsymbol{J})\left(1 - \beta \sum_{\mu} \Theta\left(-\sigma_{\mu} u_{\mu}\right)\right) + \mathcal{O}\left(\beta^{2}\right) = \int \mathrm{d} R Z(R) + \mathcal{O}\left(\beta^{2}\right) \tag{8.22}
\end{align*}

\begin{align*}
Z(R) &= V_{R}\left(1 - \frac{\beta \int_{R} \mathrm{d} \boldsymbol{J} P(\boldsymbol{J}) \sum_{\mu} \Theta\left(-\sigma_{\mu} u_{\mu}\right)}{V_{R}}\right), \quad V_{R} = \int_{R} \mathrm{d} \boldsymbol{J} P(\boldsymbol{J}) \tag{8.23}
\end{align*}

\begin{align*}
\beta F(R) &= -[\log Z(R)] = -\log V_{R} + \beta p E(R) \tag{8.24}
\end{align*}

\begin{align*}
V_{R} &\propto \sin^{N-2} \theta = \left(1 - R^{2}\right)^{(N-2)/2} \tag{8.25}
\end{align*}

\begin{align*}
\beta f(R) &= \frac{\tilde{\alpha}}{\pi} \cos^{-1} R - \frac{1}{2} \log \left(1 - R^{2}\right) \tag{8.26}
\end{align*}

\begin{align*}
\frac{R}{\sqrt{1 - R^{2}}} &= \frac{\tilde{\alpha}}{\pi} \tag{8.27}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &= \frac{1}{\pi} \cos^{-1} \frac{\tilde{\alpha}}{\sqrt{\pi^{2} + \tilde{\alpha}^{2}}} \approx \frac{1}{\tilde{\alpha}} \tag{8.28}
\end{align*}

\subsection{Gibbs algorithm}
\begin{align*}
V &= \frac{1}{Z} \int \mathrm{d} \boldsymbol{J} \delta\left(\sum_{j} J_{j}^{2} - N\right) \exp\left(-\beta E\right) \tag{8.29}
\end{align*}

\begin{align*}
{\left[V^{n}\right]} &= \int \prod_{\alpha} \mathrm{d} R_{\alpha} \int \prod_{(\alpha \beta)} \mathrm{d} q_{\alpha \beta} \int \prod_{\alpha, j} \mathrm{~d} J_{j}^{\alpha} \cdot \prod_{\alpha} \delta\left(\sum_{j}\left(J_{j}^{\alpha}\right)^{2}-N\right) \\ 
&\cdot  \prod_{\alpha} \delta\left(\sum_{j} B_{j} J_{j}^{\alpha}-N R^{\alpha}\right) \prod_{(\alpha \beta)} \delta\left(\sum_{j} J_{j}^{\alpha} J_{j}^{\beta}-N q_{\alpha \beta}\right) \cdot \prod_{\alpha, \mu}\left\{\mathrm{e}^{-\beta} + \left(1-\mathrm{e}^{-\beta}\right) \Theta\left(u_{\mu}^{\alpha} v_{\mu}\right)\right\} \tag{8.30}
\end{align*}

\subsection{Replica calculations}
\begin{align*}
I_{1}^{N} &= \int \prod_{\alpha, j} \mathrm{~d} J_{j}^{\alpha} \exp \left[\mathrm{i} \left\{E \sum_{\alpha, j}\left(J_{j}^{\alpha}\right)^{2} + F \sum_{(\alpha \beta), j} J_{j}^{\alpha} J_{j}^{\beta} + G \sum_{\alpha, j} J_{j}^{\alpha} B_{j} - N \left( n E + \frac{n(n-1)}{2} q F + n R G \right)\right\}\right] \tag{8.31}
\end{align*}

\begin{align*}
g_{1}(E, F, G) &= -\frac{1}{2} \log \left(E - \frac{F}{2}\right) - \frac{F}{4 E - 2 F} - \frac{\mathrm{i} G^{2}}{4 E - 2 F} - \mathrm{i} E - \mathrm{i} G R + \mathrm{i} \frac{q F}{2} \tag{8.33}
\end{align*}

\begin{align*}
2 E-F=\frac{\mathrm{i}}{1-q}, \frac{F+\mathrm{i} G^{2}}{-2 E+F}=\frac{q}{1-q}, \mathrm{i} G=\frac{R}{1-q}
\tag{8.34}
\end{align*}

\begin{align*}
g_{1} &= \frac{1}{2} \log(1 - q) + \frac{1 - R^{2}}{2(1 - q)}
\tag{8.35}
\end{align*}

\begin{align*}
\left(I_{2}^{N}\right)^{1 / p}=\left[2 \Theta(v) \prod_{\alpha}\left\{\mathrm{e}^{-\beta}+\left(1-\mathrm{e}^{-\beta}\right) \Theta\left(u^{\alpha}\right)\right\}\right]
\tag{8.36}
\end{align*}

\begin{align*}
\left[u^{\alpha} u^{\beta}\right]=(1-q) \delta_{\alpha, \beta}+q, \quad\left[v u^{\alpha}\right]=R, \quad\left[v^{2}\right]=1
\tag{8.37}
\end{align*}

\begin{align*}
v=\sqrt{1-\frac{R^{2}}{q}} z^{0}+\frac{R}{\sqrt{q}} t, u^{\alpha}=\sqrt{1-q} z^{\alpha}+\sqrt{q} t(\alpha=1, \ldots, n)
\tag{8.38}
\end{align*}

\begin{align*}
\left(I_{2}^{N}\right)^{1 / p} &= 2 \int \mathrm{D} t \int \mathrm{D} z^{0} \Theta\left(\sqrt{1-\frac{R^{2}}{q}} z^{0}+\frac{R}{\sqrt{q}} t\right) \cdot \prod_{\alpha=1}^{n} \int \mathrm{D} z^{\alpha}\left\{\mathrm{e}^{-\beta}+\left(1-\mathrm{e}^{-\beta}\right) \Theta\left(\sqrt{1-q} z^{\alpha}+\sqrt{q} t\right)\right\} \\
& = 2 \int \mathrm{D} t \int_{-R t / \sqrt{q - R^{2}}}^{\infty} \mathrm{D} z^{0} \left\{\int \mathrm{D} z\left[\mathrm{e}^{-\beta} + \left(1-\mathrm{e}^{-\beta}\right) \Theta\left(\sqrt{1-q} z + \sqrt{q} t\right)\right]\right\}^{n} \tag{8.39}
\end{align*}

\begin{align*}
f \equiv & \lim _{n \rightarrow 0} \frac{1}{n N} \log \left[V^{n}\right] \\
&\qquad =2 \alpha \int \mathrm{D} t \int_{-R t / \sqrt{q-R^{2}}}^{\infty} \mathrm{D} z^{0} \log \left\{\mathrm{e}^{-\beta} + \left(1-\mathrm{e}^{-\beta}\right) \int_{-\sqrt{q /(1-q) t}}^{\infty} \mathrm{D} z\right\}+\frac{1}{2} \log (1-q)+\frac{1-R^{2}}{2(1-q)}
\tag{8.40}
\end{align*}

\subsection{Generalization error at \(T=0\)}

\begin{align*}
u=\frac{R}{\sqrt{q}} z^{0}-\sqrt{\frac{q-R^{2}}{q}} t, v=\sqrt{\frac{q-R^{2}}{q}} z^{0}+\frac{R}{\sqrt{q}} t
\tag{8.41}
\end{align*}

\begin{align*}
f=2 \alpha \int_{0}^{\infty} \mathrm{D} v \int_{-\infty}^{\infty} \mathrm{D} u \log \int_{w}^{\infty} \mathrm{D} z+\frac{1}{2} \log (1-q)+\frac{1-R^{2}}{2(1-q)}
\tag{8.42}
\end{align*}

\begin{align*}
w &= \frac{\sqrt{q - R^{2}} u - R v}{\sqrt{1 - q}} \tag{8.43}
\end{align*}

\begin{align*}
\alpha \sqrt{\frac{2}{\pi}} \int_{0}^{\infty} \mathrm{D} v \int_{-\infty}^{\infty} \mathrm{D} u \frac{u \mathrm{e}^{-w^{2} / 2}}{\int_{w}^{\infty} \mathrm{D} z}=\frac{q-2 R^{2}}{1-2 q} \sqrt{\frac{q-R^{2}}{1-q}}
\tag{8.44}
\end{align*}

\begin{align*}
\alpha \sqrt{\frac{2}{\pi}} \int_{0}^{\infty} \mathrm{D} v \int_{-\infty}^{\infty} \mathrm{D} u \frac{v \mathrm{e}^{-w^{2} / 2}}{\int_{w}^{\infty} \mathrm{D} z}=\frac{1-3 q+2 R^{2}}{(1-2 q) \sqrt{1-q}}
\tag{8.45}
\end{align*}

\begin{align*}
\frac{\alpha}{\pi} \int_{-\infty}^{\infty} \mathrm{D} x \frac{\mathrm{e}^{-q x^{2} / 2}}{\int_{\sqrt{q} x}^{\infty} \mathrm{D} z}=\frac{q}{\sqrt{1-q}} \tag{8.46}
\end{align*}

\begin{align*}
\epsilon \approx \frac{\pi^{2}}{c^{2} \alpha^{2}}, \quad c=\int_{-\infty}^{\infty} \mathrm{D} x \frac{\mathrm{e}^{-x^{2} / 2}}{\int_{x}^{\infty} \mathrm{D} z} \tag{8.47}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{\sqrt{2}}{c \alpha} = \frac{0.625}{\alpha}
\tag{8.48}
\end{align*}

\subsection{Noise and unlearnable rules}

No equations.

\clearpage

\section{On-line learning}

\subsection{Learning algorithms}

\begin{align*}
\boldsymbol{J}^{m+1}=\boldsymbol{J}^{m}+\Theta(-\operatorname{sgn}(u) \operatorname{sgn}(v)) \operatorname{sgn}(v) \boldsymbol{x}=\boldsymbol{J}^{m}+\Theta(-u v) \operatorname{sgn}(v) \boldsymbol{x} \tag{8.49}
\end{align*}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} + \operatorname{sgn}(v) \boldsymbol{x} \tag{8.50}
\end{align*}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} - u \Theta(-u v) \boldsymbol{x} \tag{8.51}
\end{align*}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} + f(\operatorname{sgn}(v), u) \boldsymbol{x} \tag{8.52}
\end{align*}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} - \eta_{m} \frac{\partial V\left(\sigma \boldsymbol{x} \cdot \boldsymbol{J}^{m}\right)}{\partial \boldsymbol{J}^{m}} \tag{8.53}
\end{align*}

\subsection{Dynamics of learning}

\begin{align*}
N\left\{\left(l^{m+1}\right)^{2} - \left(l^{m}\right)^{2}\right\} &= 2 \left[f u_{m}\right] l^{m} + \left[f^{2}\right] \tag{8.54}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t} &= [f u] + \frac{\left[f^{2}\right]}{2 l} \tag{8.55}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &= \frac{[f v] - [f u] R}{l} - \frac{R}{2 l^{2}} \left[f^{2}\right] \tag{8.56}
\end{align*}

\subsection{Generalization errors for specific algorithms}

\begin{align*}
f &= \Theta(-u v) \operatorname{sgn}(v) \tag{8.57}
\end{align*}

\begin{align*}
[f u]=-[f v]=\int \mathrm{d} u \mathrm{~d} v P(u, v) \Theta(-u v) u \operatorname{sgn}(v)=\frac{R-1}{\sqrt{2 \pi}}
\tag{8.58}
\end{align*}

\begin{align*}
\left[f^{2}\right]=\int \mathrm{d} u \mathrm{~d} v P(u, v) \Theta(-u v)=E(R)=\frac{1}{\pi} \cos ^{-1} R
\tag{8.59}
\end{align*}

\begin{align*}
\frac{\mathrm{d} \delta}{\mathrm{d} t} = -\frac{\sqrt{2 \epsilon}}{2 \pi} \delta^{3} + \frac{\epsilon \delta^{2}}{\sqrt{2 \pi}}, \qquad \frac{\mathrm{d} \epsilon}{\mathrm{d} t} &= \frac{\sqrt{2 \epsilon}}{2 \pi} \delta^{2} - \sqrt{\frac{2}{\pi}} \epsilon \delta
\tag{8.60}
\end{align*}

\begin{align*}
\epsilon &= \left(\frac{1}{3 \sqrt{2}}\right)^{2/3} t^{-2/3}, \quad \delta = \frac{2 \sqrt{\pi}}{(3 \sqrt{2})^{1/3}} t^{-1/3} \tag{8.61}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}}=E(R) \approx \frac{\sqrt{2}}{\pi(3 \sqrt{2})^{1 / 3}} t^{-1 / 3}=0.28 t^{-1 / 3} 
\tag{8.62}
\end{align*}

\begin{align*}
f(\operatorname{sgn}(v), u) &= \operatorname{sgn}(v) \tag{8.63}
\end{align*}

\begin{align*}
[f u] &= \frac{2 R}{\sqrt{2 \pi}}, \quad [f v] = \sqrt{\frac{2}{\pi}}, \quad [f^{2}] = 1 \tag{8.64}
\end{align*}

\begin{align*}
\frac{\mathrm{d} \delta}{\mathrm{d} t} &= -\sqrt{\frac{2}{\pi}} \delta^{2}, \quad \frac{\mathrm{d} \epsilon}{\mathrm{d} t} = \frac{\delta^{2}}{2} - \frac{4}{\sqrt{2 \pi}} \epsilon \delta \tag{8.65}
\end{align*}

\begin{align*}
\epsilon &= \frac{\pi}{4 t}, \quad \delta = \sqrt{\frac{\pi}{2}} \frac{1}{t} \tag{8.66}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} \approx \frac{1}{\sqrt{2 \pi}} t^{-1 / 2}=0.40 t^{-1 / 2}
\tag{8.67}
\end{align*}

\begin{align*}
f(\operatorname{sgn}(v), u) &= -u \Theta(-u v) \tag{8.68}
\end{align*}

\begin{align*}
[f u] &= -\sqrt{2} \int_{0}^{\infty} \mathrm{D} u u^{2} \operatorname{Erfc}\left(\frac{R u}{\sqrt{2(1 - R^{2})}}\right), \quad [f v] = \frac{(1 - R)^{3/2}}{\pi} + R [f u] \tag{8.69}
\end{align*}

\begin{align*}
[f u] \approx-\frac{4(2 \epsilon)^{3 / 2}}{\pi} \int_{0}^{\infty} y^{2} \mathrm{~d} y \operatorname{Erfc}(y)=-c \epsilon^{3 / 2},[f v]=\left(-c+\frac{2 \sqrt{2}}{\pi}\right) \epsilon^{3 / 2}
\tag{8.70}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t}=\left(-1+\frac{1}{2 l}\right) c \epsilon^{3 / 2}
\tag{8.71}
\end{align*}

\begin{align*}
\frac{\mathrm{d} \epsilon}{\mathrm{d} t} &= 2\left(c - \frac{2 \sqrt{2}}{\pi}\right) \epsilon^{3/2} \tag{8.72}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} \approx \frac{2 \sqrt{2}}{\pi k} \cdot \frac{1}{t}=\frac{3}{2 t}
\tag{8.73}
\end{align*}

\subsection{Optimization of learning rate}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} + \eta_{m} f(\operatorname{sgn}(v), u) \boldsymbol{x} \tag{8.74}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t} &= \frac{\eta(R - 1)}{\sqrt{2 \pi}} + \frac{\eta^{2} \cos^{-1} R}{2 \pi l} \tag{8.75}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &= -\frac{\eta(R^{2} - 1)}{\sqrt{2 \pi} l} - \frac{\eta^{2} R \cos^{-1} R}{2 \pi l^{2}} \tag{8.76}
\end{align*}

\begin{align*}
\eta &= -\frac{\sqrt{2 \pi} l(R^{2} - 1)}{2 R \cos^{-1} R} \tag{8.77}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t} &= -\frac{l(R - 1)^{3}(R + 1)}{4 R^{2} \cos^{-1} R} \tag{8.78}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &= \frac{(R^{2} - 1)^{2}}{4 R \cos^{-1} R}
\tag{8.79}
\end{align*}

\begin{align*}
l &= \frac{c R}{(R + 1)^{2}}
\tag{8.80}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &= \frac{\cos^{-1} R}{\pi} \approx \frac{4}{\pi t}
\tag{8.81}
\end{align*}

\subsection{Adaptive learning rate for smooth cost function}

\begin{align*}
E(\boldsymbol{J}) &= [V(\boldsymbol{x}, \boldsymbol{\sigma}; \boldsymbol{J})]
\tag{8.82}
\end{align*}

\begin{align*}
E(\boldsymbol{J}) &= E(\boldsymbol{B}) + \frac{1}{2} (\boldsymbol{J} - \boldsymbol{B})^{\top} K(\boldsymbol{B})(\boldsymbol{J} - \boldsymbol{B})
\tag{8.83}
\end{align*}

\begin{align*}
\boldsymbol{J}^{m+1} &= \boldsymbol{J}^{m} - \eta_{m} K^{-1}(\boldsymbol{J}) \frac{\partial V(\boldsymbol{x}, \boldsymbol{\sigma}; \boldsymbol{J})}{\partial \boldsymbol{J}}
\tag{8.84}
\end{align*}

\begin{align*}
\eta_{m+1} &= \eta_{m} + a \left\{b \left(V(\boldsymbol{x}, \boldsymbol{\sigma}; \boldsymbol{J}) - E_{t}\right) - \eta_{m}\right\}
\tag{8.85}
\end{align*}

\begin{align*}
\frac{\mathrm{d} \boldsymbol{J}}{\mathrm{d} t} = -\eta K^{-1}(\boldsymbol{J}) \left[\frac{\partial V}{\partial \boldsymbol{J}}\right], \qquad \frac{\mathrm{d} \eta}{\mathrm{d} t} &= a \eta \left\{b([V] - E_{\mathrm{t}}) - \eta\right\}
\tag{8.86}
\end{align*}

\begin{align*}
\left[\frac{\partial V}{\partial \boldsymbol{J}}\right] \approx K(\boldsymbol{B})(\boldsymbol{J}-\boldsymbol{B}),
\qquad
[V]-E_{\mathrm{t}} \approx E(\boldsymbol{B})-E_{\mathrm{t}}+\frac{1}{2}^{t}(\boldsymbol{J}-\boldsymbol{B}) K(\boldsymbol{B})(\boldsymbol{J}-\boldsymbol{B})
\tag{8.87}
\end{align*}

Then the dynamical equations reduce to

\begin{align*}
\frac{\mathrm{d} \boldsymbol{J}}{\mathrm{d} t} =-\eta(\boldsymbol{J}-\boldsymbol{B}),
\qquad
\frac{\mathrm{d} \eta}{\mathrm{d} t} =a \eta\left\{\frac{b}{2}(\boldsymbol{J}-\boldsymbol{B}) K(\boldsymbol{B})(\boldsymbol{J}-\boldsymbol{B})-\eta\right\}
\tag{8.88}
\end{align*}

These equations can be rewritten in terms of the energy as

\begin{align*}
\frac{\mathrm{d} E(\boldsymbol{J})}{\mathrm{d} t}=-2 \eta\{E(\boldsymbol{J})-E(\boldsymbol{B})\},
\qquad
\frac{\mathrm{d} \eta}{\mathrm{d} t}=a b \eta\{E(\boldsymbol{J})-E(\boldsymbol{B})\}-a \eta^{2}
\tag{8.89}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &= E(\boldsymbol{J}) = E(\boldsymbol{B}) + \frac{1}{b} \left(\frac{1}{2} - \frac{1}{a}\right) \frac{1}{t} \tag{8.90}
\end{align*}

\begin{align*}
\eta &= \frac{1}{2t} \tag{8.91}
\end{align*}

\subsection{Learning with query}

\begin{align*}
P(u, v) &= \frac{\delta(u)}{\sqrt{2 \pi(1 - R^{2})}} \exp\left(-\frac{u^{2} + v^{2} - 2 R u v}{2(1 - R^{2})}\right) \tag{8.92}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t} &= \frac{1}{2 l} \tag{8.93}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &= \frac{1}{l} \sqrt{\frac{2(1 - R^{2})}{\pi}} - \frac{R}{2 l^{2}} \tag{8.94}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{1}{2 \sqrt{2 \pi} \sqrt{t}} \tag{8.95}
\end{align*}

\begin{align*}
\eta &= \frac{1}{R} \sqrt{\frac{2(1 - R^{2})}{\pi}} \tag{8.96}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{c}{\pi} \mathrm{e}^{-\alpha / \pi} \tag{8.97}
\end{align*}

\subsection{On-line learning of unlearnable rule}

\begin{align*}
\epsilon_{\mathrm{g}} &= E(R) \equiv \int \mathrm{d} u \mathrm{~d} v P(u, v) \Theta\left(-T_{a}(v) \operatorname{sgn}(u)\right) = 2 \int_{-\infty}^{0} \mathrm{D} t \Omega(R, t) \tag{8.98}
\end{align*}

\begin{align*}
\Omega(R, t) &= \int \mathrm{D} z \left\{\Theta\left(-z \sqrt{1 - R^{2}} - R t - a\right) + \Theta\left(z \sqrt{1 - R^{2}} + R t\right) - \Theta\left(z \sqrt{1 - R^{2}} + R t - a\right)\right\} \tag{8.99}
\end{align*}

\begin{align*}
[f u] &= \sqrt{\frac{2}{\pi}} R \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right), \quad [f v] = \sqrt{\frac{2}{\pi}} \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right), \quad \left[f^{2}\right] = 1 \tag{8.100}
\end{align*}

\begin{align*}
\frac{\mathrm{d} l}{\mathrm{~d} t} &= \frac{1}{2 l} + \sqrt{\frac{2}{\pi}} R \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right) \tag{8.101}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &= -\frac{R}{2 l^{2}} + \frac{1}{l} \sqrt{\frac{2}{\pi}} \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right) \left(1 - R^{2}\right) \tag{8.102}
\end{align*}

\begin{align*}
\frac{\mathrm{d} R}{\mathrm{~d} t} &\approx \frac{1}{l} \sqrt{\frac{2}{\pi}} \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right) \tag{8.103}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} \approx \frac{\sqrt{2 \epsilon}}{\pi}+\frac{2}{\sqrt{\pi}} \operatorname{Erfc}\left(\frac{a}{\sqrt{2}}\right) =\frac{1}{\sqrt{2 \pi}\left(1-2 \mathrm{e}^{-a^{2} / 2}\right)} \frac{1}{\sqrt{t}}+\frac{2}{\sqrt{\pi}} \operatorname{Erfc}\left(\frac{a}{\sqrt{2}}\right)
\tag{8.104}
\end{align*}

\begin{align*}
\epsilon_{\mathrm{g}} &\approx \frac{1}{\sqrt{6 \pi} \left(1 - 2 \mathrm{e}^{-a^{2}/2}\right)} \frac{1}{\sqrt{t}} + 1 - \frac{2}{\sqrt{\pi}} \operatorname{Erfc}\left(\frac{a}{\sqrt{2}}\right) \tag{8.105}
\end{align*}

\end{document}
