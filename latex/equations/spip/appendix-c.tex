\documentclass{article}

% Document Layout and Fonts
\usepackage[margin=0.9in]{geometry}    % Page margins
\usepackage{fontspec}                  % For custom fonts (LuaLaTeX feature)
\usepackage{tgpagella}
\usepackage{mathpazo}
\setmainfont{EB Garamond}              % Main font (EB Garamond)
\usepackage{microtype}                 % Improves text appearance
\usepackage{titlesec}                  % Customize section title fonts

% Right-align section headings
\titleformat{\section}
  {\normalfont\large\scshape\raggedright}  % Right-align and small caps
  {}{0em}{}[]

% Right-align subsection headings and add a line below
\titleformat{\subsection}
  {\normalfont\normalsize\raggedleft}     % Right-align subsections
  {}{0em}{\titlerule[0.5pt]}              % Horizontal line below

% Right-align and italicize subsubsections
\titleformat{\subsubsection}
  {\normalfont\normalsize\itshape\raggedleft} % Right-align and italicize subsubsections
  {}{0em}{}[]

% Math and Science Packages
\usepackage{amsmath, amsfonts, amssymb, mathtools, amsthm, dsfont}

% Math commands and operators
\newcommand{\minus}{\scalebox{0.8}{\(-\)}}
\newcommand{\plus}{\scalebox{0.6}{\(+\)}}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\tr}{Tr}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}    % Differential d

% Definitions, theorems, corollaries, and friends
\usepackage[english]{babel}
\usepackage[hidelinks]{hyperref}
\newtheorem{axiom}{Axiom}
\newtheorem{postulate}{Postulate}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem*{remark}{Remark}

\title{\LARGE\scshape\MakeUppercase{Appendix C: Channel Coding Theorem}}
\author{\textit{Hidetoshi Nishimori}}
\date{}

\begin{document}

\maketitle

\section{Information, uncertainty, and entropy}
\begin{align*}
H(U) = -\sum_{i=1}^{L} p_{i} \log_2 p_{i} \quad [\text{bit/symbol}] 
\tag{C.1}
\end{align*}

\begin{align*}
H_2(p) = -p \log_2 p - (1 - p) \log_2 (1 - p) 
\tag{C.2}
\end{align*}

\section{Channel capacity}
\begin{align*}
H(X \mid Y = y) = -\sum_{x} P(x \mid y) \log_2 P(x \mid y) 
\tag{C.3}
\end{align*}

\begin{align*}
H(X \mid Y) &= \sum_{y} P(y) H(X \mid y) = -\sum_{y} P(y) \sum_{x} P(x \mid y) \log_2 P(x \mid y) = -\sum_{x} \sum_{y} P(x, y) \log_2 P(x \mid y) 
\tag{C.4}
\end{align*}

\begin{align*}
H(Y \mid X) = -\sum_{x} \sum_{y} P(x, y) \log_2 P(y \mid x) 
\tag{C.5}
\end{align*}

\begin{align*}
H(X, Y) = -\sum_{x} \sum_{y} P(x, y) \log_2 P(x, y) 
\tag{C.6}
\end{align*}

\begin{align*}
H(X, Y) = H(Y) + H(X \mid Y) = H(X) + H(Y \mid X) 
\tag{C.7}
\end{align*}

\begin{align*}
I(X, Y) = H(X) - H(X \mid Y) 
\tag{C.8}
\end{align*}

\begin{align*}
I(X, Y) = H(Y) - H(Y \mid X) 
\tag{C.9}
\end{align*}

\begin{align*}
C = \max_{\{\text{input prob}\}} I(X, Y) 
\tag{C.10}
\end{align*}

\begin{align*}
H(X) = -\int P(x) \log_2 P(x) \, \mathrm{d} x 
\tag{C.11}
\end{align*}

\begin{align*}
H(Y \mid X) = -\int P(x, y) \log_2 P(y \mid x) \, \mathrm{d} x \, \mathrm{d} y 
\tag{C.12}
\end{align*}

\begin{align*}
I(X, Y) = H(X) - H(X \mid Y) = H(Y) - H(Y \mid X) 
\tag{C.13}
\end{align*}

\begin{align*}
C = \max_{\{\text{input prob}\}} I(X, Y) 
\tag{C.14}
\end{align*}

\section{BSC and Gaussian channel}

\begin{align*}
P(x = 0) = r, \quad P(x = 1) = 1 - r 
\tag{C.15}
\end{align*}

\begin{align*}
P(y=0 \mid x=0)=P(y=1 \mid x=1)=1-p, \qquad P(y=1 \mid x=0)=P(y=0 \mid x=1)=p
\tag{C.16}
\end{align*}

\begin{align*}
P(y = 0) = r(1 - p) + (1 - r)p = r + p - 2rp, \quad P(y = 1) = 1 - P(y = 0) 
\tag{C.17}
\end{align*}

\begin{align*}
& H(Y) = -(r + p - 2rp) \log_2(r + p - 2rp) -(1 - r - p + 2rp) \log_2(1 - r - p + 2rp) \\
& H(Y \mid X) = -p \log_2 p - (1 - p) \log_2(1 - p) = H_2(p) \\
& I(X, Y) = H(Y) - H(Y \mid X)
\tag{C.18}
\end{align*}

\begin{align*}
C = \max_{r} I(X, Y) = 1 + p \log_2 p + (1 - p) \log_2 (1 - p) = 1 - H_2(p) 
\tag{C.19}
\end{align*}

\begin{align*}
\int P(x) x^2 \, \mathrm{d} x = J_0^2 
\tag{C.20}
\end{align*}

\begin{align*}
P(y \mid x) = \frac{1}{\sqrt{2 \pi} J} \exp \left\{-\frac{(y - x)^2}{2 J^2}\right\} 
\tag{C.21}
\end{align*}

\begin{align*}
P(y) = \int P(y \mid x) P(x) \, \mathrm{d} x = \frac{1}{\sqrt{2 \pi} J} \int \exp \left\{-\frac{(y - x)^2}{2 J^2}\right\} P(x) \, \mathrm{d} x 
\tag{C.22}
\end{align*}

\begin{align*}
H(Y) = -\int P(y) \log_2 P(y) \, \mathrm{d} y 
\tag{C.23}
\end{align*}

\begin{align*}
H(Y \mid X) = \log_2(\sqrt{2 \pi} J) + \frac{\log_2 \mathrm{e}}{2} 
\tag{C.24}
\end{align*}

\begin{align*}
I(X, Y) = -\int P(y) \log_2 P(y) \, \mathrm{d} y - \log_2(\sqrt{2 \pi} J) - \frac{\log_2 \mathrm{e}}{2} 
\tag{C.25}
\end{align*}

\begin{align*}
\int P(y) \, \mathrm{d} y = 1, \quad \int y^2 P(y) \, \mathrm{d} y = J^2 + J_0^2 
\tag{C.26}
\end{align*}

\begin{align*}
& \frac{\delta}{\delta P(y)}\left\{-\int P(y) \log _{2} P(y) \mathrm{d} y -\lambda_{1}\left(\int P(y) \mathrm{d} y-1\right)-\lambda_{2}\left(\int y^{2} P(y) \mathrm{d} y-J^{2}-J_{0}^{2}\right)\right\}=0
\tag{C.27}
\end{align*}


\begin{align*}
-\log _{2} P(y)-\lambda_{2} y^{2}-\text { const }=0 \tag{C.28}
\end{align*}

\begin{align*}
P(y) = \frac{1}{\sqrt{2 \pi(J^2 + J_0^2)}} \exp \left\{-\frac{y^2}{2(J^2 + J_0^2)}\right\} 
\tag{C.29}
\end{align*}

\begin{align*}
C = \frac{1}{2} \log_2 \left(1 + \frac{J_0^2}{J^2}\right) 
\tag{C.30}
\end{align*}

\section{Typical sequence and random coding}
\begin{align*}
\left|\frac{m_{i}}{M} - p_{i}\right| < \epsilon 
\tag{C.31}
\end{align*}

\begin{align*}
p_{\text{typ}} &= p_{1}^{m_{1}} \ldots p_{L}^{m_{L}} \approx p_{1}^{M p_{1}} \ldots p_{L}^{M p_{L}} = 2^{M \left(p_{1} \log_2 p_{1} + \cdots + p_{L} \log_2 p_{L}\right)} \equiv 2^{-M H(U)} 
\tag{C.32}
\end{align*}

\begin{align*}
N_{\mathrm{typ}} = \frac{M!}{m_{1}! \ldots m_{L}!} 
\tag{C.33}
\end{align*}

\begin{align*}
\log_2 N_{\text{typ}} &= M\left(\log_2 M - 1\right) - \sum_{i} m_{i} \left(\log_2 m_{i} - 1\right) = -M \sum_{i} p_{i} \log_2 p_{i} = M H(U) 
\tag{C.34}
\end{align*}

\begin{align*}
N_{\text{typ}} = 2^{M H(U)} = \left(p_{\text{typ}}\right)^{-1} 
\tag{C.35}
\end{align*}

\section{Channel coding theorem}
\begin{align*}
\frac{2^N}{2^{M H(X)}} = 2^{-M[H(X) - R]} 
\tag{C.36}
\end{align*}

\begin{align*}
1 - 2^{-M[H(X) - R]} 
\tag{C.37}
\end{align*}

\begin{align*}
p_{\text{correct}} = \left[1 - 2^{-M[H(X) - R]} \right]^{2^{M H(X \mid Y) - 1}} \approx 1 - 2^{-M[H(X) - R - H(X \mid Y)]}
\tag{C.38}
\end{align*}

\begin{align*}
\max \left\{p_{\text{correct}}\right\} = 1 - 2^{-M(C - R)} 
\tag{C.39}
\end{align*}

\end{document}
