@inproceedings{abedini2023chaotic,
  address =      {Kigali, Rwanda},
  author =       {Abedini, Tohid and Heydarian, Samin and Heidari,
                  Moein and Morsali, Alireza},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=H2mbtfasD4K}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Chaotic Transformers for Deep Reinforcement Learning
                  in Algorithmic Trading},
  year =         2023
}

@inproceedings{abuelhaija2018watch,
  address =      {Montreal, Quebec, Canada},
  author =       {Abu-El-Haija, Sami and Perozzi, Bryan and Al-Rfou,
                  Rami and Alemi, Alexander A.},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/8a94ecfa54dcb88a2fa993bfa6388f9e-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Watch Your Step: Learning Node Embeddings via Graph
                  Attention},
  volume =       31,
  year =         2018
}

@inproceedings{adepu2024framequant,
  address =      {Vienna, Austria},
  author =       {Adepu, Harshavardhan and Zeng, Zhanpeng and Zhang,
                  Li and Singh, Vikas},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{https://openreview.net/forum?id=xPypr0kufs}}},
  publisher =    {OpenReview.net},
  title =        {FrameQuant: Flexible Low-Bit Quantization for
                  Transformers},
  year =         2024
}

@inproceedings{agarwal2024chai,
  address =      {Vienna, Austria},
  author =       {Agarwal, Saurabh and Acun, Bilge and Hosmer, Basil
                  and Elhoushi, Mostafa and Lee, Yejin and
                  Venkataraman, Shivaram and Papailiopoulos, Dimitris
                  and Wu, Carole-Jean},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=xcDRx8vzCa}},
  publisher =    {OpenReview.net},
  title =        {CHAI: Clustered Head Attention for Efficient LLM
                  Inference},
  year =         2024
}

@inproceedings{agostinelli2024leapformer,
  address =      {Vienna, Austria},
  author =       {Agostinelli, Victor and Hong, Sanghyun and Chen,
                  Lizhong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=XhH1OKLANY}},
  publisher =    {OpenReview.net},
  title =        {LeaPformer: Enabling Linear Transformers for
                  Autoregressive and Simultaneous Tasks via Learned
                  Proportions},
  year =         2024
}

@inproceedings{ahmad1991visit,
  address =      {Denver, Colorado, USA},
  author =       {Ahmad, Subutai},
  booktitle =    {Advances in Neural Information Processing Systems 4
                  (NIPS)},
  editor =       {Moody, J. and Hanson, S. and Lippmann, R.P.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1991/file/7f24d240521d99071c93af3917215ef7-Paper.pdf}},
  publisher =    {Morgan-Kaufmann},
  series =       {Conference Track Proceedings},
  title =        {VISIT: A Neural Model of Covert Visual Attention},
  volume =       4,
  year =         1991
}

@inproceedings{ahn2023transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ahn, Kwangjun and Cheng, Xiang and Daneshmand, Hadi
                  and Sra, Suvrit},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8ed3d610ea4b68e7afb30ea7d01422c6-Paper-Conference.pdf}},
  pages =        {45614--45650},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers Learn to Implement Preconditioned
                  Gradient Descent for In-Context Learning},
  volume =       36,
  year =         2023
}

@inproceedings{ahn2024linearb,
  address =      {Vienna, Austria},
  author =       {Ahn, Kwangjun and Cheng, Xiang and Song, Minhak and
                  Yun, Chulhee and Jadbabaie, Ali and Sra, Suvrit},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=0uI5415ry7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Linear attention is (maybe) all you need (to
                  understand Transformer optimization)},
  year =         2024
}

@inproceedings{akbari2021vatt,
  address =      {Virtual Event},
  author =       {Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and
                  Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and
                  Gong, Boqing},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/cb3213ada48302953cb0f166464ab356-Paper.pdf}},
  pages =        {24206--24221},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {VATT: Transformers for Multimodal Self-Supervised
                  Learning from Raw Video, Audio and Text},
  volume =       34,
  year =         2021
}

@inproceedings{alam2023recasting,
  address =      {Honolulu, Hawaii, USA},
  author =       {Alam, Mohammad Mahmudul and Raff, Edward and
                  Biderman, Stella and Oates, Tim and Holt, James},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/alam23a.html}},
  pages =        {490--507},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Recasting Self-Attention with Holographic Reduced
                  Representations},
  volume =       202,
  year =         2023
}

@inproceedings{alami2018unsupervised,
  address =      {Montreal, Quebec, Canada},
  author =       {Alami Mejjati, Youssef and Richardt, Christian and
                  Tompkin, James and Cosker, Darren and Kim, Kwang In},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/4e87337f366f72daa424dae11df0538c-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Unsupervised Attention-guided Image-to-Image
                  Translation},
  volume =       31,
  year =         2018
}

@inproceedings{aleks2024prompting,
  address =      {Vienna, Austria},
  author =       {Aleks, and Petrov, ar and Torr, Philip and Bibi,
                  Adel},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=3mQ6ZKTSQl}},
  publisher =    {OpenReview.net},
  title =        {Prompting a Pretrained Transformer Can Be a
                  Universal Approximator},
  year =         2024
}

@inproceedings{aless2023acat,
  address =      {Honolulu, Hawaii, USA},
  author =       {Aless, and Fontanella, Ro and Antoniou, Antreas and
                  Li, Wenwen and Wardlaw, Joanna M. and Mair, Grant
                  and Trucco, Emanuele and Storkey, Amos J.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/fontanella23a.html}},
  pages =        {10153--10169},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {ACAT: Adversarial Counterfactual Attention for
                  Classification and Detection in Medical Imaging},
  volume =       202,
  year =         2023
}

@inproceedings{alex2022tactis,
  address =      {Baltimore, Maryland, USA},
  author =       {Alex and Drouin, re and Marcotte, Étienne and
                  Chapados, Nicolas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/drouin22a.html}},
  pages =        {5447--5493},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {TACTiS: Transformer-Attentional Copulas for Time
                  Series},
  volume =       162,
  year =         2022
}

@inproceedings{ali2021xcit,
  address =      {Virtual Event},
  author =       {Ali, Alaaeldin and Touvron, Hugo and Caron, Mathilde
                  and Bojanowski, Piotr and Douze, Matthijs and
                  Joulin, Armand and Laptev, Ivan and Neverova,
                  Natalia and Synnaeve, Gabriel and Verbeek, Jakob and
                  Jegou, Herve},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a655fbe4b8d7439994aa37ddad80de56-Paper.pdf}},
  pages =        {20014--20027},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {XCiT: Cross-Covariance Image Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{ali2022xai,
  address =      {Baltimore, Maryland, USA},
  author =       {Ali, Ameen and Schnake, Thomas and Eberle, Oliver
                  and Montavon, Grégoire and Müller, Klaus-Robert and
                  Wolf, Lior},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/ali22a.html}},
  pages =        {435--451},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {XAI for Transformers: Better Explanations through
                  Conservative Propagation},
  volume =       162,
  year =         2022
}

@inproceedings{allamanis2016convolutional,
  address =      {New York City, New York, USA},
  author =       {Allamanis, Miltiadis and Peng, Hao and Sutton,
                  Charles},
  booktitle =    {Proceedings of the 33rd International Conference on
                  Machine Learning (ICML)},
  editor =       {Balcan, Maria-Florina and Weinberger, Kilian Q.},
  month =        {June},
  note =
                  {\url{\url{http://proceedings.mlr.press/v48/allamanis16.html}}},
  pages =        {2091--2100},
  publisher =    {Journal of Machine Learning Research (JMLR)},
  series =       {Workshop and Conference Proceedings},
  title =        {A Convolutional Attention Network for Extreme
                  Summarization of Source Code},
  volume =       48,
  year =         2016
}

@inproceedings{alman2023fast,
  address =      {New Orleans, Louisiana, USA},
  author =       {Alman, Josh and Song, Zhao},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/c72861451d6fa9dfa64831102b9bb71a-Paper-Conference.pdf}},
  pages =        {63117--63135},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Fast Attention Requires Bounded Entries},
  volume =       36,
  year =         2023
}

@inproceedings{alman2024to,
  address =      {Vienna, Austria},
  author =       {Alman, Josh and Song, Zhao},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=v0zNCwwkaV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {How to Capture Higher-order Correlations?
                  Generalizing Matrix Softmax Attention to Kronecker
                  Computation},
  year =         2024
}

@inproceedings{alpaydin1995selective,
  address =      {Denver, Colorado, USA},
  author =       {Alpaydin, Ethem},
  booktitle =    {Advances in Neural Information Processing Systems 8
                  (NIPS)},
  editor =       {Touretzky, David and Mozer, Michael C. and Hasselmo,
                  Michael},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1995/file/20b5e1cf8694af7a3c1ba4a87f073021-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Selective Attention for Handwritten Digit
                  Recognition},
  volume =       8,
  year =         1995
}

@inproceedings{altabaa2024abstractors,
  address =      {Vienna, Austria},
  author =       {Altabaa, Awni and Webb, Taylor Whittington and
                  Cohen, Jonathan D. and Lafferty, John},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=XNa6r6ZjoB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Abstractors and Relational Cross-Attention: An
                  Inductive Bias for Explicit Relational Reasoning in
                  Transformers},
  year =         2024
}

@inproceedings{anagnostidis2023dynamic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Anagnostidis, Sotiris and Pavllo, Dario and Biggio,
                  Luca and Noci, Lorenzo and Lucchi, Aurelien and
                  Hofmann, Thomas},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/cdaac2a02c4fdcae77ba083b110efcc3-Paper-Conference.pdf}},
  pages =        {65202--65223},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Context Pruning for Efficient and
                  Interpretable Autoregressive Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{andoorveedu2022tempo,
  address =      {New Orleans, Louisiana, USA},
  author =       {Andoorveedu, Muralidhar and Zhu, Zhanda and Zheng,
                  Bojian and Pekhimenko, Gennady},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4fc81f4cd2715d995018e0799262176b-Paper-Conference.pdf}},
  pages =        {12267--12282},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Tempo: Accelerating Transformer-Based Model Training
                  through Memory Footprint Reduction},
  volume =       35,
  year =         2022
}

@inproceedings{arad2021compositional,
  address =      {Virtual Event},
  author =       {Arad Hudson, Dor and Zitnick, Larry},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4eff0720836a198b6174eecf02cbfdbf-Paper.pdf}},
  pages =        {9506--9520},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Compositional Transformers for Scene Generation},
  volume =       34,
  year =         2021
}

@article{arik2020protoattend,
  author =       {Arik, Sercan O. and Pfister, Tomas},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v21/20-042.html}},
  number =       210,
  pages =        {1--35},
  title =        {ProtoAttend: Attention-Based Prototypical Learning},
  volume =       21,
  year =         2020
}

@inproceedings{arora2024simple,
  address =      {Vienna, Austria},
  author =       {Arora, Simran and Eyuboglu, Sabri and Zhang, Michael
                  and Timalsina, Aman and Alberti, Silas and Zou,
                  James and Rudra, Atri and Ré, Christopher},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=e93ffDcpH3}},
  publisher =    {OpenReview.net},
  title =        {Simple linear attention language models balance the
                  recall-throughput tradeoff},
  year =         2024
}

@inproceedings{ashman2024translation,
  address =      {Vienna, Austria},
  author =       {Ashman, Matthew and Diaconu, Cristiana and Kim,
                  Junhyuck and Sivaraya, Lakee and Markou, Stratis and
                  Requeima, James and Bruinsma, Wessel P. and Turner,
                  Richard E.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=pftXzp6Yn3}},
  publisher =    {OpenReview.net},
  title =        {Translation Equivariant Transformer Neural
                  Processes},
  year =         2024
}

@inproceedings{ataee2023max,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ataee Tarzanagh, Davoud and Li, Yingcong and Zhang,
                  Xuechen and Oymak, Samet},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/970f59b22f4c72aec75174aae63c7459-Paper-Conference.pdf}},
  pages =        {48314--48362},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Max-Margin Token Selection in Attention Mechanism},
  volume =       36,
  year =         2023
}

@inproceedings{athiwaratkun2024bifurcated,
  address =      {Vienna, Austria},
  author =       {Athiwaratkun, Ben and Gonugondla, Sujan Kumar and
                  Gouda, Sanjay Krishna and Qian, Haifeng and Ding,
                  Hantian and Sun, Qing and Wang, Jun and Guo,
                  Jiacheng and Chen, Liangfu and Bhatia, Parminder and
                  Nallapati, Ramesh and Sengupta, Sudipta and Xiang,
                  Bing},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{https://openreview.net/forum?id=JPNBFWQ9H2}}},
  publisher =    {OpenReview.net},
  title =        {Bifurcated Attention for Single-Context Large-Batch
                  Sampling},
  year =         2024
}

@inproceedings{atzeni2023infusing,
  address =      {Honolulu, Hawaii, USA},
  author =       {Atzeni, Mattia and Sachan, Mrinmaya and Loukas,
                  Andreas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/atzeni23a.html}},
  pages =        {1200--1217},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Infusing Lattice Symmetry Priors in Attention
                  Mechanisms for Sample-Efficient Abstract Geometric
                  Reasoning},
  volume =       202,
  year =         2023
}

@inproceedings{b1996residual,
  address =      {Bari, Italy},
  author =       {Cesar B and Era and Vico, Francisco J. and Bravo,
                  José Manuel and Harmon, Mance E. and Baird, Leemon
                  C. III},
  booktitle =    {Machine Learning: Proceedings of the Thirteenth
                  International Conference},
  editor =       {Saitta, Lorenza},
  month =        {July},
  pages =        {20--27},
  publisher =    {Morgan Kaufmann},
  title =        {Residual Q-Learning Applied to Visual Attention},
  year =         1996
}

@inproceedings{ba2015learning,
  address =      {Montreal, Quebec, Canada},
  author =       {Ba, Jimmy and Salakhutdinov, Russ R. and Grosse,
                  Roger B. and Frey, Brendan J.},
  booktitle =    {Advances in Neural Information Processing Systems 28
                  (NIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2015/file/db1915052d15f7815c8b88e879465a1e-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Wake-Sleep Recurrent Attention Models},
  volume =       28,
  year =         2015
}

@inproceedings{ba2015multiple,
  address =      {San Diego, California, USA},
  author =       {Ba, Jimmy and Mnih, Volodymyr and Kavukcuoglu,
                  Koray},
  booktitle =    {3rd International Conference on Learning
                  Representations (ICLR)},
  editor =       {Bengio, Yoshua and LeCun, Yann},
  month =        {May},
  note =         {\url{http://arxiv.org/abs/1412.7755}},
  series =       {Conference Track Proceedings},
  title =        {Multiple Object Recognition with Visual Attention},
  year =         2015
}

@inproceedings{badrinath2023waypoint,
  address =      {New Orleans, Louisiana, USA},
  author =       {Badrinath, Anirudhan and Flet-Berliac, Yannis and
                  Nie, Allen and Brunskill, Emma},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f58c24798220ba724fe05c0fa786227d-Paper-Conference.pdf}},
  pages =        {78006--78027},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Waypoint Transformer: Reinforcement Learning via
                  Supervised Learning with Intermediate Targets},
  volume =       36,
  year =         2023
}

@inproceedings{bae2000combining,
  address =      {Denver, Colorado, USA},
  author =       {Bae, Un-Min and Lee, Soo-Young},
  booktitle =    {Advances in Neural Information Processing Systems 13
                  (NIPS)},
  editor =       {Leen, T. and Dietterich, T. and Tresp, V.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2000/file/f2d887e01a80e813d9080038decbbabb-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Combining ICA and Top-Down Attention for Robust
                  Speech Recognition},
  volume =       13,
  year =         2000
}

@inproceedings{bai2021are,
  address =      {Virtual Event},
  author =       {Bai, Yutong and Mei, Jieru and Yuille, Alan L and
                  Xie, Cihang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/e19347e1c3ca0c0b97de5fb3b690855a-Paper.pdf}},
  pages =        {26831--26843},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Are Transformers More Robust than CNNs?},
  volume =       34,
  year =         2021
}

@inproceedings{bai2023transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bai, Yu and Chen, Fan and Wang, Huan and Xiong,
                  Caiming and Mei, Song},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b2e63e36c57e153b9015fece2352a9f9-Paper-Conference.pdf}},
  pages =        {57125--57211},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers as Statisticians: Provable In-Context
                  Learning with In-Context Algorithm Selection},
  volume =       36,
  year =         2023
}

@inproceedings{baluja1994using,
  address =      {Denver, Colorado, USA},
  author =       {Baluja, Shumeet and Pomerleau, Dean A.},
  booktitle =    {Advances in Neural Information Processing Systems 7
                  (NIPS)},
  editor =       {G. Tesauro and D. Touretzky and T. Leen},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1994/file/1f50893f80d6830d62765ffad7721742-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Using a Saliency Map for Active Spatial Selective
                  Attention: Implementation & Initial Results},
  volume =       7,
  year =         1994
}

@inproceedings{bao2022beit,
  address =      {Virtual Event},
  author =       {Bao, Hangbo and Dong, Li and Piao, Songhao and Wei,
                  Furu},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=p-BhZSz59o4}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {BEiT: BERT Pre-Training of Image Transformers},
  year =         2022
}

@inproceedings{bao2023one,
  address =      {Honolulu, Hawaii, USA},
  author =       {Bao, Fan and Nie, Shen and Xue, Kaiwen and Li,
                  Chongxuan and Pu, Shi and Wang, Yaole and Yue, Gang
                  and Cao, Yue and Su, Hang and Zhu, Jun},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/bao23a.html}},
  pages =        {1692--1717},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {One Transformer Fits All Distributions in
                  Multi-Modal Diffusion at Scale},
  volume =       202,
  year =         2023
}

@inproceedings{bao2024channel,
  address =      {Vienna, Austria},
  author =       {Bao, Yujia and Sivan, Srinivasan and Karaletsos,
                  Theofanis},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=CK5Hfb5hBG}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Channel Vision Transformers: An Image Is Worth 1 x
                  16 x 16 Words},
  year =         2024
}

@inproceedings{bao2024selfattention,
  address =      {Vienna, Austria},
  author =       {Bao, Han and Hataya, Ryuichiro and Karakida, Ryo},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=aRZjRj41WQ}},
  publisher =    {OpenReview.net},
  title =        {Self-attention Networks Localize When
                  QK-eigenspectrum Concentrates},
  year =         2024
}

@inproceedings{barcelo2024logical,
  address =      {Vienna, Austria},
  author =       {Barceló, Pablo and Alex and Kozachinskiy, Er and
                  Lin, Anthony Widjaja and Podolskii, Vladimir V.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=gbrHZq07mq}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Logical Languages Accepted by Transformer Encoders
                  with Hard Attention},
  year =         2024
}

@inproceedings{barshalom2024subgraphormer,
  address =      {Vienna, Austria},
  author =       {Bar-Shalom, Guy and Bevilacqua, Beatrice and Maron,
                  Haggai},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=6djDWVTUEq}},
  publisher =    {OpenReview.net},
  title =        {Subgraphormer: Unifying Subgraph GNNs and Graph
                  Transformers via Graph Products},
  year =         2024
}

@inproceedings{bartolozzi2006attention,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Bartolozzi, Chiara and Indiveri, Giacomo},
  booktitle =    {Advances in Neural Information Processing Systems 19
                  (NIPS)},
  editor =       {B. Schölkopf and J. Platt and T. Hoffman},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2006/file/7edfd52220e2032e7281061c82401195-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {A Selective Attention Multi-Chip System with Dynamic
                  Synapses and Spiking Neurons},
  volume =       19,
  year =         2006
}

@inproceedings{baykal2023alternating,
  address =      {New Orleans, Louisiana, USA},
  author =       {Baykal, Cenk and Cutler, Dylan and Dikkala, Nishanth
                  and Ghosh, Nikhil and Panigrahy, Rina and Wang, Xin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f2059277ac6ce66e7e5543001afa8bb5-Paper-Conference.pdf}},
  pages =        {76718--76736},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Alternating Updates for Efficient Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{bazzani2017recurrent,
  address =      {Toulon, France},
  author =       {Bazzani, Loris and Larochelle, Hugo and Torresani,
                  Lorenzo},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=SJRpRfKxx}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Recurrent Mixture Density Network for Spatiotemporal
                  Visual Attention},
  year =         2017
}

@inproceedings{becker2023predicting,
  address =      {Honolulu, Hawaii, USA},
  author =       {Becker, Sören and Klein, Michal and Alex and Neitz,
                  er and Parasc, Giambattista and olo and Kilbertus,
                  Niki},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/becker23a.html}},
  pages =        {1978--2002},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Predicting Ordinary Differential Equations with
                  Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{bello2021lambdanetworks,
  address =      {Virtual Event, Austria},
  author =       {Bello, Irwan},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=xTJEN-ggl1b}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {LambdaNetworks: Modeling long-range Interactions
                  without Attention},
  year =         2021
}

@inproceedings{berabi2021tfix,
  address =      {Virtual Event},
  author =       {Berabi, Berkay and He, Jingxuan and Raychev, Veselin
                  and Vechev, Martin T.},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/berabi21a.html}},
  pages =        {780--791},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {TFix: Learning to Fix Coding Errors with a
                  Text-to-Text Transformer},
  volume =       139,
  year =         2021
}

@inproceedings{bergen2021systematic,
  address =      {Virtual Event},
  author =       {Bergen, Leon and O'Donnell, Timothy and Bahdanau,
                  Dzmitry},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/0a4dc6dae338c9cb08947c07581f77a2-Paper.pdf}},
  pages =        {1390--1402},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Systematic Generalization with Edge Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{bertasius2021is,
  address =      {Virtual Event},
  author =       {Bertasius, Gedas and Wang, Heng and Torresani,
                  Lorenzo},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/bertasius21a.html}},
  pages =        {813--824},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Is Space-Time Attention All You Need for Video
                  Understanding?},
  volume =       139,
  year =         2021
}

@inproceedings{bertsch2023unlimiformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bertsch, Amanda and Alon, Uri and Neubig, Graham and
                  Gormley, Matthew},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6f9806a5adc72b5b834b27e4c7c0df9b-Paper-Conference.pdf}},
  pages =        {35522--35543},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Unlimiformer: Long-Range Transformers with Unlimited
                  Length Input},
  volume =       36,
  year =         2023
}

@inproceedings{bethune2022pay,
  address =      {New Orleans, Louisiana, USA},
  author =       {Béthune, Louis and Boissin, Thibaut and Serrurier,
                  Mathieu and Mamalet, Franck and Friedrich, Corentin
                  and Gonzalez Sanz, Alberto},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/7eb3d8ae592966543170a65e6b698828-Paper-Conference.pdf}},
  pages =        {20077--20091},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pay attention to your loss : understanding
                  misconceptions about Lipschitz neural networks},
  volume =       35,
  year =         2022
}

@inproceedings{bhargava2024should,
  address =      {Vienna, Austria},
  author =       {Bhargava, Prajjwal and Chitnis, Rohan and
                  Geramifard, Alborz and Sodhani, Shagun and Zhang,
                  Amy},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vpV7fOFQy4}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {When should we prefer Decision Transformers for
                  Offline Reinforcement Learning?},
  year =         2024
}

@inproceedings{bhatia2023tart,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bhatia, Kush and Narayan, Avanika and De Sa,
                  Christopher M and Ré, Christopher},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1ece70d2259b8e9510e2d4ca8754cecf-Paper-Conference.pdf}},
  pages =        {9751--9788},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TART: A plug-and-play Transformer module for
                  task-agnostic reasoning},
  volume =       36,
  year =         2023
}

@inproceedings{bhattamishra2024understanding,
  address =      {Vienna, Austria},
  author =       {Bhattamishra, Satwik and Patel, Arkil and Blunsom,
                  Phil and Kanade, Varun},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ekeyCgeRfC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Understanding In-Context Learning in Transformers
                  and LLMs by Learning to Learn Discrete Functions},
  year =         2024
}

@inproceedings{bhojanapalli2020lowrank,
  address =      {Virtual Event},
  author =       {Bhojanapalli, Srinadh and Yun, Chulhee and Rawat,
                  Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/bhojanapalli20a.html}},
  pages =        {864--873},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Low-Rank Bottleneck in Multi-head Attention Models},
  volume =       119,
  year =         2020
}

@inproceedings{bieber2020learning,
  address =      {Virtual Event},
  author =       {Bieber, David and Sutton, Charles and Larochelle,
                  Hugo and Tarlow, Daniel},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/62326dc7c4f7b849d6f013ba46489d6c-Paper.pdf}},
  pages =        {8626--8637},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning to Execute Programs with Instruction
                  Pointer Attention Graph Neural Networks},
  volume =       33,
  year =         2020
}

@inproceedings{bietti2023birth,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bietti, Alberto and Cabannes, Vivien and
                  Bouchacourt, Diane and Jegou, Herve and Bottou,
                  Léon},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/0561738a239a995c8cd2ef0e50cfa4fd-Paper-Conference.pdf}},
  pages =        {1560--1588},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Birth of a Transformer: A Memory Viewpoint},
  volume =       36,
  year =         2023
}

@inproceedings{biza2023invariant,
  address =      {Honolulu, Hawaii, USA},
  author =       {Biza, Ondrej and Steenkiste, Sjoerd van and Sajjadi,
                  Mehdi S. M. and Elsayed, Gamaleldin Fathy and
                  Mahendran, Aravindh and Kipf, Thomas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/biza23a.html}},
  pages =        {2507--2527},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Invariant Slot Attention: Object Discovery with
                  Slot-Centric Reference Frames},
  volume =       202,
  year =         2023
}

@inproceedings{black2024comparing,
  address =      {Vienna, Austria},
  author =       {Black, Mitchell and Wan, Zhengchao and Mishne, Gal
                  and Nayyeri, Amir and Wang, Yusu},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=va3r3hSA6n}},
  publisher =    {OpenReview.net},
  title =        {Comparing Graph Transformers via Positional
                  Encodings},
  year =         2024
}

@inproceedings{bo2023specformer,
  address =      {Kigali, Rwanda},
  author =       {Bo, Deyu and Shi, Chuan and Wang, Lele and Liao,
                  Renjie},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=0pdSt3oyJa1}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Specformer: Spectral Graph Neural Networks Meet
                  Transformers},
  year =         2023
}

@inproceedings{boixadsera2023transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Boix-Adsera, Enric and Littwin, Etai and Abbe,
                  Emmanuel and Bengio, Samy and Susskind, Joshua},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4d69c1c057a8bd570ba4a7b71aae8331-Paper-Conference.pdf}},
  pages =        {24519--24551},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers learn through gradual rank increase},
  volume =       36,
  year =         2023
}

@inproceedings{boixadsera2024reason,
  address =      {Vienna, Austria},
  author =       {Boix-Adserà, Enric and Saremi, Omid and Abbe,
                  Emmanuel and Bengio, Samy and Littwin, Etai and
                  Susskind, Joshua M.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=STUGfUz8ob}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {When can transformers reason with abstract symbols?},
  year =         2024
}

@inproceedings{bolya2024window,
  address =      {Vienna, Austria},
  author =       {Bolya, Daniel and Ryali, Chaitanya and Hoffman, Judy
                  and Feichtenhofer, Christoph},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=IPhm01y9a9}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Window Attention is Bugged: How not to Interpolate
                  Position Embeddings},
  year =         2024
}

@inproceedings{bombari2024towards,
  address =      {Vienna, Austria},
  author =       {Bombari, Simone and Mondelli, Marco},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=JBaPBPrn93}},
  publisher =    {OpenReview.net},
  title =        {Towards Understanding the Word Sensitivity of
                  Attention Layers: A Study via Random Features},
  year =         2024
}

@inproceedings{bondarenko2023quantizable,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bondarenko, Yelysei and Nagel, Markus and
                  Blankevoort, Tijmen},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/edbcb7583fd8921dad78adecfe06a99b-Paper-Conference.pdf}},
  pages =        {75067--75096},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Quantizable Transformers: Removing Outliers by
                  Helping Attention Heads Do Nothing},
  volume =       36,
  year =         2023
}

@inproceedings{bozic2021transformerfusion,
  address =      {Virtual Event},
  author =       {Bozic, Aljaz and Palafox, Pablo and Thies, Justus
                  and Dai, Angela and Niessner, Matthias},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf}},
  pages =        {1403--1414},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TransformerFusion: Monocular RGB Scene
                  Reconstruction using Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{brehmer2023geometric,
  address =      {New Orleans, Louisiana, USA},
  author =       {Brehmer, Johann and de Haan, Pim and Behrends, Sönke
                  and Cohen, Taco S},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6f6dd92b03ff9be7468a6104611c9187-Paper-Conference.pdf}},
  pages =        {35472--35496},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Geometric Algebra Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{bricken2021attention,
  address =      {Virtual Event},
  author =       {Bricken, Trenton and Pehlevan, Cengiz},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/8171ac2c5544a5cb54ac0f38bf477af4-Paper.pdf}},
  pages =        {15301--15315},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention Approximates Sparse Distributed Memory},
  volume =       34,
  year =         2021
}

@inproceedings{brody2022attentive,
  address =      {Virtual Event},
  author =       {Brody, Shaked and Alon, Uri and Yahav, Eran},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=F72ximsx7C1}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {How Attentive are Graph Attention Networks?},
  year =         2022
}

@inproceedings{brunner2020on,
  address =      {Addis Ababa, Ethiopia},
  author =       {Brunner, Gino and Liu, Yang and Pascual, Damian and
                  Richter, Oliver and Ciaramita, Massimiliano and
                  Wattenhofer, Roger},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=BJg1f6EFDB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {On Identifiability in Transformers},
  year =         2020
}

@inproceedings{bryutkin2024hamlet,
  address =      {Vienna, Austria},
  author =       {Bryutkin, Andrey and Huang, Jiahao and Deng,
                  Zhongying and Yang, Guang and Schönlieb,
                  Carola-Bibiane and Avilés-Rivero, Angelica I.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=nYX7I6PsL7}},
  publisher =    {OpenReview.net},
  title =        {HAMLET: Graph Transformer Neural Operator for
                  Partial Differential Equations},
  year =         2024
}

@inproceedings{bulat2021space,
  address =      {Virtual Event},
  author =       {Bulat, Adrian and Perez Rua, Juan Manuel and
                  Sudhakaran, Swathikiran and Martinez, Brais and
                  Tzimiropoulos, Georgios},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a34bacf839b923770b2c360eefa26748-Paper.pdf}},
  pages =        {19594--19607},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Space-time Mixing Attention for Video Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{bulatov2022recurrent,
  address =      {New Orleans, Louisiana, USA},
  author =       {Bulatov, Aydar and Kuratov, Yury and Burtsev,
                  Mikhail},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/47e288629a6996a17ce50b90a056a0e1-Paper-Conference.pdf}},
  pages =        {11079--11091},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Recurrent Memory Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{cai2022degradation,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cai, Yuanhao and Lin, Jing and Wang, Haoqian and
                  Yuan, Xin and Ding, Henghui and Zhang, Yulun and
                  Timofte, Radu and Gool, Luc V},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/f621c2ead473ca36763696b712ffda01-Paper-Conference.pdf}},
  pages =        {37749--37761},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Degradation-Aware Unfolding Half-Shuffle Transformer
                  for Spectral Compressive Imaging},
  volume =       35,
  year =         2022
}

@inproceedings{cai2022semi,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cai, Zhaowei and Ravichandran, Avinash and Favaro,
                  Paolo and Wang, Manchen and Modolo, Davide and
                  Bhotika, Rahul and Tu, Zhuowen and Soatto, Stefano},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/a4a1ee071ce0fe63b83bce507c9dc4d7-Paper-Conference.pdf}},
  pages =        {25697--25710},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Semi-Supervised Vision Transformers at Scale},
  volume =       35,
  year =         2022
}

@inproceedings{cai2023on,
  address =      {Honolulu, Hawaii, USA},
  author =       {Cai, Chen and Hy, Truong Son and Yu, Rose and Wang,
                  Yusu},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/cai23b.html}}},
  pages =        {3408--3430},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {On the Connection Between MPNN and Graph
                  Transformer},
  year =         2023
}

@inproceedings{cao2021choose,
  address =      {Virtual Event},
  author =       {Cao, Shuhao},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/d0921d442ee91b896ad95059d13df618-Paper.pdf}},
  pages =        {24924--24940},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Choose a Transformer: Fourier or Galerkin},
  volume =       34,
  year =         2021
}

@inproceedings{cao2021image,
  address =      {Virtual Event},
  author =       {Cao, Chenjie and Hong, Yuxin and Li, Xiang and Wang,
                  Chengrong and Xu, Chengming and Fu, Yanwei and Xue,
                  Xiangyang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/9996535e07258a7bbfd8b132435c5962-Paper.pdf}},
  pages =        {18433--18445},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Image Local Autoregressive Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{cao2023flow,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cao, Yuxin and Li, Yian and Zhu, Yumeng and Wang,
                  Derui and Xue, Minhui},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/456f9445d0fa1a932d19584ab788c787-Paper-Conference.pdf}},
  pages =        {21920--21932},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Flow-Attention-based Spatio-Temporal Aggregation
                  Network for 3D Mask Detection},
  volume =       36,
  year =         2023
}

@inproceedings{cao2024largevocabulary,
  address =      {Vienna, Austria},
  author =       {Cao, Ziang and Hong, Fangzhou and Wu, Tong and Pan,
                  Liang and Liu, Ziwei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=q57JLSE2j5}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Large-Vocabulary 3D Diffusion Model with
                  Transformer},
  year =         2024
}

@inproceedings{cao2024mvsformer++,
  address =      {Vienna, Austria},
  author =       {Cao, Chenjie and Ren, Xinlin and Fu, Yanwei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=wXWfvSpYHh}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MVSFormer++: Revealing the Devil in Transformer's
                  Details for Multi-View Stereo},
  year =         2024
}

@inproceedings{cao2024tempo,
  address =      {Vienna, Austria},
  author =       {Cao, Defu and Jia, Furong and Arik, Sercan Ö. and
                  Pfister, Tomas and Zheng, Yixiang and Ye, Wen and
                  Liu, Yan},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=YH5w12OUuU}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {TEMPO: Prompt-based Generative Pre-trained
                  Transformer for Time Series Forecasting},
  year =         2024
}

@inproceedings{castin2024smooth,
  address =      {Vienna, Austria},
  author =       {Castin, Valérie and Ablin, Pierre and Peyré,
                  Gabriel},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=aP0H8A1ywk}},
  publisher =    {OpenReview.net},
  title =        {How Smooth Is Attention?},
  year =         2024
}

@inproceedings{chai2022pyramid,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chai, Lei and Li, Ming},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/803cb038c7df56122e55a06c2856938f-Paper-Conference.pdf}},
  pages =        {20421--20433},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pyramid Attention for Source Code Summarization},
  volume =       35,
  year =         2022
}

@inproceedings{chan2022data,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chan, Stephanie and Santoro, Adam and Lampinen,
                  Andrew and Wang, Jane and Singh, Aaditya and
                  Richemond, Pierre and McClelland, James and Hill,
                  Felix},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/77c6ccacfd9962e2307fc64680fc5ace-Paper-Conference.pdf}},
  pages =        {18878--18891},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Data Distributional Properties Drive Emergent
                  In-Context Learning in Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{chang2023muse,
  address =      {Honolulu, Hawaii, USA},
  author =       {Chang, Huiwen and Zhang, Han and Barber, Jarred and
                  Maschinot, Aaron and Lezama, José and Jiang, Lu and
                  Yang, Ming-Hsuan and Murphy, Kevin Patrick and
                  Freeman, William T. and Rubinstein, Michael and Li,
                  Yuanzhen and Krishnan, Dilip},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/chang23b.html}},
  pages =        {4055--4075},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Muse: Text-To-Image Generation via Masked Generative
                  Transformers},
  year =         2023
}

@inproceedings{chaplot2021differentiable,
  address =      {Virtual Event},
  author =       {Chaplot, Devendra Singh and Pathak, Deepak and
                  Malik, Jitendra},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/chaplot21a.html}},
  pages =        {1484--1495},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Differentiable Spatial Planning using Transformers},
  volume =       139,
  year =         2021
}

@inproceedings{charton2024learning,
  address =      {Vienna, Austria},
  author =       {Charton, François},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cmcD05NPKa}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning the greatest common divisor: explaining
                  transformer predictions},
  year =         2024
}

@inproceedings{chatzipantazis2023se3equivariant,
  address =      {Kigali, Rwanda},
  author =       {Chatzipantazis, Evangelos and Pertigkiozoglou,
                  Stefanos and Dobriban, Edgar and Daniilidis, Kostas},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=RDy3IbvjMqT}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SE(3)-Equivariant Attention Networks for Shape
                  Reconstruction in Function Space},
  year =         2023
}

@inproceedings{chefer2022optimizing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chefer, Hila and Schwartz, Idan and Wolf, Lior},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/d9fa720cf96f7c18ac4d9e04270f0bbf-Paper-Conference.pdf}},
  pages =        {33618--33632},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Optimizing Relevance Maps of Vision Transformers
                  Improves Robustness},
  volume =       35,
  year =         2022
}

@inproceedings{chen20182,
  address =      {Montreal, Quebec, Canada},
  author =       {Chen, Yunpeng and Kalantidis, Yannis and Li, Jianshu
                  and Yan, Shuicheng and Feng, Jiashi},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/e165421110ba03099a1c0393373c5b43-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A2-Nets: Double Attention Networks},
  volume =       31,
  year =         2018
}

@inproceedings{chen2021chasing,
  address =      {Virtual Event},
  author =       {Chen, Tianlong and Cheng, Yu and Gan, Zhe and Yuan,
                  Lu and Zhang, Lei and Wang, Zhangyang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a61f27ab2165df0e18cc9433bd7f27c5-Paper.pdf}},
  pages =        {19974--19988},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Chasing Sparsity in Vision Transformers: An
                  End-to-End Exploration},
  volume =       34,
  year =         2021
}

@inproceedings{chen2021decision,
  address =      {Virtual Event},
  author =       {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and
                  Lee, Kimin and Grover, Aditya and Laskin, Misha and
                  Abbeel, Pieter and Srinivas, Aravind and Mordatch,
                  Igor},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf}},
  pages =        {15084--15097},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Decision Transformer: Reinforcement Learning via
                  Sequence Modeling},
  volume =       34,
  year =         2021
}

@inproceedings{chen2021history,
  address =      {Virtual Event},
  author =       {Chen, Shizhe and Guhur, Pierre-Louis and Schmid,
                  Cordelia and Laptev, Ivan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2e5c2cb8d13e8fba78d95211440ba326-Paper.pdf}},
  pages =        {5834--5847},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {History Aware Multimodal Transformer for
                  Vision-and-Language Navigation},
  volume =       34,
  year =         2021
}

@inproceedings{chen2021learning,
  address =      {Virtual Event},
  author =       {Chen, Chao and Geng, Haoyu and Yang, Nianzu and Yan,
                  Junchi and Xue, Daiyue and Yu, Jianping and Yang,
                  Xiaokang},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/chen21h.html}},
  pages =        {1606--1616},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning Self-Modulating Attention in Continuous
                  Time Space with Applications to Sequential
                  Recommendation},
  volume =       139,
  year =         2021
}

@inproceedings{chen2021scatterbrain,
  address =      {Virtual Event},
  author =       {Chen, Beidi and Dao, Tri and Winsor, Eric and Song,
                  Zhao and Rudra, Atri and Ré, Christopher},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/9185f3ec501c674c7c788464a36e7fb3-Paper.pdf}},
  pages =        {17413--17426},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Scatterbrain: Unifying Sparse and Low-rank
                  Attention},
  volume =       34,
  year =         2021
}

@inproceedings{chen2021searching,
  address =      {Virtual Event},
  author =       {Chen, Minghao and Wu, Kan and Ni, Bolin and Peng,
                  Houwen and Liu, Bei and Fu, Jianlong and Chao,
                  Hongyang and Ling, Haibin},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/48e95c45c8217961bf6cd7696d80d238-Paper.pdf}},
  pages =        {8714--8726},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Searching the Search Space of Vision Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{chen2021skyformer,
  address =      {Virtual Event},
  author =       {Chen, Yifan and Zeng, Qi and Ji, Heng and Yang, Yun},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/10a7cdd970fe135cf4f7bb55c0e3b59f-Paper.pdf}},
  pages =        {2122--2135},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Skyformer: Remodel Self-Attention with Gaussian
                  Kernel and Nyström Method},
  volume =       34,
  year =         2021
}

@inproceedings{chen2022adaptformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Shoufa and Ge, Chongjian and Tong, Zhan and
                  Wang, Jiangliu and Song, Yibing and Wang, Jue and
                  Luo, Ping},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/69e2f49ab0837b71b0e0cb7c555990f8-Paper-Conference.pdf}},
  pages =        {16664--16678},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {AdaptFormer: Adapting Vision Transformers for
                  Scalable Visual Recognition},
  volume =       35,
  year =         2022
}

@inproceedings{chen2022autoscaling,
  address =      {Virtual Event},
  author =       {Chen, Wuyang and Huang, Wei and Du, Xianzhi and
                  Song, Xiaodan and Wang, Zhangyang and Zhou, Denny},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=H94a1_Pyr-6}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Auto-scaling Vision Transformers without Training},
  year =         2022
}

@inproceedings{chen2022cross,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Zheng and Zhang, Yulun and Gu, Jinjin and
                  Zhang, Yongbing and Kong, Linghe and Yuan, Xin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/a37fea8e67f907311826bc1ba2654d97-Paper-Conference.pdf}},
  pages =        {25478--25490},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cross Aggregation Transformer for Image Restoration},
  volume =       35,
  year =         2022
}

@inproceedings{chen2022regionvit,
  address =      {Virtual Event},
  author =       {Chen, Chun-Fu and P, Rameswar and A, and Fan,
                  Quanfu},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=T__V3uLix7V}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {RegionViT: Regional-to-Local Attention for Vision
                  Transformers},
  year =         2022
}

@inproceedings{chen2022structureaware,
  address =      {Baltimore, Maryland, USA},
  author =       {Chen, Dexiong and O'Bray, Leslie and Borgwardt,
                  Karsten M.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/chen22r.html}},
  pages =        {3469--3489},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Structure-Aware Transformer for Graph Representation
                  Learning},
  volume =       162,
  year =         2022
}

@inproceedings{chen2022towardsd,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Yutian and Song, Xingyou and Lee, Chansoo and
                  Wang, Zi and Zhang, Richard and Dohan, David and
                  Kawakami, Kazuya and Kochanski, Greg and Doucet,
                  Arnaud and Ranzato, Marc'Aurelio and Perel, Sagi and
                  de Freitas, Nando},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/cf6501108fced72ee5c47e2151c4e153-Paper-Conference.pdf}},
  pages =        {32053--32068},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Towards Learning Universal Hyperparameter Optimizers
                  with Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{chen2022vision,
  address =      {Virtual Event},
  author =       {Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=LtKcMgGOeLt}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {When Vision Transformers Outperform ResNets without
                  Pre-training or Strong Data Augmentations},
  year =         2022
}

@inproceedings{chen2023calibrating,
  address =      {Kigali, Rwanda},
  author =       {Chen, Wenlong and Li, Yingzhen},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=jPVAFXHlbL}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Calibrating Transformers via Sparse Gaussian
                  Processes},
  year =         2023
}

@inproceedings{chen2023contiformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Yuqi and Ren, Kan and Wang, Yansen and Fang,
                  Yuchen and Sun, Weiwei and Li, Dongsheng},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/9328208f88ec69420031647e6ff97727-Paper-Conference.pdf}},
  pages =        {47143--47175},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ContiFormer: Continuous-Time Transformer for
                  Irregular Time Series Modeling},
  volume =       36,
  year =         2023
}

@inproceedings{chen2023do,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Shi and Jiang, Ming and Zhao, Qi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1e680f115a22d60cbc228a0c6dae5936-Paper-Conference.pdf}},
  pages =        {9543--9555},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {What Do Deep Saliency Models Learn about Visual
                  Attention?},
  volume =       36,
  year =         2023
}

@inproceedings{chen2023lart,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Haoyu and Tang, Hao and Timofte, Radu and
                  Gool, Luc V and Zhao, Guoying},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/88593e16b09104fb6010d370c081d7bc-Paper-Conference.pdf}},
  pages =        {43742--43753},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {LART: Neural Correspondence Learning with Latent
                  Regularization Transformer for 3D Motion Transfer},
  volume =       36,
  year =         2023
}

@inproceedings{chen2023nagphormer,
  address =      {Kigali, Rwanda},
  author =       {Chen, Jinsong and Gao, Kaiyuan and Li, Gaichao and
                  He, Kun},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=8KYeilT3Ow}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {NAGphormer: A Tokenized Graph Transformer for Node
                  Classification in Large Graphs},
  year =         2023
}

@inproceedings{chen2023ond,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Xiaohui and Wang, Yinkai and Du, Yuanqi and
                  Hassoun, Soha and Liu, Liping},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8ba80c47b9d3dced79ee835b7d3bf72a-Paper-Conference.pdf}},
  pages =        {44544--44557},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {On Separate Normalization in Self-supervised
                  Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{chen2023primal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chen, Yingyi and Tao, Qinghua and Tonin, Francesco
                  and Suykens, Johan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/cd687a58a13b673eea3fc1b2e4944cf7-Paper-Conference.pdf}},
  pages =        {65088--65101},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Primal-Attention: Self-Attention through Asymmetric
                  Kernel SVD in Primal Representation},
  volume =       36,
  year =         2023
}

@inproceedings{chen2023vision,
  address =      {Kigali, Rwanda},
  author =       {Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He,
                  Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=plKu2GByCNW}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Vision Transformer Adapter for Dense Predictions},
  year =         2023
}

@inproceedings{chen2024exact,
  address =      {Vienna, Austria},
  author =       {Chen, Brian K. and Hu, Tianyang and Jin, Hui and
                  Lee, Hwee Kuan and Kawaguchi, Kenji},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=LVF4P1NNwO}},
  publisher =    {OpenReview.net},
  title =        {Exact Conversion of In-Context Learning to Model
                  Weights in Linearized-Attention Transformers},
  year =         2024
}

@inproceedings{chen2024pathformer,
  address =      {Vienna, Austria},
  author =       {Chen, Peng and Zhang, Yingying and Cheng, Yunyao and
                  Shu, Yang and Wang, Yihang and Wen, Qingsong and
                  Yang, Bin and Guo, Chenjuan},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=lJkOCMP2aW}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Pathformer: Multi-scale Transformers with Adaptive
                  Pathways for Time Series Forecasting},
  year =         2024
}

@inproceedings{chen2024pixartalpha,
  address =      {Vienna, Austria},
  author =       {Chen, Junsong and Yu, Jincheng and Ge, Chongjian and
                  Yao, Lewei and Xie, Enze and Wang, Zhongdao and
                  Kwok, James T. and Luo, Ping and Lu, Huchuan and Li,
                  Zhenguo},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=eAKmQPe3m1}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {PixArt-α: Fast Training of Diffusion Transformer for
                  Photorealistic Text-to-Image Synthesis},
  year =         2024
}

@inproceedings{chen2024positional,
  address =      {Vienna, Austria},
  author =       {Chen, Junfeng and Wu, Kailiang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=VOcsmIBiXE}},
  publisher =    {OpenReview.net},
  title =        {Positional Knowledge is All You Need:
                  Position-induced Transformer (PiT) for Operator
                  Learning},
  year =         2024
}

@inproceedings{chen2024recursive,
  address =      {Vienna, Austria},
  author =       {Chen, Zheng and Zhang, Yulun and Gu, Jinjin and
                  Kong, Linghe and Yang, Xiaokang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=owziuM1nsR}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Recursive Generalization Transformer for Image
                  Super-Resolution},
  year =         2024
}

@inproceedings{chen2024selfattention,
  address =      {Vienna, Austria},
  author =       {Chen, Yingyi and Tao, Qinghua and Tonin, Francesco
                  and Suykens, Johan A. K.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=4RqG4K5UwL}},
  publisher =    {OpenReview.net},
  title =        {Self-Attention through Kernel-Eigen Pair Sparse
                  Variational Gaussian Processes},
  year =         2024
}

@inproceedings{chen2024what,
  address =      {Vienna, Austria},
  author =       {Chen, Xingwu and Zou, Difan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=YNbCbcGyXE}},
  publisher =    {OpenReview.net},
  title =        {What Can Transformer Learn with Varying Depth? Case
                  Studies on Sequence Learning Tasks},
  year =         2024
}

@inproceedings{cheng2024transformers,
  address =      {Vienna, Austria},
  author =       {Cheng, Xiang and Chen, Yuxin and Sra, Suvrit},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ah1BlQcLv4}},
  publisher =    {OpenReview.net},
  title =        {Transformers Implement Functional Gradient Descent
                  to Learn Non-Linear Functions In Context},
  year =         2024
}

@inproceedings{chi2020relationnet,
  address =      {Virtual Event},
  author =       {Chi, Cheng and Wei, Fangyun and Hu, Han},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/9d684c589d67031a627ad33d59db65e5-Paper.pdf}},
  pages =        {13564--13574},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {RelationNet++: Bridging Visual Representations for
                  Object Detection via Transformer Decoder},
  volume =       33,
  year =         2020
}

@inproceedings{chiang2023tighter,
  address =      {Honolulu, Hawaii, USA},
  author =       {Chiang, David and Cholak, Peter},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/chiang23a.html}},
  pages =        {5544--5562},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Tighter Bounds on the Expressivity of Transformer
                  Encoders},
  volume =       202,
  year =         2023
}

@inproceedings{chiappa2022dmap,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chiappa, Alberto Silvio and Marin Vargas, Alessandro
                  and Mathis, Alexander},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/f0fae49cdfab57c41c30c9b0244093cb-Paper-Conference.pdf}},
  pages =        {37214--37227},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DMAP: a Distributed Morphological Attention Policy
                  for learning to locomote with a changing body},
  volume =       35,
  year =         2022
}

@inproceedings{chiu2018monotonic,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Chiu, Chung-Cheng and Raffel, Colin},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Hko85plCW}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Monotonic Chunkwise Attention},
  year =         2018
}

@inproceedings{chiu2023flexible,
  address =      {New Orleans, Louisiana, USA},
  author =       {Chiu, Zih-Yun and Tuan, Yi-Lin and Wang, William
                  Yang and Yip, Michael},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/2c23b3c72127e15fedc276722faee927-Paper-Conference.pdf}},
  pages =        {13590--13612},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Flexible Attention-Based Multi-Policy Fusion for
                  Efficient Deep Reinforcement Learning},
  volume =       36,
  year =         2023
}

@inproceedings{chizhov2023selfsupervised,
  address =      {Kigali, Rwanda},
  author =       {Chizhov, Pavel and Papkov, Mikhail},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=EARgl3EH-nq}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Self-Supervised Image Denoising with Swin
                  Transformer},
  year =         2023
}

@inproceedings{cho2021cats,
  address =      {Virtual Event},
  author =       {Cho, Seokju and Hong, Sunghwan and Jeon, Sangryul
                  and Lee, Yunsung and Sohn, Kwanghoon and Kim,
                  Seungryong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4b6538a44a1dfdc2b83477cd76dee98e-Paper.pdf}},
  pages =        {9011--9023},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CATs: Cost Aggregation Transformers for Visual
                  Correspondence},
  volume =       34,
  year =         2021
}

@inproceedings{cho2022transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cho, Sungjun and Min, Seonwoo and Kim, Jinwoo and
                  Lee, Moontae and Lee, Honglak and Hong, Seunghoon},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/9c93b3cd3bc60c0fe7b0c2d74a2da966-Paper-Conference.pdf}},
  pages =        {24706--24719},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers meet Stochastic Block Models: Attention
                  with Data-Adaptive Sparsity and Cost},
  volume =       35,
  year =         2022
}

@inproceedings{cho2024spatiallyaware,
  address =      {Vienna, Austria},
  author =       {Cho, Junmo and Yoon, Jaesik and Ahn, Sungjin},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Ts95eXsPBc}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spatially-Aware Transformers for Embodied Agents},
  year =         2024
}

@inproceedings{choi2016retain,
  address =      {Barcelona, Spain},
  author =       {Choi, Edward and Bahadori, Mohammad Taha and Sun,
                  Jimeng and Kulas, Joshua and Schuetz, Andy and
                  Stewart, Walter},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/231141b34c82aa95e48810a9d1b33a79-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {RETAIN: An Interpretable Predictive Model for
                  Healthcare using Reverse Time Attention Mechanism},
  volume =       29,
  year =         2016
}

@inproceedings{choi2020encoding,
  address =      {Virtual Event},
  author =       {Choi, Kristy and Hawthorne, Curtis and Simon, Ian
                  and Dinculescu, Monica and Engel, Jesse H.},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/choi20b.html}},
  pages =        {1899--1908},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Encoding Musical Style with Transformer
                  Autoencoders},
  volume =       119,
  year =         2020
}

@inproceedings{choi2022tokenmixup,
  address =      {New Orleans, Louisiana, USA},
  author =       {Choi, Hyeong Kyu and Choi, Joonmyung and Kim,
                  Hyunwoo},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5bd09a559a8c8e230697107b0f353d39-Paper-Conference.pdf}},
  pages =        {14224--14235},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TokenMixup: Efficient Attention-guided Token-level
                  Data Augmentation for Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{choromanski2021rethinking,
  address =      {Virtual Event, Austria},
  author =       {Choromanski, Krzysztof Marcin and Likhosherstov,
                  Valerii and Dohan, David and Song, Xingyou and Gane,
                  Andreea and Sarlós, Tamás and Hawkins, Peter and
                  Davis, Jared Quincy and Mohiuddin, Afroz and Kaiser,
                  Lukasz and Belanger, David Benjamin and Colwell,
                  Lucy J. and Weller, Adrian},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Ua6zuk0WRH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Rethinking Attention with Performers},
  year =         2021
}

@inproceedings{choromanski2022from,
  address =      {Baltimore, Maryland, USA},
  author =       {Choromanski, Krzysztof and Lin, Han and Chen,
                  Haoxian and Zhang, Tianyi and Sehanobish, Arijit and
                  Likhosherstov, Valerii and Parker-Holder, Jack and
                  Sarlós, Tamás and Weller, Adrian and Weingarten,
                  Thomas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/choromanski22a.html}},
  pages =        {3962--3983},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {From Block-Toeplitz Matrices to Differential
                  Equations on Graphs: Towards a General Theory for
                  Scalable Masked Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{chorowski2015attention,
  address =      {Montreal, Quebec, Canada},
  author =       {Chorowski, Jan K. and Bahdanau, Dzmitry and Serdyuk,
                  Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle =    {Advances in Neural Information Processing Systems 28
                  (NIPS)},
  editor =       {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2015/file/1068c6e4c8051cfd4e9ea8072e3189e2-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention-Based Models for Speech Recognition},
  volume =       28,
  year =         2015
}

@inproceedings{choukroun2022error,
  address =      {New Orleans, Louisiana, USA},
  author =       {Choukroun, Yoni and Wolf, Lior},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/fcd3909db30887ce1da519c4468db668-Paper-Conference.pdf}},
  pages =        {38695--38705},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Error Correction Code Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{chowdhury2023monotonic,
  address =      {Honolulu, Hawaii, USA},
  author =       {Chowdhury, Jishnu Ray and Caragea, Cornelia},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/ray-chowdhury23b.html}},
  pages =        {28792--28808},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Monotonic Location Attention for Length
                  Generalization},
  volume =       202,
  year =         2023
}

@inproceedings{chu2021twins,
  address =      {Virtual Event},
  author =       {Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and
                  Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia,
                  Huaxia and Shen, Chunhua},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4e0928de075538c593fbdabb0c5ef2c3-Paper.pdf}},
  pages =        {9355--9366},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Twins: Revisiting the Design of Spatial Attention in
                  Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{chu2023conditional,
  address =      {Kigali, Rwanda},
  author =       {Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and
                  Wang, Xinlong and Shen, Chunhua},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3KWnuT-R1bh}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Conditional Positional Encodings for Vision
                  Transformers},
  year =         2023
}

@inproceedings{clift2020logic,
  address =      {Addis Ababa, Ethiopia},
  author =       {Clift, James and Doryn, Dmitry and Murfet, Daniel
                  and Wallbridge, James},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rkecJ6VFvr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Logic and the 2-Simplicial Transformer},
  year =         2020
}

@inproceedings{cong2022satmae,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cong, Yezhen and Khanna, Samar and Meng, Chenlin and
                  Liu, Patrick and Rozi, Erik and He, Yutong and
                  Burke, Marshall and Lobell, David and Ermon,
                  Stefano},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/01c561df365429f33fcd7a7faa44c985-Paper-Conference.pdf}},
  pages =        {197--211},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SatMAE: Pre-training Transformers for Temporal and
                  Multi-Spectral Satellite Imagery},
  volume =       35,
  year =         2022
}

@inproceedings{cong2024flatten,
  address =      {Vienna, Austria},
  author =       {Cong, Yuren and Xu, Mengmeng and Simon, Christian
                  and Chen, Shoufa and Ren, Jiawei and Xie, Yanping
                  and Pérez-Rúa, Juan-Manuel and Rosenhahn, Bodo and
                  Xiang, Tao and He, Sen},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=JgqftqZQZ7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {FLATTEN: optical FLow-guided ATTENtion for
                  consistent text-to-video editing},
  year =         2024
}

@inproceedings{cordonnier2020on,
  address =      {Addis Ababa, Ethiopia},
  author =       {Cordonnier, Jean-Baptiste and Loukas, Andreas and
                  Jaggi, Martin},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HJlnC1rKPB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {On the Relationship between Self-Attention and
                  Convolutional Layers},
  year =         2020
}

@inproceedings{covert2023learning,
  address =      {Kigali, Rwanda},
  author =       {Covert, Ian Connick and Kim, Chanwoo and Lee, Su-In},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=5ktFNz_pJLK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning to Estimate Shapley Values with Vision
                  Transformers},
  year =         2023
}

@inproceedings{crowson2024scalable,
  address =      {Vienna, Austria},
  author =       {Crowson, Katherine and Baumann, Stefan Andreas and
                  Birch, Alex and Abraham, Tanishq Mathew and Kaplan,
                  Daniel Z. and Shippole, Enrico},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=WRIn2HmtBS}},
  publisher =    {OpenReview.net},
  title =        {Scalable High-Resolution Pixel-Space Image Synthesis
                  with Hourglass Diffusion Transformers},
  year =         2024
}

@inproceedings{csordas2022neural,
  address =      {Virtual Event},
  author =       {Csordás, Róbert and Irie, Kazuki and Schmidhuber,
                  Jürgen},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=KBQP4A_J1K}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {The Neural Data Router: Adaptive Control Flow in
                  Transformers Improves Systematic Generalization},
  year =         2022
}

@inproceedings{cui2023bayesmil,
  address =      {Kigali, Rwanda},
  author =       {Cui, Yufei and Liu, Ziquan and Liu, Xiangyu and Liu,
                  Xue and Wang, Cong and Kuo, Tei-Wei and Xue, Chun
                  Jason and Chan, Antoni B.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=_geIwiOyUhZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Bayes-MIL: A New Probabilistic Perspective on
                  Attention-based Multiple Instance Learning for Whole
                  Slide Images},
  year =         2023
}

@inproceedings{cui2023learning,
  address =      {Honolulu, Hawaii, USA},
  author =       {Cui, Yiming and Yang, Linjie and Yu, Haichao},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/cui23f.html}},
  pages =        {6591--6602},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning Dynamic Query Combinations for
                  Transformer-based Object Detection and Segmentation},
  volume =       202,
  year =         2023
}

@inproceedings{cui2023mixformerv2,
  address =      {New Orleans, Louisiana, USA},
  author =       {Cui, Yutao and Song, Tianhui and Wu, Gangshan and
                  Wang, Limin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b7870bd43b2d133a1ed95582ae5d82a4-Paper-Conference.pdf}},
  pages =        {58736--58751},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MixFormerV2: Efficient Fully Transformer Tracking},
  volume =       36,
  year =         2023
}

@inproceedings{dai2020funnel,
  address =      {Virtual Event},
  author =       {Dai, Zihang and Lai, Guokun and Yang, Yiming and Le,
                  Quoc},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {Larochelle, H. and Ranzato, M. and Hadsell, R. and
                  Balcan, M.F. and Lin, H.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/2cd2915e69546904e4e5d4a2ac9e1652-Paper.pdf}},
  pages =        {4271--4282},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Funnel-Transformer: Filtering out Sequential
                  Redundancy for Efficient Language Processing},
  volume =       33,
  year =         2020
}

@inproceedings{dai2021coatnet,
  address =      {Virtual Event},
  author =       {Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan,
                  Mingxing},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/20568692db622456cc42a2e853ca21f8-Paper.pdf}},
  pages =        {3965--3977},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CoAtNet: Marrying Convolution and Attention for All
                  Data Sizes},
  volume =       34,
  year =         2021
}

@inproceedings{dai2024graphical,
  address =      {Vienna, Austria},
  author =       {Dai, Yijue and Yan, Wenzhong and Yin, Feng},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=6N8TW504aa}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Graphical Multioutput Gaussian Process with
                  Attention},
  year =         2024
}

@inproceedings{daniluk2017frustratingly,
  address =      {Toulon, France},
  author =       {Daniluk, Michal and Rocktäschel, Tim and Welbl,
                  Johannes and Riedel, Sebastian},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=ByIAPUcee}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Frustratingly Short Attention Spans in Neural
                  Language Modeling},
  year =         2017
}

@inproceedings{dao2022flashattention,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra,
                  Atri and Ré, Christopher},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf}},
  pages =        {16344--16359},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {FlashAttention: Fast and Memory-Efficient Exact
                  Attention with IO-Awareness},
  volume =       35,
  year =         2022
}

@inproceedings{dao2024flashattention,
  address =      {Vienna, Austria},
  author =       {Dao, Tri},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=mZn2Xyh9Ec}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {FlashAttention-2: Faster Attention with Better
                  Parallelism and Work Partitioning},
  year =         2024
}

@inproceedings{dao2024transformers,
  address =      {Vienna, Austria},
  author =       {Dao, Tri and Gu, Albert},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ztn8FCR1td}},
  publisher =    {OpenReview.net},
  title =        {Transformers are SSMs: Generalized Models and
                  Efficient Algorithms Through Structured State Space
                  Duality},
  year =         2024
}

@inproceedings{daras2020smyrf,
  address =      {Virtual Event},
  author =       {Daras, Giannis and Kitaev, Nikita and Odena,
                  Augustus and Dimakis, Alexandros G.},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/47d40767c7e9df50249ebfd9c7cfff77-Paper.pdf}},
  pages =        {6476--6489},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SMYRF - Efficient Attention using Asymmetric
                  Clustering},
  volume =       33,
  year =         2020
}

@inproceedings{darcet2024vision,
  address =      {Vienna, Austria},
  author =       {Darcet, Timothée and Oquab, Maxime and Mairal,
                  Julien and Bojanowski, Piotr},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=2dnO3LLiJ1}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Vision Transformers Need Registers},
  year =         2024
}

@inproceedings{darrell1995active,
  address =      {Denver, Colorado, USA},
  author =       {Darrell, Trevor and Pentland, Alex},
  booktitle =    {Advances in Neural Information Processing Systems 8
                  (NIPS)},
  editor =       {Touretzky, David and Mozer, Michael C. and Hasselmo,
                  Michael},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1995/file/43baa6762fa81bb43b39c62553b2970d-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Active Gesture Recognition using Learned Visual
                  Attention},
  volume =       8,
  year =         1995
}

@inproceedings{dascoli2021convit,
  address =      {Virtual Event},
  author =       {d'Ascoli, Stéphane and Touvron, Hugo and Leavitt,
                  Matthew L. and Morcos, Ari S. and Biroli, Giulio and
                  Sagun, Levent},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/d-ascoli21a.html}},
  pages =        {2286--2296},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {ConViT: Improving Vision Transformers with Soft
                  Convolutional Inductive Biases},
  volume =       139,
  year =         2021
}

@inproceedings{dascoli2024odeformer,
  address =      {Vienna, Austria},
  author =       {d'Ascoli, Stéphane and Becker, Sören and Schwaller,
                  Philippe and Alex, and Mathis, er and Kilbertus,
                  Niki},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=TzoHLiGVMo}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ODEFormer: Symbolic Regression of Dynamical Systems
                  with Transformers},
  year =         2024
}

@inproceedings{dasoulas2021lipschitz,
  address =      {Virtual Event},
  author =       {Dasoulas, George and Scaman, Kevin and Virmaux,
                  Aladin},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/dasoulas21a.html}},
  pages =        {2456--2466},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Lipschitz normalization for self-attention layers
                  with application to graph neural networks},
  volume =       139,
  year =         2021
}

@inproceedings{davies2021kernel,
  address =      {Virtual Event},
  author =       {Simpson, Fergus and Davies, Ian and Lalchand, Vidhi
                  and Vullo, Alessandro and Durrande, Nicolas and
                  Rasmussen, Carl Edward},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/56c3b2c6ea3a83aaeeff35eeb45d700d-Paper.pdf}},
  pages =        {10483--10495},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Kernel Identification Through Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{davis2021catformer,
  address =      {Virtual Event},
  author =       {Davis, Jared Quincy and Gu, Albert and Choromanski,
                  Krzysztof and Dao, Tri and Ré, Christopher and Finn,
                  Chelsea and Liang, Percy},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/davis21a.html}},
  pages =        {2489--2499},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Catformer: Designing Stable Transformers via
                  Sensitivity Analysis},
  volume =       139,
  year =         2021
}

@inproceedings{deco1999neurodynamical,
  address =      {Denver, Colorado, USA},
  author =       {Deco, Gustavo and Zihl, Josef},
  booktitle =    {Advances in Neural Information Processing Systems 12
                  (NIPS)},
  editor =       {S. Solla and T. Leen and K. Müller},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1999/file/b3bbccd6c008e727785cb81b1aa08ac5-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {A Neurodynamical Approach to Visual Attention},
  volume =       12,
  year =         1999
}

@inproceedings{dedieu2024learning,
  address =      {Vienna, Austria},
  author =       {Dedieu, Antoine and Lehrach, Wolfgang and Zhou,
                  Guangyao and George, Dileep and Lázaro-Gredilla,
                  Miguel},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=JUa5XNXuoT}},
  publisher =    {OpenReview.net},
  title =        {Learning Cognitive Maps from Transformer
                  Representations for Efficient Planning in Partially
                  Observed Environments},
  year =         2024
}

@inproceedings{dehghani2019universal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dehghani, Mostafa and Gouws, Stephan and Vinyals,
                  Oriol and Uszkoreit, Jakob and Kaiser, Lukasz},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HyzdRiR9Y7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Universal Transformers},
  year =         2019
}

@inproceedings{dehghani2023patch,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dehghani, Mostafa and Mustafa, Basil and Djolonga,
                  Josip and Heek, Jonathan and Minderer, Matthias and
                  Caron, Mathilde and Steiner, Andreas and Puigcerver,
                  Joan and Geirhos, Robert and Alabdulmohsin, Ibrahim
                  M and Oliver, Avital and Padlewski, Piotr and
                  Gritsenko, Alexey and Lucic, Mario and Houlsby,
                  Neil},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/06ea400b9b7cfce6428ec27a371632eb-Paper-Conference.pdf}},
  pages =        {2252--2274},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Patch nâ€™ Pack: NaViT, a Vision Transformer for any
                  Aspect Ratio and Resolution},
  volume =       36,
  year =         2023
}

@inproceedings{dehghani2023scaling,
  address =      {Honolulu, Hawaii, USA},
  author =       {Dehghani, Mostafa and Djolonga, Josip and Mustafa,
                  Basil and Padlewski, Piotr and Heek, Jonathan and
                  Gilmer, Justin and Steiner, Andreas Peter and Caron,
                  Mathilde and Geirhos, Robert and Alabdulmohsin,
                  Ibrahim and Jenatton, Rodolphe and Beyer, Lucas and
                  Tschannen, Michael and Arnab, Anurag and Wang, Xiao
                  and Ruiz, Carlos Riquelme and Minderer, Matthias and
                  Puigcerver, Joan and Evci, Utku and Kumar, Manoj and
                  Steenkiste, Sjoerd van and Elsayed, Gamaleldin Fathy
                  and Mahendran, Aravindh and Yu, Fisher and Oliver,
                  Avital and Huot, Fantine and Bastings, Jasmijn and
                  Collier, Mark and Gritsenko, Alexey A. and Birodkar,
                  Vighnesh and Vasconcelos, Cristina Nader and Tay, Yi
                  and Mensink, Thomas and Alex, and Kolesnikov, er and
                  Pavetic, Filip and Tran, Dustin and Kipf, Thomas and
                  Lucic, Mario and Zhai, Xiaohua and Keysers, Daniel
                  and Harmsen, Jeremiah J. and Houlsby, Neil},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/dehghani23a.html}},
  pages =        {7480--7512},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Scaling Vision Transformers to 22 Billion
                  Parameters},
  volume =       202,
  year =         2023
}

@inproceedings{deiseroth2023atman,
  address =      {New Orleans, Louisiana, USA},
  author =       {Deiseroth, Björn and Deb, Mayukh and Weinbach,
                  Samuel and Brack, Manuel and Schramowski, Patrick
                  and Kersting, Kristian},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/c83bc020a020cdeb966ed10804619664-Paper-Conference.pdf}},
  pages =        {63437--63460},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ATMAN: Understanding Transformer Predictions Through
                  Memory Efficient Attention Manipulation},
  volume =       36,
  year =         2023
}

@inproceedings{del2020ratt,
  address =      {Virtual Event},
  author =       {Del Chiaro, Riccardo and Twardowski, Bartłomiej and
                  Bagdanov, Andrew and van de Weijer, Joost},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/c2964caac096f26db222cb325aa267cb-Paper.pdf}},
  pages =        {16736--16748},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {RATT: Recurrent Attention to Transient Tasks for
                  Continual Image Captioning},
  volume =       33,
  year =         2020
}

@inproceedings{delmas2022artemis,
  address =      {Virtual Event},
  author =       {Delmas, Ginger and Rezende, Rafael Sampaio de and
                  Csurka, Gabriela and Larlus, Diane},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=CVfLvQq9gLo}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ARTEMIS: Attention-based Retrieval with
                  Text-Explicit Matching and Implicit Similarity},
  year =         2022
}

@inproceedings{deng2017imagetomarkup,
  address =      {Sydney, Australia},
  author =       {Deng, Yuntian and Kanervisto, Anssi and Ling,
                  Jeffrey and Alex and Rush, er M.},
  booktitle =    {Proceedings of the 34th International Conference on
                  Machine Learning (ICML)},
  editor =       {Precup, Doina and Teh, Yee Whye},
  month =        {August},
  note =         {\url{http://proceedings.mlr.press/v70/deng17a.html}},
  pages =        {980--989},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Image-to-Markup Generation with Coarse-to-Fine
                  Attention},
  volume =       70,
  year =         2017
}

@inproceedings{deng2018latent,
  address =      {Montreal, Quebec, Canada},
  author =       {Deng, Yuntian and Kim, Yoon and Chiu, Justin and
                  Guo, Demi and Rush, Alexander},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/b691334ccf10d4ab144d672f7783c8a3-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Latent Alignment and Variational Attention},
  volume =       31,
  year =         2018
}

@inproceedings{deng2020cascaded,
  address =      {Virtual Event},
  author =       {Deng, Yuntian and Rush, Alexander},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/01a0683665f38d8e5e567b3b15ca98bf-Paper.pdf}},
  pages =        {170--181},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cascaded Text Generation with Markov Transformers},
  volume =       33,
  year =         2020
}

@inproceedings{deng2023facing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Deng, Fei and Park, Junyeong and Ahn, Sungjin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e6c65eb9b56719c1aa45ff73874de317-Paper-Conference.pdf}},
  pages =        {72904--72930},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Facing Off World Model Backbones: RNNs,
                  Transformers, and S4},
  volume =       36,
  year =         2023
}

@inproceedings{deng2024polynormer,
  address =      {Vienna, Austria},
  author =       {Deng, Chenhui and Yue, Zichao and Zhang, Zhiru},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=hmv1LpNfXa}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Polynormer: Polynomial-Expressive Graph Transformer
                  in Linear Time},
  year =         2024
}

@inproceedings{dettmers2022gpt3,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dettmers, Tim and Lewis, Mike and Belkada, Younes
                  and Zettlemoyer, Luke},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c3ba4962c05c49636d4c6206a97e9c8a-Paper-Conference.pdf}},
  pages =        {30318--30332},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {GPT3.int8(): 8-bit Matrix Multiplication for
                  Transformers at Scale},
  volume =       35,
  year =         2022
}

@inproceedings{diao2023relational,
  address =      {Kigali, Rwanda},
  author =       {Diao, Cameron and Loynd, Ricky},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cFuMmbWiN6}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Relational Attention: Generalizing Transformers for
                  Graph-Structured Tasks},
  year =         2023
}

@inproceedings{ding2021attention,
  address =      {Virtual Event},
  author =       {Ding, David and Hill, Felix and Santoro, Adam and
                  Reynolds, Malcolm and Botvinick, Matt},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4c26774d852f62440fc746ea4cdd57f6-Paper.pdf}},
  pages =        {9112--9124},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention over Learned Object Embeddings Enables
                  Complex Visual Reasoning},
  volume =       34,
  year =         2021
}

@inproceedings{ding2021cogview,
  address =      {Virtual Event},
  author =       {Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and
                  Zheng, Wendi and Zhou, Chang and Yin, Da and Lin,
                  Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia
                  and Tang, Jie},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a4d92e2cd541fca87e4620aba658316d-Paper.pdf}},
  pages =        {19822--19835},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CogView: Mastering Text-to-Image Generation via
                  Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{ding2022cogview2,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ding, Ming and Zheng, Wendi and Hong, Wenyi and
                  Tang, Jie},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/6baec7c4ba0a8734ccbd528a8090cb1f-Paper-Conference.pdf}},
  pages =        {16890--16902},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CogView2: Faster and Better Text-to-Image Generation
                  via Hierarchical Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{ding2024delving,
  address =      {Vienna, Austria},
  author =       {Ding, Youlong and Wu, Xueyang and Meng, Yining and
                  Luo, Yonggang and Wang, Hao and Pan, Weike},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=FzyMdAm2fZ}},
  publisher =    {OpenReview.net},
  title =        {Delving into Differentially Private Transformer},
  year =         2024
}

@inproceedings{dong2021attention,
  address =      {Virtual Event},
  author =       {Dong, Yihe and Cordonnier, Jean-Baptiste and Loukas,
                  Andreas},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/dong21a.html}},
  pages =        {2793--2803},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Attention is not all you need: pure attention loses
                  rank doubly exponentially with depth},
  volume =       139,
  year =         2021
}

@inproceedings{dong2022mssvt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dong, Shaocong and Ding, Lihe and Wang, Haiyang and
                  Xu, Tingfa and Xu, Xinli and Wang, Jie and Bian,
                  Ziyang and Wang, Ying and Li, Jianan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4bad7c27534efca029ca0d366c47c0e3-Paper-Conference.pdf}},
  pages =        {11615--11628},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MsSVT: Mixed-scale Sparse Voxel Transformer for 3D
                  Object Detection on Point Clouds},
  volume =       35,
  year =         2022
}

@inproceedings{dong2023autoencoders,
  address =      {Kigali, Rwanda},
  author =       {Dong, Runpei and Qi, Zekun and Zhang, Linfeng and
                  Zhang, Junbo and Sun, Jianjian and Ge, Zheng and Yi,
                  Li and Ma, Kaisheng},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=8Oun8ZUVe8N}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Autoencoders as Cross-Modal Teachers: Can Pretrained
                  2D Image Transformers Help 3D Representation
                  Learning?},
  year =         2023
}

@inproceedings{dong2023efficient,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dong, Wei and Yan, Dawei and Lin, Zhijun and Wang,
                  Peng},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a4ca07aa108036f80cbb5b82285fd4b1-Paper-Conference.pdf}},
  pages =        {52548--52567},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Efficient Adaptation of Large Vision Transformer via
                  Adapter Re-Composing},
  volume =       36,
  year =         2023
}

@inproceedings{dong2023hotbev,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dong, Peiyan and Kong, Zhenglun and Meng, Xin and
                  Yu, Pinrui and Gong, Yifan and Yuan, Geng and Tang,
                  Hao and Wang, Yanzhi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/081b08068e4733ae3e7ad019fe8d172f-Paper-Conference.pdf}},
  pages =        {2824--2836},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {HotBEV: Hardware-oriented Transformer-based
                  Multi-View 3D Detector for BEV Perception},
  volume =       36,
  year =         2023
}

@inproceedings{dong2023packqvit,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dong, Peiyan and Lu, Lei and Wu, Chao and Lyu, Cheng
                  and Yuan, Geng and Tang, Hao and Wang, Yanzhi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1c92edb990a05f2269f0cc3afbb4c952-Paper-Conference.pdf}},
  pages =        {9015--9028},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {PackQViT: Faster Sub-8-bit Vision Transformers via
                  Full and Packed Quantization on the Mobile},
  volume =       36,
  year =         2023
}

@inproceedings{dong2023speeddetr,
  address =      {Honolulu, Hawaii, USA},
  author =       {Dong, Peiyan and Kong, Zhenglun and Meng, Xin and
                  Zhang, Peng and Tang, Hao and Wang, Yanzhi and Chou,
                  Chih-Hsien},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/dong23b.html}},
  pages =        {8227--8243},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {SpeedDETR: Speed-aware Transformers for End-to-end
                  Object Detection},
  volume =       202,
  year =         2023
}

@inproceedings{dosovitskiy2021image,
  address =      {Virtual Event, Austria},
  author =       {Dosovitskiy, Alexey and Beyer, Lucas and Alex, and
                  Kolesnikov, er and Weissenborn, Dirk and Zhai,
                  Xiaohua and Unterthiner, Thomas and Dehghani,
                  Mostafa and Minderer, Matthias and Heigold, Georg
                  and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby,
                  Neil},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=YicbFdNTTy}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {An Image is Worth 16x16 Words: Transformers for
                  Image Recognition at Scale},
  year =         2021
}

@inproceedings{dozat2017deep,
  address =      {Toulon, France},
  author =       {Dozat, Timothy and Manning, Christopher D.},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Hk95PK9le}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Deep Biaffine Attention for Neural Dependency
                  Parsing},
  year =         2017
}

@inproceedings{du2021vtnet,
  address =      {Virtual Event, Austria},
  author =       {Du, Heming and Yu, Xin and Zheng, Liang},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=DILxQP08O3B}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {VTNet: Visual Transformer Network for Object Goal
                  Navigation},
  year =         2021
}

@inproceedings{duan2022contextintegrated,
  address =      {Baltimore, Maryland, USA},
  author =       {Duan, Zhijian and Tang, Jingwu and Yin, Yutong and
                  Feng, Zhe and Yan, Xiang and Zaheer, Manzil and
                  Deng, Xiaotie},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/duan22a.html}},
  pages =        {5609--5626},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {A Context-Integrated Transformer-Based Neural
                  Network for Auction Design},
  volume =       162,
  year =         2022
}

@inproceedings{duan2023condaformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Duan, Lunhao and Zhao, Shanshan and Xue, Nan and
                  Gong, Mingming and Xia, Gui-Song and Tao, Dacheng},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4b4f1272c73d5afd222b6dd3391c3f77-Paper-Conference.pdf}},
  pages =        {23886--23901},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ConDaFormer: Disassembled Transformer with Local
                  Structure Enhancement for 3D Point Cloud
                  Understanding},
  volume =       36,
  year =         2023
}

@inproceedings{dunefsky2024observable,
  address =      {Vienna, Austria},
  author =       {Dunefsky, Jacob and Cohan, Arman},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ETNx4SekbY}},
  publisher =    {OpenReview.net},
  title =        {Observable Propagation: Uncovering Feature Vectors
                  in Transformers},
  year =         2024
}

@inproceedings{dusell2024stack,
  address =      {Vienna, Austria},
  author =       {DuSell, Brian and Chiang, David},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=XVhm3X8Fum}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Stack Attention: Improving the Ability of
                  Transformers to Model Hierarchical Patterns},
  year =         2024
}

@inproceedings{dutta2021redesigning,
  address =      {Virtual Event},
  author =       {Dutta, Subhabrata and Gautam, Tanya and Chakrabarti,
                  Soumen and Chakraborty, Tanmoy},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2bd388f731f26312bfc0fe30da009595-Paper.pdf}},
  pages =        {5531--5544},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Redesigning the Transformer Architecture with
                  Insights from Multi-particle Dynamical Systems},
  volume =       34,
  year =         2021
}

@inproceedings{dziri2023faith,
  address =      {New Orleans, Louisiana, USA},
  author =       {Dziri, Nouha and Lu, Ximing and Sclar, Melanie and
                  Li, Xiang (Lorraine) and Jiang, Liwei and Lin, Bill
                  Yuchen and Welleck, Sean and West, Peter and
                  Bhagavatula, Chandra and Le Bras, Ronan and Hwang,
                  Jena and Sanyal, Soumya and Ren, Xiang and Ettinger,
                  Allyson and Harchaoui, Zaid and Choi, Yejin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/deb3c28192f979302c157cb653c15e90-Paper-Conference.pdf}},
  pages =        {70293--70332},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Faith and Fate: Limits of Transformers on
                  Compositionality},
  volume =       36,
  year =         2023
}

@inproceedings{edelman2022inductive,
  address =      {Baltimore, Maryland, USA},
  author =       {Edelman, Benjamin L. and Goel, Surbhi and Kakade,
                  Sham M. and Zhang, Cyril},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/edelman22a.html}},
  pages =        {5793--5831},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Inductive Biases and Variable Creation in
                  Self-Attention Mechanisms},
  volume =       162,
  year =         2022
}

@inproceedings{elbayad2020depthadaptive,
  address =      {Addis Ababa, Ethiopia},
  author =       {Elbayad, Maha and Gu, Jiatao and Grave, Edouard and
                  Auli, Michael},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=SJg7KhVKPH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Depth-Adaptive Transformer},
  year =         2020
}

@inproceedings{eldele2024tslanet,
  address =      {Vienna, Austria},
  author =       {Eldele, Emadeldeen and Ragab, Mohamed and Chen,
                  Zhenghua and Wu, Min and Li, Xiaoli},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=CGR3vpX63X}},
  publisher =    {OpenReview.net},
  title =        {TSLANet: Rethinking Transformers for Time Series
                  Representation Learning},
  year =         2024
}

@inproceedings{elsayed2019saccader,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Elsayed, Gamaleldin and Kornblith, Simon and Le,
                  Quoc V.},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/8dd48d6a2e2cad213179a3992c0be53c-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Saccader: Improving Accuracy of Hard Attention
                  Models for Vision},
  volume =       32,
  year =         2019
}

@inproceedings{ermis2022memory,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ermis, Beyza and Zappella, Giovanni and Wistuba,
                  Martin and Rawal, Aditya and Archambeau, Cedric},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4522de4178bddb36b49aa26efad537cf-Paper-Conference.pdf}},
  pages =        {10629--10642},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Memory Efficient Continual Learning with
                  Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{esser2024scaling,
  address =      {Vienna, Austria},
  author =       {Esser, Patrick and Kulal, Sumith and Blattmann,
                  Andreas and Entezari, Rahim and Müller, Jonas and
                  Saini, Harry and Levi, Yam and Lorenz, Dominik and
                  Sauer, Axel and Boesel, Frederic and Podell, Dustin
                  and Dockhorn, Tim and English, Zion and Rombach,
                  Robin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=FPnUhsQJ5B}},
  publisher =    {OpenReview.net},
  title =        {Scaling Rectified Flow Transformers for
                  High-Resolution Image Synthesis},
  year =         2024
}

@inproceedings{esteves2018polar,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Esteves, Carlos and Allen-Blanchette, Christine and
                  Zhou, Xiaowei and Daniilidis, Kostas},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HktRlUlAZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Polar Transformer Networks},
  year =         2018
}

@inproceedings{fan2020bayesian,
  address =      {Virtual Event},
  author =       {Fan, Xinjie and Zhang, Shujian and Chen, Bo and
                  Zhou, Mingyuan},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and H. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/bcff3f632fd16ff099a49c2f0932b47a-Paper.pdf}},
  pages =        {16362--16376},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Bayesian Attention Modules},
  volume =       33,
  year =         2020
}

@inproceedings{fan2020reducing,
  address =      {Addis Ababa, Ethiopia},
  author =       {Fan, Angela and Grave, Edouard and Arm, and Joulin,
                  },
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=SylO2yStDr}},
  series =       {Conference Track Proceedings},
  title =        {Reducing Transformer Depth on Demand with Structured
                  Dropout},
  year =         2020
}

@inproceedings{fan2023lightweight,
  address =      {New Orleans, Louisiana, USA},
  author =       {Fan, Qihang and Huang, Huaibo and Zhou, Xiaoqiang
                  and He, Ran},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/3170de57bc1899315b97712043d8bb22-Paper-Conference.pdf}},
  pages =        {15234--15251},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Lightweight Vision Transformer with Bidirectional
                  Interaction},
  volume =       36,
  year =         2023
}

@inproceedings{fang2021you,
  address =      {Virtual Event},
  author =       {Fang, Yuxin and Liao, Bencheng and Wang, Xinggang
                  and Fang, Jiemin and Qi, Jiyang and Wu, Rui and Niu,
                  Jianwei and Liu, Wenyu},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/dc912a253d1e9ba40e2c597ed2376640-Paper.pdf}},
  pages =        {26183--26197},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {You Only Look at One Sequence: Rethinking
                  Transformer in Vision through Object Detection},
  volume =       34,
  year =         2021
}

@inproceedings{fang2023crosslayer,
  address =      {Kigali, Rwanda},
  author =       {Fang, Yanwen and Cai, Yuxi and Chen, Jintai and
                  Zhao, Jingyu and Tian, Guangjian and Li, Guodong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=pvgEL1yS3Ql}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Cross-Layer Retrospective Retrieving via Layer
                  Attention},
  year =         2023
}

@inproceedings{fang2023daspeech,
  address =      {New Orleans, Louisiana, USA},
  author =       {Fang, Qingkai and Zhou, Yan and Feng, Yang},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e5b1c0d4866f72393c522c8a00eed4eb-Paper-Conference.pdf}},
  pages =        {72604--72623},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DASpeech: Directed Acyclic Transformer for Fast and
                  High-quality Speech-to-Speech Translation},
  volume =       36,
  year =         2023
}

@inproceedings{fang2024invit,
  address =      {Vienna, Austria},
  author =       {Fang, Han and Song, Zhihao and Weng, Paul and Ban,
                  Yutong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=1IZLOPxtfK}},
  publisher =    {OpenReview.net},
  title =        {INViT: A Generalizable Routing Problem Solver with
                  Invariant Nested View Transformer},
  year =         2024
}

@article{fedus2022transformers,
  author =       {Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v23/21-0998.html}},
  number =       120,
  pages =        {1--39},
  title =        {Switch Transformers: Scaling to Trillion Parameter
                  Models with Simple and Efficient Sparsity},
  volume =       23,
  year =         2022
}

@inproceedings{feng2024memory,
  address =      {Vienna, Austria},
  author =       {Feng, Leo and Tung, Frederick and Hajimirsadeghi,
                  Hossein and Bengio, Yoshua and Ahmed, Mohamed Osama},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=xtwCf7iAs2}},
  publisher =    {OpenReview.net},
  title =        {Memory Efficient Neural Processes via Constant
                  Memory Attention Block},
  year =         2024
}

@inproceedings{feng2024tree,
  address =      {Vienna, Austria},
  author =       {Feng, Leo and Tung, Frederick and Hajimirsadeghi,
                  Hossein and Bengio, Yoshua and Ahmed, Mohamed Osama},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Vw24wtSddM}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tree Cross Attention},
  year =         2024
}

@inproceedings{fonseca2023continuous,
  address =      {Honolulu, Hawaii, USA},
  author =       {Fonseca, Antonio Henrique de Oliveira and Zappala,
                  Emanuele and Caro, Josue Ortega and Dijk, David van},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/de-oliveira-fonseca23a.html}},
  pages =        {7343--7365},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Continuous Spatiotemporal Transformer},
  volume =       202,
  year =         2023
}

@article{fountoulakis2023graph,
  author =       {Fountoulakis, Kimon and Levi, Amit and Yang,
                  Shenghao and Baranwal, Aseem and Jagannath, Aukosh},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v24/22-125.html}},
  number =       246,
  pages =        {1--52},
  title =        {Graph Attention Retrospective},
  volume =       24,
  year =         2023
}

@inproceedings{fowl2023decepticons,
  address =      {Kigali, Rwanda},
  author =       {Fowl, Liam H. and Geiping, Jonas and Reich, Steven
                  and Wen, Yuxin and Czaja, Wojciech and Goldblum,
                  Micah and Goldstein, Tom},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=r0BrY4BiEXO}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Decepticons: Corrupted Transformers Breach Privacy
                  in Federated Learning for Language Models},
  year =         2023
}

@inproceedings{frank2022so3krates,
  address =      {New Orleans, Louisiana, USA},
  author =       {Frank, Thorben and Unke, Oliver and Müller,
                  Klaus-Robert},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/bcf4ca90a8d405201d29dd47d75ac896-Paper-Conference.pdf}},
  pages =        {29400--29413},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {So3krates: Equivariant attention for interactions on
                  arbitrary length-scales in molecular systems},
  volume =       35,
  year =         2022
}

@inproceedings{franke2022probabilistic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Franke, Jörg and Runge, Frederic and Hutter, Frank},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/abf0ea3ae33d1a931483e327ff8d94f8-Paper-Conference.pdf}},
  pages =        {26856--26873},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Probabilistic Transformer: Modelling Ambiguities and
                  Distributions for RNA Folding and Molecule Design},
  volume =       35,
  year =         2022
}

@inproceedings{frantar2023optq,
  address =      {Kigali, Rwanda},
  author =       {Frantar, Elias and Ashkboos, Saleh and Hoefler,
                  Torsten and Alistarh, Dan},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=tcbBPnfwxS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {OPTQ: Accurate Quantization for Generative
                  Pre-trained Transformers},
  year =         2023
}

@inproceedings{friedman2023learning,
  address =      {New Orleans, Louisiana, USA},
  author =       {Friedman, Dan and Wettig, Alexander and Chen, Danqi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/995f693b73050f90977ed2828202645c-Paper-Conference.pdf}},
  pages =        {49044--49067},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Transformer Programs},
  volume =       36,
  year =         2023
}

@inproceedings{fu2022patchfool,
  address =      {Virtual Event},
  author =       {Fu, Yonggan and Zhang, Shunyao and Wu, Shang and
                  Wan, Cheng and Lin, Yingyan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=28ib9tf6zhr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Patch-Fool: Are Vision Transformers Always Robust
                  Against Adversarial Perturbations?},
  year =         2022
}

@inproceedings{fu2023can,
  address =      {New Orleans, Louisiana, USA},
  author =       {Fu, Hengyu and Guo, Tianyu and Bai, Yu and Mei,
                  Song},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/274db6bf1b01d8b4f07feaeb8c46f474-Paper-Conference.pdf}},
  pages =        {11912--11951},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {What can a Single Attention Layer Learn? A Study
                  Through the Random Features Lens},
  volume =       36,
  year =         2023
}

@inproceedings{fu2024breaking,
  address =      {Vienna, Austria},
  author =       {Fu, Jingwen and Yang, Tao and Wang, Yuwang and Lu,
                  Yan and Zheng, Nanning},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=2K87GFLYWz}},
  publisher =    {OpenReview.net},
  title =        {Breaking through the learning plateaus of in-context
                  learning in Transformer},
  year =         2024
}

@inproceedings{fu2024vcrgraphormer,
  address =      {Vienna, Austria},
  author =       {Fu, Dongqi and Hua, Zhigang and Xie, Yan and Fang,
                  Jin and Zhang, Si and Sancak, Kaan and Wu, Hao and
                  Malevich, Andrey and He, Jingrui and Long, Bo},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=SUUrkC3STJ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {VCR-Graphormer: A Mini-batch Graph Transformer via
                  Virtual Connections},
  year =         2024
}

@inproceedings{fuchs2020se,
  address =      {Virtual Event},
  author =       {Fuchs, Fabian and Worrall, Daniel and Fischer,
                  Volker and Welling, Max},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf}},
  pages =        {1970--1981},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SE(3)-Transformers: 3D Roto-Translation Equivariant
                  Attention Networks},
  volume =       33,
  year =         2020
}

@inproceedings{furuta2022generalized,
  address =      {Virtual Event},
  author =       {Furuta, Hiroki and Matsuo, Yutaka and Gu, Shixiang
                  Shane},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=CAjxVodl_v}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Generalized Decision Transformer for Offline
                  Hindsight Information Matching},
  year =         2022
}

@inproceedings{gabbur2021probabilistic,
  address =      {Virtual Event},
  author =       {Gabbur, Prasad and Bilkhu, Manjot and Movellan,
                  Javier},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/23937b42f9273974570fb5a56a6652ee-Paper.pdf}},
  pages =        {4448--4460},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Probabilistic Attention for Interactive
                  Segmentation},
  volume =       34,
  year =         2021
}

@inproceedings{gao2022earthformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Gao, Zhihan and Shi, Xingjian and Wang, Hao and Zhu,
                  Yi and Wang, Yuyang and Li, Mu and Yeung, Dit-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/a2affd71d15e8fedffe18d0219f4837a-Paper-Conference.pdf}},
  pages =        {25390--25403},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Earthformer: Exploring Space-Time Transformers for
                  Earth System Forecasting},
  volume =       35,
  year =         2022
}

@inproceedings{gao2022learning,
  address =      {Baltimore, Maryland, USA},
  author =       {Gao, Xiang and Zhang, Yuqi and Tian, Yingjie},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/gao22k.html}},
  pages =        {7183--7207},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning to Incorporate Texture Saliency Adaptive
                  Attention to Image Cartoonization},
  volume =       162,
  year =         2022
}

@inproceedings{gao2024graph,
  address =      {Vienna, Austria},
  author =       {Gao, Zhangyang and Dong, Daize and Tan, Cheng and
                  Xia, Jun and Hu, Bozhen and Li, Stan Z.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=zxxSJAVQPc}},
  publisher =    {OpenReview.net},
  title =        {A Graph is Worth K Words: Euclideanizing Graph using
                  Pure Transformer},
  year =         2024
}

@inproceedings{garg2022transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Garg, Shivam and Tsipras, Dimitris and Liang, Percy
                  S. and Valiant, Gregory},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c529dba08a146ea8d6cf715ae8930cbe-Paper-Conference.pdf}},
  pages =        {30583--30598},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {What Can Transformers Learn In-Context? A Case Study
                  of Simple Function Classes},
  volume =       35,
  year =         2022
}

@inproceedings{gatmiry2024can,
  address =      {Vienna, Austria},
  author =       {Gatmiry, Khashayar and Saunshi, Nikunj and Reddi,
                  Sashank J. and Jegelka, Stefanie and Kumar, Sanjiv},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=o8AaRKbP9K}},
  publisher =    {OpenReview.net},
  title =        {Can Looped Transformers Learn to Implement
                  Multi-step Gradient Descent for In-context
                  Learning?},
  year =         2024
}

@inproceedings{ge2021revitalizing,
  address =      {Virtual Event},
  author =       {Ge, Chongjian and Liang, Youwei and Song, Yibing and
                  Jiao, Jianbo and Wang, Jue and Luo, Ping},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/21be992eb8016e541a15953eee90760e-Paper.pdf}},
  pages =        {4193--4206},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Revitalizing CNN Attention via Transformers in
                  Self-Supervised Visual Representation Learning},
  volume =       34,
  year =         2021
}

@inproceedings{geisler2023transformers,
  address =      {Honolulu, Hawaii, USA},
  author =       {Geisler, Simon and Li, Yujia and Mankowitz, Daniel
                  J. and Cemgil, Ali Taylan and Günnemann, Stephan and
                  Paduraru, Cosmin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/geisler23a.html}},
  pages =        {11144--11172},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformers Meet Directed Graphs},
  volume =       202,
  year =         2023
}

@inproceedings{geng2021is,
  address =      {Virtual Event, Austria},
  author =       {Geng, Zhengyang and Guo, Meng-Hao and Chen, Hongxu
                  and Li, Xia and Wei, Ke and Lin, Zhouchen},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=1FvkSpWosOl}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Is Attention Better Than Matrix Decomposition?},
  year =         2021
}

@inproceedings{geng2023hiclip,
  address =      {Kigali, Rwanda},
  author =       {Geng, Shijie and Yuan, Jianbo and Tian, Yu and Chen,
                  Yuxiao and Zhang, Yongfeng},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=0eTTKOOOQkV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {HiCLIP: Contrastive Language-Image Pretraining with
                  Hierarchy-aware Attention},
  year =         2023
}

@inproceedings{geshkovski2023emergence,
  address =      {New Orleans, Louisiana, USA},
  author =       {Geshkovski, Borjan and Letrouit, Cyril and
                  Polyanskiy, Yury and Rigollet, Philippe},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b2b3e1d9840eba17ad9bbf073e009afe-Paper-Conference.pdf}},
  pages =        {57026--57037},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Emergence of Clusters in Self-Attention
                  Dynamics},
  volume =       36,
  year =         2023
}

@inproceedings{ghani2018designing,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Ghani, Abdul Rahman Abdul and Koganti, Nishanth and
                  Solano, Alfredo and Iwasawa, Yusuke and Nakayama,
                  Kotaro and Matsuo, Yutaka},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rJxqQY0LM}},
  publisher =    {OpenReview.net},
  series =       {Workshop Track Proceedings},
  title =        {Designing Efficient Neural Attention Systems Towards
                  Achieving Human-level Sharp Vision},
  year =         2018
}

@inproceedings{ghugare2024searching,
  address =      {Vienna, Austria},
  author =       {Ghugare, Raj and Miret, Santiago and Hugessen,
                  Adriana and Phielipp, Mariano and Berseth, Glen},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=nqlymMx42E}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Searching for High-Value Molecules Using
                  Reinforcement Learning and Transformers},
  year =         2024
}

@inproceedings{giannou2023looped,
  address =      {Honolulu, Hawaii, USA},
  author =       {Giannou, Angeliki and Rajput, Shashank and Sohn,
                  Jy-yong and Lee, Kangwook and Lee, Jason D. and
                  Papailiopoulos, Dimitris},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/giannou23a.html}},
  pages =        {11398--11442},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Looped Transformers as Programmable Computers},
  volume =       202,
  year =         2023
}

@inproceedings{ging2020coot,
  address =      {Virtual Event},
  author =       {Ging, Simon and Zolfaghari, Mohammadreza and
                  Pirsiavash, Hamed and Brox, Thomas},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/ff0abbcc0227c9124a804b084d161a2d-Paper.pdf}},
  pages =        {22605--22618},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {COOT: Cooperative Hierarchical Transformer for
                  Video-Text Representation Learning},
  volume =       33,
  year =         2020
}

@inproceedings{girgis2022latent,
  address =      {Virtual Event},
  author =       {Girgis, Roger and Golemo, Florian and Codevilla,
                  Felipe and Weiss, Martin and D'Souza, Jim Aldon and
                  Kahou, Samira Ebrahimi and Heide, Felix and Pal,
                  Christopher},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Dup_dDqkZC5}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Latent Variable Sequential Set Transformers for
                  Joint Multi-Agent Motion Prediction},
  year =         2022
}

@inproceedings{gkanatsios2023analogyforming,
  address =      {Kigali, Rwanda},
  author =       {Gkanatsios, Nikolaos and Singh, Mayank and Fang,
                  Zhaoyuan and Tulsiani, Shubham and Fragkiadaki,
                  Katerina},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=SRIQZTh0IK}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Analogy-Forming Transformers for Few-Shot 3D
                  Parsing},
  year =         2023
}

@inproceedings{glehn2023selfattention,
  address =      {Kigali, Rwanda},
  author =       {Glehn, Ingrid von and Spencer, James S. and Pfau,
                  David},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=xveTeHVlF7j}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Self-Attention Ansatz for Ab-initio Quantum
                  Chemistry},
  year =         2023
}

@inproceedings{goebel1992perceiving,
  address =      {Denver, Colorado, USA},
  author =       {Goebel, Rainer},
  booktitle =    {Advances in Neural Information Processing Systems 5
                  (NIPS)},
  editor =       {Hanson, S. and Cowan, J. and Giles, C.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1992/file/2f37d10131f2a483a8dd005b3d14b0d9-Paper.pdf}},
  publisher =    {Morgan-Kaufmann},
  series =       {Conference Track Proceedings},
  title =        {Perceiving Complex Visual Scenes: An Oscillator
                  Neural Network Model that Integrates Selective
                  Attention, Perceptual Organisation, and Invariant
                  Recognition},
  volume =       5,
  year =         1992
}

@inproceedings{gong2021pay,
  address =      {Virtual Event},
  author =       {Gong, Hongyu and Tang, Yun and Pino, Juan and Li,
                  Xian},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, Marco and Beygelzimer, A. and Dauphin,
                  Y. and Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/15c00b5250ddedaabc203b67f8b034fd-Paper.pdf}},
  pages =        {2668--2681},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pay Better Attention to Attention: Head Selection in
                  Multilingual and Multi-Domain Sequence Modeling},
  volume =       34,
  year =         2021
}

@inproceedings{gong2022nasvit,
  address =      {Virtual Event},
  author =       {Gong, Chengyue and Wang, Dilin and Li, Meng and
                  Chen, Xinlei and Yan, Zhicheng and Yu, and Tian, Ong
                  and Liu, Qiang and Ch, Vikas and Ra, },
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Qaw16njk6L}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {NASViT: Neural Architecture Search for Efficient
                  Vision Transformers with Gradient Conflict aware
                  Supernet Training},
  year =         2022
}

@inproceedings{gontier2020measuring,
  address =      {Virtual Event},
  author =       {Gontier, Nicolas and Sinha, Koustuv and Reddy, Siva
                  and Pal, Chris},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/fc84ad56f9f547eb89c72b9bac209312-Paper.pdf}},
  pages =        {22231--22242},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Measuring Systematic Generalization in Neural Proof
                  Generation with Transformers},
  volume =       33,
  year =         2020
}

@inproceedings{gould2024successor,
  address =      {Vienna, Austria},
  author =       {Gould, Rhys and Ong, Euan and Ogden, George and
                  Conmy, Arthur},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=kvcbV8KQsi}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Successor Heads: Recurring, Interpretable Attention
                  Heads In The Wild},
  year =         2024
}

@inproceedings{grover2022public,
  address =      {New Orleans, Louisiana, USA},
  author =       {Grover, Karish and Angara, S. M. Phaneendra and
                  Akhtar, Md Shad and Chakraborty, Tanmoy},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3d57795f0e263aa69577f1bbceade46b-Paper-Conference.pdf}},
  pages =        {9417--9431},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Public Wisdom Matters! Discourse-Aware Hyperbolic
                  Fourier Co-Attention for Social Text Classification},
  volume =       35,
  year =         2022
}

@inproceedings{gu2019levenshtein,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Gu, Jiatao and Wang, Changhan and Zhao, Junbo},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/675f9820626f5bc0afb47b57890b466e-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Levenshtein Transformer},
  volume =       32,
  year =         2019
}

@inproceedings{guan2021autoattend,
  address =      {Virtual Event},
  author =       {Guan, Chaoyu and Wang, Xin and Zhu, Wenwu},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/guan21a.html}}},
  pages =        {3864--3874},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {AutoAttend: Automated Attention Representation
                  Search},
  volume =       139,
  year =         2021
}

@inproceedings{guibas2022efficient,
  address =      {Virtual Event},
  author =       {Guibas, John and Mardani, Morteza and Li, Zongyi and
                  Tao, Andrew and An, Anima and Kumar, and Catanzaro,
                  Bryan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=EXHG-A3jlM}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Token Mixing for Transformers via Adaptive
                  Fourier Neural Operators},
  year =         2022
}

@inproceedings{gulati2023tabmt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Gulati, Manbir and Roysdon, Paul},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/90debc7cedb5cac83145fc8d18378dc5-Paper-Conference.pdf}},
  pages =        {46245--46254},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TabMT: Generating tabular data with masked
                  transformers},
  volume =       36,
  year =         2023
}

@inproceedings{guo2019nat,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Guo, Yong and Zheng, Yin and Tan, Mingkui and Chen,
                  Qi and Chen, Jian and Zhao, Peilin and Huang,
                  Junzhou},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/beed13602b9b0e6ecb5b568ff5058f07-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {NAT: Neural Architecture Transformer for Accurate
                  and Compact Architectures},
  volume =       32,
  year =         2019
}

@inproceedings{guo2021machineb,
  address =      {Virtual Event},
  author =       {Guo, Suna (Sihang) and Zhang, Ruohan and Liu, Bo and
                  Zhu, Yifeng and Ballard, Dana and Hayhoe, Mary and
                  Stone, Peter},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/d58e2f077670f4de9cd7963c857f2534-Paper.pdf}},
  pages =        {25370--25385},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Machine versus Human Attention in Deep Reinforcement
                  Learning Tasks},
  volume =       34,
  year =         2021
}

@inproceedings{guo2022divert,
  address =      {New Orleans, Louisiana, USA},
  author =       {Guo, Mingzhe and Zhang, Zhipeng and Fan, Heng and
                  Jing, Liping},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/1c8c87c36dc1e49e63555f95fa56b153-Paper-Conference.pdf}},
  pages =        {4446--4460},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Divert More Attention to Vision-Language Tracking},
  volume =       35,
  year =         2022
}

@inproceedings{guo2022segnext,
  address =      {New Orleans, Louisiana, USA},
  author =       {Guo, Meng-Hao and Lu, Cheng-Ze and Hou, Qibin and
                  Liu, Zhengning and Cheng, Ming-Ming and Hu, Shi-min},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/08050f40fff41616ccfc3080e60a301a-Paper-Conference.pdf}},
  pages =        {1140--1156},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SegNeXt: Rethinking Convolutional Attention Design
                  for Semantic Segmentation},
  volume =       35,
  year =         2022
}

@inproceedings{guo2023transformer,
  address =      {Kigali, Rwanda},
  author =       {Guo, Ruchi and Cao, Shuhao and Chen, Long},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HnlCZATopvr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer Meets Boundary Value Inverse Problems},
  year =         2023
}

@inproceedings{guo2024do,
  address =      {Vienna, Austria},
  author =       {Guo, Tianyu and Hu, Wei and Mei, Song and Wang, Huan
                  and Xiong, Caiming and Savarese, Silvio and Bai, Yu},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ikwEDva1JZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {How Do Transformers Learn In-Context Beyond Simple
                  Functions? A Case Study on Learning with
                  Representations},
  year =         2024
}

@inproceedings{guo2024slab,
  address =      {Vienna, Austria},
  author =       {Guo, Jialong and Chen, Xinghao and Tang, Yehui and
                  Wang, Yunhe},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=aQl4xiwVBc}},
  publisher =    {OpenReview.net},
  title =        {SLAB: Efficient Transformers with Simplified Linear
                  Attention and Progressive Re-parameterized Batch
                  Normalization},
  year =         2024
}

@inproceedings{guo2024temporal,
  address =      {Vienna, Austria},
  author =       {Guo, Zijian and Zhou, Weichao and Li, Wenchao},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=7bg10Jj3bG}},
  publisher =    {OpenReview.net},
  title =        {Temporal Logic Specification-Conditioned Decision
                  Transformer for Offline Safe Reinforcement Learning},
  year =         2024
}

@inproceedings{gupta2022metamorph,
  address =      {Virtual Event},
  author =       {Gupta, Agrim and Fan, Linxi and Ganguli, Surya and
                  Fei-Fei, Li},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=Opmqtk_GvYL}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MetaMorph: Learning Universal Controllers with
                  Transformers},
  year =         2022
}

@inproceedings{gülçehre2019hyperbolic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Gülçehre, Çağlar and Denil, Misha and Malinowski,
                  Mateusz and Razavi, Ali and Pascanu, Razvan and
                  Hermann, Karl Moritz and Battaglia, Peter W. and
                  Bapst, Victor and Raposo, David and Santoro, Adam
                  and Freitas, o de},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rJxHsjRqFQ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Hyperbolic Attention Networks},
  year =         2019
}

@inproceedings{hachana2023effect,
  address =      {Kigali, Rwanda},
  author =       {Hachana, Rafik and Ivanov, Vladimir V.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=SBqbPjVFfm}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Effect of Training Fragment Length on Transformers
                  in Text Complexity Prediction},
  year =         2023
}

@inproceedings{han2021transformer,
  address =      {Virtual Event},
  author =       {Han, Kai and Xiao, An and Wu, Enhua and Guo,
                  Jianyuan and Xu, Chunjing and Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf}},
  pages =        {15908--15919},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformer in Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{han2022on,
  address =      {Virtual Event},
  author =       {Han, Qi and Fan, Zejia and Dai, Qi and Sun, Lei and
                  Cheng, Ming-Ming and Liu, Jiaying and Wang,
                  Jingdong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=L3\_SsSNMmy}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {On the Connection between Local Attention and
                  Dynamic Depth-wise Convolution},
  year =         2022
}

@inproceedings{han2022predicting,
  address =      {Virtual Event},
  author =       {Han, Xu and Gao, Han and Pfaff, Tobias and Wang,
                  Jian-Xun and Liu, Liping},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=XctLdNfCmP}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Predicting Physics in Mesh-reduced Space with
                  Temporal Attention},
  year =         2022
}

@inproceedings{han2023designing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Han, Xing and Ren, Tongzheng and Nguyen, Tan and
                  Nguyen, Khai and Ghosh, Joydeep and Ho, Nhat},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a766f56d2da42cae20b5652970ec04ef-Paper-Conference.pdf}},
  pages =        {53362--53384},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Designing Robust Transformers using Robust Kernel
                  Density Estimation},
  volume =       36,
  year =         2023
}

@inproceedings{han2024hyperattention,
  address =      {Vienna, Austria},
  author =       {Han, Insu and Jayaram, Rajesh and Karbasi, Amin and
                  Mirrokni, Vahab and Woodruff, David P. and Z, Amir
                  and ieh},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Eh0Od2BJIM}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {HyperAttention: Long-context Attention in
                  Near-Linear Time},
  year =         2024
}

@inproceedings{han2024prototypical,
  address =      {Vienna, Austria},
  author =       {Han, Cheng and Lu, Yawen and Sun, Guohao and Liang,
                  James Chenhao and Cao, Zhiwen and Wang, Qifan and
                  Guan, Qiang and Dianat, Sohail A. and Rao, Raghuveer
                  and Geng, Tong and Tao, Zhiqiang and Liu, Dongfang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=JOrLz5d7OW}},
  publisher =    {OpenReview.net},
  title =        {Prototypical Transformer As Unified Motion Learners},
  year =         2024
}

@inproceedings{hansen2021stabilizing,
  address =      {Virtual Event},
  author =       {Hansen, Nicklas and Su, Hao and Wang, Xiaolong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/1e0f65eb20acbfb27ee05ddc000b50ec-Paper.pdf}},
  pages =        {3680--3693},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Stabilizing Deep Q-Learning with ConvNets and Vision
                  Transformers under Data Augmentation},
  volume =       34,
  year =         2021
}

@inproceedings{hanson1990spherical,
  address =      {Denver, Colorado, USA},
  author =       {Hanson, Stephen and Gluck, Mark},
  booktitle =    {Advances in Neural Information Processing Systems 3
                  (NIPS)},
  editor =       {Lippmann, R. P. and Moody, J. and Touretzky, D.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1990/file/9fd81843ad7f202f26c1a174c7357585-Paper.pdf}},
  publisher =    {Morgan-Kaufmann},
  series =       {Conference Track Proceedings},
  title =        {Spherical Units as Dynamic Consequential Regions:
                  Implications for Attention, Competition and
                  Categorization},
  volume =       3,
  year =         1990
}

@inproceedings{hao2022iron,
  address =      {New Orleans, Louisiana, USA},
  author =       {Hao, Meng and Li, Hongwei and Chen, Hanxiao and
                  Xing, Pengzhi and Xu, Guowen and Zhang, Tianwei},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/64e2449d74f84e5b1a5c96ba7b3d308e-Paper-Conference.pdf}},
  pages =        {15718--15731},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Iron: Private Inference on Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{hao2022learning,
  address =      {New Orleans, Louisiana, USA},
  author =       {Hao, Zhiwei and Guo, Jianyuan and Jia, Ding and Han,
                  Kai and Tang, Yehui and Zhang, Chao and Hu, Han and
                  Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3bd2d73b4e96b0ac5a319be58a96016c-Paper-Conference.pdf}},
  pages =        {9164--9175},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Efficient Vision Transformers via
                  Fine-Grained Manifold Distillation},
  volume =       35,
  year =         2022
}

@inproceedings{hao2023gnot,
  address =      {Honolulu, Hawaii, USA},
  author =       {Hao, Zhongkai and Wang, Zhengyi and Su, Hang and
                  Ying, Chengyang and Dong, Yinpeng and Liu, Songming
                  and Cheng, Ze and Song, Jian and Zhu, Jun},
  booktitle =    {International Conference on Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/hao23c.html}},
  pages =        {12556--12569},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {GNOT: A General Neural Operator Transformer for
                  Operator Learning},
  year =         2023
}

@inproceedings{hao2024dpot,
  address =      {Vienna, Austria},
  author =       {Hao, Zhongkai and Su, Chang and Liu, Songming and
                  Berner, Julius and Ying, Chengyang and Su, Hang and
                  An, Anima and Kumar, and Song, Jian and Zhu, Jun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=X7UnDevHOM}},
  publisher =    {OpenReview.net},
  title =        {DPOT: Auto-Regressive Denoising Operator Transformer
                  for Large-Scale PDE Pre-Training},
  year =         2024
}

@inproceedings{hatamizadeh2023global,
  address =      {Honolulu, Hawaii, USA},
  author =       {Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg
                  and Kautz, Jan and Molchanov, Pavlo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/hatamizadeh23a.html}},
  pages =        {12633--12646},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Global Context Vision Transformers},
  year =         2023
}

@inproceedings{hatamizadeh2024fastervit,
  address =      {Vienna, Austria},
  author =       {Hatamizadeh, Ali and Heinrich, Greg and Yin, Hongxu
                  and Tao, Andrew and Álvarez, José M. and Kautz, Jan
                  and Molchanov, Pavlo},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=kB4yBiNmXX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {FasterViT: Fast Vision Transformers with
                  Hierarchical Attention},
  year =         2024
}

@inproceedings{havens2024finegrained,
  address =      {Vienna, Austria},
  author =       {Havens, Aaron J. and Alex and Araujo, re and Zhang,
                  Huan and Hu, Bin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=EEinDTdKr1}},
  publisher =    {OpenReview.net},
  title =        {Fine-grained Local Sensitivity Analysis of Standard
                  Dot-Product Self-Attention},
  year =         2024
}

@inproceedings{haviv2024wasserstein,
  address =      {Vienna, Austria},
  author =       {Haviv, Doron and Kunes, Russell Zhang and Dougherty,
                  Thomas and Cass and Burdziak, ra and Nawy, Tal and
                  Gilbert, Anna and Pe'er, Dana},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Su0qe33cWA}},
  publisher =    {OpenReview.net},
  title =        {Wasserstein Wormhole: Scalable Optimal Transport
                  Distance with Transformer},
  year =         2024
}

@inproceedings{hay2024dynamic,
  address =      {Vienna, Austria},
  author =       {Hay, Tamir David and Wolf, Lior},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=d4uL2MSe0z}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Layer Tying for Parameter-Efficient
                  Transformers},
  year =         2024
}

@inproceedings{he2021deberta,
  address =      {Virtual Event, Austria},
  author =       {He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng
                  and Chen, Weizhu},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=XPZIaotutsD}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Deberta: Decoding-Enhanced Bert with Disentangled
                  Attention},
  year =         2021
}

@inproceedings{he2021gauge,
  address =      {Virtual Event},
  author =       {He, Lingshen and Dong, Yiming and Wang, Yisen and
                  Tao, Dacheng and Lin, Zhouchen},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/e57c6b956a6521b28495f2886ca0977a-Paper.pdf}},
  pages =        {27331--27343},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Gauge Equivariant Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{he2022hyperprompt,
  address =      {Baltimore, Maryland, USA},
  author =       {He, Yun and Zheng, Huaixiu Steven and Tay, Yi and
                  Gupta, Jai Prakash and Du, Yu and Arib, Vamsi and i
                  and Zhao, Zhe and Li, YaGuang and Chen, Zhao and
                  Metzler, Donald and Cheng, Heng-Tze and Chi, Ed H.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v162/he22f.html}},
  pages =        {8678--8690},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {HyperPrompt: Prompt-based Task-Conditioning of
                  Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{he2023deep,
  address =      {Kigali, Rwanda},
  author =       {He, Bobby and Martens, James and Zhang, Guodong and
                  Aleks and Botev, ar and Brock, Andrew and Smith,
                  Samuel L. and Teh, Yee Whye},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=NPrsUQgMjKK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Deep Transformers without Shortcuts: Modifying
                  Self-attention for Faithful Signal Propagation},
  year =         2023
}

@inproceedings{he2023hierarchical,
  address =      {New Orleans, Louisiana, USA},
  author =       {He, Wenchong and Jiang, Zhe and Xiao, Tingsong and
                  Xu, Zelin and Chen, Shigang and Fick, Ronald and
                  Medina, Miles and Angelini, Christine},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6a0480190bbe6b622c7f1d3aa9be9c0f-Paper-Conference.pdf}},
  pages =        {33365--33378},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Hierarchical Spatial Transformer for Massive Point
                  Samples in Continuous Space},
  volume =       36,
  year =         2023
}

@inproceedings{he2024dataindependent,
  address =      {Vienna, Austria},
  author =       {He, Yang and Zhou, Joey Tianyi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=7Ol6foUi1G}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Data-Independent Module-Aware Pruning for
                  Hierarchical Vision Transformers},
  year =         2024
}

@inproceedings{he2024simplifying,
  address =      {Vienna, Austria},
  author =       {He, Bobby and Hofmann, Thomas},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=RtDok9eS3s}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Simplifying Transformer Blocks},
  year =         2024
}

@inproceedings{hedegaard2023continual,
  address =      {Kigali, Rwanda},
  author =       {Hedegaard, Lukas and Bakhtiarnia, Arian and Alex and
                  Iosifidis, Ros},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=PolHquob8M7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Continual Transformers: Redundancy-Free Attention
                  for Online Inference},
  year =         2023
}

@inproceedings{henderson2023vae,
  address =      {Kigali, Rwanda},
  author =       {Henderson, James and Fehr, Fabio},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=6QkjC_cs03X}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A VAE for Transformers with Nonparametric
                  Variational Information Bottleneck},
  year =         2023
}

@inproceedings{heo2018uncertainty,
  address =      {Montreal, Quebec, Canada},
  author =       {Heo, Jay and Lee, Hae Beom and Kim, Saehoon and Lee,
                  Juho and Kim, Kwang Joon and Yang, Eunho and Hwang,
                  Sung Ju},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/285e19f20beded7d215102b49d5c09a0-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Uncertainty-Aware Attention for Reliable
                  Interpretation and Prediction},
  volume =       31,
  year =         2018
}

@inproceedings{heo2020cost,
  address =      {Virtual Event},
  author =       {Heo, Jay and Park, Junhyeon and Jeong, Hyewon and
                  Kim, Kwang Joon and Lee, Juho and Yang, Eunho and
                  Hwang, Sung Ju},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v119/heo20a.html}}},
  pages =        {4228--4238},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Cost-Effective Interactive Attention Learning with
                  Neural Attention Processes},
  volume =       119,
  year =         2020
}

@inproceedings{hern2024linearity,
  address =      {Vienna, Austria},
  author =       {Hern, Evan and ez, and Sharma, Arnab Sen and Haklay,
                  Tal and Meng, Kevin and Wattenberg, Martin and
                  Andreas, Jacob and Belinkov, Yonatan and Bau, David},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=w7LU2s14kE}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Linearity of Relation Decoding in Transformer
                  Language Models},
  year =         2024
}

@inproceedings{hertz2023prompttoprompt,
  address =      {Kigali, Rwanda},
  author =       {Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and
                  Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=_CDixzkzeyb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Prompt-to-Prompt Image Editing with Cross-Attention
                  Control},
  year =         2023
}

@inproceedings{hildebrandt1993functional,
  address =      {Denver, Colorado, USA},
  author =       {Hildebrandt, Thomas},
  booktitle =    {Advances in Neural Information Processing Systems 6
                  (NIPS)},
  editor =       {Cowan, J. and Tesauro, G. and Alspector, J.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1993/file/e0cf1f47118daebc5b16269099ad7347-Paper.pdf}},
  publisher =    {Morgan-Kaufmann},
  series =       {Conference Track Proceedings},
  title =        {Functional Models of Selective Attention and Context
                  Dependency},
  volume =       6,
  year =         1993
}

@inproceedings{hirsch2021trees,
  address =      {Virtual Event},
  author =       {Hirsch, Roy and Gilad-Bachrach, Ran},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/hirsch21a.html}}},
  pages =        {4250--4261},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Trees with Attention for Set Prediction Tasks},
  volume =       139,
  year =         2021
}

@inproceedings{hoffmann2024eurekamoments,
  address =      {Vienna, Austria},
  author =       {Hoffmann, David T. and Schrodi, Simon and Bratulic,
                  Jelena and Behrmann, Nadine and Fischer, Volker and
                  Brox, Thomas},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=HssOwuZiaB}},
  publisher =    {OpenReview.net},
  title =        {Eureka-Moments in Transformers: Multi-Step Tasks
                  Reveal Softmax Induced Optimization Problems},
  year =         2024
}

@inproceedings{hollmann2023tabpfn,
  address =      {Kigali, Rwanda},
  author =       {Hollmann, Noah and Müller, Samuel and Eggensperger,
                  Katharina and Hutter, Frank},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cp5PvcI6w8_}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {TabPFN: A Transformer That Solves Small Tabular
                  Classification Problems in a Second},
  year =         2023
}

@inproceedings{hong2022structureaware,
  address =      {Virtual Event},
  author =       {Hong, Sunghoon and Yoon, Deunsol and Kim, Kee-Eung},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=fy_XRVHqly}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Structure-Aware Transformer Policy for Inhomogeneous
                  Multi-Task Reinforcement Learning},
  year =         2022
}

@inproceedings{hong2023cogvideo,
  address =      {Kigali, Rwanda},
  author =       {Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu,
                  Xinghan and Tang, Jie},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rB6TpjAuSRy}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {CogVideo: Large-scale Pretraining for Text-to-Video
                  Generation via Transformers},
  year =         2023
}

@inproceedings{hong2024unifying,
  address =      {Vienna, Austria},
  author =       {Hong, Sunghwan and Cho, Seokju and Kim, Seungryong
                  and Lin, Stephen},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=fQHb1uZzl7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Unifying Feature and Cost Aggregation with
                  Transformers for Semantic and Visual Correspondence},
  year =         2024
}

@inproceedings{hoover2023energy,
  address =      {New Orleans, Louisiana, USA},
  author =       {Hoover, Benjamin and Liang, Yuchen and Pham, Bao and
                  Panda, Rameswar and Strobelt, Hendrik and Chau, Duen
                  Horng and Zaki, Mohammed and Krotov, Dmitry},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/57a9b97477b67936298489e3c1417b0a-Paper-Conference.pdf}},
  pages =        {27532--27559},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Energy Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{horiuchi1996analog,
  address =      {Denver, Colorado, USA},
  author =       {Horiuchi, Timothy and Morris, Tonia and Koch,
                  Christof and DeWeerth, Stephen},
  booktitle =    {Advances in Neural Information Processing Systems 9
                  (NIPS)},
  editor =       {M.C. Mozer and M. Jordan and T. Petsche},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1996/file/c0a271bc0ecb776a094786474322cb82-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Analog VLSI Circuits for Attention-Based, Visual
                  Tracking},
  volume =       9,
  year =         1996
}

@inproceedings{hou2008dynamic,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Hou, Xiaodi and Zhang, Liqing},
  booktitle =    {Advances in Neural Information Processing Systems 21
                  (NIPS)},
  editor =       {D. Koller and D. Schuurmans and Y. Bengio and
                  L. Bottou},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2008/file/a8baa56554f96369ab93e4f3bb068c22-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Visual Attention: Searching for Coding
                  Length Increments},
  volume =       21,
  year =         2008
}

@inproceedings{hou2018self,
  address =      {Montreal, Quebec, Canada},
  author =       {Hou, Qibin and Jiang, PengTao and Wei, Yunchao and
                  Cheng, Ming-Ming},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/c042f4db68f23406c6cecf84a7ebb0fe-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Self-Erasing Network for Integral Object Attention},
  volume =       31,
  year =         2018
}

@inproceedings{hou2019cross,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Hou, Ruibing and Chang, Hong and Ma, Bingpeng and
                  Shan, Shiguang and Chen, Xilin},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/01894d6f048493d2cacde3c579c315a3-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cross Attention Network for Few-shot Classification},
  volume =       32,
  year =         2019
}

@inproceedings{hou2023decoding,
  address =      {Honolulu, Hawaii, USA},
  author =       {Hou, Elizabeth Mary and Castañón, Gregory David},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/hou23a.html}},
  pages =        {13285--13308},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Decoding Layer Saliency in Language Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{hron2020infinite,
  address =      {Virtual Event},
  author =       {Hron, Jiri and Bahri, Yasaman and Sohl-Dickstein,
                  Jascha and Novak, Roman},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v119/hron20a.html}}},
  pages =        {4376--4386},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Infinite Attention: NNGP and NTK for Deep Attention
                  Networks},
  volume =       119,
  year =         2020
}

@inproceedings{hsieh2019one,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Hsieh, Ting-I and Lo, Yi-Chen and Chen, Hwann-Tzong
                  and Liu, Tyng-Luh},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/92af93f73faf3cefc129b6bc55a748a9-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {One-Shot Object Detection with Co-Attention and
                  Co-Excitation},
  volume =       32,
  year =         2019
}

@inproceedings{hsu2024diagnosing,
  address =      {Vienna, Austria},
  author =       {Hsu, Aliyah R. and Cherapanamjeri, Yeshwanth and
                  Park, Briton and Naumann, Tristan and Odisho, Anobel
                  Y. and Yu, Bin},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  day =          {7--11},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=k581sTMyPt}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Diagnosing Transformers: Illuminating Feature Spaces
                  for Clinical Decision-Making},
  year =         2024
}

@inproceedings{hu2021updet,
  address =      {Virtual Event, Austria},
  author =       {Hu, Siyi and Zhu, Fengda and Chang, Xiaojun and
                  Liang, Xiaodan},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=v9c7hr9ADKx}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {UPDeT: Universal Multi-agent RL via Policy
                  Decoupling with Transformers},
  year =         2021
}

@inproceedings{hu2023dac,
  address =      {New Orleans, Louisiana, USA},
  author =       {Hu, Zhengdong and Sun, Yifan and Wang, Jingdong and
                  Yang, Yi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/edd0d433f8a1a51aa11237a6543fc280-Paper-Conference.pdf}},
  pages =        {75189--75200},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DAC-DETR: Divide the Attention Layers and Conquer},
  volume =       36,
  year =         2023
}

@inproceedings{hu2023decision,
  address =      {Kigali, Rwanda},
  author =       {Hu, Kaizhe and Zheng, Ray Chen and Gao, Yang and Xu,
                  Huazhe},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=NmZXv4467ai}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Decision Transformer under Random Frame Dropping},
  year =         2023
}

@inproceedings{hu2024accelerating,
  address =      {Vienna, Austria},
  author =       {Hu, Yuezhou and Zhao, Kang and Huang, Weiyu and
                  Chen, Jianfei and Zhu, Jun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=kTaX87Zn6M}},
  publisher =    {OpenReview.net},
  title =        {Accelerating Transformer Pre-training with 2:4
                  Sparsity},
  year =         2024
}

@inproceedings{hu2024attentionguided,
  address =      {Vienna, Austria},
  author =       {Hu, Zican and Zhang, Zongzhang and Li, Huaxiong and
                  Chen, Chunlin and Ding, Hongyu and Wang, Zhi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=LWmuPfEYhH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Attention-Guided Contrastive Role Representations
                  for Multi-Agent Reinforcement Learning},
  year =         2024
}

@inproceedings{hu2024augmenting,
  address =      {Vienna, Austria},
  author =       {Hu, Xiang and Zhu, Qingyang and Tu, Kewei and Wu,
                  Wei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=u859gX7ADC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Augmenting Transformers with Recursively Composed
                  Multi-grained Representations},
  year =         2024
}

@inproceedings{hu2024casebased,
  address =      {Vienna, Austria},
  author =       {Hu, Yi and Tang, Xiaojuan and Yang, Haotong and
                  Zhang, Muhan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=4Vqr8SRfyX}},
  publisher =    {OpenReview.net},
  title =        {Case-Based or Rule-Based: How Do Transformers Do the
                  Math?},
  year =         2024
}

@inproceedings{hu2024harmodt,
  address =      {Vienna, Austria},
  author =       {Hu, Shengchao and Fan, Ziqing and Shen, Li and
                  Zhang, Ya and Wang, Yanfeng and Tao, Dacheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=2Asakozn3Z}},
  publisher =    {OpenReview.net},
  title =        {HarmoDT: Harmony Multi-Task Decision Transformer for
                  Offline Reinforcement Learning},
  year =         2024
}

@inproceedings{hu2024improving,
  address =      {Vienna, Austria},
  author =       {Hu, Lijie and Liu, Yixin and Liu, Ninghao and Huai,
                  Mengdi and Sun, Lichao and Wang, Di},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=YdwwWRX20q}},
  publisher =    {OpenReview.net},
  title =        {Improving Interpretation Faithfulness for Vision
                  Transformers},
  year =         2024
}

@inproceedings{hu2024outlierefficient,
  address =      {Vienna, Austria},
  author =       {Hu, Jerry Yao-Chieh and Chang, Pei-Hsuan and Luo,
                  Haozheng and Chen, Hong-Yu and Li, Weijian and Wang,
                  Wei-Po and Liu, Han},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=kLiDMGJKx1}},
  publisher =    {OpenReview.net},
  title =        {Outlier-Efficient Hopfield Layers for Large
                  Transformer-Based Models},
  year =         2024
}

@inproceedings{hu2024qvalue,
  address =      {Vienna, Austria},
  author =       {Hu, Shengchao and Fan, Ziqing and Huang, Chaoqin and
                  Shen, Li and Zhang, Ya and Wang, Yanfeng and Tao,
                  Dacheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ojtddicekd}},
  publisher =    {OpenReview.net},
  title =        {Q-value Regularized Transformer for Offline
                  Reinforcement Learning},
  year =         2024
}

@inproceedings{hu2024sparse,
  address =      {Vienna, Austria},
  author =       {Hu, Zixuan and Wei, Yongxian and Shen, Li and Wang,
                  Zhenyi and Li, Lei and Yuan, Chun and Tao, Dacheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=T0lFfO8HaK}},
  publisher =    {OpenReview.net},
  title =        {Sparse Model Inversion: Efficient Inversion of
                  Vision Transformers for Data-Free Applications},
  year =         2024
}

@inproceedings{hua2022transformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Hua, Weizhe and Dai, Zihang and Liu, Hanxiao and Le,
                  Quoc V.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/hua22a.html}},
  pages =        {9099--9117},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformer Quality in Linear Time},
  volume =       162,
  year =         2022
}

@inproceedings{huang2018fusionnet,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Huang, Hsin-Yuan and Zhu, Chenguang and Shen, Yelong
                  and Chen, Weizhu},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=BJIgi_eCZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {FusionNet: Fusing via Fully-aware Attention with
                  Application to Machine Comprehension},
  year =         2018
}

@inproceedings{huang2019adaptively,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Huang, Lun and Wang, Wenmin and Xia, Yaxian and
                  Chen, Jie},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/fecc3a370a23d13b1cf91ac3c1e1ca92-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Adaptively Aligned Image Captioning via Adaptive
                  Attention Time},
  volume =       32,
  year =         2019
}

@inproceedings{huang2019music,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Cheng-Zhi Anna and Vaswani, Ashish and
                  Uszkoreit, Jakob and Simon, Ian and Hawthorne,
                  Curtis and Shazeer, Noam and Dai, Andrew M. and
                  Hoffman, Matthew D. and Dinculescu, Monica and Eck,
                  Douglas},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rJe4ShAcF7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Music Transformer: Generating Music with Long-Term
                  Structure},
  year =         2019
}

@inproceedings{huang2020comprehensive,
  address =      {Virtual Event},
  author =       {Huang, Zeyi and Zou, Yang and Kumar, B. V. K. Vijaya
                  and Huang, Dong},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/c3535febaff29fcb7c0d20cbe94391c7-Paper.pdf}},
  pages =        {16797--16807},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Comprehensive Attention Self-Distillation for
                  Weakly-Supervised Object Detection},
  volume =       33,
  year =         2020
}

@inproceedings{huang2020improving,
  address =      {Virtual Event},
  author =       {Huang, Xiao Shi and Pérez, Felipe and Ba, Jimmy and
                  Volkovs, Maksims},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v119/huang20f.html}}},
  pages =        {4475--4483},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Improving Transformer Optimization Through Better
                  Initialization},
  volume =       119,
  year =         2020
}

@inproceedings{huang2022adaptive,
  address =      {Virtual Event},
  author =       {Huang, Hao and Fang, Yi},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=5MLb3cLCJY}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Adaptive Wavelet Transformer Network for 3D Shape
                  Representation Learning},
  year =         2022
}

@inproceedings{huang2022directed,
  address =      {Baltimore, Maryland, USA},
  author =       {Huang, Fei and Zhou, Hao and Liu, Yang and Li, Hang
                  and Huang, Minlie},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/huang22m.html}},
  pages =        {9410--9428},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Directed Acyclic Transformer for Non-Autoregressive
                  Machine Translation},
  volume =       162,
  year =         2022
}

@inproceedings{huang2022green,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Lang and You, Shan and Zheng, Mingkai and
                  Wang, Fei and Qian, Chen and Yamasaki, Toshihiko},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/7e487c72fce6e45879a78ee0872d991d-Paper-Conference.pdf}},
  pages =        {19997--20010},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Green Hierarchical Vision Transformer for Masked
                  Image Modeling},
  volume =       35,
  year =         2022
}

@inproceedings{huang2022on,
  address =      {Baltimore, Maryland, USA},
  author =       {Huang, Fei and Tao, Tianhua and Zhou, Hao and Li,
                  Lei and Huang, Minlie},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/huang22k.html}},
  pages =        {9356--9376},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {On the Learning of Non-Autoregressive Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{huang2022orthogonal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Huaibo and Zhou, Xiaoqiang and He, Ran},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5d8c01de2dc698c54201c1c7d0b86974-Paper-Conference.pdf}},
  pages =        {14596--14607},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Orthogonal Transformer: An Efficient Vision
                  Transformer Backbone with Token Orthogonalization},
  volume =       35,
  year =         2022
}

@inproceedings{huang2022spovt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Sheng Yu and Hsu, Hao-Yu and Wang, Frank},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/db6caae0f83e45e454e2215f07e7c5af-Paper-Conference.pdf}},
  pages =        {33934--33946},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SPoVT: Semantic-Prototype Variational Transformer
                  for Dense Point Cloud Semantic Completion},
  volume =       35,
  year =         2022
}

@inproceedings{huang2023are,
  address =      {Honolulu, Hawaii, USA},
  author =       {Huang, Tianjin and Yin, Lu and Zhang, Zhenyu and
                  Shen, Li and Fang, Meng and Pechenizkiy, Mykola and
                  Wang, Zhangyang and Liu, Shiwei},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/huang23o.html}},
  pages =        {14023--14038},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Are Large Kernels Better Teachers than Transformers
                  for ConvNets?},
  volume =       202,
  year =         2023
}

@inproceedings{huang2023encoding,
  address =      {Kigali, Rwanda},
  author =       {Huang, Feiqing and Lu, Kexin and Cai, Yuxi and Qin,
                  Zhen and Fang, Yanwen and Tian, Guangjian and Li,
                  Guodong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=7YfHla7IxBJ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Encoding Recurrence into Transformers},
  year =         2023
}

@inproceedings{huang2023masked,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Guoxi and Fu, Hongtao and Bors, Adrian G.},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b3bac97f3227c52c0179a6d967480867-Paper-Conference.pdf}},
  pages =        {57570--57582},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Masked Image Residual Learning for Scaling Deeper
                  Vision Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{huang2023tailoring,
  address =      {New Orleans, Louisiana, USA},
  author =       {Huang, Siyuan and Song, Yunchong and Zhou, Jiayue
                  and Lin, Zhouhan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e90ba1fc564a69809d7391bf76a5f087-Paper-Conference.pdf}},
  pages =        {73559--73581},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Tailoring Self-Attention for Graph via Rooted
                  Subtrees},
  volume =       36,
  year =         2023
}

@inproceedings{huang2023transformerpatcher,
  address =      {Kigali, Rwanda},
  author =       {Huang, Zeyu and Shen, Yikang and Zhang, Xiaofeng and
                  Zhou, Jie and Rong, Wenge and Xiong, Zhang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=4oYUGeGBPm}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-Patcher: One Mistake Worth One Neuron},
  year =         2023
}

@inproceedings{huang2024attns,
  address =      {Vienna, Austria},
  author =       {Huang, Zhongzhan and Liang, Mingfu and Zhong,
                  Shanshan and Lin, Liang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=7RHFdkAkVY}},
  publisher =    {OpenReview.net},
  title =        {AttNS: Attention-Inspired Numerical Solving For
                  Limited Data Scenarios},
  year =         2024
}

@inproceedings{huang2024incontexta,
  address =      {Vienna, Austria},
  author =       {Huang, Sili and Hu, Jifeng and Chen, Hechang and
                  Sun, Lichao and Yang, Bo},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=jmmji1EU3g}},
  publisher =    {OpenReview.net},
  title =        {In-Context Decision Transformer: Reinforcement
                  Learning via Hierarchical Chain-of-Thought},
  year =         2024
}

@inproceedings{huang2024incontextb,
  address =      {Vienna, Austria},
  author =       {Huang, Yu and Cheng, Yuan and Liang, Yingbin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=9GLvXGkUE2}},
  publisher =    {OpenReview.net},
  title =        {In-context Convergence of Transformers},
  year =         2024
}

@inproceedings{huang2024training,
  address =      {Vienna, Austria},
  author =       {Huang, Yisong and Li, Jin and Chen, Xinlong and Fu,
                  Yang-Geng},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=j4VMrwgn1M}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Training Graph Transformers via Curriculum-Enhanced
                  Attention Distillation},
  year =         2024
}

@inproceedings{hudson2018compositional,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Hudson, Drew A. and Manning, Christopher D.},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=S1Euwz-Rb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Compositional Attention Networks for Machine
                  Reasoning},
  year =         2018
}

@inproceedings{hudson2021generative,
  address =      {Virtual Event},
  author =       {Hudson, Drew A. and Zitnick, Larry},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/hudson21a.html}},
  pages =        {4487--4499},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Generative Adversarial Transformers},
  volume =       139,
  year =         2021
}

@inproceedings{hussain2024triplet,
  address =      {Vienna, Austria},
  author =       {Hussain, Md. Shamim and Zaki, Mohammed J. and
                  Subramanian, Dharmashankar},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=iPFuWc1TV2}},
  publisher =    {OpenReview.net},
  title =        {Triplet Interaction Improves Graph Transformers:
                  Accurate Molecular Graph Learning with Triplet Graph
                  Transformers},
  year =         2024
}

@inproceedings{hutchins2022block,
  address =      {New Orleans, Louisiana, USA},
  author =       {Hutchins, DeLesley and Schlag, Imanol and Wu, Yuhuai
                  and Dyer, Ethan and Neyshabur, Behnam},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/d6e0bbb9fc3f4c10950052ec2359355c-Paper-Conference.pdf}},
  pages =        {33248--33261},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Block-Recurrent Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{hutchinson2021lietransformer,
  address =      {Virtual Event},
  author =       {Hutchinson, Michael J. and Lan, Charline Le and
                  Zaidi, Sheheryar and Dupont, Emilien and Teh, Yee
                  Whye and Kim, Hyunjik},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/hutchinson21a.html}},
  pages =        {4533--4543},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {LieTransformer: Equivariant Self-Attention for Lie
                  Groups},
  volume =       139,
  year =         2021
}

@inproceedings{hwang2021video,
  address =      {Virtual Event},
  author =       {Hwang, Sukjun and Heo, Miran and Oh, Seoung Wug and
                  Kim, Seon Joo},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6f2688a5fce7d48c8d19762b88c32c3b-Paper.pdf}},
  pages =        {13352--13363},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Video Instance Segmentation using Inter-Frame
                  Communication Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{ilbert2024samformer,
  address =      {Vienna, Austria},
  author =       {Ilbert, Romain and Odonnat, Ambroise and Feofanov,
                  Vasilii and Virmaux, Aladin and Paolo, Giuseppe and
                  Palpanas, Themis and Redko, Ievgen},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=8kLzL5QBh2}},
  publisher =    {OpenReview.net},
  title =        {SAMformer: Unlocking the Potential of Transformers
                  in Time Series Forecasting with Sharpness-Aware
                  Minimization and Channel-Wise Attention},
  year =         2024
}

@inproceedings{ildiz2024from,
  address =      {Vienna, Austria},
  author =       {Ildiz, Muhammed Emrullah and Huang, Yixiao and Li,
                  Yingcong and Rawat, Ankit Singh and Oymak, Samet},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=72oT4mPLUb}},
  publisher =    {OpenReview.net},
  title =        {From Self-Attention to Markov Models: Unveiling the
                  Dynamics of Generative Transformers},
  year =         2024
}

@inproceedings{ilse2018attentionbased,
  address =      {Stockholm, Sweden},
  author =       {Ilse, Maximilian and Tomczak, Jakub M. and Welling,
                  Max},
  booktitle =    {Proceedings of the 35th International Conference on
                  Machine Learning (ICML)},
  editor =       {Dy, Jennifer G. and Krause, Andreas},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v80/ilse18a.html}},
  pages =        {2132--2141},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Attention-based Deep Multiple Instance Learning},
  volume =       80,
  year =         2018
}

@inproceedings{imfeld2024transformer,
  address =      {Vienna, Austria},
  author =       {Imfeld, Moritz and Graldi, Jacopo and Giordano,
                  Marco and Hofmann, Thomas and Anagnostidis, Sotiris
                  and Singh, Sidak Pal},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=LjeqMvQpen}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer Fusion with Optimal Transport},
  year =         2024
}

@inproceedings{inala2020neurosymbolic,
  address =      {Virtual Event},
  author =       {Inala, Jeevana Priya and Yang, Yichen and Paulos,
                  James and Pu, Yewen and Bastani, Osbert and Kumar,
                  Vijay and Rinard, Martin and Solar-Lezama, Armando},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/9d740bd0f36aaa312c8d504e28c42163-Paper.pdf}},
  pages =        {13597--13608},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Neurosymbolic Transformers for Multi-Agent
                  Communication},
  volume =       33,
  year =         2020
}

@inproceedings{iqbal2019actorattentioncritic,
  address =      {Long Beach, California, USA},
  author =       {Iqbal, Shariq and Sha, Fei},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v97/iqbal19a.html}},
  pages =        {2961--2970},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Actor-Attention-Critic for Multi-Agent Reinforcement
                  Learning},
  volume =       97,
  year =         2019
}

@inproceedings{irie2021going,
  address =      {Virtual Event},
  author =       {Irie, Kazuki and Schlag, Imanol and Csordás, Róbert
                  and Schmidhuber, Jürgen},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/3f9e3767ef3b10a0de4c256d7ef9805d-Paper.pdf}},
  pages =        {7703--7717},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Going Beyond Linear Transformers with Recurrent Fast
                  Weight Programmers},
  volume =       34,
  year =         2021
}

@inproceedings{irie2022dual,
  address =      {Baltimore, Maryland, USA},
  author =       {Irie, Kazuki and Csordás, Róbert and Schmidhuber,
                  Jürgen},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/irie22a.html}},
  pages =        {9639--9659},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {The Dual Form of Neural Networks Revisited:
                  Connecting Test Time Predictions to Training
                  Patterns via Spotlights of Attention},
  volume =       162,
  year =         2022
}

@inproceedings{ismail2019input,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Ismail, Aya Abdelsalam and Gunady, Mohamed and
                  Pessoa, Luiz and Corrada Bravo, Hector and Feizi,
                  Soheil},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/bbc12a3a98d8487f58a87d3a3070516e-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Input-Cell Attention Reduces Vanishing Saliency of
                  Recurrent Neural Networks},
  volume =       32,
  year =         2019
}

@inproceedings{itti2001modeling,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Itti, Laurent and Braun, Jochen and Koch, Christof},
  booktitle =    {Advances in Neural Information Processing Systems 14
                  (NIPS)},
  editor =       {T. Dietterich and S. Becker and Z. Ghahramani},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2001/file/cbef46321026d8404bc3216d4774c8a9-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Modeling the Modulatory Effect of Attention on Human
                  Spatial Vision},
  volume =       14,
  year =         2001
}

@inproceedings{itti2005bayesian,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Itti, Laurent and Baldi, Pierre},
  booktitle =    {Advances in Neural Information Processing Systems 18
                  (NIPS)},
  editor =       {Weiss, Y. and Schölkopf, B. and Platt, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2005/file/0172d289da48c48de8c5ebf3de9f7ee1-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Bayesian Surprise Attracts Human Attention},
  volume =       18,
  year =         2005
}

@inproceedings{ivanov2022optimal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ivanov, Dmitry and Safiulin, Iskander and Filippov,
                  Igor and Balabaeva, Ksenia},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e0c07bb70721255482020afca44cabf2-Paper-Conference.pdf}},
  pages =        {34734--34747},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Optimal-er Auctions through Attention},
  volume =       35,
  year =         2022
}

@inproceedings{jaderberg2015spatial,
  address =      {Montreal, Quebec, Canada},
  author =       {Jaderberg, Max and Simonyan, Karen and Zisserman,
                  Andrew and Kavukcuoglu, Koray},
  booktitle =    {Advances in Neural Information Processing Systems 28
                  (NIPS)},
  editor =       {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2015/file/33ceb07bf4eeb3da587e268d663aba1a-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Spatial Transformer Networks},
  volume =       28,
  year =         2015
}

@inproceedings{jaegle2021perceiver,
  address =      {Virtual Event},
  author =       {Jaegle, Andrew and Gimeno, Felix and Brock, Andy and
                  Vinyals, Oriol and Zisserman, Andrew and Carreira,
                  João},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/jaegle21a.html}},
  pages =        {4651--4664},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Perceiver: General Perception with Iterative
                  Attention},
  volume =       139,
  year =         2021
}

@inproceedings{jain2023mnemosyne,
  address =      {New Orleans, Louisiana, USA},
  author =       {Jain, Deepali and Choromanski, Krzysztof M and
                  Dubey, Kumar Avinava and Singh, Sumeet and
                  Sindhwani, Vikas and Zhang, Tingnan and Tan, Jie},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f41b6e5af73421e46ceed9cb036e72e7-Paper-Conference.pdf}},
  pages =        {77331--77358},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Mnemosyne: Learning to Train Transformers with
                  Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{jang2023puca,
  address =      {New Orleans, Louisiana, USA},
  author =       {Jang, Hyemi and Park, Junsung and Jung, Dahuin and
                  Lew, Jaihyun and Bae, Ho and Yoon, Sungroh},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/3d226fb8fbd6ee6ec70d0427f1319707-Paper-Conference.pdf}},
  pages =        {19217--19229},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {PUCA: Patch-Unshuffle and Channel Attention for
                  Enhanced Self-Supervised Image Denoising},
  volume =       36,
  year =         2023
}

@inproceedings{janny2023eagle,
  address =      {Kigali, Rwanda},
  author =       {Janny, Steeven and Béneteau, Aurélien and Nadri,
                  Madiha and Digne, Julie and Thome, Nicolas and Wolf,
                  Christian},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=mfIX4QpsARJ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {EAGLE: Large-scale Learning of Turbulent Fluid
                  Dynamics with Mesh Transformers},
  year =         2023
}

@inproceedings{jaszczur2021sparse,
  address =      {Virtual Event},
  author =       {Jaszczur, Sebastian and Chowdhery, Aakanksha and
                  Mohiuddin, Afroz and Kaiser, Lukasz and Gajewski,
                  Wojciech and Michalewski, Henryk and Kanerva, Jonni},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/51f15efdd170e6043fa02a74882f0470-Paper.pdf}},
  pages =        {9895--9907},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Sparse is Enough in Scaling Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{javaloy2023learnable,
  address =      {Kigali, Rwanda},
  author =       {Javaloy, Adrián and Sánchez-Martín, Pablo and Levi,
                  Amit and Valera, Isabel},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=WsUMeHPo-2}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learnable Graph Convolutional Attention Networks},
  year =         2023
}

@inproceedings{jeeveswaran2023birt,
  address =      {Honolulu, Hawaii, USA},
  author =       {Jeeveswaran, Kishaan and Bhat, Prashant Shivaram and
                  Zonooz, Bahram and Arani, Elahe},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/jeeveswaran23a.html}},
  pages =        {14817--14835},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {BiRT: Bio-inspired Replay in Vision Transformers for
                  Continual Learning},
  year =         2023
}

@inproceedings{jeha2022psagan,
  address =      {Virtual Event},
  author =       {Jeha, Paul and Bohlke-Schneider, Michael and
                  Mercado, Pedro and Kapoor, Shubham and Nirwan,
                  Rajbir-Singh and Flunkert, Valentin and Gasthaus,
                  Jan and Januschowski, Tim},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Ix_mh42xq5w}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {PSA-GAN: Progressive Self Attention GANs for
                  Synthetic Time Series},
  year =         2022
}

@inproceedings{jelassi2022vision,
  address =      {New Orleans, Louisiana, USA},
  author =       {Jelassi, Samy and Sander, Michael and Li, Yuanzhi},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/f69707de866eb0805683d3521756b73f-Paper-Conference.pdf}},
  pages =        {37822--37836},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Vision Transformers Provably Learn Spatial
                  Structure},
  volume =       35,
  year =         2022
}

@inproceedings{jelassi2024repeat,
  address =      {Vienna, Austria},
  author =       {Jelassi, Samy and Br, David and fonbrener and
                  Kakade, Sham M. and Malach, Eran},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=duRRoGeoQT}},
  publisher =    {OpenReview.net},
  title =        {Repeat After Me: Transformers are Better than State
                  Space Models at Copying},
  year =         2024
}

@inproceedings{jetley2018learn,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Jetley, Saumya and Lord, Nicholas A. and Lee,
                  Namhoon and Torr, Philip H. S.},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HyzbhfWRW}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learn to Pay Attention},
  year =         2018
}

@inproceedings{jia2024geminifusion,
  address =      {Vienna, Austria},
  author =       {Jia, Ding and Guo, Jianyuan and Han, Kai and Wu, Han
                  and Zhang, Chao and Xu, Chang and Chen, Xinghao},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Zsz9Pdfvtg}},
  publisher =    {OpenReview.net},
  title =        {GeminiFusion: Efficient Pixel-wise Multimodal Fusion
                  for Vision Transformer},
  year =         2024
}

@inproceedings{jiang2021tokens,
  address =      {Virtual Event},
  author =       {Jiang, Zi-Hang and Hou, Qibin and Yuan, Li and Zhou,
                  Daquan and Shi, Yujun and Jin, Xiaojie and Wang,
                  Anran and Feng, Jiashi},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf}},
  pages =        {18590--18602},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {All Tokens Matter: Token Labeling for Training
                  Better Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{jiang2021transgan,
  address =      {Virtual Event},
  author =       {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf}},
  pages =        {14745--14758},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TransGAN: Two Pure Transformers Can Make One Strong
                  GAN, and That Can Scale Up},
  volume =       34,
  year =         2021
}

@inproceedings{jiang2023pre,
  address =      {New Orleans, Louisiana, USA},
  author =       {Jiang, Zixuan and Gu, Jiaqi and Zhu, Hanqing and
                  Pan, David},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8f1bacee31caf990a4f08d84f0ccb322-Paper-Conference.pdf}},
  pages =        {45777--45793},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pre-RMSNorm and Pre-CRMSNorm Transformers:
                  Equivalent and Efficient Pre-LN Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{jiang2024spatiotemporal,
  address =      {Vienna, Austria},
  author =       {Jiang, Yizhou and Hu, Kunlin and Zhang, Tianren and
                  Gao, Haichuan and Liu, Yuqian and Fang, Ying and
                  Chen, Feng},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=XrunSYwoLr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spatio-Temporal Approximation: A Training-Free SNN
                  Conversion for Transformers},
  year =         2024
}

@inproceedings{jiao2022mask,
  address =      {New Orleans, Louisiana, USA},
  author =       {Jiao, Siyu and Zhang, Gengwei and Navasardyan, Shant
                  and Chen, Ling and Zhao, Yao and Wei, Yunchao and
                  Shi, Humphrey},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/053a18c03e0844d0c484ba2861f8ae6c-Paper-Conference.pdf}},
  pages =        {823--836},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Mask Matching Transformer for Few-Shot Segmentation},
  volume =       35,
  year =         2022
}

@inproceedings{jin2021generalizable,
  address =      {Virtual Event},
  author =       {Jin, Tao and Zhao, Zhou},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4bbdcc0e821637155ac4217bdab70d2e-Paper.pdf}},
  pages =        {9049--9060},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Generalizable Multi-linear Attention Network},
  volume =       34,
  year =         2021
}

@inproceedings{jin2022domain,
  address =      {Baltimore, Maryland, USA},
  author =       {Jin, Xiaoyong and Park, Youngsuk and Maddix,
                  Danielle C. and Wang, Hao and Wang, Yuyang},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/jin22d.html}},
  pages =        {10280--10297},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Domain Adaptation for Time Series Forecasting via
                  Attention Sharing},
  volume =       162,
  year =         2022
}

@inproceedings{jin2023edgeformers,
  address =      {Kigali, Rwanda},
  author =       {Jin, Bowen and Zhang, Yu and Meng, Yu and Han,
                  Jiawei},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=2YQrqe4RNv}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Edgeformers: Graph-Empowered Transformers for
                  Representation Learning on Textual-Edge Networks},
  year =         2023
}

@inproceedings{jong2022mention,
  address =      {Virtual Event},
  author =       {Jong, Michiel de and Zemlyanskiy, Yury and
                  FitzGerald, Nicholas and Sha, Fei and Cohen, William
                  W.},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=OY1A8ejQgEX}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Mention Memory: incorporating textual knowledge into
                  Transformers through entity mention attention},
  year =         2022
}

@inproceedings{ju2022staircase,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ju, Da and Roller, Stephen and Sukhbaatar, Sainbayar
                  and Weston, Jason E},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5565ab682d6c7f8d9da34ba0919974b0-Paper-Conference.pdf}},
  pages =        {13203--13213},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Staircase Attention for Recurrent Processing of
                  Sequences},
  volume =       35,
  year =         2022
}

@inproceedings{kacham2024polysketchformer,
  address =      {Vienna, Austria},
  author =       {Kacham, Praneeth and Mirrokni, Vahab and Zhong,
                  Peilin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ghYrfdJfjK}},
  publisher =    {OpenReview.net},
  title =        {PolySketchFormer: Fast Transformers via Sketching
                  Polynomial Kernels},
  year =         2024
}

@inproceedings{kaddour2023no,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kaddour, Jean and Key, Oscar and Nawrot, Piotr and
                  Minervini, Pasquale and Kusner, Matt J},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/51f3d6252706100325ddc435ba0ade0e-Paper-Conference.pdf}},
  pages =        {25793--25818},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {No Train No Gain: Revisiting Efficient Training
                  Algorithms For Transformer-based Language Models},
  volume =       36,
  year =         2023
}

@inproceedings{kaiser2016can,
  address =      {Barcelona, Spain},
  author =       {Kaiser, Łukasz and Bengio, Samy},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {Lee, D. and Sugiyama, M. and Luxburg, U. and Guyon,
                  I. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/fb8feff253bb6c834deb61ec76baa893-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Can Active Memory Replace Attention?},
  volume =       29,
  year =         2016
}

@inproceedings{kajitsuka2024are,
  address =      {Vienna, Austria},
  author =       {Kajitsuka, Tokio and Sato, Issei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=nJnky5K944}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Are Transformers with One Layer Self-Attention Using
                  Low-Rank Weight Matrices Universal Approximators?},
  year =         2024
}

@inproceedings{kamienny2022end,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kamienny, Pierre-Alexandre and d'Ascoli, Stéphane
                  and Lample, Guillaume and Charton, Francois},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/42eb37cdbefd7abae0835f4b67548c39-Paper-Conference.pdf}},
  pages =        {10269--10281},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {End-to-end Symbolic Regression with Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{kamra2020multi,
  address =      {Virtual Event},
  author =       {Kamra, Nitin and Zhu, Hao and Trivedi, Dweep
                  Kumarbhai and Zhang, Ming and Liu, Yan},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/fe87435d12ef7642af67d9bc82a8b3cd-Paper.pdf}},
  pages =        {22530--22541},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multi-agent Trajectory Prediction with Fuzzy Query
                  Attention},
  volume =       33,
  year =         2020
}

@inproceedings{kan2022brain,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kan, Xuan and Dai, Wei and Cui, Hejie and Zhang,
                  Zilong and Guo, Ying and Yang, Carl},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/a408234a9b80604a9cf6ca518e474550-Paper-Conference.pdf}},
  pages =        {25586--25599},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Brain Network Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{kang2024think,
  address =      {Vienna, Austria},
  author =       {Kang, Jikun and Laroche, Romain and Yuan, Xingdi and
                  Trischler, Adam and Liu, Xue and Fu, Jie},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=PSQ5Z920M8}},
  publisher =    {OpenReview.net},
  title =        {Think Before You Act: Decision Transformers with
                  Working Memory},
  year =         2024
}

@inproceedings{karch2021grounding,
  address =      {Virtual Event},
  author =       {Karch, Tristan and Teodorescu, Laetitia and Hofmann,
                  Katja and Moulin-Frier, Clément and Oudeyer,
                  Pierre-Yves},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/29daf9442f3c0b60642b14c081b4a556-Paper.pdf}},
  pages =        {5236--5249},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Grounding Spatio-Temporal Language with
                  Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{kasai2020nonautoregressive,
  address =      {Virtual Event},
  author =       {Kasai, Jungo and Cross, James and Ghazvininejad,
                  Marjan and Gu, Jiatao},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/kasai20a.html}},
  pages =        {5144--5155},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Non-autoregressive Machine Translation with
                  Disentangled Context Transformer},
  year =         2020
}

@inproceedings{katharopoulos2019processing,
  address =      {Long Beach, California, USA},
  author =       {Katharopoulos, Angelos and Fleuret, François},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v97/katharopoulos19a.html}},
  pages =        {3282--3291},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Processing Megapixel Images with Deep
                  Attention-Sampling Models},
  volume =       97,
  year =         2019
}

@inproceedings{katharopoulos2020transformers,
  address =      {Virtual Event},
  author =       {Katharopoulos, Angelos and Vyas, Apoorv and Pappas,
                  Nikolaos and Fleuret, François},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/katharopoulos20a.html}},
  pages =        {5156--5165},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformers are RNNs: Fast Autoregressive
                  Transformers with Linear Attention},
  year =         2020
}

@inproceedings{kazemnejadamirhossein2023impact,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kazemnejad, Amirhossein and Padhi, Inkit and Natesan
                  Ramamurthy, Karthikeyan and Das, Payel and Reddy,
                  Siva},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4e85362c02172c0c6567ce593122d31c-Paper-Conference.pdf}},
  pages =        {24892--24928},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Impact of Positional Encoding on Length
                  Generalization in Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{ke2021prototypical,
  address =      {Virtual Event},
  author =       {Ke, Lei and Li, Xia and Danelljan, Martin and Tai,
                  Yu-Wing and Tang, Chi-Keung and Yu, Fisher},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf}},
  pages =        {1192--1203},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Prototypical Cross-Attention Networks for Multiple
                  Object Tracking and Segmentation},
  volume =       34,
  year =         2021
}

@inproceedings{kedia2024transformers,
  address =      {Vienna, Austria},
  author =       {Kedia, Akhil and Zaidi, Mohd Abbas and Khyalia,
                  Sushil and Jung, Jungho and Goka, Harshith and Lee,
                  Haejun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=30waYPIZUA}},
  publisher =    {OpenReview.net},
  title =        {Transformers Get Stable: An End-to-End Signal
                  Propagation Theory for Language Models},
  year =         2024
}

@inproceedings{kerg2020untangling,
  address =      {Virtual Event},
  author =       {Kerg, Giancarlo and Kanuparthi, Bhargav and Goyal,
                  Anirudh and Goyette, Kyle and Bengio, Yoshua and
                  Lajoie, Guillaume},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/e2065cb56f5533494522c46a72f1dfb0-Paper.pdf}},
  pages =        {19443--19454},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Untangling tradeoffs between recurrence and
                  self-attention in artificial neural networks},
  volume =       33,
  year =         2020
}

@inproceedings{khaki2024need,
  address =      {Vienna, Austria},
  author =       {Khaki, Samir and Plataniotis, Konstantinos N.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MVmT6uQ3cQ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {The Need for Speed: Pruning Transformers with One
                  Recipe},
  year =         2024
}

@inproceedings{khalitov2023chordmixer,
  address =      {Kigali, Rwanda},
  author =       {Khalitov, Ruslan and Yu, Tong and Cheng, Lei and
                  Yang, Zhirong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=E8mzu3JbdR}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ChordMixer: A Scalable Neural Attention Model for
                  Sequences with Different Length},
  year =         2023
}

@inproceedings{kharbanda2022cascadexml,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kharbanda, Siddhant and Banerjee, Atmadeep and
                  Schultheis, Erik and Babbar, Rohit},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/0e0157ce5ea15831072be4744cbd5334-Paper-Conference.pdf}},
  pages =        {2074--2087},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CascadeXML: Rethinking Transformers for End-to-end
                  Multi-resolution Training in Extreme Multi-label
                  Classification},
  volume =       35,
  year =         2022
}

@inproceedings{khona2024towards,
  address =      {Vienna, Austria},
  author =       {Khona, Mikail and Okawa, Maya and Hula, Jan and
                  Ramesh, Rahul and Nishi, Kento and Dick, Robert
                  P. and Lubana, Ekdeep Singh and Tanaka, Hidenori},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=8VEGkphQaK}},
  publisher =    {OpenReview.net},
  title =        {Towards an Understanding of Stepwise Inference in
                  Transformers: A Synthetic Graph Navigation Model},
  year =         2024
}

@inproceedings{khosla2020neural,
  address =      {Virtual Event},
  author =       {Khosla, Meenakshi and Ngo, Gia and Jamison, Keith
                  and Kuceyeski, Amy and Sabuncu, Mert},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/b71f5aaf3371c2cdfb7a7c0497f569d4-Paper.pdf}},
  pages =        {15942--15953},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Neural encoding with visual attention},
  volume =       33,
  year =         2020
}

@inproceedings{khwaja2023celle,
  address =      {New Orleans, Louisiana, USA},
  author =       {Khwaja, Emaad and Song, Yun and Agarunov, Aaron and
                  Huang, Bo},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/0fb7c02d420c993385c7de44c2b5bf01-Paper-Conference.pdf}},
  pages =        {4899--4914},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CELLE-2: Translating Proteins to Pictures and Back
                  with a Bidirectional Text-to-Image Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{kim2017structured,
  address =      {Toulon, France},
  author =       {Kim, Yoon and Denton, Carl and Hoang, Luong and
                  Alex, Unknown and Rush, er M.},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HkE0Nvqlg}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Structured Attention Networks},
  year =         2017
}

@inproceedings{kim2018bilinear,
  address =      {Montreal, Quebec, Canada},
  author =       {Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {S. Bengio and H. Wallach and H. Larochelle and
                  K. Grauman and N. Cesa-Bianchi and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/96ea64f3a1aa2fd00c72faacf0cb8ac9-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Bilinear Attention Networks},
  volume =       31,
  year =         2018
}

@inproceedings{kim2018recurrent,
  address =      {Montreal, Quebec, Canada},
  author =       {Kim, Seungryong and Lin, Stephen and Jeon, Sang Ryul
                  and Min, Dongbo and Sohn, Kwanghoon},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/e4a93f0332b2519177ed55741ea4e5e7-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Recurrent Transformer Networks for Semantic
                  Correspondence},
  volume =       31,
  year =         2018
}

@inproceedings{kim2019learning,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Kim, Wonjae and Lee, Yoonho},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/ae3539867aaeec609a4260c6feb725f4-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Dynamics of Attention: Human Prior for
                  Interpretable Machine Reasoning},
  volume =       32,
  year =         2019
}

@inproceedings{kim2021learninga,
  address =      {Virtual Event},
  author =       {Kim, Byung-Hoon and Ye, Jong Chul and Kim, Jae-Jin},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/22785dd2577be2ce28ef79febe80db10-Paper.pdf}},
  pages =        {4314--4327},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Dynamic Graph Representation of Brain
                  Connectome with Spatio-Temporal Attention},
  volume =       34,
  year =         2021
}

@inproceedings{kim2021lipschitz,
  address =      {Virtual Event},
  author =       {Kim, Hyunjik and Papamakarios, George and Mnih,
                  Andriy},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/kim21i.html}},
  pages =        {5562--5571},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {The Lipschitz Constant of Self-Attention},
  volume =       139,
  year =         2021
}

@inproceedings{kim2021relational,
  address =      {Virtual Event},
  author =       {Kim, Manjin and Kwon, Heeseung and Wang, Chunyu and
                  Kwak, Suha and Cho, Minsu},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4392e631da381761421d5e1e0c3de25f-Paper.pdf}},
  pages =        {8046--8059},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Relational Self-Attention: What's Missing in
                  Attention for Video Understanding},
  volume =       34,
  year =         2021
}

@inproceedings{kim2021to,
  address =      {Virtual Event, Austria},
  author =       {Kim, Dongkwan and Oh, Alice},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Wi5KUNlqWty}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {How to Find Your Friendly Neighborhood: Graph
                  Attention Design with Self-Supervision},
  year =         2021
}

@inproceedings{kim2021transformers,
  address =      {Virtual Event},
  author =       {Kim, Jinwoo and Oh, Saeyoon and Hong, Seunghoon},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/ec0f40c389aeef789ce03eb814facc6c-Paper.pdf}},
  pages =        {28016--28028},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers Generalize DeepSets and Can be Extended
                  to Graphs and Hypergraphs},
  volume =       34,
  year =         2021
}

@inproceedings{kim2021vilt,
  address =      {Virtual Event},
  author =       {Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/kim21k.html}},
  pages =        {5583--5594},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {ViLT: Vision-and-Language Transformer Without
                  Convolution or Region Supervision},
  volume =       139,
  year =         2021
}

@inproceedings{kim2022neural,
  address =      {Virtual Event},
  author =       {Kim, Mingyu and Go, Kyeongryeol and Yun, Se-Young},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=JPkQwEdYn8}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Neural Processes with Stochastic Attention: Paying
                  More Attention to the Context Dataset},
  year =         2022
}

@inproceedings{kim2022pure,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kim, Jinwoo and Nguyen, Dat and Min, Seonwoo and
                  Cho, Sungjun and Lee, Moontae and Lee, Honglak and
                  Hong, Seunghoon},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5d84236751fe6d25dc06db055a3180b0-Paper-Conference.pdf}},
  pages =        {14582--14595},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pure Transformers are Powerful Graph Learners},
  volume =       35,
  year =         2022
}

@inproceedings{kim2022squeezeformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kim, Sehoon and Gholami, Amir and Shaw, Albert and
                  Lee, Nicholas and Mangalam, Karttikeya and Malik,
                  Jitendra and Mahoney, Michael W. and Keutzer, Kurt},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3ccf6da39eeb8fefc8bbb1b0124adbd1-Paper-Conference.pdf}},
  pages =        {9361--9373},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Squeezeformer: An Efficient Transformer for
                  Automatic Speech Recognition},
  volume =       35,
  year =         2022
}

@inproceedings{kim2022vitnet,
  address =      {Baltimore, Maryland, USA},
  author =       {Kim, Sangwon and Nam, Jae-Yeal and Ko, ByoungChul},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/kim22g.html}},
  pages =        {11162--11172},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {ViT-NeT: Interpretable Vision Transformers with
                  Neural Tree Decoder},
  volume =       162,
  year =         2022
}

@inproceedings{kim2023devformer,
  address =      {Honolulu, Hawaii, USA},
  author =       {Kim, Haeyeon and Kim, Minsu and Berto, Federico and
                  Kim, Joungho and Park, Jinkyoo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/kim23h.html}},
  pages =        {16541--16566},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {DevFormer: A Symmetric Transformer for Context-Aware
                  Device Placement},
  volume =       202,
  year =         2023
}

@inproceedings{kim2023preference,
  address =      {Kigali, Rwanda},
  author =       {Kim, Changyeon and Park, Jongjin and Shin, Jinwoo
                  and Lee, Honglak and Abbeel, Pieter and Lee, Kimin},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Peot1SFDX0}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Preference Transformer: Modeling Human Preferences
                  using Transformers for RL},
  year =         2023
}

@inproceedings{kim2023provable,
  address =      {Kigali, Rwanda},
  author =       {Kim, Junghwan and Kim, Michelle and Mozafari,
                  Barzan},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=8JCg5xJCTPR}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Provable Memorization Capacity of Transformers},
  year =         2023
}

@inproceedings{kim2023swift,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kim, Peter and Kwon, Junbeom and Joo, Sunghwan and
                  Bae, Sangyoon and Lee, Donggyu and Jung, Yoonho and
                  Yoo, Shinjae and Cha, Jiook and Moon, Taesup},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8313b1920ee9c78d846c5798c1ce48be-Paper-Conference.pdf}},
  pages =        {42015--42037},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SwiFT: Swin 4D fMRI Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{kim2023transformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kim, Dong Kyum and Kwon, Jea and Cha, Meeyoung and
                  Lee, C.},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/2f1eb4c897e63870eee9a0a0f7a10332-Paper-Conference.pdf}},
  pages =        {14637--14664},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformer as a hippocampal memory consolidation
                  model based on NMDAR-inspired nonlinearity},
  volume =       36,
  year =         2023
}

@inproceedings{kim2023transformerbased,
  address =      {Honolulu, Hawaii, USA},
  author =       {Kim, Chanyeong and Park, Jongwoong and Bae, Hyunglip
                  and Kim, Woo Chang},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/kim23r.html}},
  pages =        {16747--16770},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformer-based Stagewise Decomposition for
                  Large-Scale Multistage Stochastic Optimization},
  volume =       202,
  year =         2023
}

@inproceedings{kim2024polynomialbased,
  address =      {Vienna, Austria},
  author =       {Kim, Jayoung and Shin, Yehjin and Choi, Jeongwhan
                  and Wi, Hyowon and Park, Noseong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=QZd3rvlP76}},
  publisher =    {OpenReview.net},
  title =        {Polynomial-Based Self-Attention for Table
                  Representation Learning},
  year =         2024
}

@inproceedings{kim2024transformers,
  address =      {Vienna, Austria},
  author =       {Kim, Juno and Suzuki, Taiji},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=xm2lU7tteQ}},
  publisher =    {OpenReview.net},
  title =        {Transformers Learn Nonlinear Features In Context:
                  Nonconvex Mean-field Dynamics on the Attention
                  Landscape},
  year =         2024
}

@article{kissas2022learning,
  author =       {Kissas, Georgios and Seidman, Jacob H. and Guilhoto,
                  Leonardo Ferreira and Preciado, Victor M. and
                  Pappas, George J. and Perdikaris, Paris},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v23/21-1521.html}},
  number =       215,
  pages =        {1--63},
  title =        {Learning Operators with Coupled Attention},
  volume =       23,
  year =         2022
}

@inproceedings{kitaev2020reformer,
  address =      {Addis Ababa, Ethiopia},
  author =       {Kitaev, Nikita and Kaiser, Lukasz and Levskaya,
                  Anselm},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rkgNKkHtvB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Reformer: The Efficient Transformer},
  year =         2020
}

@inproceedings{knowles2023neuromodulation,
  address =      {Kigali, Rwanda},
  author =       {Knowles, Kobe and Bensemann, Joshua and Prado, Diana
                  Benavides and Yogarajan, Vithya and Witbrock,
                  Michael and Dobbie, Gillian and Chen, Yang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cYKtDg5JnxV}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Neuromodulation Gated Transformer},
  year =         2023
}

@inproceedings{knyazev2019understanding,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Knyazev, Boris and Taylor, Graham W. and Amer,
                  Mohamed},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Understanding Attention and Generalization in Graph
                  Neural Networks},
  volume =       32,
  year =         2019
}

@inproceedings{knyazev2023scale,
  address =      {Honolulu, Hawaii, USA},
  author =       {Knyazev, Boris and Hwang, Doha and Lacoste-Julien,
                  Simon},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/knyazev23a.html}}},
  pages =        {17243--17259},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Can We Scale Transformers to Predict Parameters of
                  Diverse ImageNet Models?},
  year =         2023
}

@inproceedings{kobayashi2024analyzing,
  address =      {Vienna, Austria},
  author =       {Kobayashi, Goro and Kuribayashi, Tatsuki and Yokoi,
                  Sho and Inui, Kentaro},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=mYWsyTuiRp}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Analyzing Feed-Forward Blocks in Transformers
                  through the Lens of Attention Maps},
  year =         2024
}

@inproceedings{kong2023goat,
  address =      {Honolulu, Hawaii, USA},
  author =       {Kong, Kezhi and Chen, Jiuhai and Kirchenbauer, John
                  and Ni, Renkun and Bruss, C. Bayan and Goldstein,
                  Tom},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/kong23a.html}}},
  pages =        {17375--17390},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {GOAT: A Global Transformer on Large-scale Graphs},
  year =         2023
}

@inproceedings{kong2023momentum,
  address =      {Kigali, Rwanda},
  author =       {Kong, Lingkai and Wang, Yuqing and Tao, Molei},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vCJ9-Ri-6xU}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Momentum Stiefel Optimizer, with Applications to
                  Suitably-Orthogonal Attention, and Optimal
                  Transport},
  year =         2023
}

@inproceedings{kong2024generalist,
  address =      {Vienna, Austria},
  author =       {Kong, Xiangzhe and Huang, Wenbing and Liu, Yang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=dWxb80a0TW}},
  publisher =    {OpenReview.net},
  title =        {Generalist Equivariant Transformer Towards 3D
                  Molecular Interaction Learning},
  year =         2024
}

@inproceedings{kosaraju2019social,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Kosaraju, Vineet and Sadeghian, Amir and
                  Martín-Martín, Roberto and Reid, Ian and
                  Rezatofighi, Hamid and Savarese, Silvio},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/d09bf41544a3365a46c9077ebb5e35c3-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Social-BiGAT: Multimodal Trajectory Forecasting
                  using Bicycle-GAN and Graph Attention Networks},
  volume =       32,
  year =         2019
}

@inproceedings{kossen2021selfattention,
  address =      {Virtual Event},
  author =       {Kossen, Jannik and Band, Neil and Lyle, Clare and
                  Gomez, Aidan N and Rainforth, Thomas and Gal, Yarin},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f1507aba9fc82ffa7cc7373c58f8a613-Paper.pdf}},
  pages =        {28742--28756},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Self-Attention Between Datapoints: Going Beyond
                  Individual Input-Output Pairs in Deep Learning},
  volume =       34,
  year =         2021
}

@inproceedings{kosson2023multiplication,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kosson, Atli and Jaggi, Martin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/19df21cd4931bd0caaa4d8480e9a59cd-Paper-Conference.pdf}},
  pages =        {8208--8223},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multiplication-Free Transformer Training via
                  Piecewise Affine Operations},
  volume =       36,
  year =         2023
}

@inproceedings{kratsios2022universal,
  address =      {Virtual Event},
  author =       {Kratsios, Anastasis and Zamanlooy, Behnoosh and Liu,
                  Tianlin and Dokmanic, Ivan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=JGO8CvG5S9}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Universal Approximation Under Constraints is
                  Possible with Transformers},
  year =         2022
}

@article{kratsios2023small,
  author =       {Kratsios, Anastasis and Debarnot, Valentin and
                  Dokmanić, Ivan},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v24/22-1246.html}},
  number =       170,
  pages =        {1--48},
  title =        {Small Transformers Compute Universal Metric
                  Embeddings},
  volume =       24,
  year =         2023
}

@inproceedings{kreuzer2021rethinking,
  address =      {Virtual Event},
  author =       {Kreuzer, Devin and Beaini, Dominique and Hamilton,
                  Will and Létourneau, Vincent and Tossou, Prudencio},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/b4fd1d2cb085390fbbadae65e07876a7-Paper.pdf}},
  pages =        {21618--21629},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Rethinking Graph Transformers with Spectral
                  Attention},
  volume =       34,
  year =         2021
}

@inproceedings{kumar2021colorization,
  address =      {Virtual Event, Austria},
  author =       {Kumar, Manoj and Weissenborn, Dirk and Kalchbrenner,
                  Nal},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=5NA1PinlGFu}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Colorization Transformer},
  year =         2021
}

@inproceedings{kunstner2023noise,
  address =      {Kigali, Rwanda},
  author =       {Kunstner, Frederik and Chen, Jacques and Lavington,
                  Jonathan Wilder and Schmidt, Mark},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=a65YK0cqH8g}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Noise Is Not the Main Factor Behind the Gap Between
                  Sgd and Adam on Transformers, But Sign Descent Might
                  Be},
  year =         2023
}

@inproceedings{kwon2022fast,
  address =      {New Orleans, Louisiana, USA},
  author =       {Kwon, Woosuk and Kim, Sehoon and Mahoney, Michael
                  W. and Hassoun, Joseph and Keutzer, Kurt and
                  Gholami, Amir},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/987bed997ab668f91c822a09bce3ea12-Paper-Conference.pdf}},
  pages =        {24101--24116},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Fast Post-Training Pruning Framework for
                  Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{lai2023chipformer,
  address =      {Honolulu, Hawaii, USA},
  author =       {Lai, Yao and Liu, Jinxin and Tang, Zhentao and Wang,
                  Bin and Hao, Jianye and Luo, Ping},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/lai23c.html}},
  pages =        {18346--18364},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {ChiPFormer: Transferable Chip Placement via Offline
                  Decision Transformer},
  volume =       202,
  year =         2023
}

@inproceedings{lan2023contrastive,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lan, Siming and Zhang, Rui and Yi, Qi and Guo,
                  Jiaming and Peng, Shaohui and Gao, Yunkai and Wu,
                  Fan and Chen, Ruizhi and Du, Zidong and Hu, Xing and
                  Zhang, Xishan and Li, Ling and Chen, Yunji},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/72802bef5cf1a3449e909b20c2ae18d5-Paper-Conference.pdf}},
  pages =        {36507--36523},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Contrastive Modules with Temporal Attention for
                  Multi-Task Reinforcement Learning},
  volume =       36,
  year =         2023
}

@inproceedings{langlois2021passive,
  address =      {Virtual Event},
  author =       {Langlois, Thomas and Zhao, Haicheng and Grant, Erin
                  and Dasgupta, Ishita and Griffiths, Tom and Jacoby,
                  Nori},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/e360367584297ee8d2d5afa709cd440e-Paper.pdf}},
  pages =        {27094--27106},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Passive attention in artificial neural networks
                  predicts human visual selectivity},
  volume =       34,
  year =         2021
}

@inproceedings{lao2024subtoken,
  address =      {Vienna, Austria},
  author =       {Lao, Dong and Wu, Yangchao and Liu, Tian Yu and
                  Wong, Alex and Soatto, Stefano},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{https://openreview.net/forum?id=6DBvBcW770}}},
  publisher =    {OpenReview.net},
  title =        {Sub-token ViT Embedding via Stochastic Resonance
                  Transformers},
  year =         2024
}

@inproceedings{lavie2024towards,
  address =      {Vienna, Austria},
  author =       {Lavie, Itay and Gur-Ari, Guy and Ringel, Zohar},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=HOMXUneCTR}},
  publisher =    {OpenReview.net},
  title =        {Towards Understanding Inductive Bias in
                  Transformers: A View From Infinity},
  year =         2024
}

@inproceedings{le2022stndt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Le, Trung and Shlizerman, Eli},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/72163d1c3c1726f1c29157d06e9e93c1-Paper-Conference.pdf}},
  pages =        {17926--17939},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {STNDT: Modeling Neural Population Activity with
                  Spatiotemporal Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{lebrat2021corticalflow,
  address =      {Virtual Event},
  author =       {Lebrat, Leo and Santa Cruz, Rodrigo and de Gournay,
                  Frederic and Fu, Darren and Bourgeat, Pierrick and
                  Fripp, Jurgen and Fookes, Clinton and Salvado,
                  Olivier},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f6b5f8c32c65fee991049a55dc97d1ce-Paper.pdf}},
  pages =        {29491--29505},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CorticalFlow: A Diffeomorphic Mesh Transformer
                  Network for Cortical Surface Reconstruction},
  volume =       34,
  year =         2021
}

@inproceedings{lee1999robust,
  address =      {Denver, Colorado, USA},
  author =       {Lee, Soo-Young and Mozer, Michael C},
  booktitle =    {Advances in Neural Information Processing Systems 12
                  (NIPS)},
  editor =       {S. Solla and T. Leen and K. Müller},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1999/file/5cf21ce30208cfffaa832c6e44bb567d-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Robust Recognition of Noisy and Superimposed
                  Patterns via Selective Attention},
  volume =       12,
  year =         1999
}

@inproceedings{lee2019selfattention,
  address =      {Long Beach, California, USA},
  author =       {Lee, Junhyun and Lee, Inyeop and Kang, Jaewoo},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =         {\url{http://proceedings.mlr.press/v97/lee19c.html}},
  pages =        {3734--3743},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Self-Attention Graph Pooling},
  volume =       97,
  year =         2019
}

@inproceedings{lee2019set,
  address =      {Long Beach, California, USA},
  author =       {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and
                  Kosiorek, Adam R. and Choi, Seungjin and Teh, Yee
                  Whye},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =         {\url{http://proceedings.mlr.press/v97/lee19d.html}},
  pages =        {3744--3753},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Set Transformer: A Framework for Attention-based
                  Permutation-Invariant Neural Networks},
  volume =       97,
  year =         2019
}

@inproceedings{lee2021parameter,
  address =      {Virtual Event, Austria},
  author =       {Lee, Sangho and Yu, Youngjae and Kim, Gunhee and
                  Breuel, Thomas M. and Kautz, Jan and Song, Yale},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=6UdQLhqJyFD}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Parameter Efficient Multimodal Transformers for
                  Video Representation Learning},
  year =         2021
}

@inproceedings{lee2022draft,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lee, Doyup and Kim, Chiheon and Kim, Saehoon and
                  Cho, Minsu and Han, Wook Shin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c276c3303c0723c83a43b95a44a1fcbf-Paper-Conference.pdf}},
  pages =        {30127--30138},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Draft-and-Revise: Effective Image Generation with
                  Contextual RQ-Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{lee2022multi,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao
                  and Lee, Lisa and Freeman, Daniel and Guadarrama,
                  Sergio and Fischer, Ian and Xu, Winnie and Jang,
                  Eric and Michalewski, Henryk and Mordatch, Igor},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/b2cac94f82928a85055987d9fd44753f-Paper-Conference.pdf}},
  pages =        {27921--27936},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multi-Game Decision Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{lee2022vitgan,
  address =      {Virtual Event},
  author =       {Lee, Kwonjoon and Chang, Huiwen and Jiang, Lu and
                  Zhang, Han and Tu, Zhuowen and Liu, Ce},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=dwg5rXg1WS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ViTGAN: Training GANs with Vision Transformers},
  year =         2022
}

@inproceedings{lee20233d,
  address =      {Kigali, Rwanda},
  author =       {Lee, Ho Hin and Bao, Shunxing and Huo, Yuankai and
                  L, Bennett A. and man,},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=wsZsjOSytRA}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {3D UX-Net: A Large Kernel Volumetric ConvNet
                  Modernizing Hierarchical Transformer for Medical
                  Image Segmentation},
  year =         2023
}

@inproceedings{lee2023cast,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lee, Dongho and Lee, Jongseo and Choi, Jinwoo},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/fb1b83b35e96998ddfc0ce1dab635445-Paper-Conference.pdf}},
  pages =        {79399--79425},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {CAST: Cross-Attention in Space and Time for Video
                  Action Recognition},
  volume =       36,
  year =         2023
}

@inproceedings{lee2023composite,
  address =      {Kigali, Rwanda},
  author =       {Lee, Mingu and Pitre, Saurabh and Jiang, Tianyu and
                  Letourneau, Pierre-David and Morse, Matthew J. and
                  Jang, Kanghwan and Soriaga, Joseph and Noorzad,
                  Parham and Cheng, Hsin-Pai and Lott, Christopher},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=nWTzIsgrYNN}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Composite Slice Transformer: An Efficient
                  Transformer with Composition of Multi-Scale
                  Multi-Range Attentions},
  year =         2023
}

@inproceedings{lee2023density,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lee, Namkyeong and Noh, Heewoong and Kim, Sungwon
                  and Hyun, Dongmin and Na, Gyoung S. and Park,
                  Chanyoung},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/c23fdcb9f8e28af705a87de1375a705c-Paper-Conference.pdf}},
  pages =        {61678--61698},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Density of States Prediction of Crystalline
                  Materials via Prompt-guided Multi-Modal Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{lee2023selfdistillation,
  address =      {Kigali, Rwanda},
  author =       {Lee, Seanie and Kang, Minki and Lee, Juho and Hwang,
                  Sung Ju and Kawaguchi, Kenji},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=kj6oK_Hj40}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Self-Distillation for Further Pre-training of
                  Transformers},
  year =         2023
}

@inproceedings{lee2023softmax,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lee, Changhyeon and Lee, Seulki},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/311257424b6d80e930fc93b224f0a63e-Paper-Conference.pdf}},
  pages =        {15108--15120},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Softmax Output Approximation for Activation
                  Memory-Efficient Training of Attention-based
                  Networks},
  volume =       36,
  year =         2023
}

@inproceedings{lee2023sparse,
  address =      {Kigali, Rwanda},
  author =       {Lee, Heejun and Kang, Minki and Lee, Youngwan and
                  Hwang, Sung Ju},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=VV0hSE8AxCw}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Sparse Token Transformer with Attention Back
                  Tracking},
  year =         2023
}

@inproceedings{lee2023towards,
  address =      {Honolulu, Hawaii, USA},
  author =       {Lee, Soo Yong and Bu, Fanchen and Yoo, Jaemin and
                  Shin, Kijung},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/lee23b.html}},
  pages =        {18774--18795},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Towards Deep Attention in Graph Neural Networks:
                  Problems and Remedies},
  volume =       202,
  year =         2023
}

@inproceedings{lee2024is,
  address =      {Vienna, Austria},
  author =       {Lee, Ivan and Jiang, Nan and Berg-Kirkpatrick,
                  Taylor},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Qwq4cpLtoX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Is attention required for ICL? Exploring the
                  Relationship Between Model Architecture and
                  In-Context Learning Ability},
  year =         2024
}

@inproceedings{lee2024sea,
  address =      {Vienna, Austria},
  author =       {Lee, Heejun and Kim, Jina and Willette, Jeffrey and
                  Hwang, Sung Ju},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=JbcwfmYrob}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SEA: Sparse Linear Attention with Estimated
                  Attention Mask},
  year =         2024
}

@inproceedings{lee2024teaching,
  address =      {Vienna, Austria},
  author =       {Lee, Nayoung and Sreenivasan, Kartik and Lee, Jason
                  D. and Lee, Kangwook and Papailiopoulos, Dimitris},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=dsUB4bst9S}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Teaching Arithmetic to Small Transformers},
  year =         2024
}

@inproceedings{lee2024testam,
  address =      {Vienna, Austria},
  author =       {Lee, Hyunwook and Ko, Sungahn},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=N0nTk5BSvO}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {TESTAM: A Time-Enhanced Spatio-Temporal Attention
                  Model with Mixture of Experts},
  year =         2024
}

@inproceedings{leroy2024winwin,
  address =      {Vienna, Austria},
  author =       {Leroy, Vincent and Revaud, Jérôme and Lucas, Thomas
                  and Weinzaepfel, Philippe},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=N23A4ybMJr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Win-Win: Training High-Resolution Vision
                  Transformers from Two Windows},
  year =         2024
}

@inproceedings{leviathan2023fast,
  address =      {Honolulu, Hawaii, USA},
  author =       {Leviathan, Yaniv and Kalman, Matan and Matias,
                  Yossi},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/leviathan23a.html}}},
  pages =        {19274--19286},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Fast Inference from Transformers via Speculative
                  Decoding},
  volume =       202,
  year =         2023
}

@inproceedings{levine2020limits,
  address =      {Virtual Event},
  author =       {Levine, Yoav and Wies, Noam and Sharir, Or and Bata,
                  Hofit and Shashua, Amnon},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/ff4dfdf5904e920ce52b48c1cef97829-Paper.pdf}},
  pages =        {22640--22651},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Limits to Depth Efficiencies of Self-Attention},
  volume =       33,
  year =         2020
}

@inproceedings{li2019area,
  address =      {Long Beach, California, USA},
  author =       {Li, Yang and Kaiser, Lukasz and Bengio, Samy and Si,
                  Si},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =         {\url{http://proceedings.mlr.press/v97/li19e.html}},
  pages =        {3846--3855},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Area Attention},
  volume =       97,
  year =         2019
}

@inproceedings{li2019delta,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Xingjian and Xiong, Haoyi and Wang, Hanchao and
                  Rao, Yuxuan and Liu, Liping and Huan, Jun},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rkgbwsAcYm}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Delta: Deep Learning Transfer using Feature Map with
                  Attention for Convolutional Networks},
  year =         2019
}

@inproceedings{li2019enhancing,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and
                  Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and
                  Yan, Xifeng},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/6775a0635c302542da2c32aa19d86be0-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Enhancing the Locality and Breaking the Memory
                  Bottleneck of Transformer on Time Series
                  Forecasting},
  volume =       32,
  year =         2019
}

@inproceedings{li2020deep,
  address =      {Virtual Event},
  author =       {Li, Xian and Cooper Stickland, Asa and Tang, Yuqing
                  and Kong, Xiang},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/1325cdae3b6f0f91a1b629307bf2d498-Paper.pdf}},
  pages =        {1736--1746},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Deep Transformers with Latent Depth},
  volume =       33,
  year =         2020
}

@inproceedings{li2020sac,
  address =      {Virtual Event},
  author =       {Li, Xiaoya and Meng, Yuxian and Zhou, Mingxin and
                  Han, Qinghong and Wu, Fei and Li, Jiwei},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/c5c1bda1194f9423d744e0ef67df94ee-Paper.pdf}},
  pages =        {16997--17008},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SAC: Accelerating and Structuring Self-Attention via
                  Sparse Adaptive Connection},
  volume =       33,
  year =         2020
}

@inproceedings{li2020train,
  address =      {Virtual Event},
  author =       {Li, Zhuohan and Wallace, Eric and Shen, Sheng and
                  Lin, Kevin and Keutzer, Kurt and Klein, Dan and
                  Gonzalez, Joey},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v119/li20m.html}},
  pages =        {5958--5968},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Train Big, Then Compress: Rethinking Model Size for
                  Efficient Training and Inference of Transformers},
  volume =       119,
  year =         2020
}

@inproceedings{li2021mst,
  address =      {Virtual Event},
  author =       {Li, Zhaowen and Chen, Zhiyang and Yang, Fan and Li,
                  Wei and Zhu, Yousong and Zhao, Chaoyang and Deng,
                  Rui and Wu, Liwei and Zhao, Rui and Tang, Ming and
                  Wang, Jinqiao},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6dbbe6abe5f14af882ff977fc3f35501-Paper.pdf}},
  pages =        {13165--13176},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MST: Masked Self-Supervised Transformer for Visual
                  Representation},
  volume =       34,
  year =         2021
}

@inproceedings{li2021neural,
  address =      {Virtual Event, Austria},
  author =       {Li, Yige and Lyu, Xixiang and Koren, Nodens and Lyu,
                  Lingjuan and Li, Bo and Ma, Xingjun},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=9l0K4OM-oXE}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Neural Attention Distillation: Erasing Backdoor
                  Triggers from Deep Neural Networks},
  year =         2021
}

@inproceedings{li2021referring,
  address =      {Virtual Event},
  author =       {Li, Muchen and Sigal, Leonid},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a376802c0811f1b9088828288eb0d3f0-Paper.pdf}},
  pages =        {19652--19664},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Referring Transformer: A One-step Approach to
                  Multi-task Visual Grounding},
  volume =       34,
  year =         2021
}

@inproceedings{li2021test,
  address =      {Virtual Event},
  author =       {Li, Yizhuo and Hao, Miao and Di, Zonglin and
                  Gundavarapu, Nitesh Bharadwaj and Wang, Xiaolong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/1517c8664be296f0d87d9e5fc54fdd60-Paper.pdf}},
  pages =        {2583--2597},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Test-Time Personalization with a Transformer for
                  Human Pose Estimation},
  volume =       34,
  year =         2021
}

@inproceedings{li2022efficienta,
  address =      {Virtual Event},
  author =       {Li, Chunyuan and Yang, Jianwei and Zhang, Pengchuan
                  and Gao, Mei and Xiao, Bin and Dai, Xiyang and Yuan,
                  Lu and Gao, Jianfeng},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=fVu3o-YUGQK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Self-supervised Vision Transformers for
                  Representation Learning},
  year =         2022
}

@inproceedings{li2022efficientformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Ju
                  and Evangelidis, Georgios and Tulyakov, Sergey and
                  Wang, Yanzhi and Ren, Jian},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5452ad8ee6ea6e7dc41db1cbd31ba0b8-Paper-Conference.pdf}},
  pages =        {12934--12949},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {EfficientFormer: Vision Transformers at MobileNet
                  Speed},
  volume =       35,
  year =         2022
}

@inproceedings{li2022geodesic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Zhengyu and Tang, Xuan and Xu, Zihao and Wang,
                  Xihao and Yu, Hui and Chen, Mingsong and Wei, Xian},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/28e4ee96c94e31b2d040b4521d2b299e-Paper-Conference.pdf}},
  pages =        {6190--6203},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Geodesic Self-Attention for 3D Point Clouds},
  volume =       35,
  year =         2022
}

@inproceedings{li2022learning,
  address =      {Baltimore, Maryland, USA},
  author =       {Li, Bei and Zheng, Tong and Jing, Yi and Jiao,
                  Chengbo and Xiao, Tong and Zhu, Jingbo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/li22ac.html}},
  pages =        {13225--13241},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning Multiscale Transformer Models for Sequence
                  Generation},
  volume =       162,
  year =         2022
}

@inproceedings{li2022learningc,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Lei and Donati, Nicolas and Ovsjanikov, Maks},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/bcade016e3004543b289b33e7deb7472-Paper-Conference.pdf}},
  pages =        {29336--29349},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Multi-resolution Functional Maps with
                  Spectral Attention for Robust Shape Matching},
  volume =       35,
  year =         2022
}

@inproceedings{li2022prototype,
  address =      {Virtual Event},
  author =       {Li, Tianqin and Li, Zijie and Luo, Andrew and
                  Rockwell, Harold and Farimani, Amir Barati and Lee,
                  Tai Sing},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=lY0-7bj0Vfz}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Prototype memory and attention mechanisms for few
                  shot image generation},
  year =         2022
}

@inproceedings{li2022q,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Yanjing and Xu, Sheng and Zhang, Baochang and
                  Cao, Xianbin and Gao, Peng and Guo, Guodong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/deb921bff461a7b0a5c344a4871e7101-Paper-Conference.pdf}},
  pages =        {34451--34463},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Q-ViT: Accurate and Fully Quantized Low-bit Vision
                  Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{li2022toist,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Pengfei and Tian, Beiwen and Shi, Yongliang and
                  Chen, Xiaoxue and Zhao, Hao and Zhou, Guyue and
                  Zhang, Ya-Qin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/70270a1bc28ecb2a2aefad566c5e556b-Paper-Conference.pdf}},
  pages =        {17597--17611},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TOIST: Task Oriented Instance Segmentation
                  Transformer with Noun-Pronoun Distillation},
  volume =       35,
  year =         2022
}

@inproceedings{li2022transformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Zhishan and Nie, Ying and Han, Kai and Guo,
                  Jianyuan and Xie, Lei and Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/fcfad93e2f30ab4c22f9ec5edfbb5cc0-Paper-Conference.pdf}},
  pages =        {38733--38746},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Transformer-Based Object Detector with Coarse-Fine
                  Crossing Representations},
  volume =       35,
  year =         2022
}

@inproceedings{li2022uniformer,
  address =      {Virtual Event},
  author =       {Li, Kunchang and Wang, Yali and Gao, Peng and Song,
                  Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=nBU_u6DLvoK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {UniFormer: Unified Transformer for Efficient
                  Spatial-Temporal Representation Learning},
  year =         2022
}

@inproceedings{li2022unifying,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Yanwei and Chen, Yilun and Qi, Xiaojuan and Li,
                  Zeming and Sun, Jian and Jia, Jiaya},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/752df938681b2cf15e5fc9689f0bcf3a-Paper-Conference.pdf}},
  pages =        {18442--18455},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Unifying Voxel-based Representation with Transformer
                  for 3D Object Detection},
  volume =       35,
  year =         2022
}

@inproceedings{li2023do,
  address =      {Honolulu, Hawaii, USA},
  author =       {Li, Yuchen and Li, Yuanzhi and Risteski, Andrej},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/li23p.html}}},
  pages =        {19689--19729},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {How Do Transformers Learn Topic Structure: Towards a
                  Mechanistic Understanding},
  volume =       202,
  year =         2023
}

@inproceedings{li2023efficientb,
  address =      {Kigali, Rwanda},
  author =       {Li, Kai and Yang, Runxuan and Hu, Xiaolin},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=fzberKYWKsI}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {An efficient encoder-decoder architecture with
                  top-down attention for speech separation},
  year =         2023
}

@inproceedings{li2023lazy,
  address =      {Kigali, Rwanda},
  author =       {Li, Zonglin and You, Chong and Bhojanapalli, Srinadh
                  and Li, Daliang and Rawat, Ankit Singh and Reddi,
                  Sashank J. and Ye, Ke and Chern, Felix and Yu, Felix
                  X. and Guo, Ruiqi and Kumar, Sanjiv},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=TJ2nxciYCk-}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {The Lazy Neuron Phenomenon: On Emergence of
                  Activation Sparsity in Transformers},
  year =         2023
}

@inproceedings{li2023mpcformer,
  address =      {Kigali, Rwanda},
  author =       {Li, Dacheng and Wang, Hongyi and Shao, Rulin and
                  Guo, Han and Xing, Eric P. and Zhang, Hao},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=CWmvjOEhgH-}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MPCFORMER: Fast, Performant and Provate Transformer
                  Inference with MPC},
  year =         2023
}

@inproceedings{li2023scalable,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Zijie and Shu, Dule and Barati Farimani, Amir},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/590daf74f99ee85df3d8c007df9c8187-Paper-Conference.pdf}},
  pages =        {28010--28039},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Scalable Transformer for PDE Surrogate Modeling},
  volume =       36,
  year =         2023
}

@inproceedings{li2023smartfrz,
  address =      {Kigali, Rwanda},
  author =       {Li, Sheng and Yuan, Geng and Dai, Yue and Zhang,
                  Youtao and Wang, Yanzhi and Tang, Xulong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=i9UlAr1T_xl}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SmartFRZ: An Efficient Training Framework using
                  Attention-Based Layer Freezing},
  year =         2023
}

@inproceedings{li2023smurfthp,
  address =      {Honolulu, Hawaii, USA},
  author =       {Li, Zichong and Xu, Yanbo and Zuo, Simiao and Jiang,
                  Haoming and Zhang, Chao and Zhao, Tuo and Zha,
                  Hongyuan},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/li23aj.html}}},
  pages =        {20210--20220},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {SMURF-THP: Score Matching-based UnceRtainty
                  quantiFication for Transformer Hawkes Process},
  year =         2023
}

@inproceedings{li2023theoretical,
  address =      {Kigali, Rwanda},
  author =       {Li, Hongkang and Wang, Meng and Liu, Sijia and Chen,
                  Pin-Yu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=jClGv3Qjhb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Theoretical Understanding of Shallow Vision
                  Transformers: Learning, Generalization, and Sample
                  Complexity},
  year =         2023
}

@inproceedings{li2023time,
  address =      {New Orleans, Louisiana, USA},
  author =       {Li, Zekun and Li, Shiyang and Yan, Xifeng},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/9a17c1eb808cf012065e9db47b7ca80d-Paper-Conference.pdf}},
  pages =        {49187--49204},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Time Series as Images: Vision Transformer for
                  Irregularly Sampled Time Series},
  volume =       36,
  year =         2023
}

@inproceedings{li2023transformerbased,
  address =      {Kigali, Rwanda},
  author =       {Li, Wenqiang and Li, Weijun and Sun, Linjun and Wu,
                  Min and Yu, Lina and Liu, Jingyi and Li, Yanjie and
                  Tian, Songsong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ULzyv9M1j5}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-based model for symbolic regression via
                  joint supervised learning},
  year =         2023
}

@inproceedings{li2023transformers,
  address =      {Honolulu, Hawaii, USA},
  author =       {Li, Yingcong and Ildiz, Muhammed Emrullah and
                  Papailiopoulos, Dimitris and Oymak, Samet},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/li23l.html}}},
  pages =        {19565--19594},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformers as Algorithms: Generalization and
                  Stability in In-context Learning},
  volume =       202,
  year =         2023
}

@inproceedings{li2023understanding,
  address =      {Kigali, Rwanda},
  author =       {Li, Yang and Chen, Xiaoxue and Zhao, Hao and Gong,
                  Jiangtao and Zhou, Guyue and Rossano, Federico and
                  Zhu, Yixin},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ugA1HX69sf}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Understanding Embodied Reference with Touch-Line
                  Transformer},
  year =         2023
}

@inproceedings{li2024dob,
  address =      {Vienna, Austria},
  author =       {Li, Hongkang and Wang, Meng and Lu, Songtao and Cui,
                  Xiaodong and Chen, Pin-Yu},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=I4HTPws9P6}},
  publisher =    {OpenReview.net},
  title =        {How Do Nonlinear Transformers Learn and Generalize
                  in In-Context Learning?},
  year =         2024
}

@inproceedings{li2024frequencyaware,
  address =      {Vienna, Austria},
  author =       {Li, Han and Li, Shaohui and Dai, Wenrui and Li,
                  Chenglin and Zou, Junni and Xiong, Hongkai},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HKGQDDTuvZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Frequency-Aware Transformer for Learned Image
                  Compression},
  year =         2024
}

@inproceedings{li2024iianet,
  address =      {Vienna, Austria},
  author =       {Li, Kai and Yang, Runxuan and Sun, Fuchun and Hu,
                  Xiaolin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=FM61SQzF3N}},
  publisher =    {OpenReview.net},
  title =        {IIANet: An Intra- and Inter-Modality Attention
                  Network for Audio-Visual Speech Separation},
  year =         2024
}

@inproceedings{li2024improves,
  address =      {Vienna, Austria},
  author =       {Li, Hongkang and Wang, Meng and Ma, Tengfei and Liu,
                  Sijia and Zhang, Zaixi and Chen, Pin-Yu},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=mJhXlsZzzE}},
  publisher =    {OpenReview.net},
  title =        {What Improves the Generalization of Graph
                  Transformers? A Theoretical Dive into the
                  Self-attention and Positional Encoding},
  year =         2024
}

@inproceedings{li2024learninga,
  address =      {Vienna, Austria},
  author =       {Li, Yongxin and Liu, Mengyuan and Wu, You and Wang,
                  Xucheng and Yang, Xiangyang and Li, Shuiwang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=eaNLvrP8n1}},
  publisher =    {OpenReview.net},
  title =        {Learning Adaptive and View-Invariant Vision
                  Transformer for Real-Time UAV Tracking},
  year =         2024
}

@inproceedings{li2024lorap,
  address =      {Vienna, Austria},
  author =       {Li, Guangyan and Tang, Yongqiang and Zhang,
                  Wensheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=mhI5nc5QwX}},
  publisher =    {OpenReview.net},
  title =        {LoRAP: Transformer Sub-Layers Deserve Differentiated
                  Structured Compression for Large Language Models},
  year =         2024
}

@inproceedings{li2024transformermodulated,
  address =      {Vienna, Austria},
  author =       {Li, Yuxin and Chen, Wenchao and Hu, Xinyue and Chen,
                  Bo and Sun, Baolin and Zhou, Mingyuan},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=qae04YACHs}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-Modulated Diffusion Models for
                  Probabilistic Multivariate Time Series Forecasting},
  year =         2024
}

@inproceedings{liang2022evit,
  address =      {Virtual Event},
  author =       {Liang, Youwei and Ge, Chongjian and Tong, Zhan and
                  Song, Yibing and Wang, Jue and Xie, Pengtao},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=BjyvwnXXVn_}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {EViT: Expediting Vision Transformers via Token
                  Reorganizations},
  year =         2022
}

@inproceedings{liang2022expediting,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liang, Weicong and Yuan, Yuhui and Ding, Henghui and
                  Luo, Xiao and Lin, Weihong and Jia, Ding and Zhang,
                  Zheng and Zhang, Chao and Hu, Han},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e6c2e85db1f1039177c4495ccd399ac4-Paper-Conference.pdf}},
  pages =        {35462--35477},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Expediting Large-Scale Vision Transformer for Dense
                  Prediction without Fine-tuning},
  volume =       35,
  year =         2022
}

@inproceedings{liang2022m,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liang, Hanxue and Fan, Zhiwen and Sarkar, Rishov and
                  Jiang, Ziyu and Chen, Tianlong and Zou, Kai and
                  Cheng, Yu and Hao, Cong and Wang, Zhangyang},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/b653f34d576d1790481e3797cb740214-Paper-Conference.pdf}},
  pages =        {28441--28457},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {M3ViT: Mixture-of-Experts Vision Transformer for
                  Efficient Multi-task Learning with Model-Accelerator
                  Co-design},
  volume =       35,
  year =         2022
}

@inproceedings{liang2022multi,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liang, Junwei and Zhang, Enwei and Zhang, Jun and
                  Shen, Chunhua},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5d2e24df9cfaad3189833b819c40b392-Paper-Conference.pdf}},
  pages =        {14475--14488},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multi-dataset Training of Transformers for Robust
                  Action Recognition},
  volume =       35,
  year =         2022
}

@inproceedings{liang2022no,
  address =      {Virtual Event},
  author =       {Liang, Chen and Jiang, Haoming and Zuo, Simiao and
                  He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng
                  and Chen, Weizhu and Zhao, Tuo},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=cuvga_CiVND}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {No Parameters Left Behind: Sensitivity Guided
                  Adaptive Learning Rate for Training Large
                  Transformer Models},
  year =         2022
}

@inproceedings{liang2022recurrent,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liang, Jingyun and Fan, Yuchen and Xiang, Xiaoyu and
                  Ranjan, Rakesh and Ilg, Eddy and Green, Simon and
                  Cao, Jiezhang and Zhang, Kai and Timofte, Radu and
                  Gool, Luc V},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/02687e7b22abc64e651be8da74ec610e-Paper-Conference.pdf}},
  pages =        {378--393},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Recurrent Video Restoration Transformer with Guided
                  Deformable Attention},
  volume =       35,
  year =         2022
}

@inproceedings{liang2023homodistil,
  address =      {Kigali, Rwanda},
  author =       {Liang, Chen and Jiang, Haoming and Li, Zheng and
                  Tang, Xianfeng and Yin, Bing and Zhao, Tuo},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=D7srTrGhAs}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {HomoDistil: Homotopic Task-Agnostic Distillation of
                  Pre-trained Transformers},
  year =         2023
}

@inproceedings{liang2023retr,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liang, Yixun and He, Hao and Chen, Yingcong},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/c47ec10bc135be5c3663ba344d29a6a5-Paper-Conference.pdf}},
  pages =        {62332--62351},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ReTR: Modeling Rendering Via Transformer for
                  Generalizable Neural Surface Reconstruction},
  volume =       36,
  year =         2023
}

@inproceedings{liang2024graph,
  address =      {Vienna, Austria},
  author =       {Liang, Jianqing and Chen, Min and Liang, Jiye},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=0rV7VIrcjX}},
  publisher =    {OpenReview.net},
  title =        {Graph External Attention Enhanced Transformer},
  year =         2024
}

@inproceedings{liao2019efficient,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Liao, Renjie and Li, Yujia and Song, Yang and Wang,
                  Shenlong and Hamilton, Will and Duvenaud, David
                  K. and Urtasun, Raquel and Zemel, Richard},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/d0921d442ee91b896ad95059d13df618-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Efficient Graph Generation with Graph Recurrent
                  Attention Networks},
  volume =       32,
  year =         2019
}

@inproceedings{liao2021transmatcher,
  address =      {Virtual Event},
  author =       {Liao, Shengcai and Shao, Ling},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Vaughan, J. W.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/0f49c89d1e7298bb9930789c8ed59d48-Paper.pdf}},
  pages =        {1992--2003},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TransMatcher: Deep Image Matching Through
                  Transformers for Generalizable Person
                  Re-identification},
  volume =       34,
  year =         2021
}

@inproceedings{liao2022wt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liao, Jinli and Ding, Yikang and Shavit, Yoli and
                  Huang, Dihe and Ren, Shihao and Guo, Jia and Feng,
                  Wensen and Zhang, Kai},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/38e511a690709603d4cc3a1c52b4a9fd-Paper-Conference.pdf}},
  pages =        {8564--8576},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {WT-MVSNet: Window-based Transformers for Multi-view
                  Stereo},
  volume =       35,
  year =         2022
}

@inproceedings{liao2023equiformer,
  address =      {Kigali, Rwanda},
  author =       {Liao, Yi-Lun and Smidt, Tess E.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=KwmPfARgOTD}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Equiformer: Equivariant Graph Attention Transformer
                  for 3D Atomistic Graphs},
  year =         2023
}

@inproceedings{liao2024equiformerv2,
  address =      {Vienna, Austria},
  author =       {Liao, Yi-Lun and Br and Wood, on M. and Das,
                  Abhishek and Smidt, Tess E.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=mCOBKZmrzD}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {EquiformerV2: Improved Equivariant Transformer for
                  Scaling to Higher-Degree Representations},
  year =         2024
}

@inproceedings{lin2020space,
  address =      {Addis Ababa, Ethiopia},
  author =       {Lin, Zhixuan and Wu, Yi-Fu and Peri, Vishwanath and
                  Sun, Weihao and Singh, Gautam and Deng, Fei and
                  Jiang, Jindong and Ahn, Sungjin},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rkl03ySYDH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SPACE: Unsupervised Object-Oriented Scene
                  Representation via Spatial Attention and
                  Decomposition},
  year =         2020
}

@inproceedings{lin2022flowguided,
  address =      {Baltimore, Maryland, USA},
  author =       {Lin, Jing and Cai, Yuanhao and Hu, Xiaowan and Wang,
                  Haoqian and Yan, Youliang and Zou, Xueyi and Ding,
                  Henghui and Zhang, Yulun and Timofte, Radu and Gool,
                  Luc Van},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/lin22a.html}},
  pages =        {13334--13343},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Flow-Guided Sparse Transformer for Video Deblurring},
  volume =       162,
  year =         2022
}

@inproceedings{lin2022swintrack,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lin, Liting and Fan, Heng and Zhang, Zhipeng and Xu,
                  Yong and Ling, Haibin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/6a5c23219f401f3efd322579002dbb80-Paper-Conference.pdf}},
  pages =        {16743--16754},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SwinTrack: A Simple and Strong Baseline for
                  Transformer Tracking},
  volume =       35,
  year =         2022
}

@inproceedings{lin2023pay,
  address =      {Kigali, Rwanda},
  author =       {Lin, ChungYi and Tung, Shen-Lung and Hsu, Winston
                  H.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=IkHVGw\_Ipu}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Pay Attention to Multi-Channel for Improving Graph
                  Neural Networks},
  year =         2023
}

@inproceedings{lin2024hgap,
  address =      {Vienna, Austria},
  author =       {Lin, Bor-Jiun and Lee, Chun-Yi},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=KpUdNe9lsr}},
  publisher =    {OpenReview.net},
  title =        {HGAP: Boosting Permutation Invariant and Permutation
                  Equivariant in Multi-Agent Reinforcement Learning
                  via Graph Attention Network},
  year =         2024
}

@inproceedings{lin2024transformers,
  address =      {Vienna, Austria},
  author =       {Lin, Licong and Bai, Yu and Mei, Song},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=yN4Wv17ss3}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformers as Decision Makers: Provable In-Context
                  Reinforcement Learning via Supervised Pretraining},
  year =         2024
}

@inproceedings{lin2024use,
  address =      {Vienna, Austria},
  author =       {Lin, Xiaoqiang and Wu, Zhaoxuan and Dai, Zhongxiang
                  and Hu, Wenyang and Shu, Yao and Ng, See-Kiong and
                  Jaillet, Patrick and Low, Bryan Kian Hsiang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=RLENZ8pNnn}},
  publisher =    {OpenReview.net},
  title =        {Use Your INSTINCT: INSTruction optimization for LLMs
                  usIng Neural bandits Coupled with Transformers},
  year =         2024
}

@inproceedings{lindner2023tracr,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lindner, David and Kramar, Janos and Farquhar,
                  Sebastian and Rahtz, Matthew and McGrath, Tom and
                  Mikulik, Vladimir},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/771155abaae744e08576f1f3b4b7ac0d-Paper-Conference.pdf}},
  pages =        {37876--37899},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Tracr: Compiled Transformers as a Laboratory for
                  Interpretability},
  volume =       36,
  year =         2023
}

@inproceedings{lingle2024transformervq,
  address =      {Vienna, Austria},
  author =       {Lingle, Lucas D.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=oDdzXQzP2F}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-VQ: Linear-Time Transformers via Vector
                  Quantization},
  year =         2024
}

@inproceedings{liu2016latent,
  address =      {Barcelona, Spain},
  author =       {Liu, Chang and Chen, Xinyun and Shin, Eui Chul and
                  Chen, Mingcheng and Song, Dawn},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/716e1b8c6cd17b771da77391355749f3-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Latent Attention For If-Then Program Synthesis},
  volume =       29,
  year =         2016
}

@inproceedings{liu2020kalman,
  address =      {Virtual Event},
  author =       {Liu, Hu and Lu, Jing and Zhao, Xiwei and Xu, Sulong
                  and Peng, Hao and Liu, Yutong and Zhang, Zehua and
                  Li, Jian and Jin, Junsheng and Bao, Yongjun and Yan,
                  Weipeng},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/68ce199ec2c5517597ce0a4d89620f55-Paper.pdf}},
  pages =        {9228--9238},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Kalman Filtering Attention for User Behavior
                  Modeling in CTR Prediction},
  volume =       33,
  year =         2020
}

@inproceedings{liu2020learning,
  address =      {Virtual Event},
  author =       {Liu, Xuanqing and Yu, Hsiang-Fu and Dhillon,
                  Inderjit S. and Hsieh, Cho-Jui},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v119/liu20n.html}},
  pages =        {6327--6335},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning to Encode Position for Transformer with
                  Continuous Dynamical Model},
  volume =       119,
  year =         2020
}

@inproceedings{liu2020multi,
  address =      {Virtual Event},
  author =       {Liu, Xin and Fromm, Josh and Patel, Shwetak and
                  McDuff, Daniel},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/e1228be46de6a0234ac22ded31417bc7-Paper.pdf}},
  pages =        {19400--19411},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multi-Task Temporal Shift Attention Networks for
                  On-Device Contactless Vitals Measurement},
  volume =       33,
  year =         2020
}

@inproceedings{liu2020prophet,
  address =      {Virtual Event},
  author =       {Liu, Fenglin and Ren, Xuancheng and Wu, Xian and Ge,
                  Shen and Fan, Wei and Zou, Yuexian and Sun, Xu},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/13fe9d84310e77f13a6d184dbf1232f3-Paper.pdf}},
  pages =        {1865--1876},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Prophet Attention: Predicting Attention with Future
                  Attention},
  volume =       33,
  year =         2020
}

@inproceedings{liu2021efficienta,
  address =      {Virtual Event},
  author =       {Liu, Yahui and Sangineto, Enver and Bi, Wei and
                  Sebe, Nicu and Lepri, Bruno and Nadai, Marco},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/c81e155d85dae5430a8cee6f2242e82c-Paper.pdf}},
  pages =        {23818--23830},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Efficient Training of Visual Transformers with Small
                  Datasets},
  volume =       34,
  year =         2021
}

@inproceedings{liu2021pay,
  address =      {Virtual Event},
  author =       {Liu, Hanxiao and Dai, Zihang and So, David and Le,
                  Quoc V},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4cc05b35c2f937c5bd9e7d41d3686fff-Paper.pdf}},
  pages =        {9204--9215},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pay Attention to MLPs},
  volume =       34,
  year =         2021
}

@inproceedings{liu2021post,
  address =      {Virtual Event},
  author =       {Liu, Zhenhua and Wang, Yunhe and Han, Kai and Zhang,
                  Wei and Ma, Siwei and Gao, Wen},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf}},
  pages =        {28092--28103},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Post-Training Quantization for Vision Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{liu2021universal,
  address =      {Virtual Event, Austria},
  author =       {Liu, Lu and Hamilton, William L. and Long, Guodong
                  and Jiang, Jing and Larochelle, Hugo},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=04cII6MumYV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Universal Representation Transformer Layer for
                  Few-Shot Image Classification},
  year =         2021
}

@inproceedings{liu2022bit,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Zechun and Oguz, Barlas and Pappu, Aasish and
                  Xiao, Lin and Yih, Scott and Li, Meng and
                  Krishnamoorthi, Raghuraman and Mehdad, Yashar},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5c1863f711c721648387ac2ef745facb-Paper-Conference.pdf}},
  pages =        {14303--14316},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {BiT: Robustly Binarized Multi-distilled Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{liu2022ecoformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Jing and Pan, Zizheng and He, Haoyu and Cai,
                  Jianfei and Zhuang, Bohan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4310ae054ce265e56d8ea897971149b5-Paper-Conference.pdf}},
  pages =        {10295--10308},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {EcoFormer: Energy-Saving Attention with Linear
                  Complexity},
  volume =       35,
  year =         2022
}

@inproceedings{liu2022gating,
  address =      {Baltimore, Maryland, USA},
  author =       {Liu, Rui and Kim, Young Jin and Alex and Muzio, Re
                  and Hassan, Hany},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/liu22g.html}},
  pages =        {13782--13792},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Gating Dropout: Communication-efficient
                  Regularization for Sparsely Activated Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{liu2022intermediate,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Yuanwei and Liu, Nian and Yao, Xiwen and Han,
                  Junwei},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/f7fef21d1fb3e950b12b50ad7f395e31-Paper-Conference.pdf}},
  pages =        {38020--38031},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Intermediate Prototype Mining Transformer for
                  Few-Shot Semantic Segmentation},
  volume =       35,
  year =         2022
}

@inproceedings{liu2022nona,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Yong and Wu, Haixu and Wang, Jianmin and Long,
                  Mingsheng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4054556fcaa934b0bf76da52cf4f92cb-Paper-Conference.pdf}},
  pages =        {9881--9893},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Non-stationary Transformers: Exploring the
                  Stationarity in Time Series Forecasting},
  volume =       35,
  year =         2022
}

@inproceedings{liu2022pyraformer,
  address =      {Virtual Event},
  author =       {Liu, Shizhan and Yu, Hang and Liao, Cong and Li,
                  Jianguo and Lin, Weiyao and Liu, Alex X. and
                  Dustdar, Schahram},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=0EXmFzUn5I}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Pyraformer: Low-Complexity Pyramidal Attention for
                  Long-Range Time Series Modeling and Forecasting},
  year =         2022
}

@inproceedings{liu2022rethinking,
  address =      {Baltimore, Maryland, USA},
  author =       {Liu, Yibing and Li, Haoliang and Guo, Yangyang and
                  Kong, Chenqi and Li, Jing and Wang, Shiqi},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/liu22i.html}},
  pages =        {13807--13824},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Rethinking Attention-Model Explainability through
                  Faithfulness Violation Test},
  volume =       162,
  year =         2022
}

@inproceedings{liu2022seeing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Ran and Azabou, Mehdi and Dabagia, Max and
                  Xiao, Jingyun and Dyer, Eva},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/1022661f3f43406065641f16ce25eafa-Paper-Conference.pdf}},
  pages =        {2377--2391},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Seeing the forest and the tree: Building
                  representations of both individual and collective
                  dynamics with transformers},
  volume =       35,
  year =         2022
}

@inproceedings{liu2022tuformer,
  address =      {Virtual Event},
  author =       {Liu, Xiaoyu and Su, Jiahao and Huang, Furong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=V0A5g83gdQ_}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tuformer: Data-driven Design of Transformers for
                  Improved Generalization or Efficiency},
  year =         2022
}

@inproceedings{liu2023blockwise,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Hao and Abbeel, Pieter},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1bfd87d2d92f0556819467dc08034f76-Paper-Conference.pdf}},
  pages =        {8828--8844},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Blockwise Parallel Transformers for Large Context
                  Models},
  volume =       36,
  year =         2023
}

@inproceedings{liu2023bstt,
  address =      {Kigali, Rwanda},
  author =       {Liu, Yuchen and Jia, Ziyu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ZxdkjTgK_Dl}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {BSTT: A Bayesian Spatial-Temporal Transformer for
                  Sleep Staging},
  year =         2023
}

@inproceedings{liu2023causality,
  address =      {Kigali, Rwanda},
  author =       {Liu, Ruyang and Huang, Jingjia and Li, Thomas H. and
                  Li, Ge},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=8XqDnrmZQNF}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Causality Compensated Attention for Contextual
                  Biased Visual Recognition},
  year =         2023
}

@inproceedings{liu2023constrained,
  address =      {Honolulu, Hawaii, USA},
  author =       {Liu, Zuxin and Guo, Zijian and Yao, Yihang and Cen,
                  Zhepeng and Yu, Wenhao and Zhang, Tingnan and Zhao,
                  Ding},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/liu23m.html}},
  pages =        {21611--21630},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Constrained Decision Transformer for Offline Safe
                  Reinforcement Learning},
  volume =       202,
  year =         2023
}

@inproceedings{liu2023emergent,
  address =      {Honolulu, Hawaii, USA},
  author =       {Liu, Hao and Abbeel, Pieter},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/liu23a.html}},
  pages =        {21362--21374},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Emergent Agentic Transformer from Chain of Hindsight
                  Experience},
  volume =       202,
  year =         2023
}

@inproceedings{liu2023exposing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Bingbin and Ash, Jordan and Goel, Surbhi and
                  Krishnamurthy, Akshay and Zhang, Cyril},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/510ad3018bbdc5b6e3b10646e2e35771-Paper-Conference.pdf}},
  pages =        {25549--25583},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Exposing Attention Glitches with Flip-Flop Language
                  Modeling},
  volume =       36,
  year =         2023
}

@inproceedings{liu2023fusing,
  address =      {Kigali, Rwanda},
  author =       {Liu, Baisen and Liu, Yuanjia and Zhang, Wulin and
                  Tian, Yiran},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Jx44OPxLZ2-}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Fusing 3D-CNN and lightweight Swin Transformer
                  networks for HSI},
  year =         2023
}

@inproceedings{liu2023hierarchical,
  address =      {Kigali, Rwanda},
  author =       {Liu, Xiao and Zhang, Jian and Zhang, Heng and Xue,
                  Fuzhao and You, Yang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Peb3QdR8zzP}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Hierarchical Dialogue Understanding with Special
                  Tokens and Turn-level Attention},
  year =         2023
}

@inproceedings{liu2023human,
  address =      {Kigali, Rwanda},
  author =       {Liu, Hongyu and Han, Xintong and Jin, Chenbin and
                  Qian, Lihui and Wei, Huawei and Lin, Zhe and Wang,
                  Faqiang and Dong, Haoye and Song, Yibing and Xu, Jia
                  and Chen, Qifeng},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=lQVpasnQS62}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Human MotionFormer: Transferring Human Motions with
                  Vision Transformers},
  year =         2023
}

@inproceedings{liu2023learninge,
  address =      {New Orleans, Louisiana, USA},
  author =       {Liu, Yingjie and Liu, Xuan and Yu, Hui and Tang,
                  Xuan and Wei, Xian},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b113e1441ad107b80c576b5028fd2c51-Paper-Conference.pdf}},
  pages =        {56589--56601},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Dictionary for Visual Attention},
  volume =       36,
  year =         2023
}

@inproceedings{liu2023na2q,
  address =      {Honolulu, Hawaii, USA},
  author =       {Liu, Zichuan and Zhu, Yuanyang and Chen, Chunlin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/liu23be.html}},
  pages =        {22539--22558},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {NA2Q: Neural Attention Additive Model for
                  Interpretable Multi-Agent Q-Learning},
  volume =       202,
  year =         2023
}

@inproceedings{liu2023oscillationfree,
  address =      {Honolulu, Hawaii, USA},
  author =       {Liu, Shih-Yang and Liu, Zechun and Cheng,
                  Kwang-Ting},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/liu23w.html}},
  pages =        {21813--21824},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Oscillation-free Quantization for Low-bit Vision
                  Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{liu2023transformers,
  address =      {Kigali, Rwanda},
  author =       {Liu, Bingbin and Ash, Jordan T. and Goel, Surbhi and
                  Krishnamurthy, Akshay and Zhang, Cyril},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=De4FYqjFueZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformers Learn Shortcuts to Automata},
  year =         2023
}

@inproceedings{liu2023understanding,
  address =      {Honolulu, Hawaii, USA},
  author =       {Liu, Liang and Guo, Yanan and Zhang, Youtao and
                  Yang, Jun},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/liu23n.html}},
  pages =        {21631--21657},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Understanding and Defending Patched-based
                  Adversarial Attacks for Vision Transformer},
  volume =       202,
  year =         2023
}

@inproceedings{liu2024chainb,
  address =      {Vienna, Austria},
  author =       {Liu, Zhiyuan and Liu, Hong and Zhou, Denny and Ma,
                  Tengyu},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3EWTEy9MTM}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Chain of Thought Empowers Transformers to Solve
                  Inherently Serial Problems},
  year =         2024
}

@inproceedings{liu2024itransformer,
  address =      {Vienna, Austria},
  author =       {Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu,
                  Haixu and Wang, Shiyu and Ma, Lintao and Long,
                  Mingsheng},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=JePfAI8fah}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {iTransformer: Inverted Transformers Are Effective
                  for Time Series Forecasting},
  year =         2024
}

@inproceedings{liu2024knowformer,
  address =      {Vienna, Austria},
  author =       {Liu, Junnan and Mao, Qianren and Jiang, Weifeng and
                  Li, Jianxin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=EncFNR3hxM}},
  publisher =    {OpenReview.net},
  title =        {KnowFormer: Revisiting Transformers for Knowledge
                  Graph Reasoning},
  year =         2024
}

@inproceedings{liu2024lumvit,
  address =      {Vienna, Austria},
  author =       {Liu, Lingfeng and Ni, Dong and Yuan, Hangjie},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=wkbeqr5XhC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {LUM-ViT: Learnable Under-sampling Mask Vision
                  Transformer for Bandwidth Limited Optical Signal
                  Acquisition},
  year =         2024
}

@inproceedings{liu2024ringattention,
  address =      {Vienna, Austria},
  author =       {Liu, Hao and Zaharia, Matei and Abbeel, Pieter},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  day =          {7--11},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=WsRHpHH4s0}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {RingAttention with Blockwise Transformers for
                  Near-Infinite Context},
  year =         2024
}

@inproceedings{liu2024shortlong,
  address =      {Vienna, Austria},
  author =       {Liu, Zicheng and Li, Siyuan and Wang, Li and Wang,
                  Zedong and Liu, Yunfan and Li, Stan Z.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=TRrXkVdhwi}},
  publisher =    {OpenReview.net},
  title =        {Short-Long Convolutions Help Hardware-Efficient
                  Linear Attention to Focus on Long Sequences},
  year =         2024
}

@inproceedings{liu2024simple,
  address =      {Vienna, Austria},
  author =       {Liu, Dongyang and Kan, Meina and Shan, Shiguang and
                  Chen, Xilin},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=gJeYtRuguR}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Simple Romance Between Multi-Exit Vision
                  Transformer and Token Reduction},
  year =         2024
}

@inproceedings{liu2024tangent,
  address =      {Vienna, Austria},
  author =       {Liu, Tian Yu and Golatkar, Aditya and Soatto,
                  Stefano},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=VLFhbOCz5D}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tangent Transformers for Composition, Privacy and
                  Removal},
  year =         2024
}

@inproceedings{liu2024timer,
  address =      {Vienna, Austria},
  author =       {Liu, Yong and Zhang, Haoran and Li, Chenyu and
                  Huang, Xiangdong and Wang, Jianmin and Long,
                  Mingsheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=bYRYb7DMNo}},
  publisher =    {OpenReview.net},
  title =        {Timer: Generative Pre-trained Transformers Are Large
                  Time Series Models},
  year =         2024
}

@inproceedings{liutkus2021relative,
  address =      {Virtual Event},
  author =       {Liutkus, Antoine and Cífka, Ondrej and Wu, Shih-Lun
                  and Simsekli, Umut and Yang, Yi-Hsuan and Richard,
                  Gaël},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/liutkus21a.html}}},
  pages =        {7067--7079},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Relative Positional Encoding for Transformers with
                  Linear Complexity},
  volume =       139,
  year =         2021
}

@inproceedings{locatello2020object,
  address =      {Virtual Event},
  author =       {Locatello, Francesco and Weissenborn, Dirk and
                  Unterthiner, Thomas and Mahendran, Aravindh and
                  Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy,
                  Alexey and Kipf, Thomas},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {Larochelle, H. and Ranzato, M. and Hadsell, R. and
                  Balcan, M.F. and Lin, H.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/8511df98c02ab60aea1b2356c013bc0f-Paper.pdf}},
  pages =        {11525--11538},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Object-Centric Learning with Slot Attention},
  volume =       33,
  year =         2020
}

@inproceedings{lopardo2024attention,
  address =      {Vienna, Austria},
  author =       {Lopardo, Gianluigi and Precioso, Frédéric and
                  Garreau, Damien},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=wnkC5T11Z9}},
  publisher =    {OpenReview.net},
  title =        {Attention Meets Post-hoc Interpretability: A
                  Mathematical Perspective},
  year =         2024
}

@inproceedings{lou2022dictformer,
  address =      {Virtual Event},
  author =       {Lou, Qian and Hua, Ting and Hsu, Yen-Chang and Shen,
                  Yilin and Jin, Hongxia},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=GWQWAeE9EpB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {DictFormer: Tiny Transformer with Shared Dictionary},
  year =         2022
}

@inproceedings{lu2016hierarchical,
  address =      {Barcelona, Spain},
  author =       {Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and
                  Parikh, Devi},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/9dcb88e0137649590b755372b040afad-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Hierarchical Question-Image Co-Attention for Visual
                  Question Answering},
  volume =       29,
  year =         2016
}

@inproceedings{lu2021on,
  address =      {Virtual Event, Austria},
  author =       {Lu, Haoye and Mao, Yongyi and Nayak, Amiya},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=1OCTOShAmqB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {On the Dynamics of Training Attention Models},
  year =         2021
}

@inproceedings{lu2021soft,
  address =      {Virtual Event},
  author =       {Lu, Jiachen and Yao, Jinghan and Zhang, Junge and
                  Zhu, Xiatian and Xu, Hang and Gao, Weiguo and Xu,
                  Chunjing and Xiang, Tao and Zhang, Li},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/b1d10e7bafa4421218a51b1e1f1b0ba2-Paper.pdf}},
  pages =        {21297--21309},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SOFT: Softmax-free Transformer with Linear
                  Complexity},
  volume =       34,
  year =         2021
}

@inproceedings{lu2021tnasp,
  address =      {Virtual Event},
  author =       {Lu, Shun and Li, Jixiang and Tan, Jianchao and Yang,
                  Sen and Liu, Ji},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/7fa1575cbd7027c9a799983a485c3c2f-Paper.pdf}},
  pages =        {15125--15137},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TNASP: A Transformer-based NAS Predictor with a
                  Self-evolution Framework},
  volume =       34,
  year =         2021
}

@inproceedings{lu2022bridging,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lu, Zhiying and Xie, Hongtao and Liu, Chuanbin and
                  Zhang, Yongdong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5e0b46975d1bfe6030b1687b0ada1b85-Paper-Conference.pdf}},
  pages =        {14663--14677},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Bridging the Gap Between Vision Transformers and
                  Convolutional Neural Networks on Small Datasets},
  volume =       35,
  year =         2022
}

@inproceedings{lu2022noise,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lu, Yangdi and Bo, Yang and He, Wenbo},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/92864e1191ed272deb0914b3bb50f97c-Paper-Conference.pdf}},
  pages =        {23164--23177},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Noise Attention Learning: Enhancing Noise Robustness
                  by Gradient Scaling},
  volume =       35,
  year =         2022
}

@inproceedings{lu2023hierarchical,
  address =      {New Orleans, Louisiana, USA},
  author =       {Lu, Ruiying and Wu, YuJie and Tian, Long and Wang,
                  Dongsheng and Chen, Bo and Liu, Xiyang and Hu,
                  Ruimin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1abc87c67cc400a67b869358e627fe37-Paper-Conference.pdf}},
  pages =        {8487--8500},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Hierarchical Vector Quantized Transformer for
                  Multi-class Unsupervised Anomaly Detection},
  volume =       36,
  year =         2023
}

@inproceedings{lu2024debiasing,
  address =      {Vienna, Austria},
  author =       {Lu, Shenyu and Wang, Yipei and Wang, Xiaoqian},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=jLIUfrAcMQ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Debiasing Attention Mechanism in Transformer without
                  Demographics},
  year =         2024
}

@inproceedings{lu2024fit,
  address =      {Vienna, Austria},
  author =       {Lu, Zeyu and Wang, Zidong and Huang, Di and Wu,
                  Chengyue and Liu, Xihui and Ouyang, Wanli and Bai,
                  Lei},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=jZVen2JguY}},
  publisher =    {OpenReview.net},
  title =        {FiT: Flexible Vision Transformer for Diffusion
                  Model},
  year =         2024
}

@inproceedings{lu2024rethinking,
  address =      {Vienna, Austria},
  author =       {Lu, Chenhao and Shi, Ruizhe and Liu, Yuyao and Hu,
                  Kaizhe and Du, Simon Shaolei and Xu, Huazhe},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=SyY7ScNpGL}},
  publisher =    {OpenReview.net},
  title =        {Rethinking Transformers in Solving POMDPs},
  year =         2024
}

@inproceedings{lu2024vdt,
  address =      {Vienna, Austria},
  author =       {Lu, Haoyu and Yang, Guoxing and Fei, Nanyi and Huo,
                  Yuqi and Lu, Zhiwu and Luo, Ping and Ding, Mingyu},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Un0rgm9f04}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {VDT: General-purpose Video Diffusion Transformers
                  via Mask Modeling},
  year =         2024
}

@inproceedings{luca2024simulation,
  address =      {Vienna, Austria},
  author =       {Luca, Artur Back de and Fountoulakis, Kimon},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=aA2326y3hf}},
  publisher =    {OpenReview.net},
  title =        {Simulation of Graph Algorithms with Looped
                  Transformers},
  year =         2024
}

@inproceedings{luo2021stable,
  address =      {Virtual Event},
  author =       {Luo, Shengjie and Li, Shanda and Cai, Tianle and He,
                  Di and Peng, Dinglan and Zheng, Shuxin and Ke,
                  Guolin and Wang, Liwei and Liu, Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/c0f168ce8900fa56e57789e2a2f2c9d0-Paper.pdf}},
  pages =        {22795--22807},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Stable, Fast and Accurate: Kernelized Attention with
                  Relative Positional Encoding},
  volume =       34,
  year =         2021
}

@inproceedings{luo2022your,
  address =      {New Orleans, Louisiana, USA},
  author =       {Luo, Shengjie and Li, Shanda and Zheng, Shuxin and
                  Liu, Tie-Yan and Wang, Liwei and He, Di},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/1ba5f64159d67775a251cf9ce386a2b9-Paper-Conference.pdf}},
  pages =        {4301--4315},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Your Transformer May Not be as Powerful as You
                  Expect},
  volume =       35,
  year =         2022
}

@inproceedings{luo2023one,
  address =      {Kigali, Rwanda},
  author =       {Luo, Shengjie and Chen, Tianlang and Xu, Yixian and
                  Zheng, Shuxin and Liu, Tie-Yan and Wang, Liwei and
                  He, Di},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vZTp1oPV3PC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {One Transformer Can Understand Both 2D & 3D
                  Molecular Data},
  year =         2023
}

@inproceedings{luo2023transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Luo, Yuankai and Thost, Veronika and Shi, Lei},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/94e85561a342de88b559b72c9b29f638-Paper-Conference.pdf}},
  pages =        {47764--47782},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers over Directed Acyclic Graphs},
  volume =       36,
  year =         2023
}

@inproceedings{luo2024hierarchical,
  address =      {Vienna, Austria},
  author =       {Luo, Xihaier and Qian, Xiaoning and Yoon, Byung-Jun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=LhAuVPWq6q}},
  publisher =    {OpenReview.net},
  title =        {Hierarchical Neural Operator Transformer with
                  Learnable Frequency-aware Loss Prior for
                  Arbitrary-scale Super-resolution},
  year =         2024
}

@inproceedings{ma2019tensorized,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Ma, Xindian and Zhang, Peng and Zhang, Shuai and
                  Duan, Nan and Hou, Yuexian and Zhou, Ming and Song,
                  Dawei},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d’Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/dc960c46c38bd16e953d97cdeefdbc68-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Tensorized Transformer for Language Modeling},
  volume =       32,
  year =         2019
}

@inproceedings{ma2020auto,
  address =      {Virtual Event},
  author =       {Ma, Benteng and Zhang, Jing and Xia, Yong and Tao,
                  Dacheng},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/103303dd56a731e377d01f6a37badae3-Paper.pdf}},
  pages =        {1488--1500},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Auto Learning Attention},
  volume =       33,
  year =         2020
}

@inproceedings{ma2020monotonic,
  address =      {Addis Ababa, Ethiopia},
  author =       {Ma, Xutai and Pino, Juan Miguel and Cross, James and
                  Puzon, Liezl and Gu, Jiatao},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Hyg96gBKPS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Monotonic Multihead Attention},
  year =         2020
}

@inproceedings{ma2021learning,
  address =      {Virtual Event},
  author =       {Ma, Yining and Li, Jingwen and Cao, Zhiguang and
                  Song, Wen and Zhang, Le and Chen, Zhenghua and Tang,
                  Jing},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/5c53292c032b6cb8510041c54274e65f-Paper.pdf}},
  pages =        {11096--11107},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning to Iteratively Solve Routing Problems with
                  Dual-Aspect Collaborative Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{ma2021luna,
  address =      {Virtual Event},
  author =       {Ma, Xuezhe and Kong, Xiang and Wang, Sinong and
                  Zhou, Chunting and May, Jonathan and Ma, Hao and
                  Zettlemoyer, Luke},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/14319d9cfc6123106878dc20b94fbaf3-Paper.pdf}},
  pages =        {2441--2453},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Luna: Linear Unified Nested Attention},
  volume =       34,
  year =         2021
}

@inproceedings{ma2022relvit,
  address =      {Virtual Event},
  author =       {Ma, Xiaojian and Nie, Weili and Yu, Zhiding and
                  Jiang, Huaizu and Xiao, Chaowei and Zhu, Yuke and
                  Zhu, Song-Chun and An, Anima},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=afoV8W3-IYp}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {RelViT: Concept-guided Vision Transformer for Visual
                  Relational Reasoning},
  year =         2022
}

@inproceedings{ma2023graph,
  address =      {Honolulu, Hawaii, USA},
  author =       {Ma, Liheng and Lin, Chen and Lim, Derek and
                  Romero-Soriano, Adriana and Dokania, Puneet K. and
                  Coates, Mark and Torr, Philip H. S. and Lim,
                  Ser-Nam},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v202/ma23c.html}},
  pages =        {23321--23337},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Graph Inductive Biases in Transformers without
                  Message Passing},
  volume =       202,
  year =         2023
}

@inproceedings{ma2023mega,
  address =      {Kigali, Rwanda},
  author =       {Ma, Xuezhe and Zhou, Chunting and Kong, Xiang and
                  He, Junxian and Gui, Liangke and Neubig, Graham and
                  May, Jonathan and Zettlemoyer, Luke},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=qNLe3iq2El}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Mega: Moving Average Equipped Gated Attention},
  year =         2023
}

@inproceedings{ma2024do,
  address =      {Vienna, Austria},
  author =       {Ma, Michel and Ni, Tianwei and Gehring, Clement and
                  D'Oro, Pierluca and Bacon, P.-L.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Uoved2xD81}},
  publisher =    {OpenReview.net},
  title =        {Do Transformer World Models Give Better Policy
                  Gradients?},
  year =         2024
}

@inproceedings{ma2024outlieraware,
  address =      {Vienna, Austria},
  author =       {Ma, Yuexiao and Li, Huixia and Zheng, Xiawu and
                  Ling, Feng and Xiao, Xuefeng and Wang, Rui and Wen,
                  Shilei and Chao, Fei and Ji, Rongrong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Uh5XN9d2J4}},
  publisher =    {OpenReview.net},
  title =        {Outlier-aware Slicing for Post-Training Quantization
                  in Vision Transformer},
  year =         2024
}

@inproceedings{ma2024rethinking,
  address =      {Vienna, Austria},
  author =       {Ma, Yi and Hao, Jianye and Liang, Hebin and Xiao,
                  Chenjun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=WsM4TVsZpJ}},
  publisher =    {OpenReview.net},
  title =        {Rethinking Decision Transformer via Hierarchical
                  Reinforcement Learning},
  year =         2024
}

@inproceedings{madaan2023treeformer,
  address =      {Kigali, Rwanda},
  author =       {Madaan, Lovish and Bhojanapalli, Srinadh and Jain,
                  Himanshu and Jain, Prateek},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=DWn1TEb2fK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Treeformer: Dense Gradient Trees for Efficient
                  Attention Computation},
  year =         2023
}

@inproceedings{mahankali2024one,
  address =      {Vienna, Austria},
  author =       {Mahankali, Arvind V. and Hashimoto, Tatsunori and
                  Ma, Tengyu},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=8p3fu56lKc}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {One Step of Gradient Descent is Provably the Optimal
                  In-Context Learner with One Layer of Linear
                  Self-Attention},
  year =         2024
}

@inproceedings{mahdavi2024memorization,
  address =      {Vienna, Austria},
  author =       {Mahdavi, Sadegh and Liao, Renjie and Thrampoulidis,
                  Christos},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MrR3rMxqqv}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Memorization Capacity of Multi-Head Attention in
                  Transformers},
  year =         2024
}

@inproceedings{mansimov2016generating,
  address =      {San Juan, Puerto Rico},
  author =       {Mansimov, Elman and Parisotto, Emilio and Ba, Lei
                  Jimmy and Salakhutdinov, Ruslan},
  booktitle =    {4th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Bengio, Yoshua and LeCun, Yann},
  month =        {May},
  note =         {\url{http://arxiv.org/abs/1511.02793}},
  series =       {Conference Track Proceedings},
  title =        {Generating Images from Captions with Attention},
  year =         2016
}

@inproceedings{mao2022discrete,
  address =      {Virtual Event},
  author =       {Mao, Chengzhi and Jiang, Lu and Dehghani, Mostafa
                  and Vondrick, Carl and Sukthankar, Rahul and Essa,
                  Irfan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=8hWs60AZcWk}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Discrete Representations Strengthen Vision
                  Transformer Robustness},
  year =         2022
}

@inproceedings{mao2024iceformer,
  address =      {Vienna, Austria},
  author =       {Mao, Yuzhen and Ester, Martin and Li, Ke},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=6RR3wU4mSZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {IceFormer: Accelerated Inference with Long-Sequence
                  Transformers on CPUs},
  year =         2024
}

@inproceedings{maraval2023end,
  address =      {New Orleans, Louisiana, USA},
  author =       {Maraval, Alexandre and Zimmer, Matthieu and Grosnit,
                  Antoine and Bou Ammar, Haitham},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/2561721d0ca69bab22b749cfc4f48f6c-Paper-Conference.pdf}},
  pages =        {11246--11260},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {End-to-End Meta-Bayesian Optimisation with
                  Transformer Neural Processes},
  volume =       36,
  year =         2023
}

@inproceedings{martins2016from,
  address =      {New York City, New York, USA},
  author =       {Martins, André F. T. and Fern, Ramón and Astudillo,
                  ez},
  booktitle =    {Proceedings of the 33rd International Conference on
                  Machine Learning (ICML)},
  editor =       {Balcan, Maria-Florina and Weinberger, Kilian Q.},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v48/martins16.html}},
  pages =        {1614--1623},
  publisher =    {JMLR.org},
  series =       {JMLR Workshop and Conference Proceedings},
  title =        {From Softmax to Sparsemax: A Sparse Model of
                  Attention and Multi-Label Classification},
  volume =       48,
  year =         2016
}

@inproceedings{martins2020sparse,
  address =      {Virtual Event},
  author =       {Martins, André and Farinhas, António and Treviso,
                  Marcos and Niculae, Vlad and Aguiar, Pedro and
                  Figueiredo, Mario},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {Larochelle, Hugo and Ranzato, Marco and Hadsell,
                  Raia and Balcan, M. F. and Lin, H.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/f0b76267fbe12b936bd65e203dc675c1-Paper.pdf}},
  pages =        {20989--21001},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Sparse and Continuous Attention Mechanisms},
  volume =       33,
  year =         2020
}

@inproceedings{martinturrero2024alert,
  address =      {Vienna, Austria},
  author =       {Martin-Turrero, Carmen and Bouvier, Maxence and
                  Breitenstein, Manuel and Zanuttigh, Pietro and
                  Parret, Vincent},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=8ZDFn7BDaH}},
  publisher =    {OpenReview.net},
  title =        {ALERT-Transformer: Bridging Asynchronous and
                  Synchronous Machine Learning for Real-Time
                  Event-based Spatio-Temporal Data},
  year =         2024
}

@inproceedings{mcdermott2023event,
  address =      {New Orleans, Louisiana, USA},
  author =       {McDermott, Matthew and Nestor, Bret and Argaw,
                  Peniel and Kohane, Isaac S},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4c8f197b24e9b05d22028c2de16a45d2-Paper-Datasets_and_Benchmarks.pdf}},
  pages =        {24322--24334},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Event Stream GPT: A Data Pre-processing and Modeling
                  Library for Generative, Pre-trained Transformers
                  over Continuous-time Sequences of Complex Events},
  volume =       36,
  year =         2023
}

@inproceedings{mehta2021delight,
  address =      {Virtual Event, Austria},
  author =       {Mehta, Sachin and Ghazvininejad, Marjan and Iyer,
                  Srinivasan and Zettlemoyer, Luke and Hajishirzi,
                  Hannaneh},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=ujmgfuxSLrO}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {DeLighT: Deep and Light-weight Transformer},
  year =         2021
}

@inproceedings{mehta2022mobilevit,
  address =      {Virtual Event},
  author =       {Mehta, Sachin and Rastegari, Mohammad},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=vh-0sUt8HlG}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MobileViT: Light-weight, General-purpose, and
                  Mobile-friendly Vision Transformer},
  year =         2022
}

@inproceedings{mei2022transformer,
  address =      {Virtual Event},
  author =       {Mei, Hongyuan and Yang, Chenghao and Eisner, Jason},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=Rty5g9imm7H}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer Embeddings of Irregularly Spaced Events
                  and Their Participants},
  year =         2022
}

@inproceedings{melnychuk2022causal,
  address =      {Baltimore, Maryland, USA},
  author =       {Melnychuk, Valentyn and Frauen, Dennis and
                  Feuerriegel, Stefan},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/melnychuk22a.html}},
  pages =        {15293--15329},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Causal Transformer for Estimating Counterfactual
                  Outcomes},
  volume =       162,
  year =         2022
}

@inproceedings{melo2022transformers,
  address =      {Baltimore, Maryland, USA},
  author =       {Melo, Luckeciano C.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/melo22a.html}},
  pages =        {15340--15359},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformers are Meta-Reinforcement Learners},
  volume =       162,
  year =         2022
}

@inproceedings{meng2023massediting,
  address =      {Kigali, Rwanda},
  author =       {Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex
                  J. and Belinkov, Yonatan and Bau, David},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MkbcAHIYgyS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Mass-Editing Memory in a Transformer},
  year =         2023
}

@inproceedings{mensch2018differentiable,
  address =      {Stockholm, Sweden},
  author =       {Mensch, Arthur and Blondel, Mathieu},
  booktitle =    {Proceedings of the 35th International Conference on
                  Machine Learning (ICML)},
  editor =       {Dy, Jennifer G. and Krause, Andreas},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v80/mensch18a.html}}},
  pages =        {3459--3468},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Differentiable Dynamic Programming for Structured
                  Prediction and Attention},
  volume =       80,
  year =         2018
}

@inproceedings{mentzer2022vct,
  address =      {New Orleans, Louisiana, USA},
  author =       {Mentzer, Fabian and Toderici, George D and Minnen,
                  David and Caelles, Sergi and Hwang, Sung Jin and
                  Lucic, Mario and Agustsson, Eirikur},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/54dcf25318f9de5a7a01f0a4125c541e-Paper-Conference.pdf}},
  pages =        {13091--13103},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {VCT: A Video Compression Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{merrill2023logic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Merrill, William and Sabharwal, Ashish},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a48e5877c7bf86a513950ab23b360498-Paper-Conference.pdf}},
  pages =        {52453--52463},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Logic for Expressing Log-Precision Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{merrill2024expressive,
  address =      {Vienna, Austria},
  author =       {Merrill, William and Sabharwal, Ashish},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=NjNGlPh8Wh}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {The Expressive Power of Transformers with Chain of
                  Thought},
  year =         2024
}

@inproceedings{merullo2024circuit,
  address =      {Vienna, Austria},
  author =       {Merullo, Jack and Eickhoff, Carsten and Pavlick,
                  Ellie},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=fpoAYV6Wsk}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Circuit Component Reuse Across Tasks in Transformer
                  Language Models},
  year =         2024
}

@inproceedings{mialon2021trainable,
  address =      {Virtual Event, Austria},
  author =       {Mialon, Grégoire and Chen, Dexiong and Alex, and
                  d'Aspremont, re and Mairal, Julien},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ZK6vTvb84s}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Trainable Optimal Transport Embedding for Feature
                  Aggregation and its Relationship to Attention},
  year =         2021
}

@inproceedings{miao2022interpretable,
  address =      {Baltimore, Maryland, USA},
  author =       {Miao, Siqi and Liu, Mia and Li, Pan},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/miao22a.html}},
  pages =        {15524--15543},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Interpretable and Generalizable Graph Learning via
                  Stochastic Attention Mechanism},
  volume =       162,
  year =         2022
}

@inproceedings{miao2024localitysensitive,
  address =      {Vienna, Austria},
  author =       {Miao, Siqi and Lu, Zhiyuan and Liu, Mia and Duarte,
                  Javier M. and Li, Pan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=vJx6fld6l0}},
  publisher =    {OpenReview.net},
  title =        {Locality-Sensitive Hashing-Based Efficient Point
                  Transformer with Applications in High-Energy
                  Physics},
  year =         2024
}

@inproceedings{micheli2023transformers,
  address =      {Kigali, Rwanda},
  author =       {Micheli, Vincent and Alonso, Eloi and Fleuret,
                  François},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vhFu1Acb0xb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformers are Sample-Efficient World Models},
  year =         2023
}

@inproceedings{mikula2024magnushammer,
  address =      {Vienna, Austria},
  author =       {Mikula, Maciej and Tworkowski, Szymon and Antoniak,
                  Szymon and Piotrowski, Bartosz and Jiang, Albert
                  Q. and Zhou, Jin Peng and Szegedy, Christian and
                  Kucinski, Lukasz and Milos, Piotr and Wu, Yuhuai},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=oYjPk8mqAV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Magnushammer: A Transformer-Based Approach to
                  Premise Selection},
  year =         2024
}

@inproceedings{min2022peripheral,
  address =      {New Orleans, Louisiana, USA},
  author =       {Min, Juhong and Zhao, Yucheng and Luo, Chong and
                  Cho, Minsu},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/cf78a15772ec1a6aee9bbee2d2b382c3-Paper-Conference.pdf}},
  pages =        {32097--32111},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Peripheral Vision Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{mittal2020learning,
  address =      {Virtual Event},
  author =       {Mittal, Sarthak and Lamb, Alex and Goyal, Anirudh
                  and Voleti, Vikram and Shanahan, Murray and Lajoie,
                  Guillaume and Mozer, Michael and Bengio, Yoshua},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/mittal20a.html}},
  pages =        {6972--6986},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning to Combine Top-Down and Bottom-Up Signals
                  in Recurrent Neural Networks with Attention over
                  Modules},
  volume =       119,
  year =         2020
}

@inproceedings{mittal2022compositional,
  address =      {Virtual Event},
  author =       {Mittal, Sarthak and Ch, Sharath and Raparthy, Ra and
                  Rish, Irina and Bengio, Yoshua and Lajoie,
                  Guillaume},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=IwJPj2MBcIa}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Compositional Attention: Disentangling Search and
                  Retrieval},
  year =         2022
}

@inproceedings{miyato2024gta,
  address =      {Vienna, Austria},
  author =       {Miyato, Takeru and Jaeger, Bernhard and Welling, Max
                  and Geiger, Andreas},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=uJVHygNeSZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {GTA: A Geometry-Aware Attention Mechanism for
                  Multi-View Transformers},
  year =         2024
}

@inproceedings{mnih2014recurrent,
  address =      {Montreal, Quebec, Canada},
  author =       {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex
                  and Kavukcuoglu, Koray},
  booktitle =    {Advances in Neural Information Processing Systems 27
                  (NIPS)},
  editor =       {Ghahramani, Z. and Welling, M. and Cortes, C. and
                  Lawrence, N. and Weinberger, K.Q.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2014/file/09c6c3783b4a70054da74f2538ed47c6-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Recurrent Models of Visual Attention},
  volume =       27,
  year =         2014
}

@inproceedings{mo2022adversarial,
  address =      {New Orleans, Louisiana, USA},
  author =       {Mo, Yichuan and Wu, Dongxian and Wang, Yifei and
                  Guo, Yiwen and Wang, Yisen},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/760b5def8dcb1156aac454e9c0f5f406-Paper-Conference.pdf}},
  pages =        {18599--18611},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {When Adversarial Training Meets Vision Transformers:
                  Recipes from Training to Architecture},
  volume =       35,
  year =         2022
}

@inproceedings{mo2023dit,
  address =      {New Orleans, Louisiana, USA},
  author =       {Mo, Shentong and Xie, Enze and Chu, Ruihang and
                  Hong, Lanqing and Niessner, Matthias and Li,
                  Zhenguo},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/d6c01b025cad37d5c8bab4ba18846c02-Paper-Conference.pdf}},
  pages =        {67960--67971},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DiT-3D: Exploring Plain Diffusion Transformers for
                  3D Shape Generation},
  volume =       36,
  year =         2023
}

@inproceedings{mohtashami2023random,
  address =      {New Orleans, Louisiana, USA},
  author =       {Mohtashami, Amirkeivan and Jaggi, Martin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/ab05dc8bf36a9f66edbff6992ec86f56-Paper-Conference.pdf}},
  pages =        {54567--54585},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Random-Access Infinite Context Length for
                  Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{morehead2022geometric,
  address =      {Virtual Event},
  author =       {Morehead, Alex and Chen, Chen and Cheng, Jianlin},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=CS4463zx6Hi}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Geometric Transformers for Protein Interface Contact
                  Prediction},
  year =         2022
}

@inproceedings{moreno2022kernel,
  address =      {New Orleans, Louisiana, USA},
  author =       {Moreno, Alexander and Wu, Zhenke and Nagesh, Supriya
                  and Dempsey, Walter and Rehg, James M},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/727a5a5c77be15d053b47b7c391800c2-Paper-Conference.pdf}},
  pages =        {18046--18059},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Kernel Multimodal Continuous Attention},
  volume =       35,
  year =         2022
}

@inproceedings{morsali2023mlpattention,
  address =      {Kigali, Rwanda},
  author =       {Morsali, Alireza and Heidari, Moein and Heydarian,
                  Samin and Abedini, Tohid},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=99XvUeDFYTD}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {MLP-Attention: Improving Transformer Architecture
                  with MLP Attention Weights},
  year =         2023
}

@inproceedings{mott2019towards,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Mott, Alexander and Zoran, Daniel and Chrzanowski,
                  Mike and Wierstra, Daan and Jimenez Rezende, Danilo},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/e9510081ac30ffa83f10b68cde1cac07-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Towards Interpretable Reinforcement Learning Using
                  Attention Augmented Agents},
  volume =       32,
  year =         2019
}

@inproceedings{moudgil2021soat,
  address =      {Virtual Event},
  author =       {Moudgil, Abhinav and Majumdar, Arjun and Agrawal,
                  Harsh and Lee, Stefan and Batra, Dhruv},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/3c8a49145944fed2bbcaade178a426c4-Paper.pdf}},
  pages =        {7357--7367},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SOAT: A Scene- and Object-Aware Transformer for
                  Vision-and-Language Navigation},
  volume =       34,
  year =         2021
}

@inproceedings{mu2022ctrlformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Mu, Yao Mark and Chen, Shoufa and Ding, Mingyu and
                  Chen, Jianyu and Chen, Runjian and Luo, Ping},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v162/mu22a.html}},
  pages =        {16043--16061},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {CtrlFormer: Learning Transferable State
                  Representation for Visual Control via Transformer},
  volume =       162,
  year =         2022
}

@inproceedings{muller2022transformers,
  address =      {Virtual Event},
  author =       {Müller, Samuel and Hollmann, Noah and Pineda-Arango,
                  Sebastian and Grabocka, Josif and Hutter, Frank},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=KSugKcbNf9}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformers Can Do Bayesian Inference},
  year =         2022
}

@inproceedings{muller2024aligning,
  address =      {Vienna, Austria},
  author =       {Müller, Luis and Morris, Christopher},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=4FJJfYjUQR}},
  publisher =    {OpenReview.net},
  title =        {Aligning Transformers with Weisfeiler-Leman},
  year =         2024
}

@inproceedings{munir2023cal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Munir, Muhammad Akhtar and Khan, Salman H. and Khan,
                  Muhammad Haris and Ali, Mohsen and Shahbaz Khan,
                  Fahad},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e271e30de7a2e462ca1f85cefa816380-Paper-Conference.pdf}},
  pages =        {71619--71631},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cal-DETR: Calibrated Detection Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{murty2023characterizing,
  address =      {Kigali, Rwanda},
  author =       {Murty, Shikhar and Sharma, Pratyusha and Andreas,
                  Jacob and Manning, Christopher D.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=sAOOeI878Ns}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Characterizing Intrinsic Compositionality in
                  Transformers with Tree Projections},
  year =         2023
}

@inproceedings{naeem2022i2dformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Naeem, Muhammad Ferjad and Xian, Yongqin and Gool,
                  Luc V and Tombari, Federico},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4fca3029c9ead4551937ed6987502e5f-Paper-Conference.pdf}},
  pages =        {12283--12294},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {I2DFormer: Learning Image to Document Attention for
                  Zero-Shot Image Classification},
  volume =       35,
  year =         2022
}

@inproceedings{nagrani2021attention,
  address =      {Virtual Event},
  author =       {Nagrani, Arsha and Yang, Shan and Arnab, Anurag and
                  Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/76ba9f564ebbc35b1014ac498fafadd0-Paper.pdf}},
  pages =        {14200--14213},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention Bottlenecks for Multimodal Fusion},
  volume =       34,
  year =         2021
}

@inproceedings{nahshan2024linear,
  address =      {Vienna, Austria},
  author =       {Nahshan, Yury and Kampeas, Joseph and Haleva, Emir},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=5nM2AHzqUj}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Linear Log-Normal Attention with Unbiased
                  Concentration},
  year =         2024
}

@inproceedings{nakahara1995dynamics,
  address =      {Denver, Colorado, USA},
  author =       {Nakahara, Hiroyuki and Doya, Kenji},
  booktitle =    {Advances in Neural Information Processing Systems 8
                  (NIPS)},
  editor =       {D. Touretzky and M.C. Mozer and M. Hasselmo},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1995/file/afdec7005cc9f14302cd0474fd0f3c96-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Dynamics of Attention as Near Saddle-Node
                  Bifurcation Behavior},
  volume =       8,
  year =         1995
}

@inproceedings{narayanan2023cheaply,
  address =      {New Orleans, Louisiana, USA},
  author =       {Narayanan, Deepak and Santhanam, Keshav and
                  Henderson, Peter and Bommasani, Rishi and Lee, Tony
                  and Liang, Percy S},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/d1a14493e5f84d6c6129414f0cd1a7c6-Paper-Conference.pdf}},
  pages =        {66518--66538},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cheaply Estimating Inference Efficiency Metrics for
                  Autoregressive Transformer Models},
  volume =       36,
  year =         2023
}

@inproceedings{naseer2021intriguing,
  address =      {Virtual Event},
  author =       {Naseer, Muhammad Muzammal and Ranasinghe, Kanchana
                  and Khan, Salman H and Hayat, Munawar and Shahbaz
                  Khan, Fahad and Yang, Ming-Hsuan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/c404a5adbf90e09631678b13b05d9d7a-Paper.pdf}},
  pages =        {23296--23308},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Intriguing Properties of Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{naseer2022on,
  address =      {Virtual Event},
  author =       {Naseer, Muzammal and Ranasinghe, Kanchana and Khan,
                  Salman and Khan, Fahad Shahbaz and Porikli, Fatih},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=D6nH3719vZy}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {On Improving Adversarial Transferability of Vision
                  Transformers},
  year =         2022
}

@inproceedings{ngiam2022scene,
  address =      {Virtual Event},
  author =       {Ngiam, Jiquan and Vasudevan, Vijay and Caine,
                  Benjamin and Zhang, Zhengdong and Chiang, Hao-Tien
                  Lewis and Ling, Jeffrey and Roelofs, Rebecca and
                  Bewley, Alex and Liu, Chenxi and Venugopal, Ashish
                  and Weiss, David J. and Sapp, Ben and Chen, Zhifeng
                  and Shlens, Jonathon},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Wm3EA5OlHsG}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Scene Transformer: A unified architecture for
                  predicting future trajectories of multiple agents},
  year =         2022
}

@inproceedings{nguyen2020tree,
  address =      {Addis Ababa, Ethiopia},
  author =       {Nguyen, Xuan-Phi and Joty, Shafiq R. and Hoi, Steven
                  C. H. and Socher, Richard},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HJxK5pEYvr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tree-Structured Attention with Hierarchical
                  Accumulation},
  year =         2020
}

@inproceedings{nguyen2021fmmformer,
  address =      {Virtual Event},
  author =       {Nguyen, Tan and Suliafu, Vai and Osher, Stanley and
                  Chen, Long and Wang, Bao},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f621585df244e9596dc70a39b579efb1-Paper.pdf}},
  pages =        {29449--29463},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {FMMformer: Efficient and Flexible Transformer via
                  Decomposed Near-field and Far-field Attention},
  volume =       34,
  year =         2021
}

@inproceedings{nguyen2022fourierformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Nguyen, Tan and Pham, Minh and Nguyen, Tam and
                  Nguyen, Khai and Osher, Stanley and Ho, Nhat},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/bc968adbdff4a2551649d464b83f264a-Paper-Conference.pdf}},
  pages =        {29319--29335},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {FourierFormer: Transformer Meets Generalized Fourier
                  Integral Theorem},
  volume =       35,
  year =         2022
}

@inproceedings{nguyen2022improvingb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Nguyen, Tan and Nguyen, Tam and Do, Hai and Nguyen,
                  Khai and Saragadam, Vishwanath and Pham, Minh and
                  Nguyen, Khuong Duy and Ho, Nhat and Osher, Stanley},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/b2e4edd53059e24002a0c916d75cc9a3-Paper-Conference.pdf}},
  pages =        {27937--27952},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Improving Transformer with an Admixture of Attention
                  Heads},
  volume =       35,
  year =         2022
}

@inproceedings{nguyen2022transformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Nguyen, Tung and Grover, Aditya},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/nguyen22b.html}},
  pages =        {16569--16594},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformer Neural Processes: Uncertainty-Aware Meta
                  Learning Via Sequence Modeling},
  volume =       162,
  year =         2022
}

@inproceedings{nguyen2023mitigating,
  address =      {New Orleans, Louisiana, USA},
  author =       {Nguyen, Tam and Nguyen, Tan and Baraniuk, Richard},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/fde1a69a5b6e554b2f1f727197d2651d-Paper-Conference.pdf}},
  pages =        {80233--80256},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Mitigating Over-Smoothing in Transformers via
                  Regularized Nonlocal Functionals},
  volume =       36,
  year =         2023
}

@inproceedings{nguyen2023primaldual,
  address =      {Kigali, Rwanda},
  author =       {Nguyen, Tan Minh and Nguyen, Tam Minh and Ho, Nhat
                  and Bertozzi, Andrea L. and Baraniuk, Richard G. and
                  Osher, Stanley J.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=U_T8-5hClV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Primal-Dual Framework for Transformers and Neural
                  Networks},
  year =         2023
}

@inproceedings{nguyen2023selfattention,
  address =      {Honolulu, Hawaii, USA},
  author =       {Nguyen, Khai and Nguyen, Dang and Ho, Nhat},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/nguyen23e.html}}},
  pages =        {26008--26030},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Self-Attention Amortized Distributional Projection
                  Optimization for Sliced Wasserstein Point-Cloud
                  Reconstruction},
  year =         2023
}

@inproceedings{nguyen2024pidformer,
  address =      {Vienna, Austria},
  author =       {Nguyen, Tam Minh and Uribe, César A. and Nguyen, Tan
                  Minh and Baraniuk, Richard G.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=SRzb3QDjdV}},
  publisher =    {OpenReview.net},
  title =        {PIDformer: Transformer Meets Control Theory},
  year =         2024
}

@inproceedings{ni2023basisformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ni, Zelin and Yu, Hang and Liu, Shizhan and Li,
                  Jianguo and Lin, Weiyao},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e150e6d0a1e5214740c39c6e4503ba7a-Paper-Conference.pdf}},
  pages =        {71222--71241},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {BasisFormer: Attention-based Time Series Forecasting
                  with Learnable and Interpretable Basis},
  volume =       36,
  year =         2023
}

@inproceedings{ni2023do,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ni, Tianwei and Ma, Michel and Eysenbach, Benjamin
                  and Bacon, Pierre-Luc},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/9dc5accb1e4f4a9798eae145f2e4869b-Paper-Conference.pdf}},
  pages =        {50429--50452},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {When Do Transformers Shine in RL? Decoupling Memory
                  from Credit Assignment},
  volume =       36,
  year =         2023
}

@inproceedings{nichani2024transformers,
  address =      {Vienna, Austria},
  author =       {Nichani, Eshaan and Damian, Alex and Lee, Jason D.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=jNM4imlHZv}},
  publisher =    {OpenReview.net},
  title =        {How Transformers Learn Causal Structure with
                  Gradient Descent},
  year =         2024
}

@inproceedings{niculae2017regularized,
  address =      {Long Beach, California, USA},
  author =       {Niculae, Vlad and Blondel, Mathieu},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {I. Guyon and U. Von Luxburg and S. Bengio and
                  H. Wallach and R. Fergus and S. Vishwanathan and
                  R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/2d1b2a5ff364606ff041650887723470-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Regularized Framework for Sparse and Structured
                  Neural Attention},
  volume =       30,
  year =         2017
}

@inproceedings{nie2023time,
  address =      {Kigali, Rwanda},
  author =       {Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee
                  and Kalagnanam, Jayant},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Jbdc0vTOcol}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Time Series is Worth 64 Words: Long-term
                  Forecasting with Transformers},
  year =         2023
}

@inproceedings{niebur1993neurobiology,
  address =      {Denver, Colorado, USA},
  author =       {Niebur, Ernst and Olshausen, Bruno},
  booktitle =    {Advances in Neural Information Processing Systems 6
                  (NIPS)},
  editor =       {Cowan, J. and Tesauro, G. and Alspector, J.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1993/file/ce78d1da254c0843eb23951ae077ff5f-Paper.pdf}},
  publisher =    {Morgan-Kaufmann},
  series =       {Conference Track Proceedings},
  title =        {Neurobiology, Psychophysics, and Computational
                  Models of Visual Attention},
  volume =       6,
  year =         1993
}

@inproceedings{niebur1995control,
  address =      {Denver, Colorado, USA},
  author =       {Niebur, Ernst and Koch, Christof},
  booktitle =    {Advances in Neural Information Processing Systems 8
                  (NIPS)},
  editor =       {D. Touretzky and M.C. Mozer and M. Hasselmo},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1995/file/e8b1cbd05f6e6a358a81dee52493dd06-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Control of Selective Visual Attention: Modeling the
                  "Where" Pathway},
  volume =       8,
  year =         1995
}

@inproceedings{noci2022signal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Noci, Lorenzo and Anagnostidis, Sotiris and Biggio,
                  Luca and Orvieto, Antonio and Singh, Sidak Pal and
                  Lucchi, Aurelien},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/ae0cba715b60c4052359b3d52a2cff7f-Paper-Conference.pdf}},
  pages =        {27198--27211},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Signal Propagation in Transformers: Theoretical
                  Perspectives and the Role of Rank Collapse},
  volume =       35,
  year =         2022
}

@inproceedings{noci2023shaped,
  address =      {New Orleans, Louisiana, USA},
  author =       {Noci, Lorenzo and Li, Chuning and Li, Mufan and He,
                  Bobby and Hofmann, Thomas and Maddison, Chris J and
                  Roy, Dan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/aa31dc84098add7dd2ffdd20646f2043-Paper-Conference.pdf}},
  pages =        {54250--54281},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Shaped Transformer: Attention Models in the
                  Infinite Depth-and-Width Limit},
  volume =       36,
  year =         2023
}

@inproceedings{notin2022tranception,
  address =      {Baltimore, Maryland, USA},
  author =       {Notin, Pascal and Dias, Mafalda and Frazer, Jonathan
                  and Marchena-Hurtado, Javier and Gomez, Aidan N. and
                  Marks, Debora S. and Gal, Yarin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/notin22a.html}},
  pages =        {16990--17017},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Tranception: Protein Fitness Prediction with
                  Autoregressive Transformers and Inference-time
                  Retrieval},
  volume =       162,
  year =         2022
}

@inproceedings{notin2023proteinnpt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Notin, Pascal and Weitzman, Ruben and Marks, Debora
                  and Gal, Yarin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6a4d5d85f7a52f062d23d98d544a5578-Paper-Conference.pdf}},
  pages =        {33529--33563},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ProteinNPT: Improving Protein Property Prediction
                  and Design with Non-Parametric Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{oroojlooy2020attendlight,
  address =      {Virtual Event},
  author =       {Oroojlooy, Afshin and Nazari, Mohammadreza and
                  Hajinezhad, Davood and Silva, Jorge},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {Larochelle, H. and Ranzato, M. and Hadsell, R. and
                  Balcan, M.F. and Lin, H.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/29e48b79ae6fc68e9b6480b677453586-Paper.pdf}},
  pages =        {4079--4090},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {AttendLight: Universal Attention-Based Reinforcement
                  Learning Model for Traffic Signal Control},
  volume =       33,
  year =         2020
}

@inproceedings{osman2024small,
  address =      {Vienna, Austria},
  author =       {Osman, Mohamed and Kaplan, Daniel Z.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=owfuhF0bT9}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {Small Transformers, Big Results: Efficient Diffusion
                  with Parameter Sharing},
  year =         2024
}

@inproceedings{oswald2023transformers,
  address =      {Honolulu, Hawaii, USA},
  author =       {Oswald, Johannes von and Niklasson, Eyvind and R,
                  Ettore and azzo and Sacramento, João and Alex and
                  Mordvintsev, er and Zhmoginov, Andrey and
                  Vladymyrov, Max},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/von-oswald23a.html}}},
  pages =        {35151--35174},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformers Learn In-Context by Gradient Descent},
  volume =       202,
  year =         2023
}

@inproceedings{ouyang2021contextual,
  address =      {Virtual Event},
  author =       {Ouyang, Jianbo and Wu, Hui and Wang, Min and Zhou,
                  Wengang and Li, Houqiang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, Marco and Beygelzimer, A. and Dauphin,
                  Y. and Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/18d10dc6e666eab6de9215ae5b3d54df-Paper.pdf}},
  pages =        {3135--3148},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Contextual Similarity Aggregation with
                  Self-attention for Visual Re-ranking},
  volume =       34,
  year =         2021
}

@inproceedings{oymak2023on,
  address =      {Honolulu, Hawaii, USA},
  author =       {Oymak, Samet and Rawat, Ankit Singh and
                  Soltanolkotabi, Mahdi and Thrampoulidis, Christos},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/oymak23a.html}},
  pages =        {26724--26768},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {On the Role of Attention in Prompt-tuning},
  volume =       202,
  year =         2023
}

@inproceedings{pagliardini2023fast,
  address =      {New Orleans, Louisiana, USA},
  author =       {Pagliardini, Matteo and Paliotta, Daniele and Jaggi,
                  Martin and Fleuret, François},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/bc222e8153a49c1b30a1b8ba96b35117-Paper-Conference.pdf}},
  pages =        {59808--59831},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Fast Attention Over Long Sequences With Dynamic
                  Sparse Flash Attention},
  volume =       36,
  year =         2023
}

@inproceedings{pai2024masked,
  address =      {Vienna, Austria},
  author =       {Pai, Druv and Buchanan, Sam and Wu, Ziyang and Yu,
                  Yaodong and Ma, Yi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=PvyOYleymy}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Masked Completion via Structured Diffusion with
                  White-Box Transformers},
  year =         2024
}

@inproceedings{paletta2005qlearning,
  address =      {Bonn, Germany},
  author =       {Paletta, Lucas and Fritz, Gerald and Seifert,
                  Christin},
  booktitle =    {Machine Learning: Proceedings of the Twenty-Second
                  International Conference (ICML)},
  doi =          {10.1145/1102351.1102433},
  editor =       {Raedt, Luc De and Wrobel, Stefan},
  month =        {August},
  note =         {\url{https://doi.org/10.1145/1102351.1102433}},
  pages =        {649--656},
  publisher =    {ACM},
  series =       {ACM International Conference Proceeding Series},
  title =        {Q-learning of sequential attention for visual object
                  recognition from informative local descriptors},
  volume =       119,
  year =         2005
}

@inproceedings{pamint2023using,
  address =      {Kigali, Rwanda},
  author =       {Pamânt, Andrei Florin and Darabant, Sergiu Adrian},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=WFatA9XIQ0m}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Using vision transformer-based GANs against Vision
                  Transformers},
  year =         2023
}

@inproceedings{pan2021ia,
  address =      {Virtual Event},
  author =       {Pan, Bowen and Panda, Rameswar and Jiang, Yifan and
                  Wang, Zhangyang and Feris, Rogerio and Oliva, Aude},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf}},
  pages =        {24898--24911},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {IA-RED2: Interpretability-Aware Redundancy Reduction
                  for Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{pan2022fast,
  address =      {New Orleans, Louisiana, USA},
  author =       {Pan, Zizheng and Cai, Jianfei and Zhuang, Bohan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5d5f703ee1dedbfe324b1872f44db939-Paper-Conference.pdf}},
  pages =        {14541--14554},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Fast Vision Transformers with HiLo Attention},
  volume =       35,
  year =         2022
}

@inproceedings{pan2022matt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Pan, Yue-Ting and Chou, Jing-Lun and Wei, Chun-Shu},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c981fd12b1d5703f19bd8289da9fc996-Paper-Conference.pdf}},
  pages =        {31116--31129},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MAtt: A Manifold Attention Network for EEG Decoding},
  volume =       35,
  year =         2022
}

@inproceedings{panahi2021shapeshifter,
  address =      {Virtual Event},
  author =       {Panahi, Aliakbar and Saeedi, Seyran and Arodz, Tom},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/09def3ebbc44ff3426b28fcd88c83554-Paper.pdf}},
  pages =        {1337--1350},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Shapeshifter: a Parameter-efficient Transformer
                  using Factorized Reshaped Matrices},
  volume =       34,
  year =         2021
}

@inproceedings{pandey2023are,
  address =      {New Orleans, Louisiana, USA},
  author =       {Pandey, Lalit and Wood, Samantha and Wood, Justin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e75dce944052276caf89c17aca8963d3-Paper-Conference.pdf}},
  pages =        {73104--73121},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Are Vision Transformers More Data Hungry Than
                  Newborn Visual Systems?},
  volume =       36,
  year =         2023
}

@inproceedings{pang2024frozen,
  address =      {Vienna, Austria},
  author =       {Pang, Ziqi and Xie, Ziyang and Man, Yunze and Wang,
                  Yu-Xiong},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=t0FI3Q66K5}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Frozen Transformers in Language Models Are Effective
                  Visual Encoder Layers},
  year =         2024
}

@inproceedings{panigrahi2024trainable,
  address =      {Vienna, Austria},
  author =       {Panigrahi, Abhishek and Malladi, Sadhika and Xia,
                  Mengzhou and Arora, Sanjeev},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=JcxlFe2fGC}},
  publisher =    {OpenReview.net},
  title =        {Trainable Transformer in Transformer},
  year =         2024
}

@inproceedings{papadopoulos2021hard,
  address =      {Virtual Event},
  author =       {Papadopoulos, Athanasios and Korus, Pawel and Memon,
                  Nasir},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/7b7916dd2de56297aa29cccb2bbf48d4-Paper.pdf}},
  pages =        {14694--14707},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Hard-Attention for Scalable Image Classification},
  volume =       34,
  year =         2021
}

@inproceedings{parisotto2020stabilizing,
  address =      {Virtual Event},
  author =       {Parisotto, Emilio and Song, H. Francis and Rae, Jack
                  W. and Pascanu, Razvan and Gülçehre, Çağlar and
                  Jayakumar, Siddhant M. and Jaderberg, Max and
                  Kaufman, Raphaël Lopez and Clark, Aidan and Noury,
                  Seb and Botvinick, Matthew M. and Heess, Nicolas and
                  Hadsell, Raia},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/parisotto20a.html}},
  pages =        {7487--7498},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Stabilizing Transformers for Reinforcement Learning},
  volume =       119,
  year =         2020
}

@inproceedings{parisotto2021efficient,
  address =      {Virtual Event, Austria},
  author =       {Parisotto, Emilio and Salakhutdinov, Ruslan},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=uR9LaO_QxF}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Transformers in Reinforcement Learning
                  using Actor-Learner Distillation},
  year =         2021
}

@inproceedings{park2021federated,
  address =      {Virtual Event},
  author =       {Park, Sangjoon and Kim, Gwanghyun and Kim, Jeongsol
                  and Kim, Boah and Ye, Jong Chul},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/ceb0595112db2513b9325a85761b7310-Paper.pdf}},
  pages =        {24617--24630},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Federated Split Task-Agnostic Vision Transformer for
                  COVID-19 CXR Diagnosis},
  volume =       34,
  year =         2021
}

@inproceedings{park2022do,
  address =      {Virtual Event},
  author =       {Park, Namuk and Kim, Songkuk},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=D78Go4hVcxO}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {How Do Vision Transformers Work?},
  year =         2022
}

@inproceedings{park2023do,
  address =      {Kigali, Rwanda},
  author =       {Park, Namuk and Kim, Wonjae and Heo, Byeongho and
                  Kim, Taekyung and Yun, Sangdoo},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=azCKuYyS74}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {What Do Self-Supervised Vision Transformers Learn?},
  year =         2023
}

@inproceedings{park2023energy,
  address =      {New Orleans, Louisiana, USA},
  author =       {Park, Geon Yeong and Kim, Jeongsol and Kim, Beomsu
                  and Lee, Sang Wan and Ye, Jong Chul},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f0878b7efa656b3bbd407c9248d13751-Paper-Conference.pdf}},
  pages =        {76382--76408},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Energy-Based Cross Attention for Bayesian Context
                  Update in Text-to-Image Diffusion Models},
  volume =       36,
  year =         2023
}

@inproceedings{park2023stablefdg,
  address =      {New Orleans, Louisiana, USA},
  author =       {Park, Jungwuk and Han, Dong-Jun and Kim, Jinho and
                  Wang, Shiqiang and Brinton, Christopher and Moon,
                  Jaekyun},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/dae8bdacd265399b193e6b43d44a80f0-Paper-Conference.pdf}},
  pages =        {69309--69327},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {StableFDG: Style and Attention Based Learning for
                  Federated Domain Generalization},
  volume =       36,
  year =         2023
}

@inproceedings{park2024attentionbased,
  address =      {Vienna, Austria},
  author =       {Park, Taewon and Choi, Inchul and Lee, Minho},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=FDb2JQZsFH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Attention-based Iterative Decomposition for Tensor
                  Product Representation},
  year =         2024
}

@inproceedings{parmar2018image,
  address =      {Stockholm, Sweden},
  author =       {Parmar, Niki and Vaswani, Ashish and Uszkoreit,
                  Jakob and Kaiser, Lukasz and Shazeer, Noam},
  booktitle =    {Proceedings of the 35th International Conference on
                  Machine Learning (ICML)},
  editor =       {Dy, Jennifer G. and Krause, Andreas},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v80/parmar18a.html}},
  pages =        {4052--4061},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Image Transformer},
  volume =       80,
  year =         2018
}

@inproceedings{paschalidou2021atiss,
  address =      {Virtual Event},
  author =       {Paschalidou, Despoina and Kar, Amlan and Shugrina,
                  Maria and Kreis, Karsten and Geiger, Andreas and
                  Fidler, Sanja},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/64986d86a17424eeac96b08a6d519059-Paper.pdf}},
  pages =        {12013--12026},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ATISS: Autoregressive Transformers for Indoor Scene
                  Synthesis},
  volume =       34,
  year =         2021
}

@inproceedings{paster2022you,
  address =      {New Orleans, Louisiana, USA},
  author =       {Paster, Keiran and McIlraith, Sheila and Ba, Jimmy},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/fe90657b12193c7b52a3418bdc351807-Paper-Conference.pdf}},
  pages =        {38966--38979},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {You Can’t Count on Luck: Why Decision Transformers
                  and RvS Fail in Stochastic Environments},
  volume =       35,
  year =         2022
}

@inproceedings{pathak2024transformers,
  address =      {Vienna, Austria},
  author =       {Pathak, Reese and Sen, Rajat and Kong, Weihao and
                  Das, Abhimanyu},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=sLkj91HIZU}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformers Can Optimally Learn Regression Mixture
                  Models},
  year =         2024
}

@inproceedings{patrick2021keeping,
  address =      {Virtual Event},
  author =       {Patrick, Mandela and Campbell, Dylan and Asano, Yuki
                  and Misra, Ishan and Metze, Florian and
                  Feichtenhofer, Christoph and Vedaldi, Andrea and
                  Henriques, João F.},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/67f7fb873eaf29526a11a9b7ac33bfac-Paper.pdf}},
  pages =        {12493--12506},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Keeping Your Eye on the Ball: Trajectory Attention
                  in Video Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{patro2023scattering,
  address =      {New Orleans, Louisiana, USA},
  author =       {Patro, Badri and Agneeswaran, Vijay},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a97f8072e51a785434b2da3e9cbf5aae-Paper-Conference.pdf}},
  pages =        {54152--54166},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Scattering Vision Transformer: Spectral Mixing
                  Matters},
  volume =       36,
  year =         2023
}

@inproceedings{paul2024simple,
  address =      {Vienna, Austria},
  author =       {Paul, Dipanjyoti and Chowdhury, Arpita and Xiong,
                  Xinqi and Chang, Feng-Ju and Carlyn, David Edward
                  and Stevens, Samuel and Provost, Kaiya and Karpatne,
                  Anuj and Carstens, Bryan and Rubenstein, Daniel
                  I. and Stewart, Charles V. and Berger-Wolf, Tanya
                  Y. and Su, Yu and Chao, Wei-Lun},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=bkdWThqE6q}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Simple Interpretable Transformer for Fine-Grained
                  Image Classification and Analysis},
  year =         2024
}

@inproceedings{peng2021integrating,
  address =      {Virtual Event},
  author =       {Peng, Han and Li, Ge and Wang, Wenhan and Zhao,
                  YunFei and Jin, Zhi},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/4e0223a87610176ef0d24ef6d2dcde3a-Paper.pdf}},
  pages =        {9343--9354},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Integrating Tree Path in Transformer for Code
                  Representation},
  volume =       34,
  year =         2021
}

@inproceedings{peng2021random,
  address =      {Virtual Event, Austria},
  author =       {Peng, Hao and Pappas, Nikolaos and Yogatama, Dani
                  and Schwartz, Roy and Smith, Noah A. and Kong,
                  Lingpeng},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=QtTKTdVrFBB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Random Feature Attention},
  year =         2021
}

@inproceedings{peng2022branchformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Peng, Yifan and Dalmia, Siddharth and Lane, Ian
                  R. and Watanabe, Shinji},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/peng22a.html}},
  pages =        {17627--17643},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Branchformer: Parallel MLP-Attention Architectures
                  to Capture Local and Global Context for Speech
                  Recognition and Understanding},
  volume =       162,
  year =         2022
}

@article{perez2021attention,
  author =       {Pérez, Jorge and Barceló, Pablo and Marinkovic,
                  Javier},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v22/20-302.html}},
  number =       75,
  pages =        {1--35},
  title =        {Attention is Turing-Complete},
  volume =       22,
  year =         2021
}

@inproceedings{peters2007congruence,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Peters, Robert and Itti, Laurent},
  booktitle =    {Advances in Neural Information Processing Systems 20
                  (NIPS)},
  editor =       {Platt, J. and Koller, D. and Singer, Y. and Roweis,
                  S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2007/file/621461af90cadfdaf0e8d4cc25129f91-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Congruence between Model and Human Attention Reveals
                  Unique Signatures of Critical Visual Events},
  volume =       20,
  year =         2007
}

@inproceedings{pham2024crossview,
  address =      {Vienna, Austria},
  author =       {Pham, Trung X. and Zhang, Kang and Yoo, Chang D.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=jEoIkNkqyc}},
  publisher =    {OpenReview.net},
  title =        {Cross-view Masked Diffusion Transformers for Person
                  Image Synthesis},
  year =         2024
}

@inproceedings{phan2023attentionbased,
  address =      {Honolulu, Hawaii, USA},
  author =       {Phan, Thomy and Ritz, Fabian and Altmann, Philipp
                  and Zorn, Maximilian and Nüßlein, Jonas and Kölle,
                  Michael and Gabor, Thomas and Linnhoff-Popien,
                  Claudia},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/phan23a.html}},
  pages =        {27840--27853},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Attention-Based Recurrence for Multi-Agent
                  Reinforcement Learning under Stochastic Partial
                  Observability},
  volume =       202,
  year =         2023
}

@inproceedings{pilault2023block,
  address =      {New Orleans, Louisiana, USA},
  author =       {Pilault, Jonathan and Fathi, Mahan and Firat, Orhan
                  and Pal, Chris and Bacon, Pierre-Luc and Goroshin,
                  Ross},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/16ccd203e9e3696a7ab0dcf568316379-Paper-Conference.pdf}},
  pages =        {7311--7329},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Block-State Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{poulain2024graph,
  address =      {Vienna, Austria},
  author =       {Poulain, Raphael and Beheshti, Rahmatollah},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  day =          {7--11},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=pe0Vdv7rsL}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Graph Transformers on EHRs: Better Representation
                  Improves Downstream Performance},
  year =         2024
}

@inproceedings{pozzi2020attention,
  address =      {Virtual Event},
  author =       {Pozzi, Isabella and Bohte, Sander and Roelfsema,
                  Pieter},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/1abb1e1ea5f481b589da52303b091cbb-Paper.pdf}},
  pages =        {2516--2526},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention-Gated Brain Propagation: How the brain can
                  implement reward-based error backpropagation},
  volume =       33,
  year =         2020
}

@inproceedings{prabhu2022adapting,
  address =      {New Orleans, Louisiana, USA},
  author =       {Prabhu, Viraj and Yenamandra, Sriram and Singh,
                  Aaditya and Hoffman, Judy},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/93b4d708976a1d9b1250c400e7fda811-Paper-Conference.pdf}},
  pages =        {23271--23283},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Adapting Self-Supervised Vision Transformers by
                  Probing Attention-Conditioned Masking Consistency},
  volume =       35,
  year =         2022
}

@inproceedings{press2022train,
  address =      {Virtual Event},
  author =       {Press, Ofir and Smith, Noah A. and Lewis, Mike},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=R8sQPpGCv0}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Train Short, Test Long: Attention with Linear Biases
                  Enables Input Length Extrapolation},
  year =         2022
}

@inproceedings{qi2023lipsformer,
  address =      {Kigali, Rwanda},
  author =       {Qi, Xianbiao and Wang, Jianan and Chen, Yihao and
                  Shi, Yukai and Zhang, Lei},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cHf1DcCwcH3}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {LipsFormer: Introducing Lipschitz Continuity to
                  Vision Transformers},
  year =         2023
}

@inproceedings{qian2021blending,
  address =      {Virtual Event},
  author =       {Qian, Shengju and Shao, Hao and Zhu, Yi and Li, Mu
                  and Jia, Jiaya},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2b3bf3eee2475e03885a110e9acaab61-Paper.pdf}},
  pages =        {5416--5429},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Blending Anti-Aliasing into Vision Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{qian2022entroformer,
  address =      {Virtual Event},
  author =       {Qian, Yichen and Sun, Xiuyu and Lin, Ming and Tan,
                  Zhiyu and Jin, Rong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=VrjOFfcnSV8}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Entroformer: A Transformer-based Entropy Model for
                  Learned Image Compression},
  year =         2022
}

@inproceedings{qiang2022attcat,
  address =      {New Orleans, Louisiana, USA},
  author =       {Qiang, Yao and Pan, Deng and Li, Chengyin and Li,
                  Xin and Jang, Rhongho and Zhu, Dongxiao},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/20e45668fefa793bd9f2edf19be12c4b-Paper-Conference.pdf}},
  pages =        {5052--5064},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {AttCAT: Explaining Transformers via Attentive Class
                  Activation Tokens},
  volume =       35,
  year =         2022
}

@inproceedings{qin2022cosformer,
  address =      {Virtual Event},
  author =       {Qin, Zhen and Sun, Weixuan and Deng, Hui and Li,
                  Dongxu and Wei, Yunshen and Lv, Baohong and Yan,
                  Junjie and Kong, Lingpeng and Zhong, Yiran},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Bl8CQrx2Up4}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {cosFormer: Rethinking Softmax in Attention},
  year =         2022
}

@inproceedings{qin2022understanding,
  address =      {New Orleans, Louisiana, USA},
  author =       {Qin, Yao and Zhang, Chiyuan and Chen, Ting and
                  Lakshminarayanan, Balaji and Beutel, Alex and Wang,
                  Xuezhi},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/67662aa16456e0df65ab001136f92fd0-Paper-Conference.pdf}},
  pages =        {16276--16289},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Understanding and Improving Robustness of Vision
                  Transformers through Patch-based Negative
                  Augmentation},
  volume =       35,
  year =         2022
}

@inproceedings{qin2024various,
  address =      {Vienna, Austria},
  author =       {Qin, Zhen and Sun, Weigao and Li, Dong and Shen,
                  Xuyang and Sun, Weixuan and Zhong, Yiran},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Lwm6TiUP4X}},
  publisher =    {OpenReview.net},
  title =        {Various Lengths, Constant Speed: Efficient Language
                  Modeling with Lightning Attention},
  year =         2024
}

@inproceedings{qiu2023spiking,
  address =      {Kigali, Rwanda},
  author =       {Qiu, Xuerui and Luan, Zheng and Wang, Zhaorui and
                  Zhu, Rui-Jie},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MuOFB0LQKcy}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {When Spiking Neural Networks Meet Temporal Attention
                  Image Decoding and Adaptive Spiking Neuron},
  year =         2023
}

@inproceedings{qiu2024empirical,
  address =      {Vienna, Austria},
  author =       {Qiu, Zihan and Huang, Zeyu and Huang, Youcheng and
                  Fu, Jie},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=WSl84nwG7i}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {Empirical Study on Updating Key-Value Memories in
                  Transformer Feed-Forward Layers},
  year =         2024
}

@inproceedings{qu2022particle,
  address =      {Baltimore, Maryland, USA},
  author =       {Qu, Huilin and Li, Congqiao and Qian, Sitian},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v162/qu22b.html}},
  pages =        {18281--18292},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Particle Transformer for Jet Tagging},
  volume =       162,
  year =         2022
}

@inproceedings{quirke2024understanding,
  address =      {Vienna, Austria},
  author =       {Quirke, Philip and Barez, Fazl},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rIx1YXVWZb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Understanding Addition in Transformers},
  year =         2024
}

@inproceedings{rae2020compressive,
  address =      {Addis Ababa, Ethiopia},
  author =       {Rae, Jack W. and Potapenko, Anna and Jayakumar,
                  Siddhant M. and Hillier, Chloe and Lillicrap,
                  Timothy P.},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=SylKikSYDH}},
  series =       {Conference Track Proceedings},
  title =        {Compressive Transformers for Long-Range Sequence
                  Modelling},
  year =         2020
}

@inproceedings{raffel2017online,
  address =      {Sydney, Australia},
  author =       {Raffel, Colin and Luong, Minh-Thang and Liu, Peter
                  J. and Weiss, Ron J. and Eck, Douglas},
  booktitle =    {Proceedings of the 34th International Conference on
                  Machine Learning (ICML)},
  editor =       {Precup, Doina and Teh, Yee Whye},
  month =        {August},
  note =
                  {\url{http://proceedings.mlr.press/v70/raffel17a.html}},
  pages =        {2837--2846},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Online and Linear-Time Attention by Enforcing
                  Monotonic Alignments},
  volume =       70,
  year =         2017
}

@article{raffel2020exploring,
  author =       {Raffel, Colin and Shazeer, Noam and Roberts, Adam
                  and Lee, Katherine and Narang, Sharan and Matena,
                  Michael and Zhou, Yanqi and Li, Wei and Liu, Peter
                  J.},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v21/20-074.html}},
  number =       140,
  pages =        {1--67},
  title =        {Exploring the Limits of Transfer Learning with a
                  Unified Text-to-Text Transformer},
  volume =       21,
  year =         2020
}

@inproceedings{raghu2021do,
  address =      {Virtual Event},
  author =       {Raghu, Maithra and Unterthiner, Thomas and
                  Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy,
                  Alexey},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/652cf38361a209088302ba2b8b7f51e0-Paper.pdf}},
  pages =        {12116--12128},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Do Vision Transformers See Like Convolutional Neural
                  Networks?},
  volume =       34,
  year =         2021
}

@inproceedings{ramachandran2019stand,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Ramachandran, Prajit and Parmar, Niki and Vaswani,
                  Ashish and Bello, Irwan and Levskaya, Anselm and
                  Shlens, Jon},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/3416a75f4cea9109507cacd8e2f2aefc-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Stand-Alone Self-Attention in Vision Models},
  volume =       32,
  year =         2019
}

@inproceedings{ramesh2024compositional,
  address =      {Vienna, Austria},
  author =       {Ramesh, Rahul and Lubana, Ekdeep Singh and Khona,
                  Mikail and Dick, Robert P. and Tanaka, Hidenori},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=L1eJ3NKPCd}},
  publisher =    {OpenReview.net},
  title =        {Compositional Capabilities of Autoregressive
                  Transformers: A Study on Synthetic, Interpretable
                  Tasks},
  year =         2024
}

@inproceedings{rampasek2022recipe,
  address =      {New Orleans, Louisiana, USA},
  author =       {Rampášek, Ladislav and Galkin, Michael and Dwivedi,
                  Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and
                  Beaini, Dominique},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5d4834a159f1547b267a05a4e2b7cf5e-Paper-Conference.pdf}},
  pages =        {14501--14515},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Recipe for a General, Powerful, Scalable Graph
                  Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{rao1997correlates,
  address =      {Denver, Colorado, USA},
  author =       {Rao, Rajesh},
  booktitle =    {Advances in Neural Information Processing Systems 10
                  (NIPS)},
  editor =       {M. Jordan and M. Kearns and S. Solla},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/1997/file/23ad3e314e2a2b43b4c720507cec0723-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Correlates of Attention in a Model of Dynamic Visual
                  Recognition},
  volume =       10,
  year =         1997
}

@inproceedings{rao2021dynamicvit,
  address =      {Virtual Event},
  author =       {Rao, Yongming and Zhao, Wenliang and Liu, Benlin and
                  Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/747d3443e319a22747fbb873e8b2f9f2-Paper.pdf}},
  pages =        {13937--13949},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DynamicViT: Efficient Vision Transformers with
                  Dynamic Token Sparsification},
  volume =       34,
  year =         2021
}

@inproceedings{rao2021msa,
  address =      {Virtual Event},
  author =       {Rao, Roshan and Liu, Jason and Verkuil, Robert and
                  Meier, Joshua and Canny, John F. and Abbeel, Pieter
                  and Sercu, Tom and Alex and Rives, Er},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/rao21a.html}},
  pages =        {8844--8856},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {MSA Transformer},
  volume =       139,
  year =         2021
}

@inproceedings{rao2021transformer,
  address =      {Virtual Event, Austria},
  author =       {Rao, Roshan and Meier, Joshua and Sercu, Tom and
                  Ovchinnikov, Sergey and Alex, and Rives, Er},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=fylclEqgvgd}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer protein language models are unsupervised
                  structure learners},
  year =         2021
}

@inproceedings{rassin2023linguistic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Rassin, Royi and Hirsch, Eran and Glickman, Daniel
                  and Ravfogel, Shauli and Goldberg, Yoav and Chechik,
                  Gal},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/0b08d733a5d45a547344c4e9d88bb8bc-Paper-Conference.pdf}},
  pages =        {3536--3559},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Linguistic Binding in Diffusion Models: Enhancing
                  Attribute Correspondence through Attention Map
                  Alignment},
  volume =       36,
  year =         2023
}

@inproceedings{rasul2024vqtr,
  address =      {Vienna, Austria},
  author =       {Rasul, Kashif and Bennett, Andrew and Vicente, Pablo
                  and Gupta, Umang and Ghonia, Hena and Schneider,
                  Anderson and Nevmyvaka, Yuriy},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=IxpTsFS7mh}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {VQ-TR: Vector Quantized Attention for Time Series
                  Forecasting},
  year =         2024
}

@inproceedings{ravindran2023tiny,
  address =      {Kigali, Rwanda},
  author =       {Ravindran, Renjith P. and Kavi, Narayana Murthy},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=BWWrDHaP29}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Tiny Attention: A Simple yet Effective Method for
                  Learning Contextual Word Embeddings},
  year =         2023
}

@inproceedings{rawal2024dissecting,
  address =      {Vienna, Austria},
  author =       {Rawal, Ishaan Singh and Alex, and Matyasko, er and
                  Jaiswal, Shantanu and Fern, Basura and Tan, Cheston},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Wj5wm3Os5v}},
  publisher =    {OpenReview.net},
  title =        {Dissecting Multimodality in VideoQA Transformer
                  Models by Impairing Modality Fusion},
  year =         2024
}

@inproceedings{ren2019incremental,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Ren, Mengye and Liao, Renjie and Fetaya, Ethan and
                  Zemel, Richard},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/e833e042f509c996b1b25324d56659fb-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Incremental Few-Shot Learning with Attention
                  Attractor Networks},
  volume =       32,
  year =         2019
}

@inproceedings{ren2021combiner,
  address =      {Virtual Event},
  author =       {Ren, Hongyu and Dai, Hanjun and Dai, Zihang and
                  Yang, Mengjiao and Leskovec, Jure and Schuurmans,
                  Dale and Dai, Bo},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/bd4a6d0563e0604510989eb8f9ff71f5-Paper.pdf}},
  pages =        {22470--22482},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Combiner: Full Attention Transformer with Sparse
                  Computation Cost},
  volume =       34,
  year =         2021
}

@inproceedings{ribar2024sparq,
  address =      {Vienna, Austria},
  author =       {Ribar, Luka and Chelombiev, Ivan and Hudlass-Galley,
                  Luke and Blake, Charlie and Luschi, Carlo and Orr,
                  Douglas},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=OS5dqxmmtl}},
  publisher =    {OpenReview.net},
  title =        {SparQ Attention: Bandwidth-Efficient LLM Inference},
  year =         2024
}

@inproceedings{riemer2016correcting,
  address =      {New York City, New York, USA},
  author =       {Riemer, Matthew and Vempaty, Aditya and Calmon,
                  Flávio P. and III, Fenno F. Terry Heath and Hull,
                  Richard and Khabiri, Elham},
  booktitle =    {Proceedings of the 33rd International Conference on
                  Machine Learning (ICML)},
  editor =       {Balcan, Maria-Florina and Weinberger, Kilian Q.},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v48/riemer16.html}},
  pages =        {3010--3019},
  publisher =    {JMLR.org},
  series =       {Workshop and Conference Proceedings},
  title =        {Correcting Forecasts with Multifactor Neural
                  Attention},
  year =         2016
}

@inproceedings{rigotti2022attentionbased,
  address =      {Virtual Event},
  author =       {Rigotti, Mattia and Miksovic, Christoph and Giurgiu,
                  Ioana and Gschwind, Thomas and Scotton, Paolo},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=kAa9eDS0RdO}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Attention-based Interpretability with Concept
                  Transformers},
  year =         2022
}

@inproceedings{robine2023transformerbased,
  address =      {Kigali, Rwanda},
  author =       {Robine, Jan and Höftmann, Marc and Uelwer, Tobias
                  and Harmeling, Stefan},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=TdBaDGCpjly}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-based World Models Are Happy With 100k
                  Interactions},
  year =         2023
}

@inproceedings{rockt2016reasoning,
  address =      {San Juan, Puerto Rico},
  author =       {Rocktäschel, Tim and Grefenstette, Edward and
                  Hermann, Karl Moritz and Kociský, Tomás and Blunsom,
                  Phil},
  booktitle =    {4th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Bengio, Yoshua and LeCun, Yann},
  month =        {May},
  note =         {\url{http://arxiv.org/abs/1509.06664}},
  series =       {Conference Track Proceedings},
  title =        {Reasoning about Entailment with Neural Attention},
  year =         2016
}

@inproceedings{rohekar2023causal,
  address =      {New Orleans, Louisiana, USA},
  author =       {Rohekar, Raanan Y. and Gurwicz, Yaniv and Nisimov,
                  Shami},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/642a321fba8a0f03765318e629cb93ea-Paper-Conference.pdf}},
  pages =        {31450--31465},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Causal Interpretation of Self-Attention in
                  Pre-Trained Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{romero2021group,
  address =      {Virtual Event, Austria},
  author =       {Romero, David W. and Cordonnier, Jean-Baptiste},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=JkfYjnOEo6M}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Group Equivariant Stand-Alone Self-Attention For
                  Vision},
  year =         2021
}

@inproceedings{ron2022dual,
  address =      {Baltimore, Maryland, USA},
  author =       {Ron, Tom and Hazan, Tamir},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/ron22a.html}},
  pages =        {18754--18769},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Dual Decomposition of Convex Optimization Layers for
                  Consistent Attention in Medical Images},
  year =         2022
}

@inproceedings{rong2020self,
  address =      {Virtual Event},
  author =       {Rong, Yu and Bian, Yatao and Xu, Tingyang and Xie,
                  Weiyang and Wei, Ying and Huang, Wenbing and Huang,
                  Junzhou},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/94aef38441efa3380a3bed3faf1f9d5d-Paper.pdf}},
  pages =        {12559--12571},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Self-Supervised Graph Transformer on Large-Scale
                  Molecular Data},
  volume =       33,
  year =         2020
}

@inproceedings{rosenbluth2024distinguished,
  address =      {Vienna, Austria},
  author =       {Rosenbluth, Eran and Tönshoff, Jan and Ritzert,
                  Martin and Kisin, Berke and Grohe, Martin},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=AcSChDWL6V}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Distinguished In Uniform: Self-Attention Vs. Virtual
                  Nodes},
  year =         2024
}

@inproceedings{ruiz2022finding,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ruiz, Nataniel and Bargal, Sarah and Xie, Cihang and
                  Saenko, Kate and Sclaroff, Stan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5ce3a49415f78db65a714b4f05c62f4e-Paper-Conference.pdf}},
  pages =        {14403--14418},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Finding Differences Between Transformers and
                  ConvNets Using Counterfactual Simulation Testing},
  volume =       35,
  year =         2022
}

@inproceedings{ruscio2023attentionlikelihood,
  address =      {Kigali, Rwanda},
  author =       {Ruscio, Valeria and Maiorca, Valentino and
                  Silvestri, Fabrizio},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=R82eeIF4rP_}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Attention-likelihood relationship in Transformers},
  year =         2023
}

@inproceedings{ryali2023hiera,
  address =      {Honolulu, Hawaii, USA},
  author =       {Ryali, C. and Hu, Y. T. and Bolya, D. and Wei,
                  C. and Fan, H. and Huang, P. Y. and Aggarwal, V. and
                  Arkab, and Chowdhury, Hu. and Poursaeed, O. and
                  Hoffman, J. and Malik, J. and Li, Y. and
                  Feichtenhofer, C.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, A. and Brunskill, E. and Cho, K. and
                  Engelhardt, B. and Sabato, S. and Scarlett, J.},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/ryali23a.html}}},
  pages =        {29441--29454},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Hiera: A Hierarchical Vision Transformer without the
                  Bells-and-Whistles},
  volume =       202,
  year =         2023
}

@inproceedings{s2024do,
  address =      {Vienna, Austria},
  author =       {S, Michael Eli and er, and Giryes, Raja and Suzuki,
                  Taiji and Blondel, Mathieu and Peyré, Gabriel},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=kZbTkpnafR}},
  publisher =    {OpenReview.net},
  title =        {How do Transformers Perform In-Context
                  Autoregressive Learning?},
  year =         2024
}

@inproceedings{s2024tandem,
  address =      {Vienna, Austria},
  author =       {S., Aishwarya P. and Nair, Pranav Ajit and Samaga,
                  Yashas and Boyd, Toby and Kumar, Sanjiv and Jain,
                  Prateek and Netrapalli, Praneeth},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=TN3fi7dwPo}},
  publisher =    {OpenReview.net},
  title =        {Tandem Transformers for Inference Efficient LLMs},
  year =         2024
}

@inproceedings{saha2024io,
  address =      {Vienna, Austria},
  author =       {Saha, Barna and Ye, Christopher},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=MdPBVWTfwG}},
  publisher =    {OpenReview.net},
  title =        {I/O Complexity of Attention, or How Optimal is
                  FlashAttention?},
  year =         2024
}

@inproceedings{sahiner2022unraveling,
  address =      {Baltimore, Maryland, USA},
  author =       {Sahiner, Arda and Ergen, Tolga and Ozturkler, Batu
                  and Pauly, John M. and Mardani, Morteza and Pilanci,
                  Mert},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/sahiner22a.html}},
  pages =        {19050--19088},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Unraveling Attention via Convex Duality: Analysis
                  and Interpretations of Vision Transformers},
  year =         2022
}

@inproceedings{sajjadi2022object,
  address =      {New Orleans, Louisiana, USA},
  author =       {Sajjadi, Mehdi S. M. and Duckworth, Daniel and
                  Mahendran, Aravindh and van Steenkiste, Sjoerd and
                  Pavetic, Filip and Lucic, Mario and Guibas, Leonidas
                  J. and Greff, Klaus and Kipf, Thomas},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3dc83fcfa4d13e30070bd4b230c38cfe-Paper-Conference.pdf}},
  pages =        {9512--9524},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Object Scene Representation Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{sanford2023representational,
  address =      {New Orleans, Louisiana, USA},
  author =       {Sanford, Clayton and Hsu, Daniel J and Telgarsky,
                  Matus},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/73bf692447f174984f30499ec9b20e04-Paper-Conference.pdf}},
  pages =        {36677--36707},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Representational Strengths and Limitations of
                  Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{sapkota2024meta,
  address =      {Vienna, Austria},
  author =       {Sapkota, Hitesh and Neupane, Krishna Prasad and Yu,
                  Qi},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=CquFGSIU6w}},
  publisher =    {OpenReview.net},
  title =        {Meta Evidential Transformer for Few-Shot Open-Set
                  Recognition},
  year =         2024
}

@inproceedings{sasikumar2023attention,
  address =      {Kigali, Rwanda},
  author =       {Sasikumar, Nevasini and Mantri, Krishna Sri Ipsit},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=j1gj0ndrk1}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Attention Based Variational Graph Auto-Encoder
                  (AVGAE)},
  year =         2023
}

@inproceedings{schlag2021linear,
  address =      {Virtual Event},
  author =       {Schlag, Imanol and Irie, Kazuki and Schmidhuber,
                  Jürgen},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/schlag21a.html}}},
  pages =        {9355--9366},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Linear Transformers Are Secretly Fast Weight
                  Programmers},
  volume =       139,
  year =         2021
}

@inproceedings{schwartz2017high,
  address =      {Long Beach, California, USA},
  author =       {Schwartz, Idan and Schwing, Alexander and Hazan,
                  Tamir},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {I. Guyon and U. von Luxburg and S. Bengio and
                  H. Wallach and R. Fergus and S. Vishwanathan and
                  R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/051928341be67dcba03f0e04104d9047-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {High-Order Attention Models for Visual Question
                  Answering},
  volume =       30,
  year =         2017
}

@inproceedings{seo2017bidirectional,
  address =      {Toulon, France},
  author =       {Seo, Min Joon and Kembhavi, Aniruddha and Farhadi,
                  Ali and Hajishirzi, Hannaneh},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HJ0UKP9ge}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Bidirectional Attention Flow for Machine
                  Comprehension},
  year =         2017
}

@inproceedings{seo2017visual,
  address =      {Long Beach, California, USA},
  author =       {Seo, Paul Hongsuck and Lehrmann, Andreas and Han,
                  Bohyung and Sigal, Leonid},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {Guyon, I. and von Luxburg, U. and Bengio, S. and
                  Wallach, H. and Fergus, R. and Vishwanathan, S. and
                  Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/654ad60ebd1ae29cedc37da04b6b0672-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Visual Reference Resolution using Attention Memory
                  for Visual Dialog},
  volume =       30,
  year =         2017
}

@inproceedings{sermanet2015attention,
  address =      {San Diego, California, USA},
  author =       {Sermanet, Pierre and Frome, Andrea and Real,
                  Esteban},
  booktitle =    {3rd International Conference on Learning
                  Representations (ICLR)},
  editor =       {Bengio, Yoshua and LeCun, Yann},
  month =        {May},
  note =         {\url{http://arxiv.org/abs/1412.7054}},
  series =       {Workshop Track Proceedings},
  title =        {Attention for Fine-Grained Categorization},
  year =         2015
}

@inproceedings{serra2018overcoming,
  address =      {Stockholm, Sweden},
  author =       {Serrà, Joan and Suris, Didac and Miron, Marius and
                  Alex, and Karatzoglou, Ros},
  booktitle =    {Proceedings of the 35th International Conference on
                  Machine Learning (ICML)},
  editor =       {Dy, Jennifer G. and Krause, Andreas},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v80/serra18a.html}},
  pages =        {4555--4564},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Overcoming Catastrophic Forgetting with Hard
                  Attention to the Task},
  volume =       80,
  year =         2018
}

@inproceedings{sh2024functional,
  address =      {Vienna, Austria},
  author =       {Sh, and Li, a and You, Chong and Guruganesh, Guru
                  and Ainslie, Joshua and Ontañón, Santiago and
                  Zaheer, Manzil and Sanghai, Sumit and Yang, Yiming
                  and Kumar, Sanjiv and Bhojanapalli, Srinadh},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=rR03qFesqk}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Functional Interpolation for Relative Positions
                  improves Long Context Transformers},
  year =         2024
}

@inproceedings{shabani2023scaleformer,
  address =      {Kigali, Rwanda},
  author =       {Shabani, Mohammad Amin and Abdi, Amir H. and Meng,
                  Lili and Sylvain, Tristan},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=sCrnllCtjoE}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Scaleformer: Iterative Multi-scale Refining
                  Transformers for Time Series Forecasting},
  year =         2023
}

@inproceedings{shafiullah2022behavior,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shafiullah, Nur Muhammad and Cui, Zichen and
                  Altanzaya, Ariuntuya (Arty) and Pinto, Lerrel},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/90d17e882adbdda42349db6f50123817-Paper-Conference.pdf}},
  pages =        {22955--22968},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Behavior Transformers: Cloning k modes with one
                  stone},
  volume =       35,
  year =         2022
}

@inproceedings{shankar2019posterior,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shankar, Shiv and Sarawagi, Sunita},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=BkltNhC9FX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Posterior Attention Models for Sequence to Sequence
                  Learning},
  year =         2019
}

@inproceedings{shao2021transmil,
  address =      {Virtual Event},
  author =       {Shao, Zhuchen and Bian, Hao and Chen, Yang and Wang,
                  Yifeng and Zhang, Jian and Ji, Xiangyang and Zhang,
                  Yongbing},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/10c272d06794d3e5785d5e7c5356e9ff-Paper.pdf}},
  pages =        {2136--2147},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TransMIL: Transformer based Correlated Multiple
                  Instance Learning for Whole Slide Image
                  Classification},
  volume =       34,
  year =         2021
}

@inproceedings{shao2022dynamic,
  address =      {Virtual Event},
  author =       {Shao, Wenqi and Ge, Yixiao and Zhang, Zhaoyang and
                  Xu, Xuyuan and Wang, Xiaogang and Shan, Ying and
                  Luo, Ping},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=f9MHpAGUyMn}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Token Normalization improves Vision
                  Transformers},
  year =         2022
}

@inproceedings{shao2023complementary,
  address =      {Honolulu, Hawaii, USA},
  author =       {Shao, Jianzhun and Zhang, Hongchang and Qu, Yun and
                  Liu, Chang and He, Shuncheng and Jiang, Yuhang and
                  Ji, Xiangyang},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/shao23b.html}}},
  pages =        {30776--30793},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Complementary Attention for Multi-Agent
                  Reinforcement Learning},
  volume =       202,
  year =         2023
}

@inproceedings{shen2018bidirectional,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Shen, Tao and Zhou, Tianyi and Long, Guodong and
                  Jiang, Jing and Zhang, Chengqi},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=H1cWzoxA-}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Bi-Directional Block Self-Attention for Fast and
                  Memory-Efficient Sequence Modeling},
  year =         2018
}

@inproceedings{shen2020powernorm,
  address =      {Virtual Event},
  author =       {Shen, Sheng and Yao, Zhewei and Gholami, Amir and
                  Mahoney, Michael W. and Keutzer, Kurt},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v119/shen20e.html}}},
  pages =        {8741--8751},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {PowerNorm: Rethinking Batch Normalization in
                  Transformers},
  volume =       119,
  year =         2020
}

@inproceedings{shen2020ranet,
  address =      {Virtual Event},
  author =       {Shen, Dingguo and Ji, Yuanfeng and Li, Ping and
                  Wang, Yi and Lin, Di},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/9fe8593a8a330607d76796b35c64c600-Paper.pdf}},
  pages =        {13927--13938},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {RANet: Region Attention Network for Semantic
                  Segmentation},
  volume =       33,
  year =         2020
}

@inproceedings{shen2022staged,
  address =      {Baltimore, Maryland, USA},
  author =       {Shen, Sheng and Walsh, Pete and Keutzer, Kurt and
                  Dodge, Jesse and Peters, Matthew E. and Beltagy, Iz},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/shen22f.html}},
  pages =        {19893--19908},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Staged Training for Transformer Language Models},
  volume =       162,
  year =         2022
}

@inproceedings{shen2024enhancing,
  address =      {Vienna, Austria},
  author =       {Shen, Guobin and Zhao, Dongcheng and Shen, Sicheng
                  and Zeng, Yi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=6X3TNqLb5t}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {Enhancing Spiking Transformers with Binary Attention
                  Mechanisms},
  year =         2024
}

@inproceedings{shen2024position,
  address =      {Vienna, Austria},
  author =       {Shen, Lingfeng and Mishra, Aayush and Khashabi,
                  Daniel},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=WsawczEqO6}},
  publisher =    {OpenReview.net},
  title =        {Position: Do pretrained Transformers Learn
                  In-Context by Gradient Descent?},
  year =         2024
}

@inproceedings{shettel2005top,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Shettel, Michael and Vecera, Shaun and Mozer,
                  Michael C},
  booktitle =    {Advances in Neural Information Processing Systems 18
                  (NIPS)},
  editor =       {Y. Weiss and B. Schölkopf and J. Platt},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2005/file/4f1f29888cabf5d45f866fe457737a23-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Top-Down Control of Visual Attention: A Rational
                  Account},
  volume =       18,
  year =         2005
}

@inproceedings{shi2020robustness,
  address =      {Addis Ababa, Ethiopia},
  author =       {Shi, Zhouxing and Zhang, Huan and Chang, Kai-Wei and
                  Huang, Minlie and Hsieh, Cho-Jui},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=BJxwPJHFwS}},
  series =       {Conference Track Proceedings},
  title =        {Robustness Verification for Transformers},
  year =         2020
}

@inproceedings{shi2021sparsebert,
  address =      {Virtual Event},
  author =       {Shi, Han and Gao, Jiahui and Ren, Xiaozhe and Xu,
                  Hang and Liang, Xiaodan and Li, Zhenguo and Kwok,
                  James Tin-Yau},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/shi21a.html}}},
  pages =        {9547--9557},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {SparseBERT: Rethinking the Importance Analysis in
                  Self-attention},
  volume =       139,
  year =         2021
}

@inproceedings{shi2022decision,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shi, Yucheng and Han, Yahong and Tan, Yu-an and
                  Kuang, Xiaohui},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/544696ef4847c903376ed6ec58f3a703-Paper-Conference.pdf}},
  pages =        {12921--12933},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Decision-based Black-box Attack Against Vision
                  Transformers via Patch-wise Adversarial Removal},
  volume =       35,
  year =         2022
}

@inproceedings{shi2022motion,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shi, Shaoshuai and Jiang, Li and Dai, Dengxin and
                  Schiele, Bernt},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/2ab47c960bfee4f86dfc362f26ad066a-Paper-Conference.pdf}},
  pages =        {6531--6543},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Motion Transformer with Global Intention
                  Localization and Local Movement Refinement},
  volume =       35,
  year =         2022
}

@inproceedings{shi2022rethinking,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shi, Shuwei and Gu, Jinjin and Xie, Liangbin and
                  Wang, Xintao and Yang, Yujiu and Dong, Chao},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/ea4d65c59073e8faf79222654d25fbe2-Paper-Conference.pdf}},
  pages =        {36081--36093},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Rethinking Alignment in Video Super-Resolution
                  Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{shi2022visual,
  address =      {Baltimore, Maryland, USA},
  author =       {Shi, Baifeng and Song, Yale and Joshi, Neel and
                  Darrell, Trevor and Wang, Xin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/shi22e.html}},
  pages =        {20041--20056},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Visual Attention Emerges from Recurrent Sparse
                  Reconstruction},
  volume =       162,
  year =         2022
}

@inproceedings{shi2023cross,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shi, Lucy Xiaoyang and Jiang, Yunfan and Grigsby,
                  Jake and Fan, Linxi and Zhu, Yuke},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/001608167bb652337af5df0129aeaabd-Paper-Conference.pdf}},
  pages =        {13--34},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cross-Episodic Curriculum for Transformer Agents},
  volume =       36,
  year =         2023
}

@inproceedings{shi2023upop,
  address =      {Honolulu, Hawaii, USA},
  author =       {Shi, Dachuan and Tao, Chaofan and Jin, Ying and
                  Yang, Zhendong and Yuan, Chun and Wang, Jiaqi},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/shi23e.html}},
  pages =        {31292--31311},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {UPop: Unified and Progressive Pruning for
                  Compressing Vision-Language Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{shi2024crossget,
  address =      {Vienna, Austria},
  author =       {Shi, Dachuan and Tao, Chaofan and Rao, Anyi and
                  Yang, Zhendong and Yuan, Chun and Wang, Jiaqi},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=CSIfCpXhCF}},
  publisher =    {OpenReview.net},
  title =        {CrossGET: Cross-Guided Ensemble of Tokens for
                  Accelerating Vision-Language Transformers},
  year =         2024
}

@inproceedings{shim2022understanding,
  address =      {Virtual Event},
  author =       {Shim, Kyuhong and Choi, Jungwook and Sung, Wonyong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=AvcfxqRy4Y}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Understanding the Role of Self Attention for
                  Efficient Speech Recognition},
  year =         2022
}

@inproceedings{shiraishi2024statistical,
  address =      {Vienna, Austria},
  author =       {Shiraishi, Tomohiro and Miwa, Daiki and Katsuoka,
                  Teruyuki and Duy, Vo Nguyen Le and Taji, Kouichi and
                  Takeuchi, Ichiro},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=uLonuOfrwp}},
  publisher =    {OpenReview.net},
  title =        {Statistical Test for Attention Maps in Vision
                  Transformers},
  year =         2024
}

@inproceedings{shirakawa2024longitudinal,
  address =      {Vienna, Austria},
  author =       {Shirakawa, Toru and Li, Yi and Wu, Yulun and Qiu,
                  Sky and Li, Yuxuan and Zhao, Mingduo and Iso,
                  Hiroyasu and Laan, Mark J. van der},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=CHz7WshPcp}},
  publisher =    {OpenReview.net},
  title =        {Longitudinal Targeted Minimum Loss-based Estimation
                  with Temporal-Difference Heterogeneous Transformer},
  year =         2024
}

@inproceedings{shitole2021one,
  address =      {Virtual Event},
  author =       {Shitole, Vivswan and Li, Fuxin and Kahng, Minsuk and
                  Tadepalli, Prasad and Fern, Alan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/5e751896e527c862bf67251a474b3819-Paper.pdf}},
  pages =        {11352--11363},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {One Explanation is Not Enough: Structured Attention
                  Graphs for Image Classification},
  volume =       34,
  year =         2021
}

@inproceedings{shiv2019novel,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Shiv, Vighnesh and Quirk, Chris},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/6e0917469214d8fbd8c517dcdc6b8dcf-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Novel positional encodings to enable tree-based
                  transformers},
  volume =       32,
  year =         2019
}

@inproceedings{shojaee2023transformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shojaee, Parshin and Meidani, Kazem and Barati
                  Farimani, Amir and Reddy, Chandan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8ffb4e3118280a66b192b6f06e0e2596-Paper-Conference.pdf}},
  pages =        {45907--45919},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformer-based Planning for Symbolic Regression},
  volume =       36,
  year =         2023
}

@inproceedings{shou2023pairwise,
  address =      {New Orleans, Louisiana, USA},
  author =       {Shou, Xiao and Bhattacharjya, Debarun and Gao, Tian
                  and Subramanian, Dharmashankar and Hassanzadeh,
                  Oktie and Bennett, Kristin P},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/91b047c5f5bd41ef56bfaf4ad0bd19e3-Paper-Conference.pdf}},
  pages =        {46520--46533},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Pairwise Causality Guided Transformers for Event
                  Sequences},
  volume =       36,
  year =         2023
}

@inproceedings{shou2023probabilistic,
  address =      {Honolulu, Hawaii, USA},
  author =       {Shou, Xiao and Bhattacharjya, Debarun and Gao, Tian
                  and Subramanian, Dharmashankar and Hassanzadeh,
                  Oktie and Bennett, Kristin P.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/shou23a.html}},
  pages =        {31657--31674},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Probabilistic Attention-to-Influence Neural Models
                  for Event Sequences},
  volume =       202,
  year =         2023
}

@inproceedings{shu2021adder,
  address =      {Virtual Event},
  author =       {Shu, Han and Wang, Jiahao and Chen, Hanting and Li,
                  Lin and Yang, Yujiu and Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/a57e8915461b83adefb011530b711704-Paper.pdf}},
  pages =        {19899--19909},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Adder Attention for Vision Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{shu2024dda,
  address =      {Vienna, Austria},
  author =       {Shu, Wenjie and Zhang, Zien},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=SACKV1UWc6}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {DDA: A Dual-Domain Attention Plug-and-Play Prior for
                  Pansharpening},
  year =         2024
}

@inproceedings{shukla2021multitime,
  address =      {Virtual Event, Austria},
  author =       {Shukla, Satya Narayan and Marlin, Benjamin M.},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=4c0J6lwQ4_}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Multi-Time Attention Networks for Irregularly
                  Sampled Time Series},
  year =         2021
}

@inproceedings{si2022inception,
  address =      {New Orleans, Louisiana, USA},
  author =       {Si, Chenyang and Yu, Weihao and Zhou, Pan and Zhou,
                  Yichen and Wang, Xinchao and Yan, Shuicheng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/94e85561a342de88b559b72c9b29f638-Paper-Conference.pdf}},
  pages =        {23495--23509},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Inception Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{singh2017attend,
  address =      {Long Beach, California, USA},
  author =       {Singh, Ritambhara and Lanchantin, Jack and Sekhon,
                  Arshdeep and Qi, Yanjun},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {Guyon, Isabelle and Von Luxburg, Ulrike and Bengio,
                  Samy and Wallach, Helga and Fergus, Rob and
                  Vishwanathan, Sumit and Garnett, Roman},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/d594b1a945b5d645e59e21f88bd2d83b-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attend and Predict: Understanding Gene Regulation by
                  Selective Attention on Chromatin},
  volume =       30,
  year =         2017
}

@inproceedings{singh2023transient,
  address =      {New Orleans, Louisiana, USA},
  author =       {Singh, Aaditya and Chan, Stephanie and Moskovitz,
                  Ted and Grant, Erin and Saxe, Andrew and Hill,
                  Felix},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/58692a1701314e09cbd7a5f5f3871cc9-Paper-Conference.pdf}},
  pages =        {27801--27819},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Transient Nature of Emergent In-Context Learning
                  in Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{singhryan2023attention,
  address =      {New Orleans, Louisiana, USA},
  author =       {Singh, Ryan and Buckley, Christopher L},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4e8a74988bc611495c2d3a5edac8493f-Paper-Conference.pdf}},
  pages =        {24929--24946},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention as Implicit Structural Inference},
  volume =       36,
  year =         2023
}

@inproceedings{so2019evolved,
  address =      {Long Beach, California, USA},
  author =       {So, David R. and Le, Quoc V. and Liang, Chen},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =         {\url{http://proceedings.mlr.press/v97/so19a.html}},
  pages =        {5877--5886},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {The Evolved Transformer},
  volume =       97,
  year =         2019
}

@inproceedings{so2021searching,
  address =      {Virtual Event},
  author =       {So, David and Manke, Wojciech and Liu, Hanxiao and
                  Dai, Zihang and Shazeer, Noam and Le, Quoc V},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2f3c6a4cd8af177f6456e7e51a916ff3-Paper.pdf}},
  pages =        {6010--6022},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Searching for Efficient Transformers for Language
                  Modeling},
  volume =       34,
  year =         2021
}

@inproceedings{sokar2022where,
  address =      {New Orleans, Louisiana, USA},
  author =       {Sokar, Ghada and Atashgahi, Zahra and Pechenizkiy,
                  Mykola and Mocanu, Decebal Constantin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/0aa800df4298539770b57824afc77a89-Paper-Conference.pdf}},
  pages =        {1627--1642},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Where to Pay Attention in Sparse Training for
                  Feature Selection?},
  volume =       35,
  year =         2022
}

@inproceedings{song2021dynamic,
  address =      {Virtual Event},
  author =       {Song, Lin and Zhang, Songyang and Liu, Songtao and
                  Li, Zeming and He, Xuming and Sun, Hongbin and Sun,
                  Jian and Zheng, Nanning},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2d969e2cee8cfa07ce7ca0bb13c7a36d-Paper.pdf}},
  pages =        {5770--5783},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Grained Encoder for Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{song2022transcormer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Song, Kaitao and Leng, Yichong and Tan, Xu and Zou,
                  Yicheng and Qin, Tao and Li, Dongsheng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/486ff0b164cf92b0255fe39863bcf99e-Paper-Conference.pdf}},
  pages =        {11160--11174},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transcormer: Transformer for Sentence Scoring with
                  Sliding Language Modeling},
  volume =       35,
  year =         2022
}

@inproceedings{song2022vidt,
  address =      {Virtual Event},
  author =       {Song, Hwanjun and Sun, Deqing and Chun, Sanghyuk and
                  Jampani, Varun and Han, Dongyoon and Heo, Byeongho
                  and Kim, Wonjae and Yang, Ming-Hsuan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=w4cXZDDib1H}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ViDT: An Efficient and Effective Fully
                  Transformer-based Object Detector},
  year =         2022
}

@inproceedings{song2023memto,
  address =      {New Orleans, Louisiana, USA},
  author =       {Song, Junho and Kim, Keonwoo and Oh, Jeonglyul and
                  Cho, Sungzoon},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b4c898eb1fb556b8d871fbe9ead92256-Paper-Conference.pdf}},
  pages =        {57947--57963},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MEMTO: Memory-guided Transformer for Multivariate
                  Time Series Anomaly Detection},
  volume =       36,
  year =         2023
}

@inproceedings{song2024sleb,
  address =      {Vienna, Austria},
  author =       {Song, Jiwon and Oh, Kyungseok and Kim, Taesu and
                  Kim, Hyungjun and Kim, Yulhwa and Kim, J.-J.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=fuX4hyLPmO}},
  publisher =    {OpenReview.net},
  title =        {SLEB: Streamlining LLMs through Redundancy
                  Verification and Elimination of Transformer Blocks},
  year =         2024
}

@inproceedings{sood2020improving,
  address =      {Virtual Event},
  author =       {Sood, Ekta and Tannert, Simon and Mueller, Philipp
                  and Bulling, Andreas},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/460191c72f67e90150a093b4585e7eb4-Paper.pdf}},
  pages =        {6327--6341},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Improving Natural Language Processing Tasks with
                  Human Gaze-Guided Neural Attention},
  volume =       33,
  year =         2020
}

@inproceedings{stern2019insertion,
  address =      {Long Beach, California, USA},
  author =       {Stern, Mitchell and Chan, William and Kiros, Jamie
                  and Uszkoreit, Jakob},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v97/stern19a.html}},
  pages =        {5976--5985},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Insertion Transformer: Flexible Sequence Generation
                  via Insertion Operations},
  volume =       97,
  year =         2019
}

@inproceedings{stollenga2014deep,
  address =      {Montreal, Quebec, Canada},
  author =       {Stollenga, Marijn F and Masci, Jonathan and Gomez,
                  Faustino and Schmidhuber, Jürgen},
  booktitle =    {Advances in Neural Information Processing Systems 27
                  (NIPS)},
  editor =       {Ghahramani, Z. and Welling, M. and Cortes, C. and
                  Lawrence, N. and Weinberger, K.Q.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2014/file/19de10adbaa1b2ee13f77f679fa1483a-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Deep Networks with Internal Selective Attention
                  through Feedback Connections},
  volume =       27,
  year =         2014
}

@inproceedings{strimel2023lookahead,
  address =      {Honolulu, Hawaii, USA},
  author =       {Strimel, Grant P. and Xie, Yi and King, Brian John
                  and Radfar, Martin and Rastrow, Ariya and
                  Mouchtaris, Athanasios},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/strimel23a.html}}},
  pages =        {32654--32676},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Lookahead When It Matters: Adaptive Non-causal
                  Transformers for Streaming Neural Transducers},
  year =         2023
}

@inproceedings{sun2022agnas,
  address =      {Baltimore, Maryland, USA},
  author =       {Sun, Zihao and Hu, Yu and Lu, Shun and Yang,
                  Longxing and Mei, Jilin and Han, Yinhe and Li,
                  Xiaowei},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/sun22a.html}},
  pages =        {20777--20789},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {AGNAS: Attention-Guided Micro and Macro-Architecture
                  Search},
  volume =       162,
  year =         2022
}

@inproceedings{sun2022interaction,
  address =      {New Orleans, Louisiana, USA},
  author =       {Sun, Fan-Yun and Kauvar, Isaac and Zhang, Ruohan and
                  Li, Jiachen and Kochenderfer, Mykel J. and Wu,
                  Jiajun and Haber, Nick},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/7e6361a5d73a8fab093dd8453e0b106f-Paper-Conference.pdf}},
  pages =        {20038--20050},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Interaction Modeling with Multiplex Attention},
  volume =       35,
  year =         2022
}

@inproceedings{sun2022sparse,
  address =      {Virtual Event},
  author =       {Sun, Zhiqing and Yang, Yiming and Yoo, Shinjae},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=VGnOJhd5Q1q}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Sparse Attention with Learning to Hash},
  year =         2022
}

@inproceedings{sun2023modeling,
  address =      {New Orleans, Louisiana, USA},
  author =       {Sun, Zitang and Chen, Yen-Ju and Yang, Yung-Hao and
                  Nishida, Shin’ya},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4c9477b9e2c7ec0ad3f4f15077aaf85a-Paper-Conference.pdf}},
  pages =        {24335--24348},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Modeling Human Visual Motion Processing with
                  Trainable Motion Energy Sensing and a Self-attention
                  Network},
  volume =       36,
  year =         2023
}

@inproceedings{sun2023smart,
  address =      {Kigali, Rwanda},
  author =       {Sun, Yanchao and Ma, Shuang and Madaan, Ratnesh and
                  Bonatti, Rogerio and Huang, Furong and Kapoor,
                  Ashish},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=9piH3Hg8QEf}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SMART: Self-supervised Multi-task pretrAining with
                  contRol Transformers},
  year =         2023
}

@inproceedings{t2023is,
  address =      {Kigali, Rwanda},
  author =       {T., Mukund Varma and Wang, Peihao and Chen, Xuxi and
                  Chen, Tianlong and Venugopalan, Subhashini and Wang,
                  Zhangyang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=xE-LtsE-xx}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Is Attention All That NeRF Needs?},
  year =         2023
}

@inproceedings{tai2019equivariant,
  address =      {Long Beach, California, USA},
  author =       {Tai, Kai Sheng and Bailis, Peter and Valiant,
                  Gregory},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =         {\url{http://proceedings.mlr.press/v97/tai19a.html}},
  pages =        {6086--6095},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Equivariant Transformer Networks},
  volume =       97,
  year =         2019
}

@inproceedings{takagi2022on,
  address =      {New Orleans, Louisiana, USA},
  author =       {Takagi, Shiro},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c5eddf0069fe150ac2c768e2969e38d1-Paper-Conference.pdf}},
  pages =        {30678--30692},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {On the Effect of Pre-training for Transformer in
                  Different Modality on Offline Reinforcement
                  Learning},
  volume =       35,
  year =         2022
}

@inproceedings{takakura2023approximation,
  address =      {Honolulu, Hawaii, USA},
  author =       {Takakura, Shokichi and Suzuki, Taiji},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/takakura23a.html}}},
  pages =        {33416--33447},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Approximation and Estimation Ability of Transformers
                  for Sequence-to-Sequence Functions with Infinite
                  Dimensional Input},
  year =         2023
}

@inproceedings{takamoto2023learning,
  address =      {Honolulu, Hawaii, USA},
  author =       {Takamoto, Makoto and Alesiani, Francesco and
                  Niepert, Mathias},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/takamoto23a.html}}},
  pages =        {33448--33467},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Learning Neural PDE Solvers with Parameter-Guided
                  Channel Attention},
  year =         2023
}

@inproceedings{tan2024boosting,
  address =      {Vienna, Austria},
  author =       {Tan, Zhentao and Li, Xiaodan and Wu, Yue and Chu, Qi
                  and Lu, Le and Yu, Nenghai and Ye, Jieping},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3rmpixOjPS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Boosting Vanilla Lightweight Vision Transformers via
                  Re-parameterization},
  year =         2024
}

@inproceedings{tan2024learning,
  address =      {Vienna, Austria},
  author =       {Tan, Zhentao and Mu, Yadong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=bBkQ51PmjC}},
  publisher =    {OpenReview.net},
  title =        {Learning Solution-Aware Transformers for Efficiently
                  Solving Quadratic Assignment Problem},
  year =         2024
}

@inproceedings{tang2014learning,
  address =      {Montreal, Quebec, Canada},
  author =       {Tang, Charlie and Srivastava, Nitish and
                  Salakhutdinov, Russ R},
  booktitle =    {Advances in Neural Information Processing Systems 27
                  (NIPS)},
  editor =       {Ghahramani, Z. and Welling, M. and Cortes, C. and
                  Lawrence, N. and Weinberger, K.Q.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2014/file/c22abfa379f38b5b0411bc11fa9bf92f-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Generative Models with Visual Attention},
  volume =       27,
  year =         2014
}

@inproceedings{tang2021augmented,
  address =      {Virtual Event},
  author =       {Tang, Yehui and Han, Kai and Xu, Chang and Xiao, An
                  and Deng, Yiping and Xu, Chao and Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/818f4654ed39a1c147d1e51a00ffb4cb-Paper.pdf}},
  pages =        {15316--15327},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Augmented Shortcuts for Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{tang2021probabilistic,
  address =      {Virtual Event},
  author =       {Tang, Binh and Matteson, David S.},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/c68bd9055776bf38d8fc43c0ed283678-Paper.pdf}},
  pages =        {23592--23608},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Probabilistic Transformer For Time Series Analysis},
  volume =       34,
  year =         2021
}

@inproceedings{tang2021sensory,
  address =      {Virtual Event},
  author =       {Tang, Yujin and Ha, David},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/be3e9d3f7d70537357c67bb3f4086846-Paper.pdf}},
  pages =        {22574--22587},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The Sensory Neuron as a Transformer:
                  Permutation-Invariant Neural Networks for
                  Reinforcement Learning},
  volume =       34,
  year =         2021
}

@inproceedings{tang2022ghostnetv2,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tang, Yehui and Han, Kai and Guo, Jianyuan and Xu,
                  Chang and Xu, Chao and Wang, Yunhe},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/40b60852a4abdaa696b5a1a78da34635-Paper-Conference.pdf}},
  pages =        {9969--9982},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {GhostNetV2: Enhance Cheap Operation with Long-Range
                  Attention},
  volume =       35,
  year =         2022
}

@inproceedings{tang2022quadtree,
  address =      {Virtual Event},
  author =       {Tang, Shitao and Zhang, Jiahui and Zhu, Siyu and
                  Tan, Ping},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=fR-EnKWL_Zb}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Quadtree Attention for Vision Transformers},
  year =         2022
}

@inproceedings{tang2022tvlt,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tang, Zineng and Cho, Jaemin and Nie, Yixin and
                  Bansal, Mohit},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3ea3134345f2e6228a29f35b86bce24d-Paper-Conference.pdf}},
  pages =        {9617--9632},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TVLT: Textless Vision-Language Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{tang2023brain,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tang, Jerry and Du, Meng and Vo, Vy and Lal, Vasu
                  Dev and Huth, Alexander},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/5ebbbac62b968254093023f1c95015d3-Paper-Conference.pdf}},
  pages =        {29654--29666},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Brain encoding models based on multimodal
                  transformers can transfer across language and
                  vision},
  volume =       36,
  year =         2023
}

@inproceedings{tang2023disambiguated,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tang, Wei and Zhang, Weijia and Zhang, Min-Ling},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b1917a4bcfab403c3cdd6c6bbaf9fda0-Paper-Conference.pdf}},
  pages =        {56756--56771},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Disambiguated Attention Embedding for Multi-Instance
                  Partial-Label Learning},
  volume =       36,
  year =         2023
}

@inproceedings{taniai2024crystalformer,
  address =      {Vienna, Austria},
  author =       {Taniai, Tatsunori and Igarashi, Ryo and Suzuki, Yuta
                  and Chiba, Naoya and Saito, Kotaro and Ushiku,
                  Yoshitaka and Ono, Kanta},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=fxQiecl9HB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Crystalformer: Infinitely Connected Attention for
                  Periodic Structure Encoding},
  year =         2024
}

@inproceedings{tay2018densely,
  address =      {Montreal, Quebec, Canada},
  author =       {Tay, Yi and Luu, Anh Tuan and Hui, Siu Cheung and
                  Su, Jian},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/7b66b4fd401a271a1c7224027ce111bc-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Densely Connected Attention Propagation for Reading
                  Comprehension},
  volume =       31,
  year =         2018
}

@inproceedings{tay2019compositional,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Tay, Yi and Luu, Anh Tuan and Zhang, Aston and Wang,
                  Shuohang and Hui, Siu Cheung},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/16fc18d787294ad5171100e33d05d4e2-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Compositional De-Attention Networks},
  volume =       32,
  year =         2019
}

@inproceedings{tay2020sparse,
  address =      {Virtual Event},
  author =       {Tay, Yi and Bahri, Dara and Yang, Liu and Metzler,
                  Donald and Juan, Da-Cheng},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v119/tay20a.html}},
  pages =        {9438--9447},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Sparse Sinkhorn Attention},
  volume =       119,
  year =         2020
}

@inproceedings{tay2021hypergrid,
  address =      {Virtual Event, Austria},
  author =       {Tay, Yi and Zhao, Zhe and Bahri, Dara and Metzler,
                  Donald and Juan, Da-Cheng},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=hiq1rHO8pNT}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {HyperGrid Transformers: Towards A Single Model for
                  Multiple Tasks},
  year =         2021
}

@inproceedings{tay2021long,
  address =      {Virtual Event, Austria},
  author =       {Tay, Yi and Dehghani, Mostafa and Abnar, Samira and
                  Shen, Yikang and Bahri, Dara and Pham, Philip and
                  Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and
                  Metzler, Donald},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=qVyeW-grC2k}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Long Range Arena: A Benchmark for Efficient
                  Transformers},
  year =         2021
}

@inproceedings{tay2021omninet,
  address =      {Virtual Event},
  author =       {Tay, Yi and Dehghani, Mostafa and Arib, Vamsi and
                  Gupta, Jai Prakash and Pham, Philip and Qin, Zhen
                  and Bahri, Dara and Juan, Da-Cheng and Metzler,
                  Donald},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/tay21b.html}},
  pages =        {10193--10202},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {OmniNet: Omnidirectional Representations from
                  Transformers},
  volume =       139,
  year =         2021
}

@inproceedings{tay2021synthesizer,
  address =      {Virtual Event},
  author =       {Tay, Yi and Bahri, Dara and Metzler, Donald and
                  Juan, Da-Cheng and Zhao, Zhe and Zheng, Che},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/tay21a.html}},
  pages =        {10183--10192},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Synthesizer: Rethinking Self-Attention for
                  Transformer Models},
  volume =       139,
  year =         2021
}

@inproceedings{tay2022charformer,
  address =      {Virtual Event},
  author =       {Tay, Yi and Tran, Vinh Q. and Ruder, Sebastian and
                  Gupta, Jai Prakash and Chung, Hyung Won and Bahri,
                  Dara and Qin, Zhen and Baumgartner, Simon and Yu,
                  Cong and Metzler, Donald},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=JtBRnrlOEFN}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Charformer: Fast Character Transformers via
                  Gradient-based Subword Tokenization},
  year =         2022
}

@inproceedings{tay2022scale,
  address =      {Virtual Event},
  author =       {Tay, Yi and Dehghani, Mostafa and Rao, Jinfeng and
                  Fedus, William and Abnar, Samira and Chung, Hyung
                  Won and Narang, Sharan and Yogatama, Dani and
                  Vaswani, Ashish and Metzler, Donald},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=f2OYVDyfIB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Scale Efficiently: Insights from Pretraining and
                  Finetuning Transformers},
  year =         2022
}

@inproceedings{tay2022transformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tay, Yi and Tran, Vinh and Dehghani, Mostafa and Ni,
                  Jianmo and Bahri, Dara and Mehta, Harsh and Qin,
                  Zhen and Hui, Kai and Zhao, Zhe and Gupta, Jai and
                  Schuster, Tal and Cohen, William W and Metzler,
                  Donald},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/892840a6123b5ec99ebaab8be1530fba-Paper-Conference.pdf}},
  pages =        {21831--21843},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformer Memory as a Differentiable Search Index},
  volume =       35,
  year =         2022
}

@inproceedings{tesfaldet2022attention,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tesfaldet, Mattie and Nowrouzezahrai, Derek and Pal,
                  Chris},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/361e5112d2eca09513bbd266e4b2d2be-Paper-Conference.pdf}},
  pages =        {8174--8186},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention-based Neural Cellular Automata},
  volume =       35,
  year =         2022
}

@inproceedings{thoelke2022equivariant,
  address =      {Virtual Event},
  author =       {Thölke, Philipp and Fabritiis, Gianni De},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=zNHzqZ9wrRB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Equivariant Transformers for Neural Network based
                  Molecular Potentials},
  year =         2022
}

@inproceedings{tian2023scan,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tian, Yuandong and Wang, Yiping and Chen, Beidi and
                  Du, Simon S.},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/e359ebe56ba306b674e8952349c6049e-Paper-Conference.pdf}},
  pages =        {71911--71947},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Scan and Snap: Understanding Training Dynamics and
                  Token Composition in 1-layer Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{tiezzi2020focus,
  address =      {Virtual Event},
  author =       {Tiezzi, Matteo and Melacci, Stefano and Betti,
                  Alessandro and Maggini, Marco and Gori, Marco},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/fc2dc7d20994a777cfd5e6de734fe254-Paper.pdf}},
  pages =        {22194--22204},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Focus of Attention Improves Information Transfer in
                  Visual Features},
  volume =       33,
  year =         2020
}

@inproceedings{touvron2021training,
  address =      {Virtual Event},
  author =       {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs
                  and Massa, Francisco and Alex, and Sablayrolles, Re
                  and Jégou, Hervé},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/touvron21a.html}},
  pages =        {10347--10357},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Training Data-Efficient Image Transformers &
                  Distillation through Attention},
  volume =       139,
  year =         2021
}

@inproceedings{tran2023training,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tran, Manuel and Dicente Cid, Yashin and Lahiani,
                  Amal and Theis, Fabian and Peng, Tingying and
                  Klaiman, Eldad},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/860a092bb4d9d81d3133a01c50c01578-Paper-Conference.pdf}},
  pages =        {42918--42931},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Training Transitive and Commutative Multimodal
                  Transformers with LoReTTa},
  volume =       36,
  year =         2023
}

@inproceedings{trappolini2021shape,
  address =      {Virtual Event},
  author =       {Trappolini, Giovanni and Cosmo, Luca and Moschella,
                  Luca and Marin, Riccardo and Melzi, Simone and
                  Rodolà, Emanuele},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2d3d9d5373f378108cdbd30a3c52bd3e-Paper.pdf}},
  pages =        {5731--5744},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Shape Registration in the Time of Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{trockman2023mimetic,
  address =      {Honolulu, Hawaii, USA},
  author =       {Trockman, A. and Kolter, J. Z.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/trockman23a.html}},
  pages =        {34456--34468},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Mimetic Initialization of Self-Attention Layers},
  year =         2023
}

@inproceedings{tsai2020capsules,
  address =      {Addis Ababa, Ethiopia},
  author =       {Tsai, Yao-Hung Hubert and Srivastava, Nitish and
                  Goh, Hanlin and Salakhutdinov, Ruslan},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=HJe6uANtwH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Capsules with Inverted Dot-Product Attention
                  Routing},
  year =         2020
}

@inproceedings{tseng2023coneheads,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tseng, Albert and Yu, Tao and Liu, Toni and De Sa,
                  Christopher M.},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a17251f8d595179eef5e466b1f5f7a85-Paper-Conference.pdf}},
  pages =        {51421--51433},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Coneheads: Hierarchy Aware Attention},
  volume =       36,
  year =         2023
}

@inproceedings{tworkowski2023focused,
  address =      {New Orleans, Louisiana, USA},
  author =       {Tworkowski, Szymon and Staniszewski, Konrad and
                  Pacek, Mikołaj and Wu, Yuhuai and Michalewski,
                  Henryk and Miłos, Piotr},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/8511d06d5590f4bda24d42087802cc81-Paper-Conference.pdf}},
  pages =        {42661--42688},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Focused Transformer: Contrastive Training for
                  Context Scaling},
  volume =       36,
  year =         2023
}

@inproceedings{vaishnav2023gamr,
  address =      {Kigali, Rwanda},
  author =       {Vaishnav, Mohit and Serre, Thomas},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=iLMgk2IGNyv}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {GAMR: A Guided Attention Model for (Visual)
                  Reasoning},
  year =         2023
}

@inproceedings{valeriani2023geometry,
  address =      {New Orleans, Louisiana, USA},
  author =       {Valeriani, Lucrezia and Doimo, Diego and Cuturello,
                  Francesca and Laio, Alessandro and Ansuini, Alessio
                  and Cazzaniga, Alberto},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a0e66093d7168b40246af1cddc025daa-Paper-Conference.pdf}},
  pages =        {51234--51252},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {The geometry of hidden representations of large
                  transformer models},
  volume =       36,
  year =         2023
}

@inproceedings{vaswani2017attention,
  address =      {Long Beach, California, USA},
  author =       {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki
                  and Uszkoreit, Jakob and Jones, Llion and Gomez,
                  Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {Guyon, Isabelle and Von Luxburg, Ulrike and Bengio,
                  Samy and Wallach, Hannah and Fergus, Rob and
                  Vishwanathan, Shivaram and Garnett, Roio},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention is All You Need},
  volume =       30,
  year =         2017
}

@inproceedings{velickovic2018graph,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Velickovic, Petar and Cucurull, Guillem and
                  Casanova, Arantxa and Romero, Adriana and Li, o and
                  Bengio, Yoshua},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rJXMpikCZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Graph Attention Networks},
  year =         2018
}

@inproceedings{venkataramanan2024skipattention,
  address =      {Vienna, Austria},
  author =       {Venkataramanan, Shashanka and Ghodrati, Amir and
                  Asano, Yuki M. and Porikli, Fatih and Habibian,
                  Amirhossein},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vI95kcLAoU}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Skip-Attention: Improving Vision Transformers by
                  Paying Less Attention},
  year =         2024
}

@inproceedings{vig2021bertology,
  address =      {Virtual Event, Austria},
  author =       {Vig, Jesse and Madani, Ali and Varshney, Lav R. and
                  Xiong, Caiming and Socher, Richard and Rajani,
                  Nazneen Fatema},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=YWtLZvLmud7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {BERTology Meets Biology: Interpreting Attention in
                  Protein Language Models},
  year =         2021
}

@inproceedings{vilas2023analyzing,
  address =      {New Orleans, Louisiana, USA},
  author =       {Vilas, Martina G. and Schaumlöffel, Timothy and
                  Roig, Gemma},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/7dd309df03d37643b96f5048b44da798-Paper-Conference.pdf}},
  pages =        {40030--40041},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Analyzing Vision Transformers for Image
                  Classification in Class Embedding Space},
  volume =       36,
  year =         2023
}

@inproceedings{vishniakov2024convnet,
  address =      {Vienna, Austria},
  author =       {Vishniakov, Kirill and Shen, Zhiqiang and Liu,
                  Zhuang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=9BGi9PEhNn}},
  publisher =    {OpenReview.net},
  title =        {ConvNet vs Transformer, Supervised vs CLIP: Beyond
                  ImageNet Accuracy},
  year =         2024
}

@inproceedings{vyas2020fast,
  address =      {Virtual Event},
  author =       {Vyas, Apoorv and Katharopoulos, Angelos and Fleuret,
                  François},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/f6a8dd1c954c8506aadc764cc32b895e-Paper.pdf}},
  pages =        {21665--21674},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Fast Transformers with Clustered Attention},
  volume =       33,
  year =         2020
}

@inproceedings{wan2022retroformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Wan, Yue and Hsieh, Chang-Yu and Liao, Ben and
                  Zhang, Shengyu},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/wan22a.html}},
  pages =        {22475--22490},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Retroformer: Pushing the Limits of End-to-end
                  Retrosynthesis Transformer},
  volume =       162,
  year =         2022
}

@inproceedings{wan2023seaformer,
  address =      {Kigali, Rwanda},
  author =       {Wan, Qiang and Huang, Zilong and Lu, Jiachen and Yu,
                  Gang and Zhang, Li},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=-qg8MQNrxZw}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {SeaFormer: Squeeze-enhanced Axial Transformer for
                  Mobile Semantic Segmentation},
  year =         2023
}

@inproceedings{wan2024towards,
  address =      {Vienna, Austria},
  author =       {Wan, Xingyu and Zhang, Chengquan and Lyu, Pengyuan
                  and Fan, Sen and Ni, Zihan and Yao, Kun and Ding,
                  Errui and Wang, Jingdong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=HaBVzgSdM7}},
  publisher =    {OpenReview.net},
  title =        {Towards Unified Multi-granularity Text Detection
                  with Interactive Attention},
  year =         2024
}

@inproceedings{wang2020minilm,
  address =      {Virtual Event},
  author =       {Wang, Wenhui and Wei, Furu and Dong, Li and Bao,
                  Hangbo and Yang, Nan and Zhou, Ming},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}},
  pages =        {5776--5788},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MiniLM: Deep Self-Attention Distillation for
                  Task-Agnostic Compression of Pre-Trained
                  Transformers},
  volume =       33,
  year =         2020
}

@inproceedings{wang2020pay,
  address =      {Addis Ababa, Ethiopia},
  author =       {Wang, Kafeng and Gao, Xitong and Zhao, Yiren and Li,
                  Xingjian and Dou, Dejing and Xu, Cheng-Zhong},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=ryxyCeHtPB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Pay Attention to Features, Transfer Learn Faster
                  CNNs},
  year =         2020
}

@inproceedings{wang2021evolving,
  address =      {Virtual Event},
  author =       {Wang, Yujing and Yang, Yaming and Bai, Jiangang and
                  Zhang, Mingliang and Bai, Jing and Yu, Jing and
                  Zhang, Ce and Huang, Gao and Tong, Yunhai},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/wang21ab.html}},
  pages =        {10971--10980},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Evolving Attention with Residual Convolutions},
  volume =       139,
  year =         2021
}

@inproceedings{wang2021multib,
  address =      {Virtual Event},
  author =       {Wang, Jiashun and Xu, Huazhe and Narasimhan, Medhini
                  and Wang, Xiaolong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/2fd5d41ec6cfab47e32164d5624269b1-Paper.pdf}},
  pages =        {6036--6049},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Multi-Person 3D Motion Prediction with Multi-Range
                  Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{wang2021neuralc,
  address =      {Virtual Event},
  author =       {Wang, Yufei and Xu, Can and Hu, Huang and Tao,
                  Chongyang and Wan, Stephen and Dras, Mark and
                  Johnson, Mark and Jiang, Daxin},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Vaughan, J. W.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/8ce241e1ed84937ee48322b170b9b18c-Paper.pdf}},
  pages =        {16938--16950},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Neural Rule-Execution Tracking Machine For
                  Transformer-Based Text Generation},
  volume =       34,
  year =         2021
}

@inproceedings{wang2021not,
  address =      {Virtual Event},
  author =       {Wang, Yulin and Huang, Rui and Song, Shiji and
                  Huang, Zeyi and Huang, Gao},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/64517d8435994992e682b3e4aa0a0661-Paper.pdf}},
  pages =        {11960--11973},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Not All Images are Worth 16x16 Words: Dynamic
                  Transformers for Efficient Image Recognition},
  volume =       34,
  year =         2021
}

@inproceedings{wang2022antioversmoothing,
  address =      {Virtual Event},
  author =       {Wang, Peihao and Zheng, Wenqing and Chen, Tianlong
                  and Wang, Zhangyang},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=O476oWmiNNp}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Anti-Oversmoothing in Deep Vision Transformers via
                  the Fourier Domain Analysis: From Theory to
                  Practice},
  year =         2022
}

@inproceedings{wang2022bootstrapped,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Kerong and Zhao, Hanye and Luo, Xufang and
                  Ren, Kan and Zhang, Weinan and Li, Dongsheng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e0ccda3cb17b084a6f43c62cfac4784b-Paper-Conference.pdf}},
  pages =        {34748--34761},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Bootstrapped Transformer for Offline Reinforcement
                  Learning},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022crossformer,
  address =      {Virtual Event},
  author =       {Wang, Wenxiao and Yao, Lu and Chen, Long and Lin,
                  Binbin and Cai, Deng and He, Xiaofei and Liu, Wei},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=_PHymLIxuI}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {CrossFormer: A Versatile Vision Transformer Hinging
                  on Cross-scale Attention},
  year =         2022
}

@inproceedings{wang2022deepa,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Naigang and Liu, Chi-Chun and Venkataramani,
                  Swagath and Sen, Sanchari and Chen, Chia-Yu and El
                  Maghraoui, Kaoutar and Srinivasan, Vijayalakshmi and
                  Chang, Leland},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5b5618e7d061748267d74478b7c5b1ab-Paper-Conference.pdf}},
  pages =        {14140--14154},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Deep Compression of Pre-trained Transformer Models},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022dense,
  address =      {Baltimore, Maryland, USA},
  author =       {Wang, Yuxin and Lee, Chu-Tak and Guo, Qipeng and
                  Yin, Zhangyue and Zhou, Yunhua and Huang, Xuanjing
                  and Qiu, Xipeng},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/wang22l.html}},
  pages =        {22752--22768},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {What Dense Graph Do You Need for Self-Attention?},
  volume =       162,
  year =         2022
}

@inproceedings{wang2022rtformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Jian and Gou, Chenhui and Wu, Qiman and Feng,
                  Haocheng and Han, Junyu and Ding, Errui and Wang,
                  Jingdong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/30e10e671c5e43edb67eb257abb6c3ea-Paper-Conference.pdf}},
  pages =        {7423--7436},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {RTFormer: Efficient Design for Real-Time Semantic
                  Segmentation with Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022s,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Yabin and Huang, Zhiwu and Hong, Xiaopeng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/25886d7a7cf4e33fd44072a0cd81bf30-Paper-Conference.pdf}},
  pages =        {5682--5695},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {S-Prompts Learning with Pre-trained Transformers: An
                  Occam's Razor for Domain Incremental Learning},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022transtab,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Zifeng and Sun, Jimeng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, Saeed and Mohamed, Samy and Agarwal, Ankit
                  and Belgrave, David and Cho, Kyunghyun and Oh,
                  Alina},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/1377f76686d56439a2bd7a91859972f5-Paper-Conference.pdf}},
  pages =        {2902--2915},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {TransTab: Learning Transferable Tabular Transformers
                  Across Tables},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022understanding,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Jiaxi and Wu, Ji and Huang, Lei},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/f4f2f2b3c67da711df6df557fc870c4a-Paper-Conference.pdf}},
  pages =        {37617--37630},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Understanding the Failure of Batch Normalization for
                  Transformers in NLP},
  volume =       35,
  year =         2022
}

@inproceedings{wang2022vtc,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Zhenyu and Luo, Hao and Wang, Pichao and Ding,
                  Feng and Wang, Fan and Li, Hao},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5a8177df23bdcc15a02a6739f5b9dd4a-Paper-Conference.pdf}},
  pages =        {13974--13988},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {VTC-LFC: Vision Transformer Compression with
                  Low-Frequency Components},
  volume =       35,
  year =         2022
}

@inproceedings{wang2023can,
  address =      {Kigali, Rwanda},
  author =       {Wang, Zeyu and Bai, Yutong and Zhou, Yuyin and Xie,
                  Cihang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=TKIFuQHHECj}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Can CNNs Be More Robust Than Transformers?},
  year =         2023
}

@inproceedings{wang2023closer,
  address =      {Honolulu, Hawaii, USA},
  author =       {Wang, Shaoru and Gao, Jin and Li, Zeming and Zhang,
                  Xiaoqin and Hu, Weiming},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/wang23e.html}}},
  pages =        {35624--35641},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {A Closer Look at Self-Supervised Lightweight Vision
                  Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{wang2023droppos,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Haochen and Fan, Junsong and Wang, Yuxi and
                  Song, Kaiyou and Wang, Tong and Zhang, Zhao-Xiang},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/9098e2901b4eb54772f83535f89cb8ac-Paper-Conference.pdf}},
  pages =        {46134--46151},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {DropPos: Pre-Training Vision Transformers by
                  Reconstructing Dropped Positions},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023dynamicb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Kai and Yang, Fei and Yang, Shiqi and Butt,
                  Muhammad Atif and van de Weijer, Joost},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/5321b1dabcd2be188d796c21b733e8c7-Paper-Conference.pdf}},
  pages =        {26291--26303},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Dynamic Prompt Learning: Addressing Cross-Attention
                  Leakage for Text-Based Image Editing},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023focusa,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Yuan and Luo, Naisong and Zhang, Tianzhu},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6447714b83edcbed61dbe10371dd7ae5-Paper-Conference.pdf}},
  pages =        {31524--31542},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Focus on Query: Adversarial Mining Transformer for
                  Few-Shot Segmentation},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023focusb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Haoqing and Jie, Shibo and Deng, Zhihong},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/bbb7506579431a85861a05fff048d3e1-Paper-Conference.pdf}},
  pages =        {59689--59707},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Focus Your Attention when Few-Shot Classification},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023geometric,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Yusong and Li, Shaoning and Wang, Tong and
                  Shao, Bin and Zheng, Nanning and Liu, Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/aee2f03ecb2b2c1ea55a43946b651cfd-Paper-Conference.pdf}},
  pages =        {55981--55994},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Geometric Transformer with Interatomic Positional
                  Encoding},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023h3t,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Yuzhong and Han, Xu and Zhao, Weilin and Zeng,
                  Guoyang and Liu, Zhiyuan and Sun, Maosong},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/7886b89aced4d37dd25a6f32854bf3f9-Paper-Conference.pdf}},
  pages =        {38311--38334},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {H3T: Efficient Integration of Memory Optimization
                  and Parallelism for Large-scale Transformer
                  Training},
  volume =       36,
  year =         2023
}

@inproceedings{wang2023learningb,
  address =      {Kigali, Rwanda},
  author =       {Wang, Peihao and P, Rameswar and a, and Hennigen,
                  Lucas Torroba and Greengard, Philip and Karlinsky,
                  Leonid and Feris, Rogério and Cox, David Daniel and
                  Wang, Zhangyang and Kim, Yoon},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=cDYRS5iZ16f}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning to Grow Pretrained Models for Efficient
                  Transformer Training},
  year =         2023
}

@inproceedings{wang2023magneto,
  address =      {Honolulu, Hawaii, USA},
  author =       {Wang, Hongyu and Ma, Shuming and Huang, Shaohan and
                  Dong, Li and Wang, Wenhui and Peng, Zhiliang and Wu,
                  Yu and Bajaj, Payal and Singhal, Saksham and
                  Benhaim, Alon and Patra, Barun and Liu, Zhun and
                  Chaudhary, Vishrav and Song, Xia and Wei, Furu},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/wang23u.html}},
  pages =        {36077--36092},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Magneto: A Foundation Transformer},
  volume =       202,
  year =         2023
}

@inproceedings{wang2023slotvae,
  address =      {Honolulu, Hawaii, USA},
  author =       {Wang, Yanbo and Liu, Letao and Dauwels, Justin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/wang23r.html}}},
  pages =        {36020--36035},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Slot-VAE: Object-Centric Scene Generation with Slot
                  Attention},
  volume =       202,
  year =         2023
}

@inproceedings{wang2023spatial,
  address =      {Kigali, Rwanda},
  author =       {Wang, Yuanqing and Chodera, John D.},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3DIpIf3wQMC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spatial Attention Kinetic Networks with
                  E(n)-Equivariance},
  year =         2023
}

@inproceedings{wang2023uni3detr,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wang, Zhenyu and Li, Ya-Li and Chen, Xi and Zhao,
                  Hengshuang and Wang, Shengjin},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/7d60bfd8458b67acbbaf18b892338d00-Paper-Conference.pdf}},
  pages =        {39876--39896},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Uni3DETR: Unified 3D Detection Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{wang2024card,
  address =      {Vienna, Austria},
  author =       {Wang, Xue and Zhou, Tian and Wen, Qingsong and Gao,
                  Jinyang and Ding, Bolin and Jin, Rong},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MJksrOhurE}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {CARD: Channel Aligned Robust Blend Transformer for
                  Time Series Forecasting},
  year =         2024
}

@inproceedings{wang2024efficientb,
  address =      {Vienna, Austria},
  author =       {Wang, Yili and Zhou, Kaixiong and Liu, Ninghao and
                  Wang, Ying and Wang, Xin},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Od39h4XQ3Y}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Sharpness-Aware Minimization for Molecular
                  Graph Transformer Models},
  year =         2024
}

@inproceedings{wang2024incontext,
  address =      {Vienna, Austria},
  author =       {Wang, Zhijie and Jiang, Bo and Li, Shuai},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=rJkGOARXns}},
  publisher =    {OpenReview.net},
  title =        {In-context Learning on Function Classes Unveiled for
                  Transformers},
  year =         2024
}

@inproceedings{wang2024transformers,
  address =      {Vienna, Austria},
  author =       {Wang, Zixuan and Wei, Stanley and Hsu, Daniel and
                  Lee, Jason D.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=qjqlhWDcId}},
  publisher =    {OpenReview.net},
  title =        {Transformers Provably Learn Sparse Token Selection
                  While Fully-Connected Nets Cannot},
  year =         2024
}

@inproceedings{wang2024vision,
  address =      {Vienna, Austria},
  author =       {Wang, Qiufeng and Yang, Xu and Chen, Haokun and
                  Geng, Xin},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=5ExWEazod5}},
  publisher =    {OpenReview.net},
  title =        {Vision Transformers as Probabilistic Expansion from
                  Learngene},
  year =         2024
}

@inproceedings{wang2024visual,
  address =      {Vienna, Austria},
  author =       {Wang, Yancheng and Li, Ping and Yang, Yingzhen},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=iup9NElHji}},
  publisher =    {OpenReview.net},
  title =        {Visual Transformer with Differentiable Channel
                  Selection: An Information Bottleneck Inspired
                  Approach},
  year =         2024
}

@inproceedings{watanabe2021unified,
  address =      {Virtual Event},
  author =       {Watanabe, Tomoki and Favaro, Paolo},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/watanabe21a.html}},
  pages =        {11024--11034},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {A Unified Generative Adversarial Network Training
                  via Self-Labeling and Self-Attention},
  volume =       139,
  year =         2021
}

@inproceedings{wei2016learned,
  address =      {Barcelona, Spain},
  author =       {Wei, Zijun and Adeli, Hossein and Nguyen, Minh Hoai
                  and Zelinsky, Greg and Samaras, Dimitris},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon
                  and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/a0e2a2c563d57df27213ede1ac4ac780-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learned Region Sparsity and Diversity Also Predicts
                  Visual Attention},
  volume =       29,
  year =         2016
}

@inproceedings{wei2022outlier,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wei, Xiuying and Zhang, Yunchen and Zhang, Xiangguo
                  and Gong, Ruihao and Zhang, Shanghang and Zhang, Qi
                  and Yu, Fengwei and Liu, Xianglong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/6f6db140de9c9f111b12ef8a216320a9-Paper-Conference.pdf}},
  pages =        {17402--17414},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Outlier Suppression: Pushing the Limit of Low-bit
                  Transformer Language Models},
  volume =       35,
  year =         2022
}

@inproceedings{wei2022statistically,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wei, Colin and Chen, Yining and Ma, Tengyu},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/4ebf1d74f53ece08512a23309d58df89-Paper-Conference.pdf}},
  pages =        {12071--12083},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Statistically Meaningful Approximation: a Case Study
                  on Approximating Turing Machines with Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{weiss2021thinking,
  address =      {Virtual Event},
  author =       {Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/weiss21a.html}},
  pages =        {11080--11090},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Thinking Like Transformers},
  volume =       139,
  year =         2021
}

@inproceedings{wen2024can,
  address =      {Vienna, Austria},
  author =       {Wen, Chuan and Jayaraman, Dinesh and Gao, Yang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HgZUcwFhjr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Can Transformers Capture Spatial Relations between
                  Objects?},
  year =         2024
}

@inproceedings{wenger2022salsa,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wenger, Emily and Chen, Mingjie and Charton,
                  Francois and Lauter, Kristin E.},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e28b3369186459f57c94a9ec9137fac9-Paper-Conference.pdf}},
  pages =        {34981--34994},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SALSA: Attacking Lattice Cryptography with
                  Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{whittington2022relating,
  address =      {Virtual Event},
  author =       {Whittington, James C. R. and Warren, Joseph and
                  Behrens, Tim E. J.},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=B8DVo9B1YE0}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Relating transformers to models and neural
                  representations of the hippocampal formation},
  year =         2022
}

@inproceedings{widrich2020modern,
  address =      {Virtual Event},
  author =       {Widrich, Michael and Schäfl, Bernhard and Pavlović,
                  Milena and Ramsauer, Hubert and Gruber, Lukas and
                  Holzleitner, Markus and Brandstetter, Johannes and
                  Sandve, Geir Kjetil and Greiff, Victor and
                  Hochreiter, Sepp and Klambauer, Günter},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/da4902cb0bc38210839714ebdcf0efc3-Paper.pdf}},
  pages =        {18832--18845},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Modern Hopfield Networks and Attention for Immune
                  Repertoire Classification},
  volume =       33,
  year =         2020
}

@inproceedings{wies2021which,
  address =      {Virtual Event},
  author =       {Wies, Noam and Levine, Yoav and Jannai, Daniel and
                  Shashua, Amnon},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/wies21a.html}},
  pages =        {11170--11181},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Which Transformer Architecture Fits My Data? A
                  Vocabulary Bottleneck in Self-attention},
  volume =       139,
  year =         2021
}

@inproceedings{woo2024alam,
  address =      {Vienna, Austria},
  author =       {Woo, Sunghyeon and Lee, Sunwoo and Jeon, Dongsuk},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=OfXqQ5TRwp}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {ALAM: Averaged Low-Precision Activation for
                  Memory-Efficient Training of Transformer Models},
  year =         2024
}

@inproceedings{woo2024unified,
  address =      {Vienna, Austria},
  author =       {Woo, Gerald and Liu, Chenghao and Kumar, Akshat and
                  Xiong, Caiming and Savarese, Silvio and Sahoo,
                  Doyen},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Yd8eHMY1wz}},
  publisher =    {OpenReview.net},
  title =        {Unified Training of Universal Time Series
                  Forecasting Transformers},
  year =         2024
}

@inproceedings{wortsman2024smallscale,
  address =      {Vienna, Austria},
  author =       {Wortsman, Mitchell and Liu, Peter J. and Xiao,
                  Lechao and Everett, Katie E. and Alemi, er A. and
                  Adlam, Ben and Co-Reyes, John D. and Gur, Izzeddin
                  and Kumar, Abhishek and Novak, Roman and Pennington,
                  Jeffrey and Sohl-Dickstein, Jascha and Xu, Kelvin
                  and Lee, Jaehoon and Gilmer, Justin and Kornblith,
                  Simon},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=d8w0pmvXbZ}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Small-Scale Proxies for Large-Scale Transformer
                  Training Instabilities},
  year =         2024
}

@inproceedings{wrigley2001neural,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Wrigley, Stuart and Brown, Guy},
  booktitle =    {Advances in Neural Information Processing Systems 14
                  (NIPS)},
  editor =       {T. Dietterich and S. Becker and Z. Ghahramani},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2001/file/c3535febaff29fcb7c0d20cbe94391c7-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {A Neural Oscillator Model of Auditory Selective
                  Attention},
  volume =       14,
  year =         2001
}

@inproceedings{wu2019pay,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Felix and Fan, Angela and Baevski, Alexei and
                  Dauphin, Yann N. and Auli, Michael},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=SkVhlh09tX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Pay Less Attention with Lightweight and Dynamic
                  Convolutions},
  year =         2019
}

@inproceedings{wu2020adversarialb,
  address =      {Virtual Event},
  author =       {Wu, Sifan and Xiao, Xi and Ding, Qianggang and Zhao,
                  Peilin and Wei, Ying and Huang, Junzhou},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf}},
  pages =        {17105--17115},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Adversarial Sparse Transformer for Time Series
                  Forecasting},
  volume =       33,
  year =         2020
}

@inproceedings{wu2020lite,
  address =      {Addis Ababa, Ethiopia},
  author =       {Wu, Zhanghao and Liu, Zhijian and Lin, Ji and Lin,
                  Yujun and Han, Song},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=ByeMPlHKPH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Lite Transformer with Long-Short Range Attention},
  year =         2020
}

@inproceedings{wu2021autoformer,
  address =      {Virtual Event},
  author =       {Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long,
                  Mingsheng},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/bcc0d400288793e8bdcd7c19a8ac0c2b-Paper.pdf}},
  pages =        {22419--22430},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Autoformer: Decomposition Transformers with
                  Auto-Correlation for Long-Term Series Forecasting},
  volume =       34,
  year =         2021
}

@inproceedings{wu2021generative,
  address =      {Virtual Event},
  author =       {Wu, Yi-Fu and Yoon, Jaesik and Ahn, Sungjin},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v139/wu21h.html}},
  pages =        {11307--11318},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Generative Video Transformer: Can Objects be the
                  Words?},
  volume =       139,
  year =         2021
}

@inproceedings{wu2021representing,
  address =      {Virtual Event},
  author =       {Wu, Zhanghao and Jain, Paras and Wright, Matthew and
                  Mirhoseini, Azalia and Gonzalez, Joseph E. and
                  Stoica, Ion},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6e67691b60ed3e4a55935261314dd534-Paper.pdf}},
  pages =        {13266--13279},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Representing Long-Range Context for Graph Neural
                  Networks with Global Attention},
  volume =       34,
  year =         2021
}

@inproceedings{wu2022associated,
  address =      {Virtual Event},
  author =       {Wu, Dennis Y. H. and Lin, Dinan and Chen, Vincent
                  and Chen, Hung-Hsuan},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=4N-17dske79}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Associated Learning: an Alternative to End-to-End
                  Backpropagation that Works on CNN, RNN, and
                  Transformer},
  year =         2022
}

@inproceedings{wu2022flowformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Wu, Haixu and Wu, Jialong and Xu, Jiehui and Wang,
                  Jianmin and Long, Mingsheng},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v162/wu22m.html}},
  pages =        {24226--24242},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Flowformer: Linearizing Transformers with
                  Conservation Flows},
  volume =       162,
  year =         2022
}

@inproceedings{wu2022memorizing,
  address =      {Virtual Event},
  author =       {Wu, Yuhuai and Rabe, Markus Norman and Hutchins,
                  DeLesley and Szegedy, Christian},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=TrjbxzRcnf-}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Memorizing Transformers},
  year =         2022
}

@inproceedings{wu2022nodeformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Qitian and Zhao, Wentao and Li, Zenan and Wipf,
                  David P and Yan, Junchi},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/af790b7ae573771689438bbcfc5933fe-Paper-Conference.pdf}},
  pages =        {27387--27401},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {NodeFormer: A Scalable Graph Structure Learning
                  Transformer for Node Classification},
  volume =       35,
  year =         2022
}

@inproceedings{wu2022point,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Xiaoyang and Lao, Yixing and Jiang, Li and Liu,
                  Xihui and Zhao, Hengshuang},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/d78ece6613953f46501b958b7bb4582f-Paper-Conference.pdf}},
  pages =        {33330--33342},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Point Transformer V2: Grouped Vector Attention and
                  Partition-based Pooling},
  volume =       35,
  year =         2022
}

@inproceedings{wu2022self_supervised,
  address =      {Baltimore, Maryland, USA},
  author =       {Wu, Haiyan and Gao, Yuting and Zhang, Yinqi and Lin,
                  Shaohui and Xie, Yuan and Sun, Xing and Li, Ke},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =         {\url{https://proceedings.mlr.press/v162/wu22c.html}},
  pages =        {24031--24042},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Self-supervised Models are Good Teaching Assistants
                  for Vision Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{wu2022spatial,
  address =      {Virtual Event},
  author =       {Wu, Yulun and Choma, Nicholas and Chen, Andrew Deru
                  and Cashman, Mikaela and Prates, Érica Teixeira and
                  Vergara, Verónica G. Melesse and Shah, Manesh and
                  Clyde, Austin and Brettin, Thomas S. and Jong, Wibe
                  Albert de and Kumar, Neeraj and Head, Martha S. and
                  Stevens, Rick L. and Nugent, Peter and Jacobson,
                  Daniel A. and Brown, James B.},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=kavTY__jxp}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spatial Graph Attention and Curiosity-driven Policy
                  for Antiviral Drug Discovery},
  year =         2022
}

@inproceedings{wu2022xtc,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Xiaoxia and Yao, Zhewei and Zhang, Minjia and
                  Li, Conglong and He, Yuxiong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, Saeed and Mohamed, Samy and Agarwal, Ankit
                  and Belgrave, David and Cho, Kyunghyun and Oh,
                  Alina},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/1579d5d8edacd85ac1a86aea28bdf32d-Paper-Conference.pdf}},
  pages =        {3217--3231},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {XTC: Extreme Compression for Pre-trained
                  Transformers Made Simple and Efficient},
  volume =       35,
  year =         2022
}

@inproceedings{wu20233d,
  address =      {Kigali, Rwanda},
  author =       {Wu, Zhennan and Li, Yang and Huang, Yifei and Gu,
                  Lin and Harada, Tatsuya and Sato, Hiroyuki},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=4dZeBJ83oxk}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {3D Segmenter: 3D Transformer Based Semantic
                  Segmentation via 2D Panoramic Distillation},
  year =         2023
}

@inproceedings{wu2023demystifying,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Xinyi and Ajorlou, Amir and Wu, Zihui and
                  Jadbabaie, Ali},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/6e4cdfdd909ea4e34bfc85a12774cba0-Paper-Conference.pdf}},
  pages =        {35084--35106},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Demystifying Oversmoothing in Attention-Based Graph
                  Neural Networks},
  volume =       36,
  year =         2023
}

@inproceedings{wu2023elastic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Yueh-Hua and Wang, Xiaolong and Hamaya, Masashi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/3b3889d313ba9476c12c2d77ea66b24f-Paper-Conference.pdf}},
  pages =        {18532--18550},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Elastic Decision Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{wu2023onb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Yongtao and Liu, Fanghui and Chrysos, Grigorios
                  and Cevher, Volkan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a3cf318fbeec1126da21e9185ae9908c-Paper-Conference.pdf}},
  pages =        {52197--52237},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {On the Convergence of Encoder-only Shallow
                  Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{wu2023sgformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Wu, Qitian and Zhao, Wentao and Yang, Chenxiao and
                  Zhang, Hengrui and Nie, Fan and Jiang, Haitian and
                  Bian, Yatao and Yan, Junchi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/cc57fac10eacadb3b72a907ac48f9a98-Paper-Conference.pdf}},
  pages =        {64753--64773},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SGFormer: Simplifying and Empowering Transformers
                  for Large-Graph Representations},
  volume =       36,
  year =         2023
}

@inproceedings{wu2024clipself,
  address =      {Vienna, Austria},
  author =       {Wu, Size and Zhang, Wenwei and Xu, Lumin and Jin,
                  Sheng and Li, Xiangtai and Liu, Wentao and Loy, Chen
                  Change},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=DjzvJCRsVf}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {CLIPSelf: Vision Transformer Distills Itself for
                  Open-Vocabulary Dense Prediction},
  year =         2024
}

@inproceedings{wu2024ditto,
  address =      {Vienna, Austria},
  author =       {Wu, Haoqi and Fang, Wenjing and Zheng, Yancheng and
                  Ma, Junming and Tan, Jin and Wang, Lei},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ZzXNCQGzqT}},
  publisher =    {OpenReview.net},
  title =        {Ditto: Quantization-aware Secure Inference of
                  Transformers upon MPC},
  year =         2024
}

@inproceedings{wu2024transolver,
  address =      {Vienna, Austria},
  author =       {Wu, Haixu and Luo, Huakun and Wang, Haowen and Wang,
                  Jianmin and Long, Mingsheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=Ywl6pODXjB}},
  publisher =    {OpenReview.net},
  title =        {Transolver: A Fast Transformer Solver for PDEs on
                  General Geometries},
  year =         2024
}

@inproceedings{xi2023training,
  address =      {New Orleans, Louisiana, USA},
  author =       {Xi, Haocheng and Li, ChangHao and Chen, Jianfei and
                  Zhu, Jun},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/99fc8bc48b917c301a80cb74d91c0c06-Paper-Conference.pdf}},
  pages =        {49146--49168},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Training Transformers with 4-bit Integers},
  volume =       36,
  year =         2023
}

@inproceedings{xi2024jetfire,
  address =      {Vienna, Austria},
  author =       {Xi, Haocheng and Chen, Yuxiang and Zhao, Kang and
                  Teh, Kai Jun and Chen, Jianfei and Zhu, Jun},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ltzTHGFF5i}},
  publisher =    {OpenReview.net},
  title =        {Jetfire: Efficient and Accurate Transformer
                  Pretraining with INT8 Data Flow and Per-Block
                  Quantization},
  year =         2024
}

@inproceedings{xia2023budgeted,
  address =      {Kigali, Rwanda},
  author =       {Xia, Zhuofan and Pan, Xuran and Jin, Xuan and He,
                  Yuan and Xue, Hui and Song, Shiji and Huang, Gao},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=sVzBN-DlJRi}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Budgeted Training for Vision Transformer},
  year =         2023
}

@inproceedings{xiang2023mimt,
  address =      {Kigali, Rwanda},
  author =       {Xiang, Jinxi and Tian, Kuan and Zhang, Jun},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=j9m-mVnndbm}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MIMT: Masked Image Modeling Transformer for Video
                  Compression},
  year =         2023
}

@inproceedings{xiao2021early,
  address =      {Virtual Event},
  author =       {Xiao, Tete and Singh, Mannat and Mintun, Eric and
                  Darrell, Trevor and Dollar, Piotr and Girshick,
                  Ross},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/ff1418e8cc993fe8abcfe3ce2003e5c5-Paper.pdf}},
  pages =        {30392--30400},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Early Convolutions Help Transformers See Better},
  volume =       34,
  year =         2021
}

@inproceedings{xiao2022stochastic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Xiao, Jie and Fu, Xueyang and Wu, Feng and Zha,
                  Zheng-Jun},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3ca6d336ddaa316a6ae953a20b9477cf-Paper-Conference.pdf}},
  pages =        {9315--9329},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Stochastic Window Transformer for Image Restoration},
  volume =       35,
  year =         2022
}

@inproceedings{xiao2023comcat,
  address =      {Honolulu, Hawaii, USA},
  author =       {Xiao, Jinqi and Yin, Miao and Gong, Yu and Zang,
                  Xiao and Ren, Jian and Yuan, Bo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/xiao23e.html}},
  pages =        {38125--38136},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {COMCAT: Towards Efficient Compression and
                  Customization of Attention-Based Vision Models},
  volume =       202,
  year =         2023
}

@inproceedings{xiao2023random,
  address =      {Honolulu, Hawaii, USA},
  author =       {Xiao, Jie and Fu, Xueyang and Zhou, Man and Liu,
                  Hongjian and Zha, Zheng-Jun},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/xiao23a.html}},
  pages =        {38039--38058},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Random Shuffle Transformer for Image Restoration},
  volume =       202,
  year =         2023
}

@inproceedings{xiao2024efficient,
  address =      {Vienna, Austria},
  author =       {Xiao, Guangxuan and Yu and Tian, ong and Chen, Beidi
                  and Han, Song and Lewis, Mike},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=NG7sS51zVF}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Streaming Language Models with Attention
                  Sinks},
  year =         2024
}

@inproceedings{xiao2024gaformer,
  address =      {Vienna, Austria},
  author =       {Xiao, Jingyun and Liu, Ran and Dyer, Eva L.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=c56TWtYp0W}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {GAFormer: Enhancing Timeseries Transformers Through
                  Group-Aware Embeddings},
  year =         2024
}

@inproceedings{xiao2024improved,
  address =      {Vienna, Austria},
  author =       {Xiao, Zipeng and Hao, Zhongkai and Lin, Bokai and
                  Deng, Zhijie and Su, Hang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=6w7zkf9FBR}},
  publisher =    {OpenReview.net},
  title =        {Improved Operator Learning by Orthogonal Attention},
  year =         2024
}

@inproceedings{xiao2024improving,
  address =      {Vienna, Austria},
  author =       {Xiao, Da and Meng, Qingye and Li, Shengping and
                  Yuan, Xingyuan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=RbiBKPtuHp}},
  publisher =    {OpenReview.net},
  title =        {Improving Transformers with Dynamically Composable
                  Multi-Head Attention},
  year =         2024
}

@inproceedings{xie2021segformer,
  address =      {Virtual Event},
  author =       {Xie, Enze and Wang, Wenhai and Yu, Zhiding and
                  Anandkumar, Anima and Alvarez, Jose M. and Luo,
                  Ping},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/64f1f27bf1b4ec22924fd0acb550c235-Paper.pdf}},
  pages =        {12077--12090},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SegFormer: Simple and Efficient Design for Semantic
                  Segmentation with Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{xie2023futureconditioned,
  address =      {Honolulu, Hawaii, USA},
  author =       {Xie, Zhihui and Lin, Zichuan and Ye, Deheng and Fu,
                  Qiang and Wei, Yang and Li, Shuai},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/xie23b.html}},
  pages =        {38187--38203},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Future-conditioned Unsupervised Pretraining for
                  Decision Transformer},
  volume =       202,
  year =         2023
}

@inproceedings{xing2024less,
  address =      {Vienna, Austria},
  author =       {Xing, Yujie and Wang, Xiao and Li, Yibo and Huang,
                  Hai and Shi, Chuan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=uKmcyyrZae}},
  publisher =    {OpenReview.net},
  title =        {Less is More: on the Over-Globalizing Problem in
                  Graph Transformers},
  year =         2024
}

@inproceedings{xiong2020on2,
  address =      {Virtual Event},
  author =       {Xiong, Ruibin and Yang, Yunchang and He, Di and
                  Zheng, Kai and Zheng, Shuxin and Xing, Chen and
                  Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and
                  Liu, Tie-Yan},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v119/xiong20b.html}},
  pages =        {10524--10533},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {On Layer Normalization in the Transformer
                  Architecture},
  volume =       119,
  year =         2020
}

@inproceedings{xu2017learning,
  address =      {Long Beach, California, USA},
  author =       {Xu, Dan and Ouyang, Wanli and Alameda-Pineda, Xavier
                  and Ricci, Elisa and Wang, Xiaogang and Sebe, Nicu},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {Guyon, I. and Von Luxburg, U. and Bengio, S. and
                  Wallach, H. and Fergus, R. and Vishwanathan, S. and
                  Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/a869ccbcbd9568808b8497e28275c7c8-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Deep Structured Multi-Scale Features using
                  Attention-Gated CRFs for Contour Prediction},
  volume =       30,
  year =         2017
}

@inproceedings{xu2019self,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and
                  Kumar, Sushant and Achan, Kannan},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/cf34645d98a7630e2bcca98b3e29c8f2-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Self-attention with Functional Time Representation
                  Learning},
  volume =       32,
  year =         2019
}

@inproceedings{xu2020deep,
  address =      {Virtual Event},
  author =       {Xu, Yunqiu and Fang, Meng and Chen, Ling and Du,
                  Yali and Zhou, Joey Tianyi and Zhang, Chengqi},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and H. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/bf65417dcecc7f2b0006e1f5793b7143-Paper.pdf}},
  pages =        {16495--16507},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Deep Reinforcement Learning with Stacked
                  Hierarchical Attention for Text-based Games},
  volume =       33,
  year =         2020
}

@inproceedings{xu2021long,
  address =      {Virtual Event},
  author =       {Xu, Mingze and Xiong, Yuanjun and Chen, Hao and Li,
                  Xinyu and Xia, Wei and Tu, Zhuowen and Soatto,
                  Stefano},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/08b255a5d42b89b0585260b6f2360bdd-Paper.pdf}},
  pages =        {1086--1099},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Long Short-Term Transformer for Online Action
                  Detection},
  volume =       34,
  year =         2021
}

@inproceedings{xu2021vitae,
  address =      {Virtual Event},
  author =       {Xu, Yufei and ZHANG, Qiming and Zhang, Jing and Tao,
                  Dacheng},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/efb76cff97aaf057654ef2f38cd77d73-Paper.pdf}},
  pages =        {28522--28535},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ViTAE: Vision Transformer Advanced by Exploring
                  Intrinsic Inductive Bias},
  volume =       34,
  year =         2021
}

@inproceedings{xu2022anomaly,
  address =      {Virtual Event},
  author =       {Xu, Jiehui and Wu, Haixu and Wang, Jianmin and Long,
                  Mingsheng},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=LzQQ89U1qm_}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Anomaly Transformer: Time Series Anomaly Detection
                  with Association Discrepancy},
  year =         2022
}

@inproceedings{xu2022cdtrans,
  address =      {Virtual Event},
  author =       {Xu, Tongkun and Chen, Weihua and Wang, Pichao and
                  Wang, Fan and Li, Hao and Jin, Rong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=XGzk5OKWFFc}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {CDTrans: Cross-domain Transformer for Unsupervised
                  Domain Adaptation},
  year =         2022
}

@inproceedings{xu2022prompting,
  address =      {Baltimore, Maryland, USA},
  author =       {Xu, Mengdi and Shen, Yikang and Zhang, Shun and Lu,
                  Yuchen and Zhao, Ding and Tenenbaum, Joshua B. and
                  Gan, Chuang},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v162/xu22g.html}}},
  pages =        {24631--24645},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Prompting Decision Transformer for Few-Shot Policy
                  Generalization},
  volume =       162,
  year =         2022
}

@inproceedings{xu2022vitpose,
  address =      {New Orleans, Louisiana, USA},
  author =       {Xu, Yufei and Zhang, Jing and Zhang, Qiming and Tao,
                  Dacheng},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/fbb10d319d44f8c3b4720873e4177c65-Paper-Conference.pdf}},
  pages =        {38571--38584},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ViTPose: Simple Vision Transformer Baselines for
                  Human Pose Estimation},
  volume =       35,
  year =         2022
}

@inproceedings{xu2023enhancingb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Xu, Qi and Gao, Yuyuan and Shen, Jiangrong and Li,
                  Yaxin and Ran, Xuming and Tang, Huajin and Pan,
                  Gang},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b8734840bf65c8facd619f5105c6acd0-Paper-Conference.pdf}},
  pages =        {58890--58901},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Enhancing Adaptive History Reserving by Spiking
                  Convolutional Block Attention Module in Recurrent
                  Neural Networks},
  volume =       36,
  year =         2023
}

@inproceedings{xu2023hyperdecision,
  address =      {Kigali, Rwanda},
  author =       {Xu, Mengdi and Lu, Yuchen and Shen, Yikang and
                  Zhang, Shun and Zhao, Ding and Gan, Chuang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=AatUEvC-Wjv}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Hyper-Decision Transformer for Efficient Online
                  Policy Adaptation},
  year =         2023
}

@inproceedings{xu2023se,
  address =      {New Orleans, Louisiana, USA},
  author =       {Xu, Yinshuang and Lei, Jiahui and Daniilidis,
                  Kostas},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/075b2875e2b671ddd74aeec0ac9f0357-Paper-Conference.pdf}},
  pages =        {2463--2510},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SE(3) Equivariant Convolution and Transformer in Ray
                  Space},
  volume =       36,
  year =         2023
}

@inproceedings{xu2024enhancing,
  address =      {Vienna, Austria},
  author =       {Xu, Yixing and Li, Chao and Li, Dong and Sheng, Xiao
                  and Jiang, Fan and Tian, Lu and Sirasao, Ashish and
                  Barsoum, Emad},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=NV0q2jdwo0}},
  publisher =    {OpenReview.net},
  title =        {Enhancing Vision Transformer: Amplifying
                  Non-Linearity in Feedforward Network Module},
  year =         2024
}

@inproceedings{xu2024gtmgc,
  address =      {Vienna, Austria},
  author =       {Xu, Guikun and Jiang, Yongquan and Lei, PengChuan
                  and Yang, Yan and Chen, Jim},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=F7QnIKlC1N}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {GTMGC: Using Graph Transformer to Predict Molecule's
                  Ground-State Conformation},
  year =         2024
}

@inproceedings{xue2021probing,
  address =      {Virtual Event},
  author =       {Xue, Hongwei and Huang, Yupan and Liu, Bei and Peng,
                  Houwen and Fu, Jianlong and Li, Houqiang and Luo,
                  Jiebo},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/23fa71cc32babb7b91130824466d25a5-Paper.pdf}},
  pages =        {4514--4528},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Probing Inter-modality: Visual Parsing with
                  Self-Attention for Vision-and-Language Pre-training},
  volume =       34,
  year =         2021
}

@inproceedings{xue2023study,
  address =      {Honolulu, Hawaii, USA},
  author =       {Xue, Fuzhao and Chen, Jianghai and Sun, Aixin and
                  Ren, Xiaozhe and Zheng, Zangwei and He, Xiaoxin and
                  Chen, Yongming and Jiang, Xin and You, Yang},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/xue23b.html}},
  pages =        {38913--38925},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {A Study on Transformer Configuration and Training
                  Objective},
  volume =       202,
  year =         2023
}

@inproceedings{yadav2024masked,
  address =      {Vienna, Austria},
  author =       {Yadav, Sarthak and Theodoridis, Sergios and Hansen,
                  Lars Kai and Tan, Zheng-Hua},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Q53QLftNkA}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Masked Autoencoders with Multi-Window Local-Global
                  Attention Are Better Audio Learners},
  year =         2024
}

@inproceedings{yamagata2023qlearning,
  address =      {Honolulu, Hawaii, USA},
  author =       {Yamagata, Taku and Khalil, Ahmed and
                  Santos-Rodríguez, Raúl},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/yamagata23a.html}},
  pages =        {38989--39007},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Q-learning Decision Transformer: Leveraging Dynamic
                  Programming for Conditional Sequence Modelling in
                  Offline RL},
  volume =       202,
  year =         2023
}

@inproceedings{yan2016perspective,
  address =      {Barcelona, Spain},
  author =       {Yan, Xinchen and Yang, Jimei and Yumer, Ersin and
                  Guo, Yijie and Lee, Honglak},
  booktitle =    {Advances in Neural Information Processing Systems 29
                  (NeurIPS)},
  editor =       {Lee, D. and Sugiyama, M. and Luxburg, U. and Guyon,
                  I. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2016/file/e820a45f1dfc7b95282d10b6087e11c0-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Perspective Transformer Nets: Learning Single-View
                  3D Object Reconstruction without 3D Supervision},
  volume =       29,
  year =         2016
}

@inproceedings{yan2021cate,
  address =      {Virtual Event},
  author =       {Yan, Shen and Song, Kaiqiang and Liu, Fei and Zhang,
                  Mi},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/yan21c.html}}},
  pages =        {11670--11681},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {CATE: Computation-aware Neural Architecture Encoding
                  with Transformers},
  volume =       139,
  year =         2021
}

@inproceedings{yan2021elattention,
  address =      {Virtual Event},
  author =       {Yan, Yu and Chen, Jiusheng and Qi, Weizhen and
                  Bhendawade, Nikhil and Gong, Yeyun and Duan, Nan and
                  Zhang, Ruofei},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/yan21a.html}}},
  pages =        {11648--11658},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {EL-Attention: Memory Efficient Lossless Attention
                  for Generation},
  volume =       139,
  year =         2021
}

@inproceedings{yan2022periodic,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yan, Keqiang and Liu, Yi and Lin, Yuchao and Ji,
                  Shuiwang},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/6145c70a4a4bf353a31ac5496a72a72d-Paper-Conference.pdf}},
  pages =        {15066--15080},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Periodic Graph Transformers for Crystal Material
                  Property Prediction},
  volume =       35,
  year =         2022
}

@inproceedings{yan2023temporally,
  address =      {Honolulu, Hawaii, USA},
  author =       {Yan, Wilson and Hafner, Danijar and James, Stephen
                  and Abbeel, Pieter},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/yan23b.html}},
  pages =        {39062--39098},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Temporally Consistent Transformers for Video
                  Generation},
  volume =       202,
  year =         2023
}

@inproceedings{yan2024complete,
  address =      {Vienna, Austria},
  author =       {Yan, Keqiang and Fu, Cong and Qian, Xiaofeng and
                  Qian, Xiaoning and Ji, Shuiwang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=BnQY9XiRAS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Complete and Efficient Graph Transformers for
                  Crystal Material Property Prediction},
  year =         2024
}

@inproceedings{yan2024masked,
  address =      {Vienna, Austria},
  author =       {Yan, Caixia and Chang, Xiaojun and Li, Zhihui and
                  Yao, Lina and Luo, Minnan and Zheng, Qinghua},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=LUpC8KTvdV}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Masked Distillation Advances Self-Supervised
                  Transformer Architecture Search},
  year =         2024
}

@inproceedings{yan2024multiscale,
  address =      {Vienna, Austria},
  author =       {Yan, Haotian and Wu, Ming and Zhang, Chuang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=lAhWGOkpSR}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Multi-Scale Representations by Varying Window
                  Attention for Semantic Segmentation},
  year =         2024
}

@inproceedings{yang2019ouroboros,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Yang, Qian and Huo, Zhouyuan and Wang, Wenlin and
                  Carin, Lawrence},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/1b79b52d1bf6f71b2b1eb7ca08ed0776-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Ouroboros: On Accelerating Training of
                  Transformer-Based Language Models},
  volume =       32,
  year =         2019
}

@inproceedings{yang2021associating,
  address =      {Virtual Event},
  author =       {Yang, Zongxin and Wei, Yunchao and Yang, Yi},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/147702db07145348245dc5a2f2fe5683-Paper.pdf}},
  pages =        {2491--2502},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Associating Objects with Transformers for Video
                  Object Segmentation},
  volume =       34,
  year =         2021
}

@inproceedings{yang2021cross,
  address =      {Virtual Event},
  author =       {Yang, Hongji and Lu, Xiufan and Zhu, Yingying},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f31b20466ae89669f9741e047487eb37-Paper.pdf}},
  pages =        {29009--29020},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Cross-View Geo-Localization with Layer-to-Layer
                  Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{yang2021focal,
  address =      {Virtual Event},
  author =       {Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan
                  and Dai, Xiyang and Xiao, Bin and Yuan, Lu and Gao,
                  Jianfeng},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/fc1a36821b02abbd2503fd949bfc9131-Paper.pdf}},
  pages =        {30008--30022},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Focal Attention for Long-Range Interactions in
                  Vision Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{yang2021graphformers,
  address =      {Virtual Event},
  author =       {Yang, Junhan and Liu, Zheng and Xiao, Shitao and Li,
                  Chaozhuo and Lian, Defu and Agrawal, Sanjay and
                  Singh, Amit and Sun, Guangzhong and Xie, Xing},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f18a6d1cde4b205199de8729a6637b42-Paper.pdf}},
  pages =        {28798--28810},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {GraphFormers: GNN-Nested Transformers for
                  Representation Learning on Textual Graph},
  volume =       34,
  year =         2021
}

@inproceedings{yang2021implicit,
  address =      {Virtual Event},
  author =       {Yang, Jingyu and Shen, Sheng and Yue, Huanjing and
                  Li, Kun},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6e7d5d259be7bf56ed79029c4e621f44-Paper.pdf}},
  pages =        {13304--13315},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Implicit Transformer Network for Screen Content
                  Image Continuous Super-Resolution},
  volume =       34,
  year =         2021
}

@inproceedings{yang2021simam,
  address =      {Virtual Event},
  author =       {Yang, Lingxiao and Zhang, Ru-Yuan and Li, Lida and
                  Xie, Xiaohua},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{\url{http://proceedings.mlr.press/v139/yang21o.html}}},
  pages =        {11863--11874},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {SimAM: A Simple, Parameter-Free Attention Module for
                  Convolutional Neural Networks},
  volume =       139,
  year =         2021
}

@inproceedings{yang2022learningb,
  address =      {Virtual Event},
  author =       {Yang, Ruihan and Zhang, Minghao and Hansen, Nicklas
                  and Xu, Huazhe and Wang, Xiaolong},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=nhnJ3oo6AB}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning Vision-Guided Quadrupedal Locomotion
                  End-to-End with Cross-Modal Transformers},
  year =         2022
}

@inproceedings{yang2022transformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yang, Yaodong and Chen, Guangyong and Wang, Weixun
                  and Hao, Xiaotian and Hao, Jianye and Heng,
                  Pheng-Ann},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e1cf57f1e104c6c05e31894c15a65e99-Paper-Conference.pdf}},
  pages =        {34874--34886},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformer-based Working Memory for Multiagent
                  Reinforcement Learning with Action Parsing},
  volume =       35,
  year =         2022
}

@inproceedings{yang2022transformers,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yang, Yongyi and Huang, Zengfeng and Wipf, David P.},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/efd1e27afcb94addd03b9e14c8d9f78f-Paper-Conference.pdf}},
  pages =        {36958--36971},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Transformers from an Optimization Perspective},
  volume =       35,
  year =         2022
}

@inproceedings{yang2023biot,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yang, Chaoqi and Westover, M and Sun, Jimeng},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f6b30f3e2dd9cb53bbf2024402d02295-Paper-Conference.pdf}},
  pages =        {78240--78260},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {BIOT: Biosignal Transformer for Cross-data Learning
                  in the Wild},
  volume =       36,
  year =         2023
}

@inproceedings{yang2023efficienta,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yang, Yuedong and Chiang, Hung-Yueh and Li, Guihong
                  and Marculescu, Diana and Marculescu, Radu},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/2f75a57e9c71e8369da0150ea769d5a2-Paper-Conference.pdf}},
  pages =        {14725--14736},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Efficient Low-rank Backpropagation for Vision
                  Transformer Adaptation},
  volume =       36,
  year =         2023
}

@inproceedings{yang2023evolutionary,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yang, Shangshang and Yu, Xiaoshan and Tian, Ye and
                  Yan, Xueming and Ma, Haiping and Zhang, Xingyi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/3e53d82a1113e3d240059a9195668edc-Paper-Conference.pdf}},
  pages =        {19520--19539},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Evolutionary Neural Architecture Search for
                  Transformer in Knowledge Tracing},
  volume =       36,
  year =         2023
}

@inproceedings{yang2023gpvit,
  address =      {Kigali, Rwanda},
  author =       {Yang, Chenhongyi and Xu, Jiarui and Mello, Shalini
                  De and Crowley, Elliot J. and Wang, Xiaolong},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=IowKt5rYWsK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {GPViT: A High Resolution Non-Hierarchical Vision
                  Transformer with Group Propagation},
  year =         2023
}

@inproceedings{yang2023learning,
  address =      {Kigali, Rwanda},
  author =       {Yang, Zhun and Ishay, Adam and Lee, Joohyung},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=udNhDCr2KQe}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning to Solve Constraint Satisfaction Problems
                  with Recurrent Transformer},
  year =         2023
}

@inproceedings{yang2023moat,
  address =      {Kigali, Rwanda},
  author =       {Yang, Chenglin and Qiao, Siyuan and Yu, Qihang and
                  Yuan, Xiaoding and Zhu, Yukun and Yuille, Alan
                  L. and Adam, Hartwig and Chen, Liang-Chieh},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=H0HGljkxQFN}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MOAT: Alternating Mobile Convolution and Attention
                  Brings Strong Vision Models},
  year =         2023
}

@inproceedings{yang2024do,
  address =      {Vienna, Austria},
  author =       {Yang, Kai and Ackermann, Jan and He, Zhenyu and
                  Feng, Guhao and Zhang, Bohang and Feng, Yunzhen and
                  Ye, Qiwei and He, Di and Wang, Liwei},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=xLikRS9OhW}},
  publisher =    {OpenReview.net},
  title =        {Do Efficient Transformers Really Save Computation?},
  year =         2024
}

@inproceedings{yang2024gated,
  address =      {Vienna, Austria},
  author =       {Yang, Songlin and Wang, Bailin and Shen, Yikang and
                  P, Rameswar and a, and Kim, Yoon},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=ia5XvxFUJT}},
  publisher =    {OpenReview.net},
  title =        {Gated Linear Attention Transformers with
                  Hardware-Efficient Training},
  year =         2024
}

@inproceedings{yang2024looped,
  address =      {Vienna, Austria},
  author =       {Yang, Liu and Lee, Kangwook and Nowak, Robert D. and
                  Papailiopoulos, Dimitris},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HHbRxoDTxE}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Looped Transformers are Better at Learning Learning
                  Algorithms},
  year =         2024
}

@inproceedings{yang2024one,
  address =      {Vienna, Austria},
  author =       {Yang, Xu and Yao, Huaxiu and Wei, Ying},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=01ahsMovBx}},
  publisher =    {OpenReview.net},
  title =        {One Meta-tuned Transformer is What You Need for
                  Few-shot Learning},
  year =         2024
}

@inproceedings{yao2022zeroquant,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yao, Zhewei and Yazdani Aminabadi, Reza and Zhang,
                  Minjia and Wu, Xiaoxia and Li, Conglong and He,
                  Yuxiong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/adf7fa39d65e2983d724ff7da57f00ac-Paper-Conference.pdf}},
  pages =        {27168--27183},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ZeroQuant: Efficient and Affordable Post-Training
                  Quantization for Large-Scale Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{yao2023spike,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yao, Man and Hu, JiaKui and Zhou, Zhaokun and Yuan,
                  Li and Tian, Yonghong and Xu, Bo and Li, Guoqi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/ca0f5358dbadda74b3049711887e9ead-Paper-Conference.pdf}},
  pages =        {64043--64058},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Spike-driven Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{yao2024mobile,
  address =      {Vienna, Austria},
  author =       {Yao, Zhiyu and Wang, Jian and Wu, Haixu and Wang,
                  Jingdong and Long, Mingsheng},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=VHtIDVaOKC}},
  publisher =    {OpenReview.net},
  title =        {Mobile Attention: Mobile-Friendly Linear-Attention
                  for Vision Transformers},
  year =         2024
}

@inproceedings{yao2024spikedriven,
  address =      {Vienna, Austria},
  author =       {Yao, Man and Hu, Jiakui and Hu, Tianxiang and Xu,
                  Yifan and Zhou, Zhaokun and Tian, Yonghong and Xu,
                  Bo and Li, Guoqi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=1SIBN5Xyw7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spike-Driven Transformer V2: Meta Spiking Neural
                  Network Architecture Inspiring the Design of
                  Next-Generation Neuromorphic Chips},
  year =         2024
}

@inproceedings{yasuda2023sequential,
  address =      {Kigali, Rwanda},
  author =       {Yasuda, Taisuke and Bateni, Mohammad Hossein and
                  Chen, Lin and Fahrbach, Matthew and Fu, Gang and
                  Mirrokni, Vahab},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=TTLLGx3eet}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Sequential Attention for Feature Selection},
  year =         2023
}

@inproceedings{ye2023neural,
  address =      {New Orleans, Louisiana, USA},
  author =       {Ye, Joel and Collinger, Jennifer and Wehbe, Leila
                  and Gaunt, Robert},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/fe51de4e7baf52e743b679e3bdba7905-Paper-Conference.pdf}},
  pages =        {80352--80374},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Neural Data Transformer 2: Multi-Context Pretraining
                  for Neural Spiking Activity},
  volume =       36,
  year =         2023
}

@inproceedings{yi2023nar,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yi, Yun and Zhang, Haokui and Xiao, Rong and Wang,
                  Nannan and Wang, Xiaoyu},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {Oh, A. and Naumann, T. and Globerson, A. and Saenko,
                  K. and Hardt, M. and Levine, S.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/c60bd92a01804b7df0540ed7ca2f7c05-Paper-Conference.pdf}},
  pages =        {62727--62739},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {NAR-Former V2: Rethinking Transformer for Universal
                  Neural Network Representation Learning},
  volume =       36,
  year =         2023
}

@inproceedings{yilmaz2022de,
  address =      {Baltimore, Maryland, USA},
  author =       {Yilmaz, Melih and Fondrie, William and Bittremieux,
                  Wout and Oh, Sewoong and Noble, William S.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/yilmaz22a.html}},
  pages =        {25514--25522},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {De novo mass spectrometry peptide sequencing with a
                  transformer model},
  volume =       162,
  year =         2022
}

@inproceedings{yin2024stablemask,
  address =      {Vienna, Austria},
  author =       {Yin, Qingyu and He, Xuzheng and Zhuang, Xiang and
                  Zhao, Yu and Yao, Jianhua and Shen, Xiaoyu and
                  Zhang, Qiang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=GFfWzAReAc}},
  publisher =    {OpenReview.net},
  title =        {StableMask: Refining Causal Masking in Decoder-Only
                  Transformer},
  year =         2024
}

@inproceedings{ying2021transformers,
  address =      {Virtual Event},
  author =       {Ying, Chengxuan and Cai, Tianle and Luo, Shengjie
                  and Zheng, Shuxin and Ke, Guolin and He, Di and
                  Shen, Yanming and Liu, Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f1c1592588411002af340cbaedd6fc33-Paper.pdf}},
  pages =        {28877--28888},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Do Transformers Really Perform Badly for Graph
                  Representation?},
  volume =       34,
  year =         2021
}

@inproceedings{yoo2023improving,
  address =      {Honolulu, Hawaii, USA},
  author =       {Yoo, Seungryong and Kim, Eunji and Jung, Dahuin and
                  Lee, Jungbeom and Yoon, Sungroh},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/yoo23a.html}}},
  pages =        {40075--40092},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Improving Visual Prompt Tuning for Self-supervised
                  Vision Transformers},
  volume =       202,
  year =         2023
}

@inproceedings{yorsh2024on,
  address =      {Vienna, Austria},
  author =       {Yorsh, Uladzislau and Holena, Martin and Bojar,
                  Ondrej and Herel, David},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=pexcddsXGY}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {On Difficulties of Attention Factorization through
                  Shared Memory},
  year =         2024
}

@inproceedings{you2019attentionxml,
  address =      {Vancouver, British Columbia, Canada},
  author =       {You, Ronghui and Zhang, Zihan and Wang, Ziye and
                  Dai, Suyang and Mamitsuka, Hiroshi and Zhu,
                  Shanfeng},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/9e6a921fbc428b5638b3986e365d4f21-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {AttentionXML: Label Tree-based Attention-Aware Deep
                  Model for High-Performance Extreme Multi-Label Text
                  Classification},
  volume =       32,
  year =         2019
}

@inproceedings{you2022,
  address =      {New Orleans, Louisiana, USA},
  author =       {You, Chenyu and Zhao, Ruihan and Liu, Fenglin and
                  Dong, Siyuan and Chinchali, Sandeep and Topcu, Ufuk
                  and Staib, Lawrence and Duncan, James},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/be99227ef4a4de84bb45d7dc7b53f808-Paper-Conference.pdf}},
  pages =        {29582--29596},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Class-Aware Adversarial Transformers for Medical
                  Image Segmentation},
  volume =       35,
  year =         2022
}

@inproceedings{you2023shiftaddvit,
  address =      {New Orleans, Louisiana, USA},
  author =       {You, Haoran and Shi, Huihong and Guo, Yipin and Lin,
                  Yingyan},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/69c49f75ca31620f1f0d38093d9f3d9b-Paper-Conference.pdf}},
  pages =        {33319--33337},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ShiftAddViT: Mixture of Multiplication Primitives
                  Towards Efficient Vision Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{you2024linear,
  address =      {Vienna, Austria},
  author =       {You, Haoran and Fu, Yichao and Wang, Zheng and
                  Yazdanbakhsh, Amir and Lin, Yingyan Celine},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=7mFSaP6IiN}},
  publisher =    {OpenReview.net},
  title =        {When Linear Attention Meets Autoregressive Decoding:
                  Towards More Effective and Efficient Linearized
                  Large Language Models},
  year =         2024
}

@inproceedings{you2024spikeziptf,
  address =      {Vienna, Austria},
  author =       {You, Kang and Xu, Zekai and Nie, Chen and Deng,
                  Zhijie and Guo, Qinghai and Wang, Xiang and He,
                  Zhezhi},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=NeotatlYOL}},
  publisher =    {OpenReview.net},
  title =        {SpikeZIP-TF: Conversion is All You Need for
                  Transformer-based SNN},
  year =         2024
}

@inproceedings{yu2004inference,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Yu, Angela J. and Dayan, Peter},
  booktitle =    {Advances in Neural Information Processing Systems 17
                  (NIPS)},
  editor =       {Saul, L. and Weiss, Y. and Bottou, L.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2004/file/0e4a2c65bdaddd66a53422d93daebe68-Paper.pdf}},
  publisher =    {MIT Press},
  series =       {Conference Track Proceedings},
  title =        {Inference, Attention, and Decision in a Bayesian
                  Neural Architecture},
  volume =       17,
  year =         2004
}

@inproceedings{yu2018qanets,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Yu, Adams Wei and Dohan, David and Luong, Minh-Thang
                  and Zhao, Rui and Chen, Kai and Norouzi, Mohammad
                  and Le, Quoc V.},
  booktitle =    {6th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=B14TlG-RW}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {QANet: Combining Local Convolution with Global
                  Self-Attention for Reading Comprehension},
  year =         2018
}

@inproceedings{yu2018stacked,
  address =      {Montreal, Quebec, Canada},
  author =       {Yu, Yunlong and Ji, Zhong and Fu, Yanwei and Guo,
                  Jichang and Pang, Yanwei and Zhang, Zhongfei},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {S. Bengio and H. Wallach and H. Larochelle and
                  K. Grauman and N. Cesa-Bianchi and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/9087b0efc7c7acd1ef7e153678809c77-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Stacked Semantics-Guided Attention Model for
                  Fine-Grained Zero-Shot Learning},
  volume =       31,
  year =         2018
}

@inproceedings{yu2020learning,
  address =      {Addis Ababa, Ethiopia},
  author =       {Yu, Tianshu and Wang, Runzhong and Yan, Junchi and
                  Li, Baoxin},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=rJgBd2NYPH}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning deep graph matching with
                  channel-independent embedding and Hungarian
                  attention},
  year =         2020
}

@inproceedings{yu2021glance,
  address =      {Virtual Event},
  author =       {Yu, Qihang and Xia, Yingda and Bai, Yutong and Lu,
                  Yongyi and Yuille, Alan L and Shen, Wei},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Vaughan, J.W.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6c524f9d5d7027454a783c841250ba71-Paper.pdf}},
  pages =        {12992--13003},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Glance-and-Gaze Vision Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{yu2022museformer,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yu, Botao and Lu, Peiling and Wang, Rui and Hu, Wei
                  and Tan, Xu and Ye, Wei and Zhang, Shikun and Qin,
                  Tao and Liu, Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/092c2d45005ea2db40fc24c470663416-Paper-Conference.pdf}},
  pages =        {1376--1388},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Museformer: Transformer with Fine- and
                  Coarse-Grained Attention for Music Generation},
  volume =       35,
  year =         2022
}

@inproceedings{yu2022unified,
  address =      {Virtual Event},
  author =       {Yu, Shixing and Chen, Tianlong and Shen, Jiayi and
                  Yuan, Huan and Tan, Jianchao and Yang, Sen and Liu,
                  Ji and Wang, Zhangyang},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=9jsZiUgkCZP}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Unified Visual Transformer Compression},
  year =         2022
}

@inproceedings{yu2023megabyte,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yu, Lili and Simig, Daniel and Flaherty, Colin and
                  Aghajanyan, Armen and Zettlemoyer, Luke and Lewis,
                  Mike},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f8f78f8043f35890181a824e53a57134-Paper-Conference.pdf}},
  pages =        {78808--78823},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MEGABYTE: Predicting Million-byte Sequences with
                  Multiscale Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{yu2023white,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yu, Yaodong and Buchanan, Sam and Pai, Druv and Chu,
                  Tianzhe and Wu, Ziyang and Tong, Shengbang and
                  Haeffele, Benjamin and Ma, Yi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1e118ba9ee76c20df728b42a35fb4704-Paper-Conference.pdf}},
  pages =        {9422--9457},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {White-Box Transformers via Sparse Rate Reduction},
  volume =       36,
  year =         2023
}

@inproceedings{yu2024amortizedperiod,
  address =      {Vienna, Austria},
  author =       {Yu, Hang and Liao, Cong and Liu, Ruolan and Li,
                  Jianguo and Hu, Yun and Wang, Xinzhe},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=psEswR8Jz4}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {AmortizedPeriod: Attention-based Amortized Inference
                  for Periodicity Identification},
  year =         2024
}

@inproceedings{yu2024joma,
  address =      {Vienna, Austria},
  author =       {Yu, and Tian, ong and Wang, Yiping and Zhang, Zhenyu
                  and Chen, Beidi and Du, Simon Shaolei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=LbJqRGNYCf}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {JoMA: Demystifying Multilayer Transformers via Joint
                  Dynamics of MLP and Attention},
  year =         2024
}

@inproceedings{yu2024learning,
  address =      {Vienna, Austria},
  author =       {Yu, Youn-Yeol and Choi, Jeongwhan and Cho, Woojin
                  and Lee, Kookjin and Kim, Nayong and Chang, Kiseok
                  and Woo, ChangSeung and Kim, Ilho and Lee, SeokWoo
                  and Yang, Joon-Young and Yoon, Sooyoung and Park,
                  Noseong},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=90yw2uM6J5}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Learning Flexible Body Collision Dynamics with
                  Hierarchical Contact Mesh Transformer},
  year =         2024
}

@inproceedings{yu2024treatment,
  address =      {Vienna, Austria},
  author =       {Yu, Ruoqi and Wang, Shulei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=oOGqJ6Z1sA}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Treatment Effects Estimation By Uniform Transformer},
  year =         2024
}

@inproceedings{yu2024unveiling,
  address =      {Vienna, Austria},
  author =       {Yu, Zhongzhi and Wang, Zheng and Fu, Yonggan and
                  Shi, Huihong and Shaikh, Khalid and Lin, Yingyan
                  Celine},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=DLTjFFiuUJ}},
  publisher =    {OpenReview.net},
  title =        {Unveiling and Harnessing Hidden Attention Sinks:
                  Enhancing Large Language Models without Training
                  through Attention Calibration},
  year =         2024
}

@inproceedings{yu2024vonet,
  address =      {Vienna, Austria},
  author =       {Yu, Haonan and Xu, Wei},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=qCyhvr0GG8}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {VONet: Unsupervised Video Object Learning With
                  Parallel U-Net Attention and Object-wise Sequential
                  VAE},
  year =         2024
}

@inproceedings{yuan2021hrformer,
  address =      {Virtual Event},
  author =       {Yuan, Yuhui and Fu, Rao and Huang, Lang and Lin,
                  Weihong and Zhang, Chao and Chen, Xilin and Wang,
                  Jingdong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/3bbfdde8842a5c44a0323518eec97cbe-Paper.pdf}},
  pages =        {7281--7293},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {HRFormer: High-Resolution Vision Transformer for
                  Dense Predict},
  volume =       34,
  year =         2021
}

@inproceedings{yuan2022effectiveness,
  address =      {New Orleans, Louisiana, USA},
  author =       {Yuan, Jing and Barmpoutis, Panagiotis and Stathaki,
                  Tania},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/afb8caec018d3c8f6ef8b81fa52386fe-Paper-Conference.pdf}},
  pages =        {27427--27440},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Effectiveness of Vision Transformer for Fast and
                  Accurate Single-Stage Pedestrian Detection},
  volume =       35,
  year =         2022
}

@inproceedings{yuan2023monocular,
  address =      {Kigali, Rwanda},
  author =       {Yuan, Weihao and Gu, Xiaodong and Li, Heng and Dong,
                  Zilong and Zhu, Siyu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =
                  {\url{\url{https://openreview.net/forum?id=-iADdfa4GKH}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Monocular Scene Reconstruction with 3D SDF
                  Transformers},
  year =         2023
}

@inproceedings{yue2024agile3d,
  address =      {Vienna, Austria},
  author =       {Yue, Yuanwen and Mahadevan, Sabarinath and Schult,
                  Jonas and Engelmann, Francis and Leibe, Bastian and
                  Schindler, Konrad and Kontogianni, Theodora},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=9cQtXpRshE}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {AGILE3D: Attention Guided Interactive Multi-Object
                  3D Segmentation},
  year =         2024
}

@inproceedings{yuksekogun2024attention,
  address =      {Vienna, Austria},
  author =       {Yüksekgönül, Mert and Ch, Varun and Rasekaran, and
                  Jones, Erik and Gunasekar, Suriya and Naik, Ranjita
                  and Palangi, Hamid and Kamar, Ece and Nushi,
                  Besmira},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=gfFVATffPd}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Attention Satisfies: A Constraint-Satisfaction Lens
                  on Factual Errors of Language Models},
  year =         2024
}

@inproceedings{yun2019graph,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Yun, Seongjun and Jeong, Minbyul and Kim, Raehyun
                  and Kang, Jaewoo and Kim, Hyunwoo J.},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/9d63484abb477c97640154d40595a3bb-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Graph Transformer Networks},
  volume =       32,
  year =         2019
}

@inproceedings{yun2020connections,
  address =      {Virtual Event},
  author =       {Yun, Chulhee and Chang, Yin-Wen and Bhojanapalli,
                  Srinadh and Rawat, Ankit Singh and Reddi, Sashank
                  and Kumar, Sanjiv},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/9ed27554c893b5bad850a422c3538c15-Paper.pdf}},
  pages =        {13783--13794},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {O(n) Connections are Expressive Enough: Universal
                  Approximability of Sparse Transformers},
  volume =       33,
  year =         2020
}

@inproceedings{yun2020transformers,
  address =      {Addis Ababa, Ethiopia},
  author =       {Yun, Chulhee and Bhojanapalli, Srinadh and Rawat,
                  Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=ByxRM0Ntvr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Are Transformers Universal Approximators of
                  Sequence-to-Sequence Functions?},
  year =         2020
}

@inproceedings{yun2022time,
  address =      {Baltimore, Maryland, USA},
  author =       {Yun, Sukmin and Kim, Jaehyung and Han, Dongyoon and
                  Song, Hwanjun and Ha, Jung-Woo and Shin, Jinwoo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/yun22a.html}},
  pages =        {25804--25816},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Time Is MattEr: Temporal Self-supervision for Video
                  Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{z2023kdeformer,
  address =      {Honolulu, Hawaii, USA},
  author =       {Z, Amir and ieh and Han, Insu and Daliri, Majid and
                  Karbasi, Amin},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/zandieh23a.html}}},
  pages =        {40605--40623},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {KDEformer: Accelerating Transformers via Kernel
                  Density Estimation},
  volume =       202,
  year =         2023
}

@inproceedings{zagoruyko2017paying,
  address =      {Toulon, France},
  author =       {Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle =    {5th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=Sks9_ajex}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Paying More Attention to Attention: Improving the
                  Performance of Convolutional Neural Networks via
                  Attention Transfer},
  year =         2017
}

@inproceedings{zaheer2020big,
  address =      {Virtual Event},
  author =       {Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar
                  Avinava and Ainslie, Joshua and Alberti, Chris and
                  Ontanon, Santiago and Pham, Philip and Ravula,
                  Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf}},
  pages =        {17283--17297},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Big Bird: Transformers for Longer Sequences},
  volume =       33,
  year =         2020
}

@inproceedings{zanca2017variational,
  address =      {Long Beach, California, USA},
  author =       {Zanca, Dario and Gori, Marco},
  booktitle =    {Advances in Neural Information Processing Systems 30
                  (NeurIPS)},
  editor =       {I. Guyon and U. von Luxburg and S. Bengio and
                  H. Wallach and R. Fergus and S. Vishwanathan and
                  R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2017/file/194cf6c2de8e00c05fcf16c498adc7bf-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Variational Laws of Visual Attention for Dynamic
                  Scenes},
  volume =       30,
  year =         2017
}

@inproceedings{zaratiana2024lost,
  address =      {Vienna, Austria},
  author =       {Zaratiana, Urchade},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Jr3XQRtn3B}},
  publisher =    {OpenReview.net},
  series =       {The Second Tiny Papers Track},
  title =        {Lost or Liberated? A Dive into Bidirectional
                  Transformer LMs Without Positional Encoding},
  year =         2024
}

@inproceedings{zeng2021,
  address =      {Virtual Event},
  author =       {Zeng, Yanhong and Yang, Huan and Chao, Hongyang and
                  Wang, Jianbo and Fu, Jianlong},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/b056eb1587586b71e2da9acfe4fbd19e-Paper.pdf}},
  pages =        {21125--21137},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Improving Visual Quality of Image Synthesis by A
                  Token-based Generator with Transformers},
  volume =       34,
  year =         2021
}

@inproceedings{zeng2021topological,
  address =      {Virtual Event},
  author =       {Zeng, Sebastian and Graf, Florian and Hofer,
                  Christoph and Kwitt, Roland},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/d062f3e278a1fbba2303ff5a22e8c75e-Paper.pdf}},
  pages =        {24871--24882},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Topological Attention for Time Series Forecasting},
  volume =       34,
  year =         2021
}

@inproceedings{zeng2021you,
  address =      {Virtual Event},
  author =       {Zeng, Zhanpeng and Xiong, Yunyang and Ravi, Sathya
                  N. and Acharya, Shailesh and Fung, Glenn Moo and
                  Singh, Vikas},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/zeng21a.html}},
  pages =        {12321--12332},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {You Only Sample (Almost) Once: Linear Cost
                  Self-Attention Via Bernoulli Sampling},
  volume =       139,
  year =         2021
}

@inproceedings{zeng2022multi,
  address =      {Baltimore, Maryland, USA},
  author =       {Zeng, Zhanpeng and Pal, Sourav and Kline, Jeffery
                  and Fung, Glenn Moo and Singh, Vikas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/zeng22a.html}},
  pages =        {25955--25972},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Multi Resolution Analysis (MRA) for Approximate
                  Self-Attention},
  volume =       162,
  year =         2022
}

@inproceedings{zeng2023lookupffn,
  address =      {Honolulu, Hawaii, USA},
  author =       {Zeng, Zhanpeng and Davies, Michael and Pulijala,
                  Pranav and Sankaralingam, Karthikeyan and Singh,
                  Vikas},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v202/zeng23a.html}}},
  pages =        {40707--40718},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {LookupFFN: Making Transformers Compute-lite for CPU
                  inference},
  volume =       202,
  year =         2023
}

@inproceedings{zeng2023vcc,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zeng, Zhanpeng and Hawkins, Cole and Hong, Mingyi
                  and Zhang, Aston and Pappas, Nikolaos and Singh,
                  Vikas and Zheng, Shuai},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/4054556fcaa934b0bf76da52cf4f92cb-Paper-Conference.pdf}},
  pages =        {20260--20286},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {VCC: Scaling Transformers to 128K Tokens or More by
                  Prioritizing Important Tokens},
  volume =       36,
  year =         2023
}

@inproceedings{zha2021shifted,
  address =      {Virtual Event},
  author =       {Zha, Xuefan and Zhu, Wentao and Xun, Lv and Yang,
                  Sen and Liu, Ji},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/5edc4f7dce28c711afc6265b4f99bf57-Paper.pdf}},
  pages =        {11384--11396},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Shifted Chunk Transformer for Spatio-Temporal
                  Representational Learning},
  volume =       34,
  year =         2021
}

@inproceedings{zhai2023simple,
  address =      {Kigali, Rwanda},
  author =       {Zhai, Yuwen and Hao, Jing and Gao, Liang and Li,
                  Xinyu and Gao, Yiping and Han, Shumin},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  editor =       {Maughan, Krystal and Liu, Rosanne and Burns, Thomas
                  F.},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=isodM5jTA7h}},
  publisher =    {OpenReview.net},
  series =       {The First Tiny Papers Track},
  title =        {Simple Parameter-free Self-attention Approximation},
  year =         2023
}

@inproceedings{zhai2023stabilizing,
  address =      {Honolulu, Hawaii, USA},
  author =       {Zhai, Shuangfei and Likhomanenko, Tatiana and
                  Littwin, Etai and Busbridge, Dan and Ramapuram,
                  Jason and Zhang, Yizhe and Gu, Jiatao and Susskind,
                  Joshua M.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/zhai23a.html}},
  pages =        {40770--40803},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Stabilizing Transformer Training by Preventing
                  Attention Entropy Collapse},
  volume =       202,
  year =         2023
}

@inproceedings{zhang2018attention,
  address =      {Montreal, Quebec, Canada},
  author =       {Zhang, Liang and Zhu, Guangming and Mei, Lin and
                  Shen, Peiyi and Shah, Syed Afaq Ali and Bennamoun,
                  Mohammed},
  booktitle =    {Advances in Neural Information Processing Systems 31
                  (NeurIPS)},
  editor =       {Bengio, S. and Wallach, H. and Larochelle, H. and
                  Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2018/file/287e03db1d99e0ec2edb90d079e142f3-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Attention in Convolutional LSTM for Gesture
                  Recognition},
  volume =       31,
  year =         2018
}

@inproceedings{zhang2019residual,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Yulun and Li, Kunpeng and Li, Kai and Zhong,
                  Bineng and Fu, Yun},
  booktitle =    {7th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=HkeGhoA5FX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Residual Non-local Attention Networks for Image
                  Restoration},
  year =         2019
}

@inproceedings{zhang2019self,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Zhang, Zehua and Yu, Chen and Crandall, David},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {Wallach, H. and Larochelle, H. and Beygelzimer,
                  A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/3eb65004054f5d21fca4087f5658c727-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {A Self Validation Network for Object-Level Human
                  Attention Estimation},
  volume =       32,
  year =         2019
}

@inproceedings{zhang2019selfattention,
  address =      {Long Beach, California, USA},
  author =       {Zhang, Han and Goodfellow, Ian J. and Metaxas,
                  Dimitris N. and Odena, Augustus},
  booktitle =    {Proceedings of the 36th International Conference on
                  Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month =        {June},
  note =
                  {\url{http://proceedings.mlr.press/v97/zhang19d.html}},
  pages =        {7354--7363},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Self-Attention Generative Adversarial Networks},
  volume =       97,
  year =         2019
}

@inproceedings{zhang2020accelerating,
  address =      {Virtual Event},
  author =       {Zhang, Minjia and He, Yuxiong},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {H. Larochelle and M. Ranzato and R. Hadsell and
                  M.F. Balcan and H. Lin},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf}},
  pages =        {14011--14023},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Accelerating Training of Transformer-Based Language
                  Models with Progressive Layer Dropping},
  volume =       33,
  year =         2020
}

@inproceedings{zhang2020adaptive,
  address =      {Addis Ababa, Ethiopia},
  author =       {Zhang, Kai and Zhu, Yaokang and Wang, Jun and Zhang,
                  Jie},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=BJxWx0NYPr}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Adaptive Structural Fingerprints for Graph Attention
                  Networks},
  year =         2020
}

@inproceedings{zhang2020are,
  address =      {Virtual Event},
  author =       {Zhang, Jingzhao and Karimireddy, Sai Praneeth and
                  Veit, Andreas and Kim, Seungyeon and Reddi, Sashank
                  and Kumar, Sanjiv and Sra, Suvrit},
  booktitle =    {Advances in Neural Information Processing Systems 33
                  (NeurIPS)},
  editor =       {Larochelle, H. and Ranzato, M. and Hadsell, R. and
                  Balcan, M. F. and Lin, H.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2020/file/b05b57f6add810d3b7490866d74c0053-Paper.pdf}},
  pages =        {15383--15393},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Why are Adaptive Methods Good for Attention Models?},
  volume =       33,
  year =         2020
}

@inproceedings{zhang2020hypersagnn,
  address =      {Addis Ababa, Ethiopia},
  author =       {Zhang, Ruochi and Zou, Yuesong and Ma, Jian},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=ryeHuJBtPH}},
  series =       {Conference Track Proceedings},
  title =        {Hyper-SAGNN: A Self-Attention Based Graph Neural
                  Network for Hypergraphs},
  year =         2020
}

@inproceedings{zhang2021alignment,
  address =      {Virtual Event},
  author =       {Zhang, Shujian and Fan, Xinjie and Zheng, Huangjie
                  and Tanwisuth, Korawat and Zhou, Mingyuan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P. S. and Wortman Vaughan, J.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/6fd6b030c6afec018415662d0db43f9d-Paper.pdf}},
  pages =        {13444--13457},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Alignment Attention by Matching Key and Query
                  Distributions},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2021bayesian,
  address =      {Virtual Event},
  author =       {Zhang, Shujian and Fan, Xinjie and Chen, Bo and
                  Zhou, Mingyuan},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/zhang21f.html}},
  pages =        {12413--12426},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Bayesian Attention Belief Networks},
  volume =       139,
  year =         2021
}

@inproceedings{zhang2021co,
  address =      {Virtual Event},
  author =       {Zhang, He and Ju, Fusong and Zhu, Jianwei and He,
                  Liang and Shao, Bin and Zheng, Nanning and Liu,
                  Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/770f8e448d07586afbf77bb59f698587-Paper.pdf}},
  pages =        {14252--14263},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Co-evolution Transformer for Protein Contact
                  Prediction},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2021fast,
  address =      {Virtual Event},
  author =       {Zhang, Jiong and Chang, Wei-Cheng and Yu, Hsiang-Fu
                  and Dhillon, Inderjit},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/3bbca1d243b01b47c2bf42b29a8b265c-Paper.pdf}},
  pages =        {7267--7280},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Fast Multi-Resolution Transformer Fine-Tuning for
                  Extreme Multi-label Text Classification},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2021few,
  address =      {Virtual Event},
  author =       {Zhang, Gengwei and Kang, Guoliang and Yang, Yi and
                  Wei, Yunchao},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/b8b12f949378552c21f28deff8ba8eb6-Paper.pdf}},
  pages =        {21984--21996},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Few-Shot Segmentation via Cycle-Consistent
                  Transformer},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2021learningc,
  address =      {Virtual Event},
  author =       {Zhang, Jing and Xie, Jianwen and Barnes, Nick and
                  Li, Ping},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/8289889263db4a40463e3f358bb7c7a1-Paper.pdf}},
  pages =        {15448--15463},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning Generative Vision Transformer with
                  Energy-Based Latent Space for Saliency Prediction},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2021poolingformer,
  address =      {Virtual Event},
  author =       {Zhang, Hang and Gong, Yeyun and Shen, Yelong and Li,
                  Weisheng and Lv, Jiancheng and Duan, Nan and Chen,
                  Weizhu},
  booktitle =    {Proceedings of the 38th International Conference on
                  Machine Learning (ICML)},
  editor =       {Meila, Marina and Zhang, Tong},
  month =        {July},
  note =
                  {\url{http://proceedings.mlr.press/v139/zhang21h.html}},
  pages =        {12437--12446},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Poolingformer: Long Document Modeling with Pooling
                  Attention},
  volume =       139,
  year =         2021
}

@inproceedings{zhang2021rest,
  address =      {Virtual Event},
  author =       {Zhang, Qinglong and Yang, Yu-Bin},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/82c2559140b95ccda9c6ca4a8b981f1e-Paper.pdf}},
  pages =        {15475--15485},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ResT: An Efficient Transformer for Visual
                  Recognition},
  volume =       34,
  year =         2021
}

@inproceedings{zhang2022feature,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Jian-Wei and Sun, Yifan and Yang, Yi and
                  Chen, Wei},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/2ae33575c3374050654ae7802326c81d-Paper-Conference.pdf}},
  pages =        {6575--6588},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Feature-Proxy Transformer for Few-Shot Segmentation},
  volume =       35,
  year =         2022
}

@inproceedings{zhang2022hierarchicalb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Zaixi and Liu, Qi and Hu, Qingyong and Lee,
                  Chee-Kong},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/854a9ab0f323b841955e70ca383b27d1-Paper-Conference.pdf}},
  pages =        {21171--21183},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Hierarchical Graph Transformer with Adaptive Node
                  Sampling},
  volume =       35,
  year =         2022
}

@inproceedings{zhang2022platon,
  address =      {Baltimore, Maryland, USA},
  author =       {Zhang, Qingru and Zuo, Simiao and Liang, Chen and
                  Bukharin, er and He, Pengcheng and Chen, Weizhu and
                  Zhao, Tuo},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v162/zhang22ao.html}}},
  pages =        {26809--26823},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {PLATON: Pruning Large Transformer Models with Upper
                  Confidence Bound of Weight Importance},
  volume =       162,
  year =         2022
}

@inproceedings{zhang2022relational,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Fengzhuo and Liu, Boyi and Wang, Kaixin and
                  Tan, Vincent and Yang, Zhuoran and Wang, Zhaoran},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/e8da56eb93676e8f60ed2b696e44e7dc-Paper-Conference.pdf}},
  pages =        {35825--35838},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Relational Reasoning via Set Transformers: Provable
                  Efficiency and Applications to MARL},
  volume =       35,
  year =         2022
}

@inproceedings{zhang2022segvit,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Bowen and Tian, Zhi and Tang, Quan and Chu,
                  Xiangxiang and Wei, Xiaolin and Shen, Chunhua and
                  Liu, Yifan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/20189b1aaa8edbb6d8bd6c1067ab5f3f-Paper-Conference.pdf}},
  pages =        {4971--4982},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SegViT: Semantic Segmentation with Plain Vision
                  Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{zhang2023accurate,
  address =      {Kigali, Rwanda},
  author =       {Zhang, Jiale and Zhang, Yulun and Gu, Jinjin and
                  Zhang, Yongbing and Kong, Linghe and Yuan, Xin},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=IloMJ5rqfnt}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Accurate Image Restoration with Attention
                  Retractable Transformer},
  year =         2023
}

@inproceedings{zhang2023autogt,
  address =      {Kigali, Rwanda},
  author =       {Zhang, Zizhao and Wang, Xin and Guan, Chaoyu and
                  Zhang, Ziwei and Li, Haoyang and Zhu, Wenwu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=GcM7qfl5zY}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {AutoGT: Automated Graph Transformer Architecture
                  Search},
  year =         2023
}

@inproceedings{zhang2023cab,
  address =      {Honolulu, Hawaii, USA},
  author =       {Zhang, Jun and Jiang, Shuyang and Feng, Jiangtao and
                  Zheng, Lin and Kong, Lingpeng},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/zhang23r.html}},
  pages =        {41194--41218},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {CAB: Comprehensive Attention Benchmarking on Long
                  Sequence Modeling},
  volume =       202,
  year =         2023
}

@inproceedings{zhang2023crossformer,
  address =      {Kigali, Rwanda},
  author =       {Zhang, Yunhao and Yan, Junchi},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vSVLM2j9eie}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Crossformer: Transformer Utilizing Cross-Dimension
                  Dependency for Multivariate Time Series Forecasting},
  year =         2023
}

@inproceedings{zhang2023global,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Zechuan and Sun, Li and Yang, Zongxin and
                  Chen, Ling and Yang, Yi},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1857d2e8f51ed219ca0c2663239b38e5-Paper-Conference.pdf}},
  pages =        {7818--7830},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Global-correlated 3D-decoupling Transformer for
                  Clothed Avatar Reconstruction},
  volume =       36,
  year =         2023
}

@inproceedings{zhang2023hidden,
  address =      {Kigali, Rwanda},
  author =       {Zhang, Shaolei and Feng, Yang},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=9y0HFvaAYD6}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Hidden Markov Transformer for Simultaneous Machine
                  Translation},
  year =         2023
}

@inproceedings{zhang2023hivit,
  address =      {Kigali, Rwanda},
  author =       {Zhang, Xiaosong and Tian, Yunjie and Xie, Lingxi and
                  Huang, Wei and Dai, Qi and Ye, Qixiang and Tian, Qi},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3F6I-0-57SC}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {HiViT: A Simpler and More Efficient Design of
                  Hierarchical Vision Transformer},
  year =         2023
}

@inproceedings{zhang2023mg,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Yu and Liu, Yepeng and Miao, Duoqian and
                  Zhang, Qi and Shi, Yiwei and Hu, Liang},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/daeef96627a461ec43b7567b2930cfde-Paper-Conference.pdf}},
  pages =        {69328--69347},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {MG-ViT: A Multi-Granularity Method for Compact and
                  Efficient Vision Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{zhang2023papr,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Yanshu and Peng, Shichong and Moazeni,
                  Alireza and Li, Ke},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/bda5c35eded86adaf0231748e3ce071c-Paper-Conference.pdf}},
  pages =        {60307--60328},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {PAPR: Proximity Attention Point Rendering},
  volume =       36,
  year =         2023
}

@inproceedings{zhang2023realc,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Zhejun and Liniger, Alexander and Sakaridis,
                  Christos and Yu, Fisher and Gool, Luc V},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/b37c2e26b75ee02fcabd65a2a0367136-Paper-Conference.pdf}},
  pages =        {57481--57499},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Real-Time Motion Prediction via Heterogeneous
                  Polyline Transformer with Relative Pose Encoding},
  volume =       36,
  year =         2023
}

@inproceedings{zhang2023storm,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhang, Weipu and Wang, Gang and Sun, Jian and Yuan,
                  Yetian and Huang, Gao},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/5647763d4245b23e6a1cb0a8947b38c9-Paper-Conference.pdf}},
  pages =        {27147--27166},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {STORM: Efficient Stochastic Transformer based World
                  Models for Reinforcement Learning},
  volume =       36,
  year =         2023
}

@inproceedings{zhang2023unlocking,
  address =      {Honolulu, Hawaii, USA},
  author =       {Zhang, Yan and Zhang, David W. and Lacoste-Julien,
                  Simon and Burghouts, Gertjan J. and Snoek, Cees
                  G. M.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/zhang23ba.html}},
  pages =        {41931--41951},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Unlocking Slot Attention by Changing Optimal
                  Transport Costs},
  year =         2023
}

@inproceedings{zhang2024llamaadapter,
  address =      {Vienna, Austria},
  author =       {Zhang, Renrui and Han, Jiaming and Liu, Chris and
                  Zhou, Aojun and Lu, Pan and Qiao, Yu and Li,
                  Hongsheng and Gao, Peng},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=d4UiXAHN2W}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {LLaMA-Adapter: Efficient Fine-Tuning of Large
                  Language Models with Zero-Initialized Attention},
  year =         2024
}

@inproceedings{zhang2024sequential,
  address =      {Vienna, Austria},
  author =       {Zhang, Bin and Mao, Hangyu and Li, Lijuan and Xu,
                  Zhiwei and Li, Dapeng and Zhao, Rui and Fan,
                  Guoliang},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=M3qRRkOuTN}},
  publisher =    {OpenReview.net},
  title =        {Sequential Asynchronous Action Coordination in
                  Multi-Agent Systems: A Stackelberg Decision
                  Transformer Approach},
  year =         2024
}

@inproceedings{zhang2024synergistic,
  address =      {Vienna, Austria},
  author =       {Zhang, Yuyao and Wei, Lan and Freris, Nikolaos M.},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=COO51g41Q4}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Synergistic Patch Pruning for Vision Transformer:
                  Unifying Intra- & Inter-Layer Patch Importance},
  year =         2024
}

@inproceedings{zhang2024tell,
  address =      {Vienna, Austria},
  author =       {Zhang, Qingru and Singh, An and Liu, Liyuan and Liu,
                  Xiaodong and Yu, Bin and Gao, Jianfeng and Zhao,
                  Tuo},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=xZDWO0oejD}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tell Your Model Where to Attend: Post-hoc Attention
                  Steering for LLMs},
  year =         2024
}

@inproceedings{zhang2024towardsa,
  address =      {Vienna, Austria},
  author =       {Zhang, Jiaqi and Jennings, Joel and Hilmkil, Agrin
                  and Pawlowski, Nick and Zhang, Cheng and Ma, Chao},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=cFDaYtZR4u}},
  publisher =    {OpenReview.net},
  title =        {Towards Causal Foundation Model: on Duality between
                  Optimal Balancing and Attention},
  year =         2024
}

@article{zhang2024trained,
  author =       {Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter
                  L.},
  journal =      {Journal of Machine Learning Research},
  note =         {\url{http://jmlr.org/papers/v25/23-1042.html}},
  number =       49,
  pages =        {1--55},
  title =        {Trained Transformers Learn Linear Models In-Context},
  volume =       25,
  year =         2024
}

@inproceedings{zhang2024xformer,
  address =      {Vienna, Austria},
  author =       {Zhang, Jiale and Zhang, Yulun and Gu, Jinjin and
                  Dong, Jiahua and Kong, Linghe and Yang, Xiaokang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=vXrIQLzIKY}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Xformer: Hybrid X-Shaped Transformer for Image
                  Denoising},
  year =         2024
}

@inproceedings{zhao2020transformerxh,
  address =      {Addis Ababa, Ethiopia},
  author =       {Zhao, Chen and Xiong, Chenyan and Rosset, Corby and
                  Song, Xia and Bennett, Paul N. and Tiwary, Saurabh},
  booktitle =    {8th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =         {\url{https://openreview.net/forum?id=r1eIiCNYwS}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-XH: Multi-Evidence Reasoning with eXtra
                  Hop Attention},
  year =         2020
}

@inproceedings{zhao2021improved,
  address =      {Virtual Event},
  author =       {Zhao, Long and Zhang, Zizhao and Chen, Ting and
                  Metaxas, Dimitris and Zhang, Han},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/98dce83da57b0395e163467c9dae521b-Paper.pdf}},
  pages =        {18367--18380},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Improved Transformer for High-Resolution GANs},
  volume =       34,
  year =         2021
}

@inproceedings{zhao2021proto,
  address =      {Virtual Event},
  author =       {Zhao, Zelin and Samel, Karan and Chen, Binghong and
                  Song, Lee},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and
                  Liang, P.S. and Vaughan, J. W.},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/8d34201a5b85900908db6cae92723617-Paper.pdf}},
  pages =        {17021--17036},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {ProTo: Program-Guided Transformer for Program-Guided
                  Tasks},
  volume =       34,
  year =         2021
}

@inproceedings{zhao2022alignment,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhao, Yizhou and Li, Zhenyang and Guo, Xun and Lu,
                  Yan},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/5820ad65b1c27411417ae8b59433e580-Paper-Conference.pdf}},
  pages =        {13627--13639},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Alignment-guided Temporal Attention for Video Action
                  Recognition},
  volume =       35,
  year =         2022
}

@inproceedings{zhao2023are,
  address =      {Kigali, Rwanda},
  author =       {Zhao, Haiteng and Ma, Shuming and Zhang, Dongdong
                  and Deng, Zhi-Hong and Wei, Furu},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=uagC-X9XMi8}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Are More Layers Beneficial to Graph Transformers?},
  year =         2023
}

@inproceedings{zhao2023mixpro,
  address =      {Kigali, Rwanda},
  author =       {Zhao, Qihao and Huang, Yangyu and Hu, Wei and Zhang,
                  Fan and Liu, Jun},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=dRjWsd3gwsm}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {MixPro: Data Augmentation with MaskMix and
                  Progressive Attention Labeling for Vision
                  Transformer},
  year =         2023
}

@inproceedings{zhao2024defense,
  address =      {Vienna, Austria},
  author =       {Zhao, Xingyi and Xu, Depeng and Yuan, Shuhan},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=1SiEfsCecd}},
  publisher =    {OpenReview.net},
  title =        {Defense against Backdoor Attack on Pre-trained
                  Language Models via Head Pruning and Attention
                  Normalization},
  year =         2024
}

@inproceedings{zhao2024gradientbased,
  address =      {Vienna, Austria},
  author =       {Zhao, Chenyang and Wang, Kun and Zeng, Xingyu and
                  Zhao, Rui and Chan, Antoni B.},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=WT4X3QYopC}},
  publisher =    {OpenReview.net},
  title =        {Gradient-based Visual Explanation for
                  Transformer-based CLIP},
  year =         2024
}

@inproceedings{zhao2024pinnsformer,
  address =      {Vienna, Austria},
  author =       {Zhao, Leo Zhiyuan and Ding, Xueying and Prakash,
                  B. Aditya},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=DO2WFXU1Be}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {PINNsFormer: A Transformer-Based Framework for
                  Physics-Informed Neural Networks},
  year =         2024
}

@inproceedings{zhao2024tuning,
  address =      {Vienna, Austria},
  author =       {Zhao, Bingchen and Tu, Haoqin and Wei, Chen and Mei,
                  Jieru and Xie, Cihang},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=YR3ETaElNK}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Tuning LayerNorm in Attention: Towards Efficient
                  Multi-Modal LLM Finetuning},
  year =         2024
}

@inproceedings{zheng2021delayed,
  address =      {Virtual Event},
  author =       {Zheng, Wenqing and Guo, Qiangqiang and Yang, Hao and
                  Wang, Peihao and Wang, Zhangyang},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/654516d1b4df6917094de807156adc14-Paper.pdf}},
  pages =        {12141--12153},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Delayed Propagation Transformer: A Universal
                  Computation Engine towards Practical Control in
                  Cyber-Physical Systems},
  volume =       34,
  year =         2021
}

@inproceedings{zheng2022dance,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zheng, Hao and Lin, Hui and Zhao, Rong and Shi,
                  Luping},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/cba76ef96c4cd625631ab4d33285b045-Paper-Conference.pdf}},
  pages =        {31430--31443},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Dance of SNN and ANN: Solving binding problem by
                  combining spike timing and reconstructive attention},
  volume =       35,
  year =         2022
}

@inproceedings{zheng2022linear,
  address =      {Baltimore, Maryland, USA},
  author =       {Zheng, Lin and Wang, Chong and Kong, Lingpeng},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v162/zheng22b.html}}},
  pages =        {27011--27041},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Linear Complexity Randomized Self-attention
                  Mechanism},
  volume =       162,
  year =         2022
}

@inproceedings{zheng2022online,
  address =      {Baltimore, Maryland, USA},
  author =       {Zheng, Qinqing and Zhang, Amy and Grover, Aditya},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v162/zheng22c.html}}},
  pages =        {27042--27059},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Online Decision Transformer},
  volume =       162,
  year =         2022
}

@inproceedings{zheng2022ripple,
  address =      {Baltimore, Maryland, USA},
  author =       {Zheng, Lin and Pan, Huijie and Kong, Lingpeng},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{\url{https://proceedings.mlr.press/v162/zheng22a.html}}},
  pages =        {26993--27010},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Ripple Attention for Visual Perception with
                  Sub-quadratic Complexity},
  volume =       162,
  year =         2022
}

@inproceedings{zheng2022savit,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zheng, Chuanyang and Li, Zheyang and Zhang, Kai and
                  Yang, Zhi and Tan, Wenming and Xiao, Jun and Ren, Ye
                  and Pu, Shiliang},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3b11c5cc84b6da2838db348b37dbd1a2-Paper-Conference.pdf}},
  pages =        {9010--9023},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {SAViT: Structure-Aware Vision Transformer Pruning
                  via Collaborative Optimization},
  volume =       35,
  year =         2022
}

@inproceedings{zheng2023efficient,
  address =      {Kigali, Rwanda},
  author =       {Zheng, Lin and Yuan, Jianbo and Wang, Chong and
                  Kong, Lingpeng},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=G-uNfHKrj46}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Efficient Attention via Control Variates},
  year =         2023
}

@inproceedings{zhong2024erq,
  address =      {Vienna, Austria},
  author =       {Zhong, Yunshan and Hu, Jiawei and Huang, You and
                  Zhang, Yuxin and Ji, Rongrong},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=jKUWlgra9b}},
  publisher =    {OpenReview.net},
  title =        {ERQ: Error Reduction for Post-Training Quantization
                  of Vision Transformers},
  year =         2024
}

@inproceedings{zhou2021hopper,
  address =      {Virtual Event, Austria},
  author =       {Zhou, Honglu and Kadav, Asim and Lai, Farley and
                  Alex, and Niculescu-Mizil, Ru and Min, Martin
                  Renqiang and Kapadia, Mubbasir and Graf, Hans Peter},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=MaZFq7bJif7}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Hopper: Multi-hop Transformer for Spatiotemporal
                  Reasoning},
  year =         2021
}

@inproceedings{zhou2021pretraining,
  address =      {Virtual Event, Austria},
  author =       {Zhou, Wangchunshu and Lee, Dong-Ho and Selvam, Ravi
                  Kiran and Lee, Seyeon and Ren, Xiang},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=3k20LAiHYL2}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Pre-training Text-to-Text Transformers for
                  Concept-centric Common Sense},
  year =         2021
}

@inproceedings{zhou2022fedformer,
  address =      {Baltimore, Maryland, USA},
  author =       {Zhou, Tian and Ma, Ziqing and Wen, Qingsong and
                  Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/zhou22g.html}},
  pages =        {27268--27286},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {FEDformer: Frequency Enhanced Decomposed Transformer
                  for Long-term Series Forecasting},
  volume =       162,
  year =         2022
}

@inproceedings{zhou2022jump,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhou, Haoyi and Xiao, Siyang and Zhang, Shanghang
                  and Peng, Jieqi and Zhang, Shuai and Li, Jianxin},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {Koyejo, S. and Mohamed, S. and Agarwal, A. and
                  Belgrave, D. and Cho, K. and Oh, A.},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/71ec377d5df1fc61ee7770857820519b-Paper-Conference.pdf}},
  pages =        {17899--17910},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Jump Self-attention: Capturing High-order Statistics
                  in Transformers},
  volume =       35,
  year =         2022
}

@inproceedings{zhou2022towardsb,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhou, Shangchen and Chan, Kelvin and Li, Chongyi and
                  Loy, Chen Change},
  booktitle =    {Advances in Neural Information Processing Systems 35
                  (NeurIPS)},
  editor =       {S. Koyejo and S. Mohamed and A. Agarwal and
                  D. Belgrave and K. Cho and A. Oh},
  month =        {November},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2022/file/c573258c38d0a3919d8c1364053c45df-Paper-Conference.pdf}},
  pages =        {30599--30611},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Towards Robust Blind Face Restoration with Codebook
                  Lookup Transformer},
  volume =       35,
  year =         2022
}

@inproceedings{zhou2022understanding,
  address =      {Baltimore, Maryland, USA},
  author =       {Zhou, Daquan and Yu, Zhiding and Xie, Enze and Xiao,
                  Chaowei and An, Animashree and Kumar, and Feng,
                  Jiashi and Álvarez, José M.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Chaudhuri, Kamalika and Jegelka, Stefanie and Song,
                  Le and Szepesvári, Csaba and Niu, Gang and Sabato,
                  Sivan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v162/zhou22m.html}},
  pages =        {27378--27394},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Understanding The Robustness in Vision Transformers},
  volume =       162,
  year =         2022
}

@inproceedings{zhou2023learning,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhou, Bohan and Li, Ke and Jiang, Jiechuan and Lu,
                  Zongqing},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/bb203e938836544655996d1bb94a0fd7-Paper-Conference.pdf}},
  pages =        {59585--59605},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Learning from Visual Observation via Offline
                  Pretrained State-to-Go Transformer},
  volume =       36,
  year =         2023
}

@inproceedings{zhou2023neural,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhou, Allan and Yang, Kaien and Jiang, Yiding and
                  Burns, Kaylee and Xu, Winnie and Sokota, Samuel and
                  Kolter, J. Zico and Finn, Chelsea},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/f4757db82a02eea015670ecca605d5cc-Paper-Conference.pdf}},
  pages =        {77485--77502},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Neural Functional Transformers},
  volume =       36,
  year =         2023
}

@inproceedings{zhou2023spikformer,
  address =      {Kigali, Rwanda},
  author =       {Zhou, Zhaokun and Zhu, Yuesheng and He, Chao and
                  Wang, Yaowei and Yan, Shuicheng and Tian, Yonghong
                  and Yuan, Li},
  booktitle =    {11th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=frE4fUwz_h}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Spikformer: When Spiking Neural Network Meets
                  Transformer},
  year =         2023
}

@inproceedings{zhou2024algorithms,
  address =      {Vienna, Austria},
  author =       {Zhou, Hattie and Bradley, Arwen and Littwin, Etai
                  and Razin, Noam and Saremi, Omid and Susskind,
                  Joshua M. and Bengio, Samy and Nakkiran, Preetum},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=AssIuHnmHX}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {What Algorithms can Transformers Learn? A Study in
                  Length Generalization},
  year =         2024
}

@inproceedings{zhou2024multimax,
  address =      {Vienna, Austria},
  author =       {Zhou, Yuxuan and Fritz, Mario and Keuper, Margret},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =
                  {\url{\url{https://openreview.net/forum?id=IC9UZ8lm25}}},
  publisher =    {OpenReview.net},
  title =        {MultiMax: Sparse and Multi-Modal Attention Learning},
  year =         2024
}

@inproceedings{zhu2019semantic,
  address =      {Vancouver, British Columbia, Canada},
  author =       {Zhu, Yizhe and Xie, Jianwen and Tang, Zhiqiang and
                  Peng, Xi and Elgammal, Ahmed},
  booktitle =    {Advances in Neural Information Processing Systems 32
                  (NeurIPS)},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d'Alché-Buc and E. Fox and R. Garnett},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2019/file/172fd0d638b3282151bd8f3d652cb640-Paper.pdf}},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Semantic-Guided Multi-Attention Localization for
                  Zero-Shot Learning},
  volume =       32,
  year =         2019
}

@inproceedings{zhu2021deformable,
  address =      {Virtual Event, Austria},
  author =       {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin
                  and Wang, Xiaogang and Dai, Jifeng},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=gZ9hCDWe6ke}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Deformable DETR: Deformable Transformers for
                  End-to-End Object Detection},
  year =         2021
}

@inproceedings{zhu2021iot,
  address =      {Virtual Event, Austria},
  author =       {Zhu, Jinhua and Wu, Lijun and Xia, Yingce and Xie,
                  Shufang and Qin, Tao and Zhou, Wengang and Li,
                  Houqiang and Liu, Tie-Yan},
  booktitle =    {9th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=ipUPfYxWZvM}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {IOT: Instance-wise Layer Reordering for Transformer
                  Structures},
  year =         2021
}

@inproceedings{zhu2021long,
  address =      {Virtual Event},
  author =       {Zhu, Chen and Ping, Wei and Xiao, Chaowei and
                  Shoeybi, Mohammad and Goldstein, Tom and Anandkumar,
                  Anima and Catanzaro, Bryan},
  booktitle =    {Advances in Neural Information Processing Systems 34
                  (NeurIPS)},
  editor =       {M. Ranzato and A. Beygelzimer and Y. Dauphin and
                  P.S. Liang and J. Wortman Vaughan},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2021/file/9425be43ba92c2b4454ca7bf602efad8-Paper.pdf}},
  pages =        {17723--17736},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Long-Short Transformer: Efficient Transformers for
                  Language and Vision},
  volume =       34,
  year =         2021
}

@inproceedings{zhu2022transformerbased,
  address =      {Virtual Event},
  author =       {Zhu, Yinhao and Yang, Yang and Cohen, Taco},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=IDwN6xjHnK8}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Transformer-based Transform Coding},
  year =         2022
}

@inproceedings{zhu2023polyhedron,
  address =      {New Orleans, Louisiana, USA},
  author =       {Zhu, Tan and Dou, Fei and Wang, Xinyu and Lu, Jin
                  and Bi, Jinbo},
  booktitle =    {Advances in Neural Information Processing Systems 36
                  (NeurIPS)},
  editor =       {A. Oh and T. Naumann and A. Globerson and K. Saenko
                  and M. Hardt and S. Levine},
  month =        {December},
  note =
                  {\url{https://proceedings.neurips.cc/paper_files/paper/2023/file/1d83ad88759cef8192451543e5d59bf6-Paper-Conference.pdf}},
  pages =        {9213--9225},
  publisher =    {Curran Associates, Inc.},
  series =       {Conference Track Proceedings},
  title =        {Polyhedron Attention Module: Learning Adaptive-order
                  Interactions},
  volume =       36,
  year =         2023
}

@inproceedings{zhu2023xtab,
  address =      {Honolulu, Hawaii, USA},
  author =       {Zhu, Bingzhao and Shi, Xingjian and Erickson, Nick
                  and Li, Mu and Karypis, George and Shoaran, Mahsa},
  booktitle =    {International Conference on Machine Learning (ICML)},
  editor =       {Krause, Andreas and Brunskill, Emma and Cho,
                  Kyunghyun and Engelhardt, Barbara and Sabato, Sivan
                  and Scarlett, Jonathan},
  month =        {July},
  note =
                  {\url{https://proceedings.mlr.press/v202/zhu23k.html}},
  pages =        {43181--43204},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {XTab: Cross-table Pretraining for Tabular
                  Transformers},
  year =         2023
}

@inproceedings{zhu2024enhancing,
  address =      {Vienna, Austria},
  author =       {Zhu, Zhiyu and Wang, Xinyi and Jin, Zhibo and Zhang,
                  Jiayu and Chen, Huaming},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=1BuWv9poWz}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Enhancing Transferable Adversarial Attacks on Vision
                  Transformers through Gradient Normalization Scaling
                  and High-Frequency Adaptation},
  year =         2024
}

@inproceedings{zhuge2024towards,
  address =      {Vienna, Austria},
  author =       {Zhuge, Zhengyang and Wang, Peisong and Yao, Xingting
                  and Cheng, Jian},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=yL6hljtjW4}},
  publisher =    {OpenReview.net},
  title =        {Towards Efficient Spiking Transformer: a Token
                  Sparsification Framework for Training and Inference
                  Acceleration},
  year =         2024
}

@inproceedings{zimerman2024converting,
  address =      {Vienna, Austria},
  author =       {Zimerman, Itamar and Baruch, Moran and Drucker, Nir
                  and Ezov, Gilad and Soceanu, Omri and Wolf, Lior},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=9HPoJ6ulgV}},
  publisher =    {OpenReview.net},
  title =        {Converting Transformers to Polynomial Form for
                  Secure Inference Over Homomorphic Encryption},
  year =         2024
}

@inproceedings{zimerman2024viewing,
  address =      {Vienna, Austria},
  author =       {Zimerman, Itamar and Wolf, Lior},
  booktitle =    {Forty-first International Conference on Machine
                  Learning (ICML)},
  month =        {July},
  note =         {\url{https://openreview.net/forum?id=nOyj26YdIQ}},
  publisher =    {OpenReview.net},
  title =        {Viewing Transformers Through the Lens of Long
                  Convolutions Layers},
  year =         2024
}

@inproceedings{ziv2024masked,
  address =      {Vienna, Austria},
  author =       {Ziv, Alon and Gat, Itai and Lan, Gaël Le and Remez,
                  Tal and Kreuk, Felix and Copet, Jade and Alex and
                  Défossez, re and Synnaeve, Gabriel and Adi, Yossi},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=Ny8NiVfi95}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Masked Audio Generation using a Single
                  Non-Autoregressive Transformer},
  year =         2024
}

@inproceedings{zou2024multilevel,
  address =      {Vienna, Austria},
  author =       {Zou, Longwei and Zhang, Han and Deng, Yangdong},
  booktitle =    {12th International Conference on Learning
                  Representations (ICLR)},
  month =        {May},
  note =         {\url{https://openreview.net/forum?id=BI1N3lTWtn}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {A Multi-Level Framework for Accelerating Training
                  Transformer Models},
  year =         2024
}

@inproceedings{zuo2020transformer,
  address =      {Virtual Event},
  author =       {Zuo, Simiao and Jiang, Haoming and Li, Zichong and
                  Zhao, Tuo and Zha, Hongyuan},
  booktitle =    {Proceedings of the 37th International Conference on
                  Machine Learning (ICML)},
  month =        {July},
  note =         {\url{http://proceedings.mlr.press/v119/zuo20a.html}},
  pages =        {11692--11702},
  publisher =    {PMLR},
  series =       {Proceedings of Machine Learning Research},
  title =        {Transformer Hawkes Process},
  volume =       119,
  year =         2020
}

@inproceedings{zuo2022taming,
  address =      {Virtual Event},
  author =       {Zuo, Simiao and Liu, Xiaodong and Jiao, Jian and
                  Kim, Young Jin and Hassan, Hany and Zhang, Ruofei
                  and Gao, Jianfeng and Zhao, Tuo},
  booktitle =    {10th International Conference on Learning
                  Representations (ICLR)},
  month =        {April},
  note =
                  {\url{\url{https://openreview.net/forum?id=B72HXs80q4}}},
  publisher =    {OpenReview.net},
  series =       {Conference Track Proceedings},
  title =        {Taming Sparsely Activated Transformer with
                  Stochastic Experts},
  year =         2022
}
